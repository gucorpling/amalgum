 1. IntroductionWith the development of technology and social progress, industrialization and automation have occupied increasingly important positions in industrial production. Safety production is one of the key principles of industrial production, and fault diagnosis is an effective means to ensure safe production. It is important to classify various faults in a timely and accurate manner during the fault diagnosis process.Data-driven fault diagnosis methods are often used for fault classification. They use artificial intelligence technology to build a model from the historical data for fault classification [1]. There are many reported results on the specific content of data-driven fault diagnosis methods [2,3,4].However, any fault classification method has its limitations and often cannot classify all faults correctly. Hence, a concept that integrates various classification methods to classify the same object has gradually been accepted [5,6]. Based on an effective ensemble method, the decision fusion system often provides more accurate classification results.The performance of an ensemble classification system is mainly affected by two factors, namely the diversity of the base classifiers and the decision fusion strategy. The latter is studied in this paper. The role of the decision fusion strategy is to combine the decisions of various base classifiers to enhance the final classification results and reduce decision conflicts. The effectiveness of the decision fusion theory had been verified in many studies [7,8,9]. Basic decision fusion strategies include the voting method, the weighted voting method, Bayesian theory, and the Dempster–Shafer evidence theory [10,11,12,13]. Of these, the voting method is a simple and useful fusion strategy, but it treats all base classifiers equally, which is inappropriate.In fact, the performance of each base classifier varies under different conditions. It is necessary to evaluate the performance of the base classifier and determine the weight or priority of the base classifiers according to specific conditions. This has rarely been studied in the field of fault classification [14,15]. In addition, there are many performance evaluation indicators for the base classifier, and a single performance evaluation indicator cannot comprehensively measure the performance of the base classifier. In view of this, Ge et al. [14,15] pointed out that multiple evaluation indicators can provide more detailed information about the base classifiers, which is more conducive to the determination of the weights for the base classifiers. Additionally, they proposed to determine the weight of the base classifier by the analytic hierarchy process (AHP) under multiple evaluation indicators in [14,15].The AHP can be combined with expert experience to generate the subjective weights of the base classifiers. However, it is unreliable to consider only subjective weights in a decision system. When the subjective tendency of the expert is serious, mistakes will inevitably occur. On the contrary, the objective weight relies entirely on the data and is not affected by personal preferences. However, counter-intuitive results may appear if the weights are determined only from the data. Therefore, a natural idea is to combine the subjective weight with the objective weight to obtain the combined weight (CW).In this paper, a new decision fusion system based on the CW and an improved voting method is proposed. In the proposed decision fusion system, the CW, which integrates the subjective and objective weights is determined using the AHP and EW-TOPSIS (entropy weight-technique for order performance by similarity to ideal solution). In addition, a new improved voting method is proposed based on the concept of validity, which is used to distinguish the performance differences of different fault classification methods for different faults. Thus, the rigid 0–1 rule of the voting method can be avoided, and the advantages of various base classifiers for different faults can be maximized. The proposed decision fusion system is illustrated in the Tennessee Eastman (TE) benchmark process.The rest of the paper is organized as follows. Section 2 reviews the AHP and EW-TOPSIS. Section 3 describes the proposed method. In Section 4, the performance of the proposed decision fusion system is verified by the TE process. Finally, conclusions are made. 2. Methods 2.1. The AHPThe AHP was originally introduced by Saaty to determine the best scheme based on experience [16]. It can concretize the subjective judgments and tendencies of experts and express them in numerical form to determine the priority levels of alternatives. There are usually three levels for the simplest AHP, namely the topmost target layer, the middle standard layer, and the bottom-most alternative layer. The middle standard layer can be further subdivided, and substandard layers can be established to obtain a more comprehensive and detailed judgment indicator for some more complex or accurate problems. Assuming there are n indicators and m alternatives, the specific steps of the AHP are described as follows [17,18,19,20,21]:Step 1: Determine the hierarchy structure according to actual problems and needs.Step 2: Construct the judgment matrix according to expert experience.





A

=

[






a

11





⋯




a

1
n







⋮


⋱


⋮






a

n
1





⋯




a

n
n







]





(1)


where


a

i
j



 represents the importance of indicator i compared to indicator j;


a

j
i


=

1
/


a

i
j





. The judgment matrix is an expression of the relative importance of each indicator compared to the target layer or each alternative to a standard layer and is usually measured by the importance scale shown in Table 1.Step 3: Calculate the hierarchical weight vector and perform a consistency check.The weight vector is calculated as follows:




W
i

=




W
i

′


/



∑

i
=
1

n



W
i



′





,




(2)







W
i

′

=




∏

j
=
1

n



a

i
j





n


,
 

i
=
1
,
⋯
,
n
,




(3)


where


W
i


 is the weight of the indicator and



w


d


=



(


W
1

,

W
2

,
⋯
,

W
n


)


T


 is the weight vector of the indicators.Calculate the largest eigenvalue


λ

max



 of the judgment matrix:




λ

max


=

1
n



∑

i
=
1

n







(


A



w


d



)


i




W
i





.




(4)

The consistency check is performed as follows:



C
R
=


C
I

/

R
I


,




(5)


where

C
I
=



λ

max


−
1


n
−
1



,

R
I

 is given in Table 2, and n in Table 2 represents the dimension of the judgment matrix. If

C
R
<
0.1

, the consistency check is satisfied. Otherwise, the judgment matrix should be reconstructed.Step 4: Similarly, the judgment matrix of m alternatives relative to each indicator can be constructed as



A

1


,



A

2


,
⋯
,



A

n


, in turn, where



A

i

,
 
i
=
1
,
⋯
,
n

 is an

m
×
m

 matrix. Additionally, the weight vector is recorded as



w

1

,


w

2

,
⋯
,


w

n


. Thus, the overall weight vector



w



a
h
p




 is:





w



a
h
p



=

(



w

1

,


w

2

,
⋯
,


w

n


)

×


w


d


=



(


w

a
h

p
1



,

w

a
h

p
2



,
⋯
,

w

a
h

p
m




)


T

.




(6)

 2.2. EW-TOPSISThe AHP is an important method that is used to determine the experts’ subjective weights. In contrast, the entropy weight (EW) is not affected by personal preferences and relies entirely on the data. It is an important method that is used to obtain objective weights. The idea of EW stems from information entropy. The smaller the entropy value is, the greater the EW is [22].The technique for order performance by similarity to ideal solution (TOPSIS) is an effective multi-criteria decision-making method, which is often used to solve problems such as alternative ranking and optimal scheme determination [23]. It measures the pros and cons of the scheme by the distance between the scheme and the positive and negative ideal solutions. That is, if the scheme is closest to the positive ideal solution and the farthest from the negative ideal solution, it is considered to be the preferred scheme [24,25].Studies on either EW or TOPSIS are common, but most of them are used to determine the weights of the evaluation indicators and make the best ranking. The combination of EW and TOPSIS is rarely used to determine the weights of the alternatives.The calculation of EW-TOPSIS has been introduced in many studies [26,27,28,29,30] and is summarized as follows:Step 1: Assume that there are m alternatives and n indicators, and the matrix

X

 is:




X

=

[






x

11





⋯




x

1
n







⋮


⋱


⋮






x

m
1





⋯




x

m
n







]

,




(7)


where


x

i
j



 indicates the value of indicator j of the alternative i.Step 2: To avoid analysis errors caused by data forms and orders of magnitude, normalization is needed. Here, the range method is used for normalization.For the benefit indicator (the larger the value of the indicator, the better):




y

i
j


=



x

i
j


−


min

i


(


x

i
j



)





max

i


(


x

i
j



)

−


min

i


(


x

i
j



)



.




(8)

For the cost indicator (the smaller the value of the indicator, the better):




y

i
j


=




max

i


(


x

i
j



)

−

x

i
j






max

i


(


x

i
j



)

−


min

i


(


x

i
j



)



,




(9)


where


y

i
j



 is the normalized value.Step 3: Determine the information entropy and EW of each indicator.The information entropy of each indicator is defined as follows:




H
j

=
−

1

ln
m




∑

i
=
1

m



f

i
j


ln

f

i
j




,
 
j
=
1
,
⋯
,
n
,




(10)


where


f

i
j


=



y

i
j



/



∑

i
=
1

m



y

i
j







 and if


f

i
j


=
0

 then


f

i
j


ln

f

i
j


=
0

.According to the information entropy of indicators, the EW of each indicator can be obtained as follows:




w
j



′

=


1
−

H
j



n
−


∑

j
=
1

n



H
j






,
 
j
=

1
,
…
,
n
,




(11)


where

0
≤

w
j



′

≤
1

,



∑

j
=
1

n



w
j



′



=
1

.Step 4: Construct decision matrix

S

:




S

=

[






w
1



′


y

11





⋯




w
n



′


y

1
n







⋮


⋱


⋮






w
1



′


y

m
1





⋯




w
n



′


y

m
n







]

.




(12)

Step 5: Determine the positive ideal solution and the negative ideal solution



S


+


,


S


−



:





S


+


=

{


s
1
+

,

s
2
+

,
⋯
,

s
n
+


}

=

{


(



max

i


s

i
j


|
j
∈

I
′


)

,

(



min

i


s

i
j


|
j
∈

I
″


)


}

,




(13)







S


−


=

{


s
1
−

,

s
2
−

,
⋯
,

s
n
−


}

=

{


(



min

i


s

i
j


|
j
∈

I
′


)

,

(



max

i


s

i
j


|
j
∈

I
″


)


}

,




(14)


where


s

i
j


=

w
j



′


y

i
j



,

I
′

 is the benefit indicator, and

I
″

 is the cost indicator.Step 6: Calculate the Euclidean distance between the alternatives and the positive and negative ideal solutions


D
i
+

,

D
i
−


:




D
i
+

=




∑

j
=
1

n





(


s

i
j


−

s
j
+


)


2





,
 
i
=
1
,
⋯
,
m
,




(15)






D
i
−

=




∑

j
=
1

n





(


s

i
j


−

s
j
−


)


2





,
 
i
=
1
,
⋯
,
m
.




(16)

Step 7: Calculate the relative closeness between the alternatives and the ideal solution


C
i
+


:




C
i
+

=



D
i
−




D
i
+

+

D
i
−



,
 
i
=
1
,
⋯
,
m
,




(17)


where

0
<

C
i
+

<
1

, and the greater the value of


C
i
+


 is, the better the alternative is.Step 8: Normalize the relative closeness to determine the objective weight of the alternative:




w

e

t
i



=



C
i
+


/



∑

i
=
1

m



C
i
+





,
 
i
=
1
,
⋯
,
m
,




(18)


where


w

e

t
i




 is the objective weight of the alternative. The objective weight vectors for all alternatives are as follows:





w



e
t



=



(


w

e

t
1



,

w

e

t
2



,
⋯
,

w

e

t
m




)


T

.




(19)

Since AHP and EW-TOPSIS are used for the weight determination of the base classifier k, the classifier is used instead of the alternative, so the combined weights based on AHP and EW-TOPSIS are expressed as follows:




C
W

=
0

.
5



w



a
h
p



+
0

.
5



w



e
t



=



(

c

w
1

,
c

w
2

,
⋯
,
c

w
c


)


T

,




(20)


where c is the number of classifiers. 3. The Proposed MethodThe ensemble method integrates various fault classification methods to improve the fault classification capability. A basic ensemble method includes the selection of base classifiers and the determination of fusion strategies. In this study, six basic classifiers were selected: linear discriminant analysis (LDA), K-nearest neighbor (KNN), Bayesian classifier (BN), random forest (RF), support vector machine (SVM) and the BP neural network (BP). Decision fusion is achieved by the CW and improved voting methods.The specific framework of our proposed fusion system is shown in Figure 1. 3.1. Selection of Base ClassifiersConsidering the requirement of diversity for the ensemble classification system, we selected six representative classifiers from the supervised category. Among them, LDA is a linear classifier, which is suitable for the classification of linear separable problems. KNN is a simple classifier, which determines the classification result by comparing the distance between the sample to be classified and all training samples. BN is one of the commonly used classifiers. It has an advantage in terms of classification speed and is suitable for applications with small-scale samples and missing values. RF is an integrated classifier based on the decision tree and has the advantage of a low computation cost. It can deal with high-dimensional samples and sample imbalance. The typical advantage of SVM is that it can use small samples and is also good for nonlinear problems. The BP neural network is a multi-layer feed-forward neural network with error backpropagation, which is advantageous for dealing with nonlinear problems. 3.2. Classifier Performance EvaluationTo measure the classification performance, four evaluation indicators were used [14]:



A
c
c
u
r
a
c
y

(

A
C
C

)

=


n
u
m
b
e
r
 
o
f
 
f
a
u
l
t
 
s
a
m
p
l
e
s
 
c
o
r
r
e
c
t
l
y
 
c
l
a
s
s
i
f
i
e
d


s
a
m
p
l
e
 
n
u
m
b
e
r
 
o
f
 
a
l
l
 
f
a
u
l
t
 
s
a
m
p
l
e
s


,




(21)





M
i
s
s
i
n
g
R
a
t
e

(

M
R

)

=


n
u
m
b
e
r
 
o
f
 
f
a
u
l
t
 
s
a
m
p
l
e
s
 
c
l
a
s
s
i
f
i
e
d
 
a
s
 
n
o
r
m
a
l
 
s
a
m
p
l
e
s


s
a
m
p
l
e
 
n
u
m
b
e
r
 
o
f
 
a
l
l
 
f
a
u
l
t
 
s
a
m
p
l
e
s


,




(22)





P
r
e
c
i
s
i
o
n

(
P
)

=

1
t



∑

j
=
1

t




n
u
m
b
e
r
 
o
f
 
s
a
m
p
l
e
s
 
c
l
a
s
s
i
f
i
e
d
 
a
s
 
f
a
u
l
t
 
j
 
a
n
d
 
a
c
t
u
a
l
l
y
 
f
a
u
l
t
 
j


t
h
e
 
n
u
m
b
e
r
 
o
f
 
s
a
m
p
l
e
s
 
c
l
a
s
s
i
f
i
e
d
 
a
s
 
f
a
u
l
t
 
j




,




(23)


where t is the number of fault classes.




F
−
v
a
l
u
e

(
F
)

=


2
×
P
×
R


P
+
R


,




(24)


where P is the precision and R is the recall rate.The information used to calculate these performance evaluation indicators is given by the confusion matrix. The confusion matrix is also a way to measure the classifier’s performance, and its form is as follows [14]:




C



M


k


=

[






N

11

k




⋯




N

1
t

k






⋮


⋱


⋮






N

t
1

k




⋯




N

t
t

k






]

,
 
k
=
1
,
2
,
⋯
,
c
,




(25)


where


N

i
j

k


 represents the percentage of cases where fault i classified as fault j by classifier k. c is the number of base classifiers, and t is the number of fault classes. 3.3. Formatting of Mathematical ComponentsVoting is a simple and practical decision-making fusion strategy, but its fusion results are often unreasonable because it ignores the performance differences of various methods. In the process of fusion, the method with excellent performance should have greater/more influence on the voting results. This paper proposes a validity concept based on the confusion matrix to improve the voting method.The concept of the validity value is defined as follows:




v
j
k

=

N

j
j

k

−




∑

i
=
1
,
i
≠
j

t



N

i
j

k







∑

i
=
1

t



N

i
j

k





,
 
j
=
1
,
⋯
,
t
,




(26)


where


v
j
k


 represents the validity of classifier k for fault j. The larger the value of


v
j
k


, the higher the credibility of the result when a test sample is classified as fault j by classifier k. Additionally, the following conditions should be met:




v
j
k

=

{





0
,
 

v
j
k

<
0







v
j
k

,
 

v
j
k

≥
0






.




(27)

In the improved voting method, the voting result is determined by the validity value of the base classifier for different faults. Different from the conventional voting method, the fusion results given by the improved voting method are no longer crisp (i.e., either 0 or 1), but they take values in the interval of 0–1. This not only avoids the shortcomings of the original voting method, which does not consider the difference in performance of each classifier on different faults, but also enhances the impact of the classifiers with good performance in terms of voting results.A validity matrix can be obtained by using the improved voting method:




V

=

[






v
1
1






v
2
1








⋯




v
t
1
















v
1
2






⋮












v
2
2






⋮














⋯




v
t
2














⋯


⋮














v
1
c






v
2
c








⋯




v
t
c










]


,
 

j
=
1
,
⋯
,
t
.




(28)

Combined with the combined weights, the decision of the fusion system is:




D

=

C



W

T

∗

V

=

(


d
1

,

d
2

,
⋯
,

d
t


)

.




(29)

Finally, the maximum value is used as the fusion decision:



F
D
=


arg
max

j


{


d
j


}


,
 

j
=
1
,
2
,
⋯
,
t
.




(30)

In summary, the proposed decision fusion system uses multiple performance evaluation indicators to measure the performance of the base classifier and determine the combined weights based on AHP and EW-TOPSIS for the base classifiers under these indicators. In addition, an improved voting method based on validity was developed to improve the effectiveness of decision fusion. In the next section, the proposed method is verified by the TE process. 4. Results 4.1. TE ProcessThe TE process is a test platform for complex chemical processes. It was proposed by Downs et al. [31] and has been widely used to evaluate the performance of process monitoring algorithms. The TE process mainly consists of five units: a reactor, a condenser, a compressor, a stripper, and a separator. It contains 53 variables, including 41 measurement variables and 12 manipulated variables. All 21 faults can be simulated on this test platform. Among them, faults 1–7 are step faults, faults 8–12 are random variation faults, and faults 16–20 are unknown faults. For more details, please refer to [31,32].In this study, all 21 faults were used. The training set for each fault contained 380 samples, with each sample being 52-dimensional (the 12th manipulated variable of Agitator Speed was omitted). The validation data for each fault comprised 100 samples. The test sets for each fault contained 800 samples. The datasets can be downloaded from http://web.mit.edu/braatzgroup/links.html. 4.2. ExperimentThe parameter settings of the base classifiers were as follows: the number of neighbors was 7 for the KNN classifier; the number of base decision trees was set to 100 for the RF classifier; and the grid parameters optimization method was used to determine the optimal parameters c and g of the SVM; the number of hidden layers of the BP neural network was set to 21, and the number of training iterations was 100.In this case, the confusion matrix of the six base classifiers was first determined. Then, the structure of the AHP was constructed based on four performance evaluation indicators and six base classifiers, as shown in Figure 2.Next, we determined the importance of the four performance evaluation indicators and constructed a judgment matrix. The indicator F was considered to be the most important performance evaluation indicator, because it is the combination of the recall rate and precision. The indicator ACC can effectively display the classification accuracy of the classifier, so it was regarded as the second most important performance evaluation indicator. MR was also considered to be the second most important performance evaluation indicator. P was the third most important performance evaluation indicator. Combined with Table 1, the judgment matrix shown in Table 3 was obtained.Where


λ

max


=
4.0104

,

C
I
=
0.0035

,

R
I
=
0.90

, and

C
R
=
0.0039

. The consistency check was satisfied.In the same way, the judgment matrix of the base classifier for each performance evaluation indicator was constructed in turn, and the judgment matrix was obtained according to the confusion matrix. Figure 3 shows the weight of each base classifier relative to each performance evaluation indicator. Finally, the weight of the basic classifier based on the AHP is shown in Figure 4.Performance evaluation indicators of each base classifier are calculated by the confusion matrix as shown in Figure 5.The weights of the base classifiers based on EW-TOPSIS are shown in Figure 6, and the CWs are shown in Figure 7.For comparison, the classification accuracies of the six base classifiers and the proposed method are listed in Table 4. Among them, VOTE represents the majority voting method, and IVM represents the improved voting method, CWM represents the classification accuracy when only the combination weights are used, ETIVM represents the combination of the objective weights and the improved voting method, AIVM represents the combination of the subjective weights and the improved voting method, and CWIVM represents the combination of combination weights and the improved voting method. 4.3. DiscussionThe following conclusions can be drawn from the analysis of Table 4: Compared with the basic classifier, the average classification accuracies of IVM and CWM improved by at least 1.17% and 1.84%, respectively. Compared with the majority voting method, the average classification accuracies of IVM and CWM increased by 8.98% and 9.65%, respectively. This shows the effectiveness of IVM and CWM. Further, by analyzing the results of ETIVM, AIVM, and CWIVM, it can be seen that although the improved voting method can be further improved by combining the improved voting method with the weight of the base classifier determined by a single objective or subjective method, it is far less effective than the combination of the combined weight and the improved voting method. The average classification accuracy of CWIVM reached 79.29%—at least 5.06% and 12.87% higher than that of the base classifier and majority voting method, respectively.However, the classification accuracy of the proposed method on faults 3, 9, and 15 was lower than 40%. This is unacceptable for industrial process monitoring, which need further investigation. 5. ConclusionsIn this paper, a new ensemble classification system with combined weights and improved voting rules was presented. The combined weights were obtained by integrating the experts’ subjective weights and data-induced objective weights. The AHP and EW-TOPSIS were used to generate subjective weights and objective weights, respectively, for the base classifiers in the proposed fusion system. The concept of validity was defined in this paper in order to change the deficiencies of the conventional voting method, and a new voting method based on the validity was proposed to improve the fusion results. The experiments on the TE process demonstrate the effectiveness of the proposed method.
