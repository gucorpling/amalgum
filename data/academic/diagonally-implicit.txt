 1. IntroductionIn many mathematical models of real-world problems, Initial Value Problems (IVPs) involving systems of Ordinary Differential Equations (ODEs) exhibit a phenomenon called stiffness. This phenomenon frequently arises in the study of vibrations, chemical engineering, electrical circuits and control theory. Throughout the history of the development of numerical methods for stiff ODEs, considerable attention has been given to creating a robust algorithm with optimal stability properties. This has led us to design an efficient method that possesses a small error constant, zero stability and a large stability region. Such approaches have been taken by numerous researchers, such as [1,2,3,4,5,6,7].In this article, we consider the IVPs for first order ODEs of the form





y
′

=
f

(
x
,
y
)

,




(1)


with

y

(
a
)

=

y
0


 in the interval of

a
≤
x
≤
b

. The system (1) is said to be linear with constant coefficients if

f
(
x
,
y
)
=
A
y
+
Φ
(
x
)

, where A is an

m
×
m

 constant matrix, while y, f and

Φ
(
x
)

 are m-dimensional vectors. The matrix A has distinct eigenvalues,

λ
i

 and corresponding eigenvectors,

c
i

, where

i
=
1
,
2
,
…
,
m

 . The system of ODEs has a general solution in the form of




y

(
x
)

=

∑

i
=
0

m


k
i


e


λ
i

x



c
i

+
Ψ

(
x
)

.





According to the definition provided in [8], (1) is considered stiff if the eigenvalues

λ
i

 of



∂
f


∂
y



 satisfy the following conditions:(i) 

R
e
(

λ
i

)
<
0

 and(ii) 



m
a
x

i


|
R
e


(

λ
i

)


|
≫



m
i
n

i


|
R
e

(

λ
i

)

|


 where the ratio




m
a
x

i


|
R
e


(

λ
i

)





m
i
n

i


|
R
e

(

λ
i

)

|



 is called the stiffness ratio or stiffness index.For a non-linear system, (1) is stiff in an interval I of x if, for

x
∈
I
,

 the eigenvalues


λ
i


(
x
)


 satisfy (i) and (ii) above.According to [8], stiffness requires solving the implicit equations by using Newton iteration, which in turn demands an evaluation of the Jacobian at each step. These requirements will increase the computational time and therefore, is not cost-efficient for the users. Because of the high cost of evaluating the stages in a fully implicit method, [9] reported that many researchers have opted to reduce it to a diagonally implicit method. Prior works along this line were discussed by [10,11,12,13,14].In practical applications involving stiff ODEs, the Diagonally Implicit Runge–Kutta (DIRK) class is the most often used among the Implicit Runge–Kutta (IRK) methods. Figure 1 illustrates the fully implicit and diagonally implicit classes of Runge–Kutta (RK) methods, which can be defined as a 3 × 3 matrix. As stated in [15], RK methods are characterized by excellent stability properties that make them useful for solving stiff ODEs systems. However, for a Fully Implicit Runge–Kutta (FIRK) method, a system of

n
×
r

 non-linear equations must be solved in each of its integration stage, where n is the dimension of the problem and r is the number of stages, as described by [16]. Thus, the authors of [17,18] proposed a DIRK method that uses a lower triangular matrix, A with


a

i
j


=
0

 for

i
<
j

. It implies that the DIRK technique needs to solve a series of r-implicit structures for each n instead of an

n
×
r

 system as in the FIRK method. This structure permits solving each stage of the system separately instead of solving all the stages simultaneously. Another common requirement, as stated in [19], is for the non-zero diagonal entries of A to be identical, allowing for a maximum of one lower-upper (LU) decomposition per integration stage.The well-known Backward Differentiation Formula (BDF) has been the technique of choice for the numerical solution of stiff differential equations for many years. The classical BDF method approximates the solution for

y

n
+
1


 at

x

n
+
1


 point in every step. Ibrahim et al. in [20] introduced the Block Backward Differentiation Formula (BBDF) method to reduce the number of integration steps and the computational time of existing numerical integrator while maintaining the accuracy. Many attempts have been made to implement the BBDF method in solving stiff problems because it has been proven as more accurate and efficient than the non-block method (see [20,21,22]) and existing solvers (see [23,24]).Motivated by the fact that the existing works carried out based on RK and BBDF are suitable for solving stiff ODEs, we aim to formulate an efficient BBDF method in a diagonally implicit form that is expected to be faster than the fully implicit methods in the existing literature.This paper is organized as follows. The derivation of the method is presented in Section 2. In Section 3, we discuss the stability properties of the method encompassing zero stability, absolute stability, order of the method and convergence. Next, the implementation of the derived method using Newton iteration is discussed in Section 4, followed by the numerical results for the proposed and existing methods in Section 5. Finally, the conclusions are provided in Section 6. 2. The
ρ
-Diagonally Implicit Block Backward Differentiation FormulaVarious methods can be used to compute the approximate solution of

y
(
x
)

. One of these methods is the general linear k-step method in the form of





∑

j
=
0

k


α
j


y

n
+
j


=
h

∑

j
=
0

k


β
j


f

n
+
j


.




(2)

If


β
0

=

β
1

=
…
=

β

k
-
1


=
0

 and


β
k

≠
0

, (2) becomes a BDF as outlined by Gear in [25] in the form of





∑

j
=
0

k


α
j


y

n
+
j


=
h

β
k


f

n
+
k


.




(3)

Vijitha-Kumara in [26] modified the formula in (3) by taking an arbitrary


β

k
-
1


≠
0

, introducing the free parameter
ρ
 and formulating the non-block Fixed Step Formula (FSF) of





∑

j
=
0

k


α
j


y

n
+
j


=
h

β
k



f

n
+
k


-
ρ

f

n
+
k
-
1



,




(4)


where


β

k
-
1


=
ρ

β
k


.The definition of the k-step 2-point block linear multistep method (LMM) of BBDF as given by Ibrahim et al. in [20] is in the form of





∑

j
=
0

k


A

j
,
i



y

n
+
j


=
h

∑

j
=
0

k


B

j
,
i



f

n
+
j


,




(5)


where

k
=
i
=
1
,
2

 for

y

n
+
1


 and

y

n
+
2


 respectively;


A

k
,
i


=
1

;


A

j
,
i


,

B

j
,
i



 are

r
×
r

 coefficient matrices;


f

n
+
j


=
f

(

x

n
+
j


,

y

n
+
j


)


 and h = step size used. This constant step size method is implemented by approximating


y

n
+
1


,
…
,

y

n
+
j



 concurrently in a block at the time discretization points of


x

n
+
1


,
…
,

x

n
+
j



.In this section, we will derive the
ρ
-Diagonally Implicit Block Backward Differentiation Formula (
ρ
-DIBBDF) based on the derivation of BBDF by Ibrahim et al. in [20] and FSF by Vijitha-Kumara in [26]. FSF is a non-block method, where the computation proceeds to an approximation of

y

n
+
1


 at the

x

n
+
1


 one step at a time. To increase the efficiency of the classical approach, we proposed a method that constructed in a block, where the solutions of

y

n
+
1


 and

y

n
+
2


 were approximated concurrently in a block by using three back values at the points


x
n

,

x

n
-
1



 and

x

n
-
2


 of the previous block. The development of our method involves the hybrid-like process of implementing the FSF and BBDF, which produce as many A-stable formulae as possible. Suleiman et al. [22] extended the formula in (5), implemented the strategy in [26] by adding extra future points and proposed the 2-point Superclass of BBDF (2SBBDF). The BBDF and 2SBBDF are formulated in a fully implicit manner. We are motivated to develop the
ρ
-DIBBDF to enhance the efficiency of the fully implicit BBDF method by proposing a diagonally implicit method that requires fewer computations of the differentiation coefficients, thus minimizing the cumulative error (refer to [10]). Our proposed method differs from the Diagonally Implicit 2-point BBDF (DI2BBDF) in [10], which provides a fixed formula for each point and order because our method generates a different set of formulae depending on the free parameter chosen in an attempt to achieve the optimal stability properties and accurate numerical results.The
ρ
-DIBBDF method takes the general form of





∑

j
=
0


k
+
2



α

j
-
2
,
k



y

n
+
j
-
2


=
h

β

k
,
k




f

n
+
k


-
ρ

f

n
+
k
-
1



,

k
=
1
,
2




(6)


where


β

k
-
1
,
k


=
ρ

β

k
,
k



. The linear difference operator

L
i

 associated with the formula in (6), is defined as




L

y
(

x
n

)
;
h

=

∑

j
=
0


k
+
2



α

j
-
2
,
k



y

n
+
j
-
2


-
h

β

j
,
k



(

y

n
+
k

′

-
ρ

y

n
+
k
-
1

′

)

.




(7)

Expanding

y

n
+
j
-
2


 and its derivative by using the Taylor series method and collecting the common terms of the derivative y in (7) gives




L

y
(

x
n

)
;
h

=

C
0

y

(
x
)

+

C
1

h

y
′


(
x
)

+
…
+

C
q


h
q


y

(
q
)



(
x
)

.




(8)

The general form of the constant

C
q

 is given by







C
0




=

∑

j
=
0


k
+
2



α

j
-
2
,
k


,






C
1




=

∑

j
=
0


k
+
2





(
j
-
2
)

1


1
!



α

j
-
2
,
k


-


k

(
0
)



0
!



β

j
,
k


+
ρ

β

j
,
k


,





⋮






C
q




=

∑

j
=
0


k
+
2





(
j
-
2
)

q


q
!



α

j
-
2
,
k


-


k

(
q
-
1
)



(
q
-
1
)
!



β

j
,
k


+



(
k
-
1
)


(
q
-
1
)



(
q
-
1
)
!


ρ

β

j
,
k


,


q
=
2
,
3
,
…







(9)

The values of

k
=
1
,
2

 in (6) indicate the first and second points, respectively. By setting


α

1
,
1


=
1

,


α

2
,
2


=
1

,


α

0
,
2


=
0

 and solving (9) simultaneously, we obtain the following coefficients of

α

j
-
2
,
k


 and

β

j
,
k


 in terms of
ρ
 as listed in Table 1:Substituting the coefficients obtained in Table 1 into (6) gives the following general corrector formula for the 2-point
ρ
-DIBBDF:






y

n
+
1





=
-


ρ
+
2


2
ρ
-
11



y

n
-
2


+


3

2
ρ
+
3



2
ρ
-
11



y

n
-
1


-


3

ρ
+
6



2
ρ
-
11



y
n

+


6
ρ


2
ρ
-
11


h

f
n

-

6

2
ρ
-
11


h

f

n
+
1


,






y

n
+
2





=
-


2
ρ
+
3


6
ρ
-
19



y

n
-
2


+


2

3
ρ
+
4



6
ρ
-
19



y

n
-
1


+


2

ρ
-
12



6
ρ
-
19



y

n
+
1


+


12
ρ


6
ρ
-
19


h

f

n
+
1


-

12

6
ρ
-
19


h

f

n
+
2


.







(10)

The matrix form of the corrector formula in (10) is therefore represented by














1


0






-


2

ρ
-
12



6
ρ
-
19





1









y

n
+
1









y

n
+
2











=




0



-


ρ
+
2


2
ρ
-
11









0




-


2
ρ
+
3


6
ρ
-
19












y

n
-
3









y

n
-
2







+






3

2
ρ
+
3



2
ρ
-
11





-


3

ρ
+
6



2
ρ
-
11











2

3
ρ
+
4



6
ρ
-
19





0









y

n
-
1









y
n













+
h




0




6
ρ


2
ρ
-
11








0



0









f

n
-
1









f
n






+
h





-

6

2
ρ
-
11





0








12
ρ


6
ρ
-
19






-

12

6
ρ
-
19












f

n
+
1









f

n
+
2







.










(11)

 3. Selection of Parameter
ρ
To determine whether the numerical method can provide acceptable results, we need to investigate the stability of the method. In this section, the practical efficiency of the numerical method concerning three essential concepts, namely zero stability, absolute stability and convergence will be studied. According to Dahlquist in [27], a potentially useful numerical method for solving stiff ODE systems must have good accuracy and a reasonably large region of absolute stability. In designing an efficient method, authors in [2,3,7] considered developing methods with smaller error constants. The development of our method closely follows the works of [22,26] but in the DI scheme. To overcome the setback in choosing the best
ρ
 as reported in [28], we will choose a better value for
ρ
 with optimal stability properties that will give better accuracy to the approximate solution. The parameter
ρ
 is restricted to

(
-
1
,
1
)

 so that the underlying
ρ
-DIBBDF in (6) satisfies the necessary condition for stiff stability. The relevant proof for

y

n
+
1


 is provided in this section concerning the theorem due to [29] (refer to [26]). The proof of the second point is straightforward by adopting an approach similar to that of the first point.To begin with, the associate
ϱ
 and
σ
 polynomials of (6) are given as follows







ϱ
(
ξ
)




=

ξ
3

+

α

0
,
k



ξ
2

+

α

-
1
,
k


ξ
+

α

-
2
,
k


,






σ
(
ξ
)




=

β

k
,
k




ξ
3

-
ρ

ξ
2


.









Then, by using the following polynomials of

r
(
z
)

 and

s
(
z
)

,







r
(
z
)




=




1
-
z

2


3

ϱ



1
+
z


1
-
z



,






s
(
z
)




=




1
-
z

2


3

σ



1
+
z


1
-
z



,









we define

P
(
z
,
μ
)
=
r
(
z
)
-
μ
s
(
z
)

 where

μ
=
h
λ

.

P
(
z
,
μ
)

 can be simplified as




-

2
ρ
-
11

P

(
z
,
μ
)

=

a
3


z
3

+

a
2


z
2

+

a
1

z
+

a
0

,




(12)


where







a
0




=
6
(
ρ
-
1
)
μ
,






a
1




=
-
12
(
ρ
-
1
)
+
6
(
ρ
-
3
)
μ
,






a
2




=
-
12
(
ρ
-
3
)
-
6
(
ρ
+
3
)
μ
,






a
3




=
8
(
ρ
+
5
)
-
6
(
ρ
+
1
)
μ
.







(13)

The following lemma will be used in the next theorem.Lemma 1. Let

p

(
x
)

=

a
3


x
3

+

a
2


x
2

+

a
1

x
+

a
0


, where

a
i

 are real numbers and


a
3

≠
0

. Then

p
(
x
)

 is a Hurwitz polynomial if and only if the conditions (i) and (ii) both hold.(i) 


a
i



a
r
e
 
e
i
t
h
e
r
 
a
l
l
 
p
o
s
i
t
i
v
e
 
o
r
 
n
e
g
a
t
i
v
e


,(ii) 



a
1


a
2

-

a
0


a
3

>
0
.


Proof.  See [30]. □According to [26], (6) is

A
0

-stable if and only if its corresponding

P
(
z
,
μ
)

 is a Hurwitz polynomial for all

μ
<
0

.Theorem 1. The method is

A
0

-stable for all ρ in

(
-
1
,
1
)

 .Proof.  Clearly from (13),


a
i

>
0

, where

i
=
0
,
1
,
2
,
3

 for all

μ
<
0

 and

ρ
∈
(
-
1
,
1
)

. For (ii),


a
1


a
2

-

a
0


a
3


 can be written as

144

(
ρ
-
1
)


(
ρ
-
3
)

-
48

(

ρ
2

-
8
ρ
+
13
)

μ
+
288

μ
2


. Thus,


a
1


a
2

-

a
0


a
3

>
0

 for all

μ
<
0

 and

ρ
∈
(
-
1
,
1
)

. By Lemma 1,

-

2
ρ
-
11

P

(
z
,
μ
)


 in (12) is a Hurwitz polynomial and so is

P
(
z
,
μ
)

 for all

μ
<
0

 and

ρ
∈
(
-
1
,
1
)

. □The following theorem due to [31] gives necessary and sufficient conditions for stiff stability.Theorem 2. The conditions (i)–(iv) are necessary and sufficient for a convergent method to be stiffly stable.(i) The method is

A
0

-stable,(ii) The modulus of any root of the polynomial


ϱ
(
ξ
)


ξ
-
1


 is less than 1,(iii) The roots of

σ
(
ξ
)

 of modulus 1 are simple,(iv) If

ξ
0

 is a root of

σ
(
ξ
)

 with


|


ξ
0


|
=
1


, then


ϱ
(
ξ
)


ξ

σ
′


(
ξ
)



 at

ξ
=

ξ
0


 is real and positive.The following lemma will be used to prove the next theorem.Lemma 2. Let

p

(
x
)

=

a
2


x
2

+

a
1

x
+

a
0


, where


a
0

,

a
1

,

a
2

≠
0

 and


a
0

,

a
1

,

a
2


 are real. Then

p
(
x
)

 is a Schur polynomial if and only if the conditions of (i) and (ii) are met.(i) |a0| < |a2| ,
(ii) |a1| < |a2 + a0| .
Proof.  See [26]. □Theorem 3. The method is strongly stable for

ρ
∈
(
-
1
,
1
)

.Proof.  It suffices to show that


ϱ
(
ξ
)


ξ
-
1


 is a Schur polynomial for

ρ
∈
(
-
1
,
1
)

. From Table 1,


α

-
2
,
1


+

α

-
1
,
1


+

α

0
,
1


+
1
=
0

,

ϱ
(
ξ
)

 can be simplified as

ϱ

(
ξ
)

=

(
ξ
-
1
)


(

a
2


x
2

+

a
1

x
+

a
0

)


, where


a
0

=
-

α

-
2
,
1


=
-


ρ
+
2


2
ρ
-
11


,

a
1

=
-

(

α

-
2
,
1


+

α

-
1
,
1


)

=
-



-
5
ρ
-
7


2
ρ
-
11




 and


a
2

=
1

. Since

-


ρ
+
2


2
ρ
-
11


≤

1
3


 for

-
1
<
ρ
<
1

, we have


a
0

<

a
2


. Now,


a
2

+

a
0

=


ρ
-
13


2
ρ
-
11



 and


|



a
2

+

a
0



|
-
|


a
1


|
=



6
(
ρ
-
1
)


2
ρ
-
11


>
0

 for

-
1
<
ρ
<
1

. Thus, by Lemma 2,


ϱ
(
ξ
)


ξ
-
1


 is a Schur polynomial. □Theorem 4. The method is stiffly stable for

ρ
∈
(
-
1
,
1
)

.Proof. 

σ

(
ξ
)

=

β

1
,
1




ξ
3

-
ρ

ξ
2



 where


β

1
,
1


=


-
6


2
ρ
-
11



. The roots of

σ
(
ξ
)

 are

0
,
ρ

 and it has simple root of modulus 1 when

ρ
=
-
1

. Now Theorem 2 together with Theorem 1 and Theorem 3 imply that the method is stiffly stable for all

ρ
∈
(
-
1
,
1
)

. □Corollary 1. The method is

A
(
α
)

-stable for all

ρ
∈
(
-
1
,
1
)

.Proof.  Stiff stability implies

A
(
α
)

-stability (refer to [31]). □For the order 3 method, the intensive work done by [26] shows that

ρ
=
-
0
.
75

 will produce accurate numerical results with optimal stability properties. The stability analysis of the proposed method for

ρ
=
-
0
.
75

 will be presented in the following subsections. 3.1. Zero StabilityZero stability is one of the important forms of stability for the numerical solution of IVPs. It is defined by [32] as:Definition 1. The method in (10) is said to have zero stability if no root of its characteristic polynomial has a modulus higher than one and if any root with a modulus of one is simple.Consider the scalar test equation


y
′

=
λ
y

. Substitute

h
λ
=

h
¯


 into (11) and rewrite it in the matrix form to get















1
+

6

2
ρ
-
11



h
¯




0






-


2

ρ
-
12



6
ρ
-
19


-


12
ρ


6
ρ
-
19



h
¯





1
+

12

6
ρ
-
19



h
¯











y

n
+
1









y

n
+
2











=






3

2
ρ
+
3



2
ρ
-
11





-


3

ρ
+
6



2
ρ
-
11


+


6
ρ


2
ρ
-
11



h
¯










2

3
ρ
+
4



6
ρ
-
19





0









y

n
-
1









y
n













+




0



-


ρ
+
2


2
ρ
-
11









0




-


2
ρ
+
3


6
ρ
-
19












y

n
-
3









y

n
-
2

















(14)


which is equivalent to


A
0


Y
m

=

B
0


Y

m
-
1


+

C
0


Y

m
-
2



. By inserting the coefficients of


A
0

,

B
0


 and

C
0

 in (14) into the determinant formula viz.


|


A
0


t
2

-

B
0

t
-

C
0


|


, we obtain the following stability polynomial in terms of
ρ
:






R
(
t
,

h
¯

)




=



-
1


(
2
ρ
-
11
)
(
6
ρ
-
19
)



72


h
¯

2


ρ
2


t
3

-
72


h
¯

2


t
4

-
24

h
¯


ρ
2


t
3

-
60

h
¯

ρ

t
4

-
12

ρ
2


t
4

+
24

h
¯


ρ
2


t
2

-
288

h
¯

ρ

t
3








+
246

h
¯


t
4

+
30

ρ
2


t
3

+
104
ρ

t
4

+
12

h
¯

ρ

t
2

+
108

h
¯


t
3

-
24

ρ
2


t
2

-
24
ρ

t
3

-
209

t
4

-
18

h
¯


t
2

+
6

ρ
2

t







-
96
ρ

t
2

+
261

t
3

+
16
ρ
t
-
63

t
2

+
11
t
=
0
.







(15)

By plugging


h
¯

=
0

 and solving (15) with respect to t, we obtain the roots, t as listed in (16).









t



=
0
,
1
,

1

12

ρ
2

-
104
ρ
+
209



9

ρ
2

+


9

ρ
4

+
1152

ρ
3

+
2346

ρ
2

-
120
ρ
-
1623


+
40
ρ
+
26

,







-

1

12

ρ
2

-
104
ρ
+
209



-
9

ρ
2

+


9

ρ
4

+
1152

ρ
3

+
2346

ρ
2

-
120
ρ
-
1623


-
40
ρ
-
26

.










(16)

By setting

ρ
=
-
0
.
75

, we obtain the roots,

t
=
0
,
1
,
0
.
003617
±
0
.
08982
i

. Since the roots of the stability polynomial for

ρ
=
-
0
.
75

 satisfy Definition 1, we conclude that the method is said to be zero stable. 3.2. Absolute StabilityAccording to [32], if the employed method has a region of absolute stability that includes the entire negative-plane, then there will be no constraint on the step length imposed by the stability.Definition 2. A numerical method is said to be A-stable if


ℜ
A

⊇

{
h
λ
∣
R
e

(
h
λ
)

<
0
}


.However, the A-stability requirement places a severe restriction on selecting appropriate LMMs. This restriction is known as Dahlquist’s second barrier, which states that the order of an A-stable LMM must be

≤
2

 (see [27]). This demanding requirement motivates the following definition by [33]:Definition 3. A numerical method is said to be

A
(
α
)

-stable,

α
∈

0
,
π
/
2


 if


ℜ
A

⊇

{
h
λ
∣
-
α
<
π
-
a
r
g

(
h
λ
)

<
α
}


 as shown in Figure 2.The boundary of the stability region is determined by putting

t
=

e

i
θ



 in (15) where

0
≤
θ
≤
2
π

 for which

|
t
|
<
1

. The stable region is located outside the boundary of the solid line and the unstable region is within the enclosed area. The absolute stability region of our method for

ρ
=
-
0
.
75

 is plotted in a complex

h
λ

 plane and shown below.Referring to Figure 3, we can observe that almost the whole left-plane of the circle lies within a stable region and hence, based on Definition 3, the method is considered

A
(
α
)

-stable. 3.3. Order of the Method and Error ConstantThe definition of the order of the method given by [8] is provided in Definition 4, as follows:Definition 4. The linear multistep method (5) and the associated difference operator,

L
i

 as defined by (6), are said to be of order p if in (8),


C
0

=

C
1

=
…
=

C
p

=
0

 and


C

p
+
1


≠
0

, where

C

p
+
1


 is the error constant.The error constant of the method can be obtained by substituting the corresponding values of

α

j
,
k


 and

β

j
,
k


 in Table 1 into (9), which gives







C
0




=

∑

j
=
0

4


α

j
,
k


=




0






0





,






C
1




=

∑

j
=
0

4


j

1
!



α

j
,
k


-

β

j
,
k


=




0






0





,






C
2




=

∑

j
=
0

4



j
2


2
!



α

j
,
k


-

j

1
!



β

j
,
k


=




0






0





,






C
3




=

∑

j
=
0

4



j
3


3
!



α

j
,
k


-


j
2


2
!



β

j
,
k


=




0






0





,






C
4




=

∑

j
=
0

4



j
4


4
!



α

j
,
k


-


j
3


3
!



β

j
,
k


=






1
2



ρ
+
3


2
ρ
-
11











3
(
ρ
+
2
)


6
ρ
-
19







=






-
9

100









-
15

94






.







(17)

Since


C
4

≠
0

 in (17), following Definition 4, we conclude that the derived method has the order 3 with


-
9

100

 and


-
15

94

 as the error constants of

y

n
+
1


 and

y

n
+
2


 respectively. 3.4. ConvergenceAn essential property of an acceptable LMM is that the solution generated by the method converges to an exact solution as the step size approaches zero. A theorem provided by [35] states that a method of an LMM class in (6) is convergent if and only if, it is both consistent and zero stable. The proof for this theorem can be found in [35]. For this theorem to be satisfied, the following consistency conditions given by [8] must be fulfilled:(a)


∑

j
=
0


k
+
2



α

j
-
2
,
k


=
0
,

(b)


∑

j
=
0


k
+
2


j

α

j
-
2
,
k


=

∑

j
=
0


k
+
2



β

j
,
k


.

By applying the above consistency conditions for the respective coefficients of

y

n
+
1


 and

y

n
+
2


 in Table 1, we obtained:








a
)


∑

j
=
0


k
+
2



α

j
-
2
,
k


=






ρ
+
2


2
ρ
-
11










2
ρ
+
3


6
ρ
-
19







+






-
3

2
ρ
+
3



2
ρ
-
11










-
2

3
ρ
+
4



6
ρ
-
19







+






3

ρ
+
6



2
ρ
-
11








0





+




1








-
2

ρ
-
12



6
ρ
-
19







+




0






1





=




0






0





,







b
)


∑

j
=
0


k
+
2


j

α

j
-
2
,
k


=
0






ρ
+
2


2
ρ
-
11










2
ρ
+
3


6
ρ
-
19







+
1






-
3

2
ρ
+
3



2
ρ
-
11










-
2

3
ρ
+
4



6
ρ
-
19







+
2






3

ρ
+
6



2
ρ
-
11








0





+
3




1








-
2

ρ
-
12



6
ρ
-
19







+
4




0






1











=






6
ρ
-
6


2
ρ
-
11










12
ρ
-
12


6
ρ
-
19







=





21
25








42
47












=

∑

j
=
0


k
+
2



β

j
,
k


.








Since the method for

ρ
=
-
0
.
75

 is zero stable as stated in Section 3.1 and both consistency conditions are successfully met, we conclude that the derived method converged.The

α
,
D

 in

A
(
α
)

-stability and error constants

(
E
C
)

 of the underlying
ρ
-DIBBDF in (7) for

ρ
=
-
0
.
75
,
-
0
.
60
,
0
.
50

 and

0
.
95

 are given in Table 2. We choose these
ρ
 values to compare with

ρ
=
-
0
.
75

 to ensure a higher accuracy for the numerical results by selecting the best parameter

(
ρ
=
-
0
.
75
)
,

 as proven for the non-block FSF in [26]. 4. Implementation of the MethodIn this section, the approximation of

y

n
+
1


 and

y

n
+
2


 values in (14) will be implemented using the Newton’s iteration. Formula in (10) can be represented in the following form:






y

n
+
1





=

α
1


y

n
+
2


+

β
1

h

f
n

+

β
2

h

f

n
+
1


+

η
1

,






y

n
+
2





=

α
2


y

n
+
1


+

β
3

h

f

n
+
1


+

β
4

h

f

n
+
2


+

η
2

,







(18)


where

η
1

 and

η
2

 are the back values. Equation (18) in the form of the matrix-vector is equivalent to





I
-
A

Y
=
h


B
1


F
1

+

B
2


F
2


+
ζ
,






with










I
=




1


0






0



1




,
A
=




0



α
1








α
2




0




,

B
1

=




0



β
1







0



0




,

B
2

=





β
2



0







β
3





β
4





,






Y
=





y

n
+
1









y

n
+
2







,

F
1

=





f

n
-
1









f
n






,

F
2

=





f

n
+
1









f

n
+
2







,
ζ
=





η
1








η
2






.










(19)

Let





F
^

=

I
-
A

Y
-
h


B
1


F
1

+

B
2


F
2


-
ζ
=
0
.




(20)

By applying Newton’s iteration to the system in (20), the

(
i
+
1
)

th iterative value of

y

n
+
j


 is generated and we obtain





y

n
+
j


(
i
+
1
)


=

y

n
+
j


(
i
)


-



F
^


(

y

n
+
j


(
i
)


)





F
^

′


(

y

n
+
j


(
i
)


)



,

j
=
1
,
2
.




(21)

Equation (21) is equivalent to





y

n
+
j


(
i
+
1
)


-

y

n
+
j


(
i
)


=
-



I
-
A


Y

n
+
j


(
i
)


-
h


B
1


F
1

+

B
2


F
2


-
ζ



I
-
A

-
h



B
1



∂

F
1



∂
Y




Y

n
+
j


(
i
)



+

B
2



∂

F
2



∂
Y




Y

n
+
j


(
i
)







,




(22)


where




∂
F


∂
Y




Y

n
+
j


(
i
)





 denotes the Jacobian matrix of F with respect to Y. By letting


E

n
+
j


(
i
+
1
)


=

y

n
+
j


(
i
+
1
)


-

y

n
+
j


(
i
)



, (22) can be expressed in the simplest form





E

n
+
j


(
i
+
1
)


=


P
¯


-
1



Q
¯

.




(23)

It follows that





P
¯


E

n
+
j


(
i
+
1
)


=

Q
¯

,




(24)


where











P
¯

=


I
-
A

-
h



B
1



∂

F
1



∂
Y




Y

n
+
j


(
i
)



+

B
2



∂

F
2



∂
Y




Y

n
+
j


(
i
)






,

Q
¯

=
-

I
-
A


Y

n
+
j


(
i
)


-
h


B
1


F
1

+

B
2


F
2


-
ζ
.










(25)

By plugging the corresponding entries of

I
,
A
,

B
1

,

B
2


 in (19) into (25) we obtain











P
¯

=






1
-

β
2

h


∂

f

n
+
1




∂

y

n
+
1









-

α
1









-

α
2

-

β
3

h


∂

f

n
+
1




∂

y

n
+
1










1
-

β
4

h


∂

f

n
+
2




∂

y

n
+
2










,

Q
¯

=





-

y

n
+
1

i

+

α
1


y

n
+
2

i

+

β
1

h

f
n
i

+

β
2

h

f

n
+
1

i

+

η
1








-

y

n
+
2

i

+

α
2


y

n
+
1

i

+

β
3

h

f

n
+
1

i

+

β
4

h

f

n
+
2

i

+

η
2






.










(26)

Equation (21) in matrix form for formula in (10) will produce















1
+


2

ρ
-
3



h


∂

f

n
+
1




∂

y

n
+
1







0






-

3
4




ρ
-
3


ρ
-
2



-


3
ρ


2
ρ
-
4


h


∂

f

n
+
1




∂

y

n
+
1








1
+


3

2
ρ
-
4



h


∂

f

n
+
1




∂

y

n
+
1














E

n
+
1


(
i
+
1
)









E

n
+
2


(
i
+
1
)







=





-
1



0







3
4




ρ
-
3


ρ
-
2







-
1










y

n
+
1


(
i
)









y

n
+
2


(
i
)













+
h




0




2
ρ


ρ
-
3








0



0









f

n
-
1


(
i
)









f
n

(
i
)







+
h





-

2

ρ
-
3





0








3
ρ


2
ρ
-
4






-

3

2
ρ
-
4












f

n
+
1


(
i
)









f

n
+
2


(
i
)







.










(27)

The approximate values of

y

n
+
1


 and

y

n
+
2


 are therefore derived from





y

n
+
j


(
i
+
1
)


=

y

n
+
j


(
i
)


+

E

n
+
j


(
i
+
1
)


,

j
=
1
,
2
.




(28)

The computation was performed in

P
E
C
E

 mode in accordance with the terminology used in the LMM context. P and C indicate one predictor or corrector implementation, respectively and E indicates one evaluation of the function


y
′

=
f

(
x
,
y
)


. The predictor formula used in this

P
E
C
E

 sequence are given by:






y

n
+
1


(
p
)





=
-

y

n
-
1


+
2

y
n

,






y

n
+
2


(
p
)





=
-
2

y

n
-
1


+
3

y
n

.







(29)

The approximation of

y

n
+
1


 and

y

n
+
2


 values will be executed simultaneously in every step. The

P
E
C
E

 block method mode is described as:






P
:

y

n
+
1


(
p
)


→
E
:

f

n
+
1


(
p
)


→
C
:

y

n
+
1


(
c
)


→
E
:

f

n
+
1


(
c
)


,






P
:

y

n
+
2


(
p
)


→
E
:

f

n
+
2


(
p
)


→
C
:

y

n
+
2


(
c
)


→
E
:

f

n
+
2


(
c
)


.







(30)

 5. Numerical ResultsIn the interest of validating the numerical results of our method, the
ρ
-DIBBDF algorithm was written in C programming language on the Microsoft Visual C++ platform to obtain the approximate values. BBDF in [20] and DI2BBDF in [10] are chosen as the methods of comparison because they are of the same order as our derived method. For our method, we choose

ρ
=
-
0
.
60
,
0
.
50
,
0
.
95

 to compare with

ρ
=
-
0
.
75

. Due to space limitation, only some
ρ
 values will be examined. A detailed description of the selection of
ρ
, was discussed in [26]. For the four selected test problems, the numerical results of the maximum error and execution time are given in Table 3, Table 4, Table 5 and Table 6, with




M
A
X
E
=



m
a
x

︸


1
≤
i
≤
T



(




m
a
x

︸


1
≤
i
≤
N



|




(

y
i

)

t

-


(
y

(

x
i

)

)

t



|
)

,






where T is the total number of steps, N is the number of equations,

y
i

 and

y
(

x
i

)

 are the approximated and exact solutions, respectively.Test Problem 1:





y
′

=
-
2
π
sin

(
2
π
x
)

-

1

10

-
3




y
-
cos
(
2
π
x
)

,

y

(
0
)

=
1
,

0
≤
x
≤
1






Exact solution:



y
(
x
)
=
cos
(
2
π
x
)





Source: [36]Test Problem 2:





y
′

=
5

e

5
x




y
-
x

2

+
1
,

y

(
0
)

=
-
1
,

0
≤
x
≤
1






Exact solution:



y

(
x
)

=
x
-

e

-
5
x







Source: [37]Test Problem 3:







y

1

′




=
-

y
2
′

-

10

-
5



y
1


1
-

y

1

2

-

y

2

2


,


y
1


(
0
)

=
1
,

0
≤
x
≤
3






y

2

′




=

y
1
′

-
3
×

10

-
5



y
2


1
-

y

1

2

-

y

2

2


,



y
2


(
0
)

=
0









Exact solution:







y
1


(
x
)





=
cos
(
x
)







y
2


(
x
)





=
sin
(
x
)








Source: [36]Test Problem 4:







y

1

′




=
-
21

y
1

+
19

y
2

-
20

y
3

,


y
1


(
0
)

=
1
,

0
≤
x
≤
10






y

2

′




=
19

y
1

-
21

y
2

+
20

y
3

,


y
2


(
0
)

=
0






y

3

′




=
40

y
1

-
40

y
2

-
40

y
3

,


y
3


(
0
)

=
-
1









Exact solution:







y
1


(
x
)





=
0
.
5


e

-
2
x


+

e

-
40
x



cos
(
40
x
)
+
sin
(
40
x
)









y
2


(
x
)





=
0
.
5


e

-
2
x


-

e

-
40
x



cos
(
40
x
)
+
sin
(
40
x
)









y
2


(
x
)





=
2

e

-
40
x



-

1
2

cos

(
40
x
)

+

1
2

sin

(
40
x
)










Source: [8]The notations used in Table 3, Table 4, Table 5 and Table 6 are described as follows:H :Step sizeMAXE :Maximum errorTIME :Execution time (seconds)ρ-DIBBDF(ρi) :ρ-Diagonally Implicit Block Backward Differentiation Formula (ρ value)BBDF :Block Backward Differentiation Formula of order 3 in [20]DI2BBDF :Diagonally Implicit 2-point BBDF of order 3 in [10]Table 3, Table 4, Table 5 and Table 6 display the numerical results of
ρ
-DIBBDF, BBDF and DI2BBDF using different step sizes of


10

-
2


,

10

-
4



 and

10

-
6


. Based on the results, we observe that our method with

ρ
=
-
0
.
75

 obtains a smaller MAXE than

ρ
=
-
0
.
60
,
0
.
50
,
0
.
95

 for all the test problems. This is due to the stability properties discussed in Section 3, whereby a good choice of the parameter
ρ
, we can produce a method that has better accuracy. For MAXE, we observe that for all the
ρ
 values, the
ρ
-DIBBDF outperforms the BBDF method. This is due to the nature of the BBDF method, which has more interpolating points in the fully implicit form, thus increasing the cumulative errors during the computation process (refer to [10]). Compared to DI2BBDF, our method obtains comparable accuracy for all the tested problems. For TIME, our method with

ρ
=
-
0
.
75

 manages to solve the test problems in less execution time compared to BBDF and DI2BBDF.To illustrate the performances of the suggested method and other compared methods, graphical presentations of the numerical results are shown in Figure 4, Figure 5, Figure 6 and Figure 7. For a particular abscissa, the lowest value of the coordinate is considered to be more efficient at the abscissa considered. It follows that the graphs of


log
10

M
A
X
E

 against


log
10

T
I
M
E

 demonstrate the advantage of the
ρ
-DIBBDF(−0.75) method over the other
ρ
, BBDF and DI2BBDF methods in terms of efficiency. Overall, we observe that the
ρ
-DIBBDF(−0.75) method performs better than the other
ρ
, BBDF and DI2BBDF methods. 6. ConclusionsIn this study, we developed the
ρ
-DIBBDF method with the best choice of the parameter
ρ
 that holds optimal stability properties. The stability analysis shows that this order 3 method is zero stable,

A
(
α
)

-stable and convergent. Based on Section 3, we noted that the stability properties of the methods compared in Table 2 are related to the MAXE obtained in Section 5. By choosing the best value for the parameter
ρ
, we developed a method that possesses a smaller error constant, a reasonably big
α
 and a larger stability region than the compared methods, thus leading to more accurate results. The proposed method performed better with higher accuracy and less execution time compared to the existing methods, BBDF and DI2BBDF because the DI structure applied to the formula led to an efficient implementation.Therefore, we conclude that the
ρ
-DIBBDF method has significance as an efficient numerical method for solving stiff first order ODEs.
