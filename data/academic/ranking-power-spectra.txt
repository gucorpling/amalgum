 1. IntroductionMany real-world signals including physiological signals are irregular in some aspects. They are neither purely periodic nor can they be expressed by an analytic formula. The inherent irregularities imply the uncertainty during the evolution of the underlying process from which the signals are observed. The uncertainty enables information transfer but also limits the predictability of those signals. The unpredictability of signal in time domain makes researchers have to toil in frequency domain. Fourier transform (FT) bridges signals in original space (time domain) with their representations in dual space (frequency domain) by decomposing a signal satisfying some weak constraints into infinitely many periodic components, which has numerous applications in signal processing. For most of the real-world applications, finite samples drawn (usually evenly spaced) from a continuous random process cannot give us full information about the process’ evolution but only a discrete depiction. FT was adapted into discrete Fourier transform (DFT) for such scenarios [1]. Moreover, line spectrum wherein the total energy of the signal distributes on only few frequency components is rarely encountered among physiological signals due to the inherent irregularities therein.To characterize the irregularity of digital signals in frequency domain, spectral entropy is introduced analogous to the Shannon entropy in information theory [2]. The estimations on the frequency grid are firstly divided by the total power, and then, a list of proxies in the form of probabilities whose sum is 1 is obtained. Then, the Shannon entropy formula, which is the negative sum of probability-weighted log probabilities, map those proxies into a quantity representing the irregularity of energy distribution on frequency domain. Under this perspective, a flat spectrum has maximal spectral entropy, and the spectrum of a single frequency signal has minimal spectral entropy, which is zero. Spectral entropy has been applied in diverse areas, including endpoint detection in speech segmentation [3] and spectrum sensing in cognitive radio [4]. Moreover, it has also served as the base of a famous inductive bias, maximum entropy [5], which is widely adopted for spectrum estimation of some kinds of physiological signals like electroencephalogram (EEG). Although spectral entropy is well-defined and can be computed efficiently by Fast Fourier Transform (FFT), it is difficult to relate spectral entropy with other interpretable properties of interest of original signal, especially when taking no account of the overwhelming endorsement from its counterpart (information entropy), which is the foundational concept in information theory which quantifies the uncertainty. Furthermore, it is apparent that the spectral entropy ignored the order information since the power estimations are arranged on the frequency grid with intrinsic partial order structure. Any permutations of these values on the grid yields a same spectral entropy, but obviously, the representations of those signals in time domain can look very different.The motivation to incorporate the order information carried by the power spectrum is guided by the following belief. The normal operations of any system (biological/electromechanical, etc.) are impossible without the proper processing of information through some physical/chemical process. It could be the signaling between different modules within the system or the communications between the system as a whole and the external environment. Information transfers happening in those scenarios are accomplished with the help of carrier signals of particular forms with nontrivial structures in their spectra. Moreover, only limited frequency precision of the control and recognition of those signals is practical for real systems. Therefore, it is unreasonable for well-designed artificial systems or natural systems that have gone through long-term evolution to arrange the internal signals responsible for different functions close with each other in frequency domain within a certain time window. Otherwise, the efficient transfer of information could be degraded, and frequency divided multiplex [4] in modern communication systems can be considered as a living example of this belief.Therefore, if we use power estimations on the frequency grid as proxies of the intensities of activities corresponding to those frequencies, it seems reasonable to infer that the energy distributed on neighboring rather than remote frequency grids is more likely caused by the very same function. The alpha band activities (8–13 Hz) which can be interrupted by visual perception tasks in human’s EEG is one of the examples. To sum up, we want to develop a metric to characterize the aforementioned structural irregularities of the power spectra, that is, how the frequency components of different intensities in a spectrum close to each other instead of what is captured in spectral entropy, which is how the intensities of frequency components are distributed no matter their locations in frequency domain. It was supposed to assign a larger value to a signal wherein the frequency components having similar intensities are distributed far apart from, rather than close to, each other. In addition, the similarities of intensities can be reflected (partially and heuristically) by the relative order of power estimates on discrete frequency grid. That is why the order information in the spectrum can shed new light on the structure aspects of signal and how the order information is incorporated into our analysis.In this paper, we explore the effectiveness of the order information carried by the power spectra of signals. Given the motivation illustrated above, in Section 2 we provide details about our method. In Section 3 we present several use cases to justify the effectiveness of our preliminary approach and, more importantly, the promising potential to find some new research niche in the field of physiological signal processing. Finally, discussion about the limitations of our work and future directions are followed in Section 4. 2. Materials and Methods Given an equally spaced, real-valued digital signal

s

, we assume the length of
s
 is an even number

2
N

, for simplicity. Then DFT is applied to
s
 and a complex-valued vector

s
^

 of dimension

2
N

 is obtained as follows:






s
k


^

=


∑


i
=
0


2
N
−
1



s
i

·

e

−
j
·


i
·
k
·
2
π


2
N




,
 
k
=
0
,
1
,
…
,
2
N
−
1




(1)

Due to the conjugate symmetry of


s
^


, we take the square of the modulus of the first half of




s
k


^


 and get


P
s

∈

R
N


. Thanks to the Parseval identity, the 1-norm of


P
s


 equals to the energy of
s
 up to factor 1/2. Although


P
s


 has a dimension of energy instead of power, the constant factor having a dimension of time does not change the relative ordinal relations between its components. So we just use


P
s


 as the estimations of power on normalized frequency range


[

0
,
π

]


, whereby the


k

t
h



 component of


P
s


 is the estimation of signal’s power on grid point


(

k
−
1

)

·
π
/
N

.Now, let us assume again that every two components of


P
s


 are different from each other, so we can rank these
N
 components without any ambiguity in ascending/descending order.These grid points have an intrinsic partial order structure from low frequency range to high frequency range, so we get eigen-triple for these grid points:




(




1


2


3










P
s


(
1
)







σ

(
1
)














P
s


(
2
)







σ

(
2
)














P
s


(
3
)







σ

(
3
)












…


N








…




…












P
s


(
N
)







σ

(
N
)










)





(2)

The first row indicates the grid points by their location on frequency range. The second row contains the corresponding power estimations. The third row contains the relative order of corresponding power estimation among all estimations, denoted by

σ

(
·
)


. Since no duplicated values in


P
s


 are assumed,




{

σ

(
i
)


}



i
=
1

N


 will traverse number set


{

1
,
2
,
3
,
…
,
N

}


.The first two rows of


(
2
)


 are just a kind of representation of traditional power spectrum. Novelty lies in taking the order information, carried in the third row, into consideration. It should be noted that the first and the third row together have defined a permutation over the natural number set


{

1
,
2
,
3
,
…
,
N

}


, with its complete detail determined by
s
 implicitly. Remember that spectral entropy is defined in a permutation-invariant way. Such an invariance must be broken down so as to disentangle the order information. Therefore, this permutation per se returns the long-overdue ladder to understand structural irregularities of signals under a new perspective.The sketch of our method is illustrated in Figure 1. Using the measurements in time domain (Figure 1a), the power estimations on normalized frequency grid with resolution determined by half the length of original signal are obtained (Figure 1b). By ranking these estimations in descending order, we arrange


σ


(
i
)



−
1



 against

i

. As shown in Figure 1c, the first stem indicates the location on the frequency grid of the largest power component and so on. From (b) to (c), we are actually performing a nonlinear stretching while the order information of the spectrum is preserved and calibrated. Then a distance matrix
M
 (in Figure 1d) is induced for every point pair. Here in (c) we define


M

i
j


=

M

j
i


=

|


σ


(
i
)



−
1


−

σ


(
j
)



−
1



|


.So
M
 is real-symmetric with trace identically equals to 0. The structural aspects of
M
 are reflected in its eigenvalues (Figure 1e). Due to the sophisticated relationships between its entries, it is unwise to reshape such a high dimensional object with far lower degrees of freedom into a long vector for pattern recognition. In addition to the eigenvalues, a descriptor, named as Circular Difference Descriptor (


C
i

D

), accounting for the total variation of the locations on frequency grids of frequency components having adjacent intensities is defined as follows, to a large extent, in a heuristic manner:




C
i


D
N

=

1
N

·

(


|


σ


(
N
)



−
1


−

σ


(
1
)



−
1



|

+


∑


i
=
1


N
−
1



|


σ


(
i
)



−
1


−

σ


(

i
+
1

)



−
1



|


)





(3)

The first term makes Circular Difference veritable and endows


C
i

D

 translational invariance instead of permutational invariance. Another heuristic descriptor is defined slightly different from


C
i


D
N


, named as Correspondence Difference Descriptor (


C
o

D

). It equals to the 1-norm of the difference of


σ


(
i
)



−
1



 and

i

, aiming to characterize the difference between




{


σ

−
1



(
i
)


}



i
=
1

N


 and the perfectly ordered case where

σ

(
i
)

=
i

,




C
o


D
N

=

1
N

·


∑


i
=
1

N


|


σ


(
i
)



−
1


−
i

|





(4)

Results from the Monte-Carlo simulation (shown in Figure 2) imply that the empirical distributions of


C
i


D
N


 and


C
o


D
N


 among all permutations could well be Gaussian. Although theoretical distributions of


C
i


D
N


 and


C
o


D
N


 must have bounded supports for finite

N

, they fit a bell-shaped curve very well, which in theory has unbounded support. Since permutational invariance of spectral entropy is broken herein,


C
i

D

 and


C
o

D

 actually encode the signal in different ways but both with guaranteed information gain with respect to spectral entropy. To be specific, given




{

σ

(
i
)


}



i
=
1

N


 without




{


P
s


(
i
)


}



i
=
1

N


, the corresponding


C
i

D

 and


C
o

D

 are fixed, but the distribution of




{


P
s


(
i
)


}



i
=
1

N


 can form widely differed spectra. We take flat spectrum in


(
5
)


 and line spectrum in


(
6
)


 as examples:




P
s


(
i
)

=
k
+

σ


(
i
)



−
1


·
ε
,
 
ε
↓
0
 
,
 
k
↑

1
N





(5)






P
s


(


σ


(
1
)



−
1



)

=
1
−


N

(

N
−
1

)


2

·
ε
,
 

P
s


(


σ


(
i
)



−
1



)

=
ε
·
i
,
 
i
≠
1
,
 
ε
↓
0




(6)

The corresponding spectral entropy values vary from infinitesimal (in


(
5
)


) to maximum possible (in


(
6
)


). On the contrary, given




{


P
s


(
i
)


}



i
=
1

N


, any permutation on it yields an exactly same spectral entropy, as mentioned before, but the corresponding


C
i

D

 and


C
o

D

 will absolutely transverse all possible values.The relationship between spectral entropy and the proposed descriptors is illustrated in Figure 3. The set A denotes full space of signals’ spectra whereby for each




{


P
s


(
i
)


}



i
=
1

N


 no duplicate value exists for its sub-components


P
s


(
i
)

≠

P
s


(
j
)

,
∀
i
≠
j
∈

{

1
,
2
,
…
,
N

}


, which is an assumption made by us for simplicity and with only minimal loss of generality. Signals in the set B have the same spectral entropy, denoted by

S

E
0


. The following conditions need to be satisfied for signals in C:



S
E
{



{


P
i


(
k
)


}



k
=
1

N

}
=
S
E
{



{


P
j


(
k
)


}



k
=
1

N

}
=
S

E
0

,
i
≠
j




(7)





σ
{



{


P
i


(
k
)


}



k
=
1

N

}
=
σ
{



{


P
j


(
k
)


}



k
=
1

N

}




(8)








{


P
i


(
k
)


}



k
=
1

N

≠



{


P
j


(
k
)


}



k
=
1

N


 
under
 
any
 
permutation





(9)

Spectral entropy operator is denoted by

S
E

{
·
}


, and

σ
{



{


P
i


(
k
)


}



k
=
1

N

}

 denotes the rank vector of




{


P
i


(
k
)


}



k
=
1

N


. For example, if we have


P
i


(
k
)

>

P
i


(

k
+
1

)

,
∀
k
∈

{

1
,
2
,
…
,
N
−
1

}


, then we will have

σ
{



{


P
i


(
k
)


}



k
=
1

N

}
=

[

1
,
2
,
3
,
…
,
N

]


.Since all members in C are with a same rank vector, we can obtain many different counterparts of C which share this spectral entropy value with it by a certain permutation on the arrangement of




{


P
i


(
k
)


}



k
=
1

N


. Since there are


(

N
!
−
1

)


 different permutations other than the identical permutation, the following relationship is obtained:



B
=

C
1

∪

C
2

∪
⋯
∪

C

N
!






(10)






C
i

∩

C
j

=
∅
,
 
i
=
1
,
2
,
⋯
,
 
N
,
 
j
=
1
,
2
,
⋯
,
 
N
,
i
≠
j




(11)

Until now, we get a coverage of B by

N
!

 disjoint subsets. Members in the same subset share a specific spectral entropy value, a same rank vector, and cannot be transformed to be identical to each other by simply rearranging their sub-components.Given only the value of spectral entropy (

S
E
=
S

E
0


) without rank vector, we can localize the signal in A to B. Given

σ
{



{

P

(
k
)


}



k
=
1

N

}

, the location will be more accurate (to one of many Cs in B). From this perspective, we can distinguish signals which have completely different order structures with the same spectral entropy.If no a priori about the signals’ spectra is available, then the equiprobable distribution of




{

σ

(
i
)


}



i
=
1

N


 is substantially and implicitly pre-assumed. Then under such circumstance, the so-called Kullback–Liebler Divergence (KLD) which is a widely used method to measure the difference between two probability distributions is adopted to illustrate the advantage when using the proposed descriptors. KLD between the proposed descriptors and spectral entropy as different coding schemes having probability distribution


p
1


(
·
)


 and


p
2


(
·
)


 are always nonnegative [6], no matter the direction (KLD is lack of symmetry). KLD between two distributions


p
1


(
x
)


 and


p
2


(
x
)


 is defined as follows:






K
L
(

p
1

‖

p
2

)
=
∫

p
1


(
x
)

l
o
g



p
1


(
x
)




p
2


(
x
)



d
x
≥
0






K
L
(

p
2

‖

p
1

)
=
∫

p
2


(
x
)

l
o
g



p
2


(
x
)




p
1


(
x
)



d
x
≥
0







(12)

Such a property is welcomed since it guarantees the nonnegative information gain when using both spectral entropy and the proposed descriptors instead of only one of them. In other words, the representation will be more informative with a combination of our proposed descriptors and spectral entropy.As for the distance matrix with its entries


M

i
j



 representing the distance or similarity between point
i
 and
j
, distance measures other than the absolute difference can be applied on


σ


(
i
)



−
1



 and


σ


(
j
)



−
1



 to form different distance matrices. Given any distance measure, a topology is induced on this finite set




{


P
s


(
i
)


}



i
=
1

N


, based on the coarse-grained, discrete-valued rankings among them, and certainly, more order information is unrevealed yet. For example,


C
i

D

 is just the circular difference of the first sub-diagonal line of

M

, captures only a portion of full information.To sum up, by ranking power estimations of signal on a discrete frequency grid, an interesting picture of order structure carried by signal’s spectrum is obtained. 3. ResultsIn this section we provide several use cases to show the effectiveness of order information carried by signal’s power spectrum in physiological signal processing. 3.1. Surface Electromyography (sEMG)It was found the proposed descriptors may be able to distinguish sEMG signals collected under different actions. A publicly available dataset containing sEMG recordings from three females and two males acting six different actions is involved in the analysis [7]. Wilcoxon rank sum test and Kruskal–Wallis test with Bonferroni’s correction are used to compare the medians of each class. A representative example is given in Figure 4 with statistical significance achieved between the medians among most of comparisons. As for full comparison, Supplementary Information contains all comparisons for remaining subjects. 3.2. Electroencephalogram (EEG)It was also found that the proposed descriptors may be able to distinguish brain signals under different pathological states. A publicly available dataset, Bonn Seizure Dataset, which is widely used as materials for brain signal related pattern recognition and machine learning tasks is employed [8]. In this dataset, 5 subsets contain 100 recordings each with identical length, sampling frequency and other conditions, collected under different pathological states. Rank sum test used in 3.1 is performed. Significant (p < 0.001) differences between the medians of the values of proposed descriptors corresponding to these 5 subsets were observed in most of the cases, with boxplots given in Figure 5.  3.3. Speech SignalWhen
N
 is fixed and performing the operator defined in (3) and (4) on moving window mounted on a long signal, we are able to unfold the structural irregularities of signal in a finer time resolution, and thus, change point detection is possible. In Figure 6 we provide an example of endpoint detection in human speech signals. It can be seen that the start points and stop points of syllables are accompanied by the steep increase/decrease of descriptors’ values. In this example, we also found that the descriptors defined in (3) and (4), which are purely based on order information, as opposed to spectral entropy, which has nothing to do with order information, could become noise vulnerable in some problems. This is due to the amplitudes of




{


P
s


(
i
)


}



i
=
1

N


 are barely removed after transforming into




{

σ

(
i
)


}



i
=
1

N


. Consider such a case where a large portion of




{


P
s


(
i
)


}



i
=
1

N


 only accounts for a negligible portion of total energy, then, their relative order can vary drastically because of possible noise and so can the descriptors’ values. However, it seems unreasonable to deem the structure of signal must have changed accordingly.Therefore, a simple thresholding segmentation trick of total variance, similar to what is usually adopted in principal component analysis is used in this case. The descriptors are calculated based on the first
L
 components




{


σ


(
i
)



−
1



}



i
=
1

L


 whereby
L
 is defined as follows:



L
=
min

{

l
 
|


∑


i
=
1

l


P
s


(


σ


(
i
)



−
1



)

≥
q
·

(



∑


i
=
1

N


P
s


(
i
)


)


}





(13)

The

q
∈

(

0
,
 
1

]


 is a tunable parameter selecting L largest frequency components accounting for just above a preset portion of total energy. This trick improves the robustness against wide-band weak noise but removes some welcomed properties. Possible modifications of naive descriptors proposed here will be discussed later.  3.4. Amplitude-Integrated EEG (aEEG)Another example validates the effectiveness of the proposed method by revealing the temporal evolution of physiological process is founded in the analysis of aEEG [9]. aEEG is a kind of condensed sketch of long-term EEG recording. It was believed to be able to reflect long term trends of brain activities in a horizon suitable for visual inspection and evaluation. It has been widely used for seizure detection in neonates, brain disorder evaluation, etc. In Figure 7 a segment of EEG drawn from CHB-MIT dataset [10] is transformed into aEEG first and then similar analysis used in Section 3.3 is adopted. Ictal period is indicated by colored bar. 4. DiscussionOrder structure of signal’s spectrum is revealed by simply ranking the power estimations. Several use cases justify that taking that order structure into consideration could contribute valuable information to the processing of physiological signals. The possible applications include serving as candidate features for pattern recognition among signals, change point detection in process tracking for anomaly detection and many more.The permutation of length N defined by rankings of power estimations on frequency grid has huge capacity (

N
!

). Although in practice it is not necessarily that these

N
!

 different ordinal patterns are equiprobable, the proved information gain under such an assumption is still hoped to be found in practice. An established metric, permutation entropy is based on ranking consecutive measurements in time domain and doing statistics among a sufficient number of segments [11]. The length of such segments must be small otherwise the density estimation will be impractical for time series of reasonable length. Our method delves into the order structure of signal’s representation in dual space (frequency domain) instead of original space (time domain). Every point in the dual space is bridged to all points in the time domain through FT, so no one-to-one correspondence exists between original measurements and mapped points in the proposed method. This is also an important distinction.The proposed descriptors in their original forms could be noise vulnerable, but they can be modified using techniques include but not limit what is used here. In practice, we observed high correlation between


C
i

D

 and


C
o

D

, and one could outperform another at times. In addition, the pairwise distances in the distance matrix in Figure 1d can be induced in a way other than that used here. Anyway, more fruitful and distinguishable features can be extracted along this way from such a representation with large capacity. As for future research, we have several proposals.The first is to establish relationships between the order information given by a recorded digital signal of length 2N and that of its sub-signals, obtained by (nonuniformly) down-sampling these 2N points. Uniformly down-sampling is equivalent to folding the power spectrum. Situations will be more sophisticated under nonuniform cases (include but not limit to evolving/truncating case where the length of signal is ever-increasing), but usually a more flat spectrum with lower frequency resolution is produced. The original signal with its sub-signals together could provide an informative and hierarchical object of study.The second is to develop distance measures other than the absolute difference of ranks used here. By incorporating both the discrete-valued ranks and the continuous-valued power estimations, parameters more robust to broad band noise could be anticipated. Furthermore, could ‘ranking’ of power spectrum of a continuous function (signal) be possible in some sense?The third is about the topology induced from the distance matrix. The distance matrix in Figure 1d or the distance defined by possible modified measures, as mentioned above, whereby block structures frequently occur, provides full neighborhood information of N points on frequency grid. Given such information, could we find some relations with the eigenvalues of DisMat (with possible modification mentioned in the second point) with some properties of interest of original signal? Despite that, we can also calculate so-called persistent homology—a dominant methodology usually referred as synonym of topological data analysis (TDA)—of these N points by computing a series of simplicial complexes with their topological invariants [12] and get topological description of signal’s power spectrum. That means the order information in spectrum enables a nontrivial embedding method of data points with temporal structure. Such an embedding method is different from the famous delay-embedding [13], which is an operation performed in signal’s original space rather than dual space. Delay-embedding could be vulnerable to short and noisy process. A messy point cloud could provide nothing except for ‘topological noises’. However, by ranking power spectrum, the data points are arranged in an organized way, and the application of TDA can be free from such pitfalls encountered in delay-embedding.In conclusion, order structures of physiological signals’ power spectra are almost neglected in existing methods, but they are not meaningless. On the contrary, such structures could provide a unique perspective to understand the intrinsic properties of physiological processes.
