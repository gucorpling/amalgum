#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=5. Ethical Concerns from Algorithmic Decision-Making in AVs
1-1	0-2	5.	_	_	_	_
1-2	3-10	Ethical	abstract[1]	new[1]	_	_
1-3	11-19	Concerns	abstract[1]	new[1]	_	_
1-4	20-24	from	abstract[1]	new[1]	_	_
1-5	25-36	Algorithmic	abstract[1]|abstract[2]	new[1]|new[2]	coref	2-8[6_2]
1-6	37-52	Decision-Making	abstract[1]|abstract[2]	new[1]|new[2]	_	_
1-7	53-55	in	abstract[1]|abstract[2]	new[1]|new[2]	_	_
1-8	56-59	AVs	abstract[1]|abstract[2]|abstract	new[1]|new[2]|new	coref	2-11

#Text=This Section explores ethical issues associated with algorithmic decision-making in AVs , their implications for AV safety risks and discrimination and the steps taken to tackle these issues .
2-1	60-64	This	organization[4]	new[4]	coref	3-1[15_4]
2-2	65-72	Section	organization[4]	new[4]	_	_
2-3	73-81	explores	_	_	_	_
2-4	82-89	ethical	abstract[5]	new[5]	appos	2-13[8_5]
2-5	90-96	issues	abstract[5]	new[5]	_	_
2-6	97-107	associated	_	_	_	_
2-7	108-112	with	_	_	_	_
2-8	113-124	algorithmic	abstract[6]	giv[6]	coref	4-11[30_6]
2-9	125-140	decision-making	abstract[6]	giv[6]	_	_
2-10	141-143	in	abstract[6]	giv[6]	_	_
2-11	144-147	AVs	abstract[6]|abstract	giv[6]|giv	coref	3-9[18_0]
2-12	148-149	,	_	_	_	_
2-13	150-155	their	abstract[8]	giv[8]	coref	2-27[14_8]
2-14	156-168	implications	abstract[8]	giv[8]	_	_
2-15	169-172	for	abstract[8]	giv[8]	_	_
2-16	173-175	AV	abstract[8]|abstract|abstract[11]	giv[8]|new|new[11]	coref|coref	3-19[22_11]|4-11
2-17	176-182	safety	abstract[8]|abstract|abstract[11]	giv[8]|new|new[11]	coref	3-20
2-18	183-188	risks	abstract[8]|abstract[11]	giv[8]|new[11]	_	_
2-19	189-192	and	abstract[8]	giv[8]	_	_
2-20	193-207	discrimination	abstract[8]|abstract	giv[8]|new	coref	3-15
2-21	208-211	and	abstract[8]	giv[8]	_	_
2-22	212-215	the	abstract[8]|abstract[13]	giv[8]|new[13]	_	_
2-23	216-221	steps	abstract[8]|abstract[13]	giv[8]|new[13]	_	_
2-24	222-227	taken	_	_	_	_
2-25	228-230	to	_	_	_	_
2-26	231-237	tackle	_	_	_	_
2-27	238-243	these	abstract[14]	giv[14]	coref	4-17[32_14]
2-28	244-250	issues	abstract[14]	giv[14]	_	_
2-29	251-252	.	_	_	_	_

#Text=Section 5.1 discusses the sources of bias in AVs ’ algorithms that can yield discrimination by disproportionately allocating more safety risks to some groups of individuals .
3-1	253-260	Section	organization[15]	giv[15]	coref	4-3[25_15]
3-2	261-264	5.1	organization[15]	giv[15]	_	_
3-3	265-274	discusses	_	_	_	_
3-4	275-278	the	abstract[16]	new[16]	_	_
3-5	279-286	sources	abstract[16]	new[16]	_	_
3-6	287-289	of	abstract[16]	new[16]	_	_
3-7	290-294	bias	abstract[16]|abstract[17]	new[16]|new[17]	coref	7-1[0_17]
3-8	295-297	in	abstract[16]|abstract[17]	new[16]|new[17]	_	_
3-9	298-301	AVs	abstract[16]|abstract[17]|abstract[18]|abstract[19]	new[16]|new[17]|giv[18]|new[19]	coref|coref	4-11[29_19]|10-6[0_18]
3-10	302-303	’	abstract[16]|abstract[17]|abstract[18]|abstract[19]	new[16]|new[17]|giv[18]|new[19]	_	_
3-11	304-314	algorithms	abstract[16]|abstract[17]|abstract[19]	new[16]|new[17]|new[19]	_	_
3-12	315-319	that	_	_	_	_
3-13	320-323	can	_	_	_	_
3-14	324-329	yield	_	_	_	_
3-15	330-344	discrimination	abstract	giv	coref	4-23
3-16	345-347	by	_	_	_	_
3-17	348-366	disproportionately	_	_	_	_
3-18	367-377	allocating	_	_	_	_
3-19	378-382	more	abstract[22]	giv[22]	coref	5-23[45_22]
3-20	383-389	safety	abstract|abstract[22]	giv|giv[22]	coref	4-20[34_0]
3-21	390-395	risks	abstract[22]	giv[22]	_	_
3-22	396-398	to	_	_	_	_
3-23	399-403	some	person[23]	new[23]	_	_
3-24	404-410	groups	person[23]	new[23]	_	_
3-25	411-413	of	person[23]	new[23]	_	_
3-26	414-425	individuals	person[23]|person	new[23]|new	coref	8-21[51_0]
3-27	426-427	.	_	_	_	_

#Text=Next , Section 5.2 explores approaches to incorporate ethics into AV algorithms ’ decision-making and highlight their implications for AV safety and discrimination .
4-1	428-432	Next	_	_	_	_
4-2	433-434	,	_	_	_	_
4-3	435-442	Section	organization[25]	giv[25]	coref	5-3[36_25]
4-4	443-446	5.2	organization[25]	giv[25]	_	_
4-5	447-455	explores	_	_	_	_
4-6	456-466	approaches	abstract	new	_	_
4-7	467-469	to	_	_	_	_
4-8	470-481	incorporate	_	_	_	_
4-9	482-488	ethics	abstract	new	_	_
4-10	489-493	into	_	_	_	_
4-11	494-496	AV	abstract|abstract[29]|abstract[30]	giv|giv[29]|giv[30]	ana|coref	4-17[0_29]|4-20
4-12	497-507	algorithms	abstract[29]|abstract[30]	giv[29]|giv[30]	_	_
4-13	508-509	’	abstract[29]|abstract[30]	giv[29]|giv[30]	_	_
4-14	510-525	decision-making	abstract[30]	giv[30]	_	_
4-15	526-529	and	_	_	_	_
4-16	530-539	highlight	_	_	_	_
4-17	540-545	their	abstract|abstract[32]	giv|giv[32]	coref|coref	5-13[41_0]|17-18[136_32]
4-18	546-558	implications	abstract[32]	giv[32]	_	_
4-19	559-562	for	abstract[32]	giv[32]	_	_
4-20	563-565	AV	abstract[32]|abstract|abstract[34]	giv[32]|giv|giv[34]	coref|coref	5-10|5-24[0_34]
4-21	566-572	safety	abstract[32]|abstract[34]	giv[32]|giv[34]	_	_
4-22	573-576	and	abstract[32]	giv[32]	_	_
4-23	577-591	discrimination	abstract[32]|abstract	giv[32]|giv	coref	5-27
4-24	592-593	.	_	_	_	_

#Text=Lastly , Section 5.3 examines how the incentives of AV stakeholders shape AV algorithms ’ design and resulting decisions that can introduce new safety risks and discrimination .
5-1	594-600	Lastly	_	_	_	_
5-2	601-602	,	_	_	_	_
5-3	603-610	Section	abstract[36]	giv[36]	coref	17-1[131_36]
5-4	611-614	5.3	abstract[36]	giv[36]	_	_
5-5	615-623	examines	_	_	_	_
5-6	624-627	how	_	_	_	_
5-7	628-631	the	abstract[37]	new[37]	coref	17-33[142_37]
5-8	632-642	incentives	abstract[37]	new[37]	_	_
5-9	643-645	of	abstract[37]	new[37]	_	_
5-10	646-648	AV	abstract[37]|organization|person[39]	new[37]|giv|new[39]	coref|coref	5-13|16-45[130_39]
5-11	649-661	stakeholders	abstract[37]|person[39]	new[37]|new[39]	_	_
5-12	662-667	shape	_	_	_	_
5-13	668-670	AV	abstract|abstract[41]|abstract[42]	giv|giv[41]|new[42]	coref|coref	12-5[81_0]|15-24[105_41]
5-14	671-681	algorithms	abstract[41]|abstract[42]	giv[41]|new[42]	_	_
5-15	682-683	’	abstract[41]|abstract[42]	giv[41]|new[42]	_	_
5-16	684-690	design	abstract[42]	new[42]	_	_
5-17	691-694	and	_	_	_	_
5-18	695-704	resulting	abstract[43]	new[43]	coref	24-7[0_43]
5-19	705-714	decisions	abstract[43]	new[43]	_	_
5-20	715-719	that	_	_	_	_
5-21	720-723	can	_	_	_	_
5-22	724-733	introduce	_	_	_	_
5-23	734-737	new	abstract[45]	giv[45]	coref	10-35[76_45]
5-24	738-744	safety	abstract|abstract[45]	giv|giv[45]	coref	10-35
5-25	745-750	risks	abstract[45]	giv[45]	_	_
5-26	751-754	and	abstract[45]	giv[45]	_	_
5-27	755-769	discrimination	abstract[45]|abstract	giv[45]|giv	coref	9-6
5-28	770-771	.	_	_	_	_

#Text=5.1 .
6-1	772-775	5.1	abstract	new	coref	15-45[110_0]
6-2	776-777	.	_	_	_	_

#Text=Bias
7-1	778-782	Bias	abstract	giv	coref	10-1

#Text=A system is considered biased when it contains “ intended ” or “ unintended ” characteristics that unfairly discriminate against certain individuals or groups of individuals in society .
8-1	783-784	A	abstract[49]	new[49]	ana	8-7[0_49]
8-2	785-791	system	abstract[49]	new[49]	_	_
8-3	792-794	is	_	_	_	_
8-4	795-805	considered	_	_	_	_
8-5	806-812	biased	_	_	_	_
8-6	813-817	when	_	_	_	_
8-7	818-820	it	abstract	giv	coref	21-23[192_0]
8-8	821-829	contains	_	_	_	_
8-9	830-831	“	_	_	_	_
8-10	832-840	intended	_	_	_	_
8-11	841-842	”	_	_	_	_
8-12	843-845	or	_	_	_	_
8-13	846-847	“	_	_	_	_
8-14	848-858	unintended	_	_	_	_
8-15	859-860	”	_	_	_	_
8-16	861-876	characteristics	_	_	_	_
8-17	877-881	that	_	_	_	_
8-18	882-890	unfairly	_	_	_	_
8-19	891-903	discriminate	_	_	_	_
8-20	904-911	against	_	_	_	_
8-21	912-919	certain	person[51]	giv[51]	coref	15-59[0_51]
8-22	920-931	individuals	person[51]	giv[51]	_	_
8-23	932-934	or	person[51]	giv[51]	_	_
8-24	935-941	groups	person[51]|person[52]	giv[51]|new[52]	coref	9-30[62_52]
8-25	942-944	of	person[51]|person[52]	giv[51]|new[52]	_	_
8-26	945-956	individuals	person[51]|person[52]	giv[51]|new[52]	_	_
8-27	957-959	in	person[51]|person[52]	giv[51]|new[52]	_	_
8-28	960-967	society	person[51]|person[52]|abstract	giv[51]|new[52]|new	_	_
8-29	968-969	.	_	_	_	_

#Text=In American anti-discrimination law , discrimination exists when there is disparate treatment , which is the “ discriminatory intent or the formal application of different rules to people of different groups ” , and/or disparate impact , which is the result that “ differ for different groups ” .
9-1	970-972	In	_	_	_	_
9-2	973-981	American	abstract[55]	new[55]	_	_
9-3	982-1001	anti-discrimination	abstract|abstract[55]	new|new[55]	_	_
9-4	1002-1005	law	abstract[55]	new[55]	_	_
9-5	1006-1007	,	_	_	_	_
9-6	1008-1022	discrimination	abstract	giv	coref	19-59
9-7	1023-1029	exists	_	_	_	_
9-8	1030-1034	when	_	_	_	_
9-9	1035-1040	there	_	_	_	_
9-10	1041-1043	is	_	_	_	_
9-11	1044-1053	disparate	abstract[57]	new[57]	_	_
9-12	1054-1063	treatment	abstract[57]	new[57]	_	_
9-13	1064-1065	,	_	_	_	_
9-14	1066-1071	which	_	_	_	_
9-15	1072-1074	is	_	_	_	_
9-16	1075-1078	the	abstract[58]	new[58]	coref	25-53[236_58]
9-17	1079-1080	“	abstract[58]	new[58]	_	_
9-18	1081-1095	discriminatory	abstract[58]	new[58]	_	_
9-19	1096-1102	intent	abstract[58]	new[58]	_	_
9-20	1103-1105	or	_	_	_	_
9-21	1106-1109	the	abstract[59]	new[59]	_	_
9-22	1110-1116	formal	abstract[59]	new[59]	_	_
9-23	1117-1128	application	abstract[59]	new[59]	_	_
9-24	1129-1131	of	abstract[59]	new[59]	_	_
9-25	1132-1141	different	abstract[59]|abstract[60]	new[59]|new[60]	_	_
9-26	1142-1147	rules	abstract[59]|abstract[60]	new[59]|new[60]	_	_
9-27	1148-1150	to	abstract[59]|abstract[60]	new[59]|new[60]	_	_
9-28	1151-1157	people	abstract[59]|abstract[60]|person[61]	new[59]|new[60]|new[61]	coref	27-9[0_61]
9-29	1158-1160	of	abstract[59]|abstract[60]|person[61]	new[59]|new[60]|new[61]	_	_
9-30	1161-1170	different	abstract[59]|abstract[60]|person[61]|person[62]	new[59]|new[60]|new[61]|giv[62]	coref	9-46[65_62]
9-31	1171-1177	groups	abstract[59]|abstract[60]|person[61]|person[62]	new[59]|new[60]|new[61]|giv[62]	_	_
9-32	1178-1179	”	_	_	_	_
9-33	1180-1181	,	_	_	_	_
9-34	1182-1188	and/or	abstract[63]	new[63]	_	_
9-35	1189-1198	disparate	abstract[63]	new[63]	_	_
9-36	1199-1205	impact	abstract[63]	new[63]	_	_
9-37	1206-1207	,	_	_	_	_
9-38	1208-1213	which	_	_	_	_
9-39	1214-1216	is	_	_	_	_
9-40	1217-1220	the	abstract[64]	new[64]	_	_
9-41	1221-1227	result	abstract[64]	new[64]	_	_
9-42	1228-1232	that	_	_	_	_
9-43	1233-1234	“	_	_	_	_
9-44	1235-1241	differ	_	_	_	_
9-45	1242-1245	for	_	_	_	_
9-46	1246-1255	different	person[65]	giv[65]	coref	13-8[91_65]
9-47	1256-1262	groups	person[65]	giv[65]	_	_
9-48	1263-1264	”	_	_	_	_
9-49	1265-1266	.	_	_	_	_

#Text=Bias can be introduced into AVs during the human designers ’ construction of the datasets , models , and the parameters of the algorithm , which potentially leads to unfair or discriminatory allocations of safety risks .
10-1	1267-1271	Bias	person	giv	coref	11-3[77_0]
10-2	1272-1275	can	_	_	_	_
10-3	1276-1278	be	_	_	_	_
10-4	1279-1289	introduced	_	_	_	_
10-5	1290-1294	into	_	_	_	_
10-6	1295-1298	AVs	abstract	giv	coref	15-25[104_0]
10-7	1299-1305	during	_	_	_	_
10-8	1306-1309	the	place[69]	new[69]	_	_
10-9	1310-1315	human	person[68]|place[69]	new[68]|new[69]	coref	16-12[119_68]
10-10	1316-1325	designers	person[68]|place[69]	new[68]|new[69]	_	_
10-11	1326-1327	’	person[68]|place[69]	new[68]|new[69]	_	_
10-12	1328-1340	construction	place[69]	new[69]	_	_
10-13	1341-1343	of	place[69]	new[69]	_	_
10-14	1344-1347	the	place[69]|object[70]	new[69]|new[70]	_	_
10-15	1348-1356	datasets	place[69]|object[70]	new[69]|new[70]	_	_
10-16	1357-1358	,	place[69]	new[69]	_	_
10-17	1359-1365	models	place[69]|abstract	new[69]|new	_	_
10-18	1366-1367	,	place[69]	new[69]	_	_
10-19	1368-1371	and	place[69]	new[69]	_	_
10-20	1372-1375	the	place[69]|abstract[72]	new[69]|new[72]	_	_
10-21	1376-1386	parameters	place[69]|abstract[72]	new[69]|new[72]	_	_
10-22	1387-1389	of	place[69]|abstract[72]	new[69]|new[72]	_	_
10-23	1390-1393	the	place[69]|abstract[72]|abstract[73]	new[69]|new[72]|new[73]	coref	14-3[95_73]
10-24	1394-1403	algorithm	place[69]|abstract[72]|abstract[73]	new[69]|new[72]|new[73]	_	_
10-25	1404-1405	,	_	_	_	_
10-26	1406-1411	which	_	_	_	_
10-27	1412-1423	potentially	_	_	_	_
10-28	1424-1429	leads	_	_	_	_
10-29	1430-1432	to	_	_	_	_
10-30	1433-1439	unfair	abstract[74]	new[74]	_	_
10-31	1440-1442	or	abstract[74]	new[74]	_	_
10-32	1443-1457	discriminatory	abstract[74]	new[74]	_	_
10-33	1458-1469	allocations	abstract[74]	new[74]	_	_
10-34	1470-1472	of	abstract[74]	new[74]	_	_
10-35	1473-1479	safety	abstract[74]|abstract|abstract[76]	new[74]|giv|giv[76]	coref|coref	15-39[108_0]|15-52[113_76]
10-36	1480-1485	risks	abstract[74]|abstract[76]	new[74]|giv[76]	_	_
10-37	1486-1487	.	_	_	_	_

#Text=Firstly , statistical bias exists when the input data are not statistically representative of the overall population .
11-1	1488-1495	Firstly	_	_	_	_
11-2	1496-1497	,	_	_	_	_
11-3	1498-1509	statistical	abstract[77]	giv[77]	coref	15-7[101_77]
11-4	1510-1514	bias	abstract[77]	giv[77]	_	_
11-5	1515-1521	exists	_	_	_	_
11-6	1522-1526	when	_	_	_	_
11-7	1527-1530	the	abstract[79]	new[79]	coref	12-8[0_79]
11-8	1531-1536	input	abstract|abstract[79]	new|new[79]	coref	14-18
11-9	1537-1541	data	abstract[79]	new[79]	_	_
11-10	1542-1545	are	_	_	_	_
11-11	1546-1549	not	_	_	_	_
11-12	1550-1563	statistically	_	_	_	_
11-13	1564-1578	representative	_	_	_	_
11-14	1579-1581	of	_	_	_	_
11-15	1582-1585	the	abstract[80]	new[80]	_	_
11-16	1586-1593	overall	abstract[80]	new[80]	_	_
11-17	1594-1604	population	abstract[80]	new[80]	_	_
11-18	1605-1606	.	_	_	_	_

#Text=For instance , training an AV using data from only one country could result in the AV learning localised patterns and not accurately modelling driving behaviours that apply in other countries or contexts .
12-1	1607-1610	For	_	_	_	_
12-2	1611-1619	instance	_	_	_	_
12-3	1620-1621	,	_	_	_	_
12-4	1622-1630	training	_	_	_	_
12-5	1631-1633	an	abstract[81]	giv[81]	coref	12-16[84_81]
12-6	1634-1636	AV	abstract[81]	giv[81]	_	_
12-7	1637-1642	using	_	_	_	_
12-8	1643-1647	data	abstract	giv	_	_
12-9	1648-1652	from	_	_	_	_
12-10	1653-1657	only	place[83]	new[83]	_	_
12-11	1658-1661	one	place[83]	new[83]	_	_
12-12	1662-1669	country	place[83]	new[83]	_	_
12-13	1670-1675	could	_	_	_	_
12-14	1676-1682	result	_	_	_	_
12-15	1683-1685	in	_	_	_	_
12-16	1686-1689	the	abstract[84]	giv[84]	coref	16-15[0_84]
12-17	1690-1692	AV	abstract[84]	giv[84]	_	_
12-18	1693-1701	learning	_	_	_	_
12-19	1702-1711	localised	abstract[85]	new[85]	_	_
12-20	1712-1720	patterns	abstract[85]	new[85]	_	_
12-21	1721-1724	and	_	_	_	_
12-22	1725-1728	not	_	_	_	_
12-23	1729-1739	accurately	_	_	_	_
12-24	1740-1749	modelling	_	_	_	_
12-25	1750-1757	driving	_	_	_	_
12-26	1758-1768	behaviours	abstract	new	_	_
12-27	1769-1773	that	_	_	_	_
12-28	1774-1779	apply	_	_	_	_
12-29	1780-1782	in	_	_	_	_
12-30	1783-1788	other	place[87]	new[87]	_	_
12-31	1789-1798	countries	place[87]	new[87]	_	_
12-32	1799-1801	or	_	_	_	_
12-33	1802-1810	contexts	abstract	new	_	_
12-34	1811-1812	.	_	_	_	_

#Text=Thus , the under- or overrepresentation of certain groups in the data can lead to inaccurate classifications and biased outcomes .
13-1	1813-1817	Thus	_	_	_	_
13-2	1818-1819	,	_	_	_	_
13-3	1820-1823	the	abstract[89]	new[89]	_	_
13-4	1824-1830	under-	abstract[89]	new[89]	_	_
13-5	1831-1833	or	_	_	_	_
13-6	1834-1852	overrepresentation	abstract[90]	new[90]	_	_
13-7	1853-1855	of	abstract[90]	new[90]	_	_
13-8	1856-1863	certain	abstract[90]|person[91]	new[90]|giv[91]	coref	19-32[160_91]
13-9	1864-1870	groups	abstract[90]|person[91]	new[90]|giv[91]	_	_
13-10	1871-1873	in	abstract[90]|person[91]	new[90]|giv[91]	_	_
13-11	1874-1877	the	abstract[90]|person[91]|abstract[92]	new[90]|giv[91]|new[92]	coref	19-45[163_92]
13-12	1878-1882	data	abstract[90]|person[91]|abstract[92]	new[90]|giv[91]|new[92]	_	_
13-13	1883-1886	can	_	_	_	_
13-14	1887-1891	lead	_	_	_	_
13-15	1892-1894	to	_	_	_	_
13-16	1895-1905	inaccurate	abstract[93]	new[93]	_	_
13-17	1906-1921	classifications	abstract[93]	new[93]	_	_
13-18	1922-1925	and	_	_	_	_
13-19	1926-1932	biased	abstract[94]	new[94]	coref	18-10[149_94]
13-20	1933-1941	outcomes	abstract[94]	new[94]	_	_
13-21	1942-1943	.	_	_	_	_

#Text=Secondly , the algorithm can be biased relative to legal and moral standards if it utilises sensitive input variables .
14-1	1944-1952	Secondly	_	_	_	_
14-2	1953-1954	,	_	_	_	_
14-3	1955-1958	the	abstract[95]	giv[95]	ana	14-15[0_95]
14-4	1959-1968	algorithm	abstract[95]	giv[95]	_	_
14-5	1969-1972	can	_	_	_	_
14-6	1973-1975	be	_	_	_	_
14-7	1976-1982	biased	_	_	_	_
14-8	1983-1991	relative	_	_	_	_
14-9	1992-1994	to	_	_	_	_
14-10	1995-2000	legal	abstract[96]	new[96]	coref	20-20[183_96]
14-11	2001-2004	and	abstract[96]	new[96]	_	_
14-12	2005-2010	moral	abstract[96]	new[96]	_	_
14-13	2011-2020	standards	abstract[96]	new[96]	_	_
14-14	2021-2023	if	_	_	_	_
14-15	2024-2026	it	abstract	giv	coref	15-31[106_0]
14-16	2027-2035	utilises	_	_	_	_
14-17	2036-2045	sensitive	abstract[99]	new[99]	coref	20-11[179_99]
14-18	2046-2051	input	abstract|abstract[99]	giv|new[99]	coref	21-17
14-19	2052-2061	variables	abstract[99]	new[99]	_	_
14-20	2062-2063	.	_	_	_	_

#Text=Individual-specific characteristics , such as a person ’s age and gender that are used as decision-making criteria can be penalised or privileged by the AVs ’ algorithms to meet the algorithm ’s pre-defined preferences , such as prioritising the safety of children or minimising the total quantity of harm , causing more safety risks to be allocated to individuals that share the penalised characteristics .
15-1	2064-2083	Individual-specific	abstract[100]	new[100]	coref	15-62[115_100]
15-2	2084-2099	characteristics	abstract[100]	new[100]	_	_
15-3	2100-2101	,	abstract[100]	new[100]	_	_
15-4	2102-2106	such	abstract[100]	new[100]	_	_
15-5	2107-2109	as	abstract[100]	new[100]	_	_
15-6	2110-2111	a	abstract[100]|abstract[102]	new[100]|new[102]	_	_
15-7	2112-2118	person	abstract[100]|person[101]|abstract[102]	new[100]|giv[101]|new[102]	coref	16-4[0_101]
15-8	2119-2121	’s	abstract[100]|person[101]|abstract[102]	new[100]|giv[101]|new[102]	_	_
15-9	2122-2125	age	abstract[100]|abstract[102]	new[100]|new[102]	_	_
15-10	2126-2129	and	abstract[100]	new[100]	_	_
15-11	2130-2136	gender	abstract[100]|abstract	new[100]|new	_	_
15-12	2137-2141	that	_	_	_	_
15-13	2142-2145	are	_	_	_	_
15-14	2146-2150	used	_	_	_	_
15-15	2151-2153	as	_	_	_	_
15-16	2154-2169	decision-making	_	_	_	_
15-17	2170-2178	criteria	_	_	_	_
15-18	2179-2182	can	_	_	_	_
15-19	2183-2185	be	_	_	_	_
15-20	2186-2195	penalised	_	_	_	_
15-21	2196-2198	or	_	_	_	_
15-22	2199-2209	privileged	_	_	_	_
15-23	2210-2212	by	_	_	_	_
15-24	2213-2216	the	abstract[105]	giv[105]	coref	17-44[146_105]
15-25	2217-2220	AVs	abstract[104]|abstract[105]	giv[104]|giv[105]	coref	17-11[0_104]
15-26	2221-2222	’	abstract[104]|abstract[105]	giv[104]|giv[105]	_	_
15-27	2223-2233	algorithms	abstract[105]	giv[105]	_	_
15-28	2234-2236	to	_	_	_	_
15-29	2237-2241	meet	_	_	_	_
15-30	2242-2245	the	abstract[107]	new[107]	coref	17-7[133_107]
15-31	2246-2255	algorithm	abstract[106]|abstract[107]	giv[106]|new[107]	coref	16-12[0_106]
15-32	2256-2258	’s	abstract[106]|abstract[107]	giv[106]|new[107]	_	_
15-33	2259-2270	pre-defined	abstract[107]	new[107]	_	_
15-34	2271-2282	preferences	abstract[107]	new[107]	_	_
15-35	2283-2284	,	_	_	_	_
15-36	2285-2289	such	_	_	_	_
15-37	2290-2292	as	_	_	_	_
15-38	2293-2305	prioritising	_	_	_	_
15-39	2306-2309	the	abstract[108]	giv[108]	coref	15-53[0_108]
15-40	2310-2316	safety	abstract[108]	giv[108]	_	_
15-41	2317-2319	of	abstract[108]	giv[108]	_	_
15-42	2320-2328	children	abstract[108]|person	giv[108]|new	_	_
15-43	2329-2331	or	_	_	_	_
15-44	2332-2342	minimising	_	_	_	_
15-45	2343-2346	the	abstract[110]	giv[110]	_	_
15-46	2347-2352	total	abstract[110]	giv[110]	_	_
15-47	2353-2361	quantity	abstract[110]	giv[110]	_	_
15-48	2362-2364	of	abstract[110]	giv[110]	_	_
15-49	2365-2369	harm	abstract[110]|abstract	giv[110]|new	_	_
15-50	2370-2371	,	_	_	_	_
15-51	2372-2379	causing	_	_	_	_
15-52	2380-2384	more	abstract[113]	giv[113]	coref	17-21[139_113]
15-53	2385-2391	safety	abstract|abstract[113]	giv|giv[113]	_	_
15-54	2392-2397	risks	abstract[113]	giv[113]	_	_
15-55	2398-2400	to	_	_	_	_
15-56	2401-2403	be	_	_	_	_
15-57	2404-2413	allocated	_	_	_	_
15-58	2414-2416	to	_	_	_	_
15-59	2417-2428	individuals	person	giv	coref	19-49[164_0]
15-60	2429-2433	that	_	_	_	_
15-61	2434-2439	share	_	_	_	_
15-62	2440-2443	the	abstract[115]	giv[115]	_	_
15-63	2444-2453	penalised	abstract[115]	giv[115]	_	_
15-64	2454-2469	characteristics	abstract[115]	giv[115]	_	_
15-65	2470-2471	.	_	_	_	_

#Text=These forms of bias can be introduced unintentionally or intentionally by algorithm designers and AV manufacturers to maximise profits , such as prioritising the safety of AV passengers to maximise profits , and this is exacerbated by the lack of legal frameworks to hold these stakeholders accountable .
16-1	2472-2477	These	abstract[116]	new[116]	_	_
16-2	2478-2483	forms	abstract[116]	new[116]	_	_
16-3	2484-2486	of	abstract[116]	new[116]	_	_
16-4	2487-2491	bias	abstract[116]|abstract	new[116]|giv	coref	18-2
16-5	2492-2495	can	_	_	_	_
16-6	2496-2498	be	_	_	_	_
16-7	2499-2509	introduced	_	_	_	_
16-8	2510-2525	unintentionally	_	_	_	_
16-9	2526-2528	or	_	_	_	_
16-10	2529-2542	intentionally	_	_	_	_
16-11	2543-2545	by	_	_	_	_
16-12	2546-2555	algorithm	abstract|person[119]	giv|giv[119]	coref|coref	23-18[210_0]|23-25[211_119]
16-13	2556-2565	designers	person[119]	giv[119]	_	_
16-14	2566-2569	and	person[119]	giv[119]	_	_
16-15	2570-2572	AV	person[119]|object|organization[121]	giv[119]|giv|new[121]	coref	16-27
16-16	2573-2586	manufacturers	person[119]|organization[121]	giv[119]|new[121]	_	_
16-17	2587-2589	to	_	_	_	_
16-18	2590-2598	maximise	_	_	_	_
16-19	2599-2606	profits	abstract	new	coref	16-31
16-20	2607-2608	,	_	_	_	_
16-21	2609-2613	such	_	_	_	_
16-22	2614-2616	as	_	_	_	_
16-23	2617-2629	prioritising	_	_	_	_
16-24	2630-2633	the	abstract[123]	new[123]	ana	16-34[0_123]
16-25	2634-2640	safety	abstract[123]	new[123]	_	_
16-26	2641-2643	of	abstract[123]	new[123]	_	_
16-27	2644-2646	AV	abstract[123]|organization|person[125]	new[123]|giv|new[125]	coref	17-21
16-28	2647-2657	passengers	abstract[123]|person[125]	new[123]|new[125]	_	_
16-29	2658-2660	to	_	_	_	_
16-30	2661-2669	maximise	_	_	_	_
16-31	2670-2677	profits	abstract	giv	_	_
16-32	2678-2679	,	_	_	_	_
16-33	2680-2683	and	_	_	_	_
16-34	2684-2688	this	abstract	giv	coref	17-22
16-35	2689-2691	is	_	_	_	_
16-36	2692-2703	exacerbated	_	_	_	_
16-37	2704-2706	by	_	_	_	_
16-38	2707-2710	the	abstract[128]	new[128]	_	_
16-39	2711-2715	lack	abstract[128]	new[128]	_	_
16-40	2716-2718	of	abstract[128]	new[128]	_	_
16-41	2719-2724	legal	abstract[128]|abstract[129]	new[128]|new[129]	_	_
16-42	2725-2735	frameworks	abstract[128]|abstract[129]	new[128]|new[129]	_	_
16-43	2736-2738	to	_	_	_	_
16-44	2739-2743	hold	_	_	_	_
16-45	2744-2749	these	person[130]	giv[130]	_	_
16-46	2750-2762	stakeholders	person[130]	giv[130]	_	_
16-47	2763-2774	accountable	_	_	_	_
16-48	2775-2776	.	_	_	_	_

#Text=Section 5.2 explores various types of ethical preferences to which AVs may be programmed to follow and their implications of AV safety risks in greater detail , and Section 5.3 explores how perverse incentives influence the choice of preferences that are programmed into AVs ’ algorithms .
17-1	2777-2784	Section	organization[131]	giv[131]	coref	17-29[141_131]
17-2	2785-2788	5.2	organization[131]	giv[131]	_	_
17-3	2789-2797	explores	_	_	_	_
17-4	2798-2805	various	abstract[132]	new[132]	_	_
17-5	2806-2811	types	abstract[132]	new[132]	_	_
17-6	2812-2814	of	abstract[132]	new[132]	_	_
17-7	2815-2822	ethical	abstract[132]|abstract[133]	new[132]|giv[133]	ana	17-18[0_133]
17-8	2823-2834	preferences	abstract[132]|abstract[133]	new[132]|giv[133]	_	_
17-9	2835-2837	to	_	_	_	_
17-10	2838-2843	which	_	_	_	_
17-11	2844-2847	AVs	abstract	giv	coref	17-44[145_0]
17-12	2848-2851	may	_	_	_	_
17-13	2852-2854	be	_	_	_	_
17-14	2855-2865	programmed	_	_	_	_
17-15	2866-2868	to	_	_	_	_
17-16	2869-2875	follow	_	_	_	_
17-17	2876-2879	and	_	_	_	_
17-18	2880-2885	their	abstract|abstract[136]	giv|giv[136]	coref	17-39
17-19	2886-2898	implications	abstract[136]	giv[136]	_	_
17-20	2899-2901	of	abstract[136]	giv[136]	_	_
17-21	2902-2904	AV	abstract[136]|abstract|abstract[139]	giv[136]|giv|giv[139]	coref	27-13[253_139]
17-22	2905-2911	safety	abstract[136]|abstract|abstract[139]	giv[136]|giv|giv[139]	coref	21-53
17-23	2912-2917	risks	abstract[136]|abstract[139]	giv[136]|giv[139]	_	_
17-24	2918-2920	in	abstract[136]|abstract[139]	giv[136]|giv[139]	_	_
17-25	2921-2928	greater	abstract[136]|abstract[139]|abstract[140]	giv[136]|giv[139]|new[140]	_	_
17-26	2929-2935	detail	abstract[136]|abstract[139]|abstract[140]	giv[136]|giv[139]|new[140]	_	_
17-27	2936-2937	,	_	_	_	_
17-28	2938-2941	and	_	_	_	_
17-29	2942-2949	Section	abstract[141]	giv[141]	_	_
17-30	2950-2953	5.3	abstract[141]	giv[141]	_	_
17-31	2954-2962	explores	_	_	_	_
17-32	2963-2966	how	_	_	_	_
17-33	2967-2975	perverse	abstract[142]	giv[142]	_	_
17-34	2976-2986	incentives	abstract[142]	giv[142]	_	_
17-35	2987-2996	influence	_	_	_	_
17-36	2997-3000	the	abstract[143]	new[143]	_	_
17-37	3001-3007	choice	abstract[143]	new[143]	_	_
17-38	3008-3010	of	abstract[143]	new[143]	_	_
17-39	3011-3022	preferences	abstract[143]|abstract	new[143]|giv	coref	26-14[242_0]
17-40	3023-3027	that	_	_	_	_
17-41	3028-3031	are	_	_	_	_
17-42	3032-3042	programmed	_	_	_	_
17-43	3043-3047	into	_	_	_	_
17-44	3048-3051	AVs	abstract[145]|abstract[146]	giv[145]|giv[146]	coref|coref	18-4[0_146]|18-13[0_145]
17-45	3052-3053	’	abstract[145]|abstract[146]	giv[145]|giv[146]	_	_
17-46	3054-3064	algorithms	abstract[146]	giv[146]	_	_
17-47	3065-3066	.	_	_	_	_

#Text=Lessening bias in algorithms is therefore crucial to mitigate discriminatory outcomes from AVs .
18-1	3067-3076	Lessening	_	_	_	_
18-2	3077-3081	bias	abstract	giv	coref	19-18
18-3	3082-3084	in	_	_	_	_
18-4	3085-3095	algorithms	abstract	giv	coref	19-73
18-5	3096-3098	is	_	_	_	_
18-6	3099-3108	therefore	_	_	_	_
18-7	3109-3116	crucial	_	_	_	_
18-8	3117-3119	to	_	_	_	_
18-9	3120-3128	mitigate	_	_	_	_
18-10	3129-3143	discriminatory	abstract[149]	giv[149]	coref	26-8[240_149]
18-11	3144-3152	outcomes	abstract[149]	giv[149]	_	_
18-12	3153-3157	from	_	_	_	_
18-13	3158-3161	AVs	abstract	giv	coref	26-12[241_0]
18-14	3162-3163	.	_	_	_	_

#Text=In autonomous systems in general , scholars have recommended ways to detect and offset the effects of bias , such as modifying algorithmic outputs to balance the effects of bias between protected and unprotected groups , introducing minimally intrusive modification to remove bias from the data , incorporating individuals from potentially discriminated groups , testing techniques to measure discrimination and identify groups of users significantly affected by bias in software and creating algorithms that certify the absence of data bias .
19-1	3164-3166	In	_	_	_	_
19-2	3167-3177	autonomous	abstract[151]	new[151]	_	_
19-3	3178-3185	systems	abstract[151]	new[151]	_	_
19-4	3186-3188	in	abstract[151]	new[151]	_	_
19-5	3189-3196	general	abstract[151]|abstract	new[151]|new	_	_
19-6	3197-3198	,	_	_	_	_
19-7	3199-3207	scholars	person	new	coref	21-3
19-8	3208-3212	have	_	_	_	_
19-9	3213-3224	recommended	_	_	_	_
19-10	3225-3229	ways	abstract	new	_	_
19-11	3230-3232	to	_	_	_	_
19-12	3233-3239	detect	_	_	_	_
19-13	3240-3243	and	_	_	_	_
19-14	3244-3250	offset	_	_	_	_
19-15	3251-3254	the	abstract[155]	new[155]	_	_
19-16	3255-3262	effects	abstract[155]	new[155]	_	_
19-17	3263-3265	of	abstract[155]	new[155]	_	_
19-18	3266-3270	bias	abstract[155]|abstract	new[155]|giv	coref	19-30[159_0]
19-19	3271-3272	,	_	_	_	_
19-20	3273-3277	such	_	_	_	_
19-21	3278-3280	as	_	_	_	_
19-22	3281-3290	modifying	_	_	_	_
19-23	3291-3302	algorithmic	abstract[157]	new[157]	coref	21-45[199_157]
19-24	3303-3310	outputs	abstract[157]	new[157]	_	_
19-25	3311-3313	to	_	_	_	_
19-26	3314-3321	balance	_	_	_	_
19-27	3322-3325	the	abstract[158]	new[158]	coref	22-12[206_158]
19-28	3326-3333	effects	abstract[158]	new[158]	_	_
19-29	3334-3336	of	abstract[158]	new[158]	_	_
19-30	3337-3341	bias	abstract[158]|abstract[159]	new[158]|giv[159]	coref	19-43[0_159]
19-31	3342-3349	between	abstract[158]|abstract[159]	new[158]|giv[159]	_	_
19-32	3350-3359	protected	abstract[158]|abstract[159]|person[160]	new[158]|giv[159]|giv[160]	coref	19-51[165_160]
19-33	3360-3363	and	abstract[158]|abstract[159]|person[160]	new[158]|giv[159]|giv[160]	_	_
19-34	3364-3375	unprotected	abstract[158]|abstract[159]|person[160]	new[158]|giv[159]|giv[160]	_	_
19-35	3376-3382	groups	abstract[158]|abstract[159]|person[160]	new[158]|giv[159]|giv[160]	_	_
19-36	3383-3384	,	_	_	_	_
19-37	3385-3396	introducing	_	_	_	_
19-38	3397-3406	minimally	abstract[161]	new[161]	_	_
19-39	3407-3416	intrusive	abstract[161]	new[161]	_	_
19-40	3417-3429	modification	abstract[161]	new[161]	_	_
19-41	3430-3432	to	_	_	_	_
19-42	3433-3439	remove	_	_	_	_
19-43	3440-3444	bias	abstract	giv	coref	19-68[170_0]
19-44	3445-3449	from	_	_	_	_
19-45	3450-3453	the	abstract[163]	giv[163]	coref	19-79[0_163]
19-46	3454-3458	data	abstract[163]	giv[163]	_	_
19-47	3459-3460	,	_	_	_	_
19-48	3461-3474	incorporating	_	_	_	_
19-49	3475-3486	individuals	person[164]	giv[164]	_	_
19-50	3487-3491	from	person[164]	giv[164]	_	_
19-51	3492-3503	potentially	person[164]|person[165]	giv[164]|giv[165]	_	_
19-52	3504-3517	discriminated	person[164]|person[165]	giv[164]|giv[165]	_	_
19-53	3518-3524	groups	person[164]|person[165]	giv[164]|giv[165]	_	_
19-54	3525-3526	,	_	_	_	_
19-55	3527-3534	testing	_	_	_	_
19-56	3535-3545	techniques	abstract	new	_	_
19-57	3546-3548	to	_	_	_	_
19-58	3549-3556	measure	_	_	_	_
19-59	3557-3571	discrimination	abstract	giv	coref	27-18[254_0]
19-60	3572-3575	and	_	_	_	_
19-61	3576-3584	identify	_	_	_	_
19-62	3585-3591	groups	person[168]	new[168]	_	_
19-63	3592-3594	of	person[168]	new[168]	_	_
19-64	3595-3600	users	person[168]|person	new[168]|new	_	_
19-65	3601-3614	significantly	_	_	_	_
19-66	3615-3623	affected	_	_	_	_
19-67	3624-3626	by	_	_	_	_
19-68	3627-3631	bias	abstract[170]	giv[170]	coref	19-79[175_170]
19-69	3632-3634	in	abstract[170]	giv[170]	_	_
19-70	3635-3643	software	abstract[170]|abstract	giv[170]|new	_	_
19-71	3644-3647	and	_	_	_	_
19-72	3648-3656	creating	_	_	_	_
19-73	3657-3667	algorithms	abstract	giv	coref	21-14
19-74	3668-3672	that	_	_	_	_
19-75	3673-3680	certify	_	_	_	_
19-76	3681-3684	the	abstract[173]	new[173]	_	_
19-77	3685-3692	absence	abstract[173]	new[173]	_	_
19-78	3693-3695	of	abstract[173]	new[173]	_	_
19-79	3696-3700	data	abstract[173]|abstract|abstract[175]	new[173]|giv|giv[175]	coref|coref	20-3[0_175]|20-6[177_0]
19-80	3701-3705	bias	abstract[173]|abstract[175]	new[173]|giv[175]	_	_
19-81	3706-3707	.	_	_	_	_

#Text=Apart from bias originating from the data and selection of variables and criterion , Danks and London recommend clarifying ethical standards such as fairness to evaluate bias .
20-1	3708-3713	Apart	_	_	_	_
20-2	3714-3718	from	_	_	_	_
20-3	3719-3723	bias	abstract	giv	coref	20-27
20-4	3724-3735	originating	_	_	_	_
20-5	3736-3740	from	_	_	_	_
20-6	3741-3744	the	abstract[177]	giv[177]	coref	24-11[219_177]
20-7	3745-3749	data	abstract[177]	giv[177]	_	_
20-8	3750-3753	and	abstract[177]	giv[177]	_	_
20-9	3754-3763	selection	abstract[177]|abstract[178]	giv[177]|new[178]	_	_
20-10	3764-3766	of	abstract[177]|abstract[178]	giv[177]|new[178]	_	_
20-11	3767-3776	variables	abstract[177]|abstract[178]|abstract[179]	giv[177]|new[178]|giv[179]	coref	21-15[191_179]
20-12	3777-3780	and	abstract[177]|abstract[178]|abstract[179]	giv[177]|new[178]|giv[179]	_	_
20-13	3781-3790	criterion	abstract[177]|abstract[178]|abstract[179]|abstract	giv[177]|new[178]|giv[179]|new	_	_
20-14	3791-3792	,	abstract[177]|abstract[178]|abstract[179]	giv[177]|new[178]|giv[179]	_	_
20-15	3793-3798	Danks	abstract[177]|abstract[178]|abstract[179]|person	giv[177]|new[178]|giv[179]|new	_	_
20-16	3799-3802	and	abstract[177]|abstract[178]|abstract[179]	giv[177]|new[178]|giv[179]	_	_
20-17	3803-3809	London	abstract[177]|abstract[178]|abstract[179]|person	giv[177]|new[178]|giv[179]|new	_	_
20-18	3810-3819	recommend	_	_	_	_
20-19	3820-3830	clarifying	_	_	_	_
20-20	3831-3838	ethical	abstract[183]	giv[183]	_	_
20-21	3839-3848	standards	abstract[183]	giv[183]	_	_
20-22	3849-3853	such	abstract[183]	giv[183]	_	_
20-23	3854-3856	as	abstract[183]	giv[183]	_	_
20-24	3857-3865	fairness	abstract[183]|abstract	giv[183]|new	_	_
20-25	3866-3868	to	_	_	_	_
20-26	3869-3877	evaluate	_	_	_	_
20-27	3878-3882	bias	abstract	giv	coref	22-8[203_0]
20-28	3883-3884	.	_	_	_	_

#Text=Furthermore , scholars recommend increasing transparency to identify biases , such as designing algorithms whose original input variables can be traced throughout the system ( i. e. , traceability ) and auditing algorithms to enhance their interpretability so that biases can be detected and the system ’s outputs can be verified against safety requirements .
21-1	3885-3896	Furthermore	_	_	_	_
21-2	3897-3898	,	_	_	_	_
21-3	3899-3907	scholars	person	giv	_	_
21-4	3908-3917	recommend	_	_	_	_
21-5	3918-3928	increasing	abstract[187]	new[187]	_	_
21-6	3929-3941	transparency	abstract[187]	new[187]	_	_
21-7	3942-3944	to	_	_	_	_
21-8	3945-3953	identify	_	_	_	_
21-9	3954-3960	biases	abstract	new	coref	21-40
21-10	3961-3962	,	_	_	_	_
21-11	3963-3967	such	_	_	_	_
21-12	3968-3970	as	_	_	_	_
21-13	3971-3980	designing	_	_	_	_
21-14	3981-3991	algorithms	abstract	giv	coref	21-33
21-15	3992-3997	whose	abstract[191]	giv[191]	ana	22-12[0_191]
21-16	3998-4006	original	abstract[191]	giv[191]	_	_
21-17	4007-4012	input	abstract|abstract[191]	giv|giv[191]	_	_
21-18	4013-4022	variables	abstract[191]	giv[191]	_	_
21-19	4023-4026	can	_	_	_	_
21-20	4027-4029	be	_	_	_	_
21-21	4030-4036	traced	_	_	_	_
21-22	4037-4047	throughout	_	_	_	_
21-23	4048-4051	the	abstract[192]	giv[192]	coref	21-46[198_192]
21-24	4052-4058	system	abstract[192]	giv[192]	_	_
21-25	4059-4060	(	_	_	_	_
21-26	4061-4063	i.	_	_	_	_
21-27	4064-4066	e.	_	_	_	_
21-28	4067-4068	,	_	_	_	_
21-29	4069-4081	traceability	abstract	new	_	_
21-30	4082-4083	)	_	_	_	_
21-31	4084-4087	and	_	_	_	_
21-32	4088-4096	auditing	_	_	_	_
21-33	4097-4107	algorithms	abstract	giv	ana	21-36
21-34	4108-4110	to	_	_	_	_
21-35	4111-4118	enhance	_	_	_	_
21-36	4119-4124	their	abstract|abstract[196]	giv|new[196]	coref	22-10[204_0]
21-37	4125-4141	interpretability	abstract[196]	new[196]	_	_
21-38	4142-4144	so	_	_	_	_
21-39	4145-4149	that	_	_	_	_
21-40	4150-4156	biases	abstract	giv	_	_
21-41	4157-4160	can	_	_	_	_
21-42	4161-4163	be	_	_	_	_
21-43	4164-4172	detected	_	_	_	_
21-44	4173-4176	and	_	_	_	_
21-45	4177-4180	the	abstract[199]	giv[199]	_	_
21-46	4181-4187	system	abstract[198]|abstract[199]	giv[198]|giv[199]	_	_
21-47	4188-4190	’s	abstract[198]|abstract[199]	giv[198]|giv[199]	_	_
21-48	4191-4198	outputs	abstract[199]	giv[199]	_	_
21-49	4199-4202	can	_	_	_	_
21-50	4203-4205	be	_	_	_	_
21-51	4206-4214	verified	_	_	_	_
21-52	4215-4222	against	_	_	_	_
21-53	4223-4229	safety	abstract|abstract[201]	giv|new[201]	coref	27-14
21-54	4230-4242	requirements	abstract[201]	new[201]	_	_
21-55	4243-4244	.	_	_	_	_

#Text=However , there are challenges in identifying bias in algorithms and their discriminatory effects .
22-1	4245-4252	However	_	_	_	_
22-2	4253-4254	,	_	_	_	_
22-3	4255-4260	there	_	_	_	_
22-4	4261-4264	are	_	_	_	_
22-5	4265-4275	challenges	abstract	new	_	_
22-6	4276-4278	in	_	_	_	_
22-7	4279-4290	identifying	_	_	_	_
22-8	4291-4295	bias	abstract[203]	giv[203]	coref	23-35[0_203]
22-9	4296-4298	in	abstract[203]	giv[203]	_	_
22-10	4299-4309	algorithms	abstract[203]|abstract[204]	giv[203]|giv[204]	coref	23-3[207_204]
22-11	4310-4313	and	abstract[203]|abstract[204]	giv[203]|giv[204]	_	_
22-12	4314-4319	their	abstract[203]|abstract[204]|abstract|abstract[206]	giv[203]|giv[204]|giv|giv[206]	coref	24-24[222_206]
22-13	4320-4334	discriminatory	abstract[203]|abstract[204]|abstract[206]	giv[203]|giv[204]|giv[206]	_	_
22-14	4335-4342	effects	abstract[203]|abstract[204]|abstract[206]	giv[203]|giv[204]|giv[206]	_	_
22-15	4343-4344	.	_	_	_	_

#Text=Firstly , many algorithms are designed to be highly complex for greater accuracy , but this renders the algorithm opaque and difficult to interpret even by the designers themselves , concealing the sources of bias .
23-1	4345-4352	Firstly	_	_	_	_
23-2	4353-4354	,	_	_	_	_
23-3	4355-4359	many	abstract[207]	giv[207]	ana	23-29[0_207]
23-4	4360-4370	algorithms	abstract[207]	giv[207]	_	_
23-5	4371-4374	are	_	_	_	_
23-6	4375-4383	designed	_	_	_	_
23-7	4384-4386	to	_	_	_	_
23-8	4387-4389	be	_	_	_	_
23-9	4390-4396	highly	_	_	_	_
23-10	4397-4404	complex	_	_	_	_
23-11	4405-4408	for	_	_	_	_
23-12	4409-4416	greater	abstract[208]	new[208]	ana	23-16[0_208]
23-13	4417-4425	accuracy	abstract[208]	new[208]	_	_
23-14	4426-4427	,	_	_	_	_
23-15	4428-4431	but	_	_	_	_
23-16	4432-4436	this	abstract	giv	_	_
23-17	4437-4444	renders	_	_	_	_
23-18	4445-4448	the	abstract[210]	giv[210]	coref	25-41[233_210]
23-19	4449-4458	algorithm	abstract[210]	giv[210]	_	_
23-20	4459-4465	opaque	abstract[210]	giv[210]	_	_
23-21	4466-4469	and	abstract[210]	giv[210]	_	_
23-22	4470-4479	difficult	abstract[210]	giv[210]	_	_
23-23	4480-4482	to	abstract[210]	giv[210]	_	_
23-24	4483-4492	interpret	abstract[210]	giv[210]	_	_
23-25	4493-4497	even	person[211]	giv[211]	_	_
23-26	4498-4500	by	person[211]	giv[211]	_	_
23-27	4501-4504	the	person[211]	giv[211]	_	_
23-28	4505-4514	designers	person[211]	giv[211]	_	_
23-29	4515-4525	themselves	person[211]|abstract	giv[211]|giv	coref	24-4[216_0]
23-30	4526-4527	,	_	_	_	_
23-31	4528-4538	concealing	_	_	_	_
23-32	4539-4542	the	abstract[213]	new[213]	_	_
23-33	4543-4550	sources	abstract[213]	new[213]	_	_
23-34	4551-4553	of	abstract[213]	new[213]	_	_
23-35	4554-4558	bias	abstract[213]|abstract	new[213]|giv	coref	25-30[230_0]
23-36	4559-4560	.	_	_	_	_

#Text=Secondly , as ML algorithms make decisions mainly based on the training data that changes over time , it is difficult to predict potentially discriminatory effects in advance .
24-1	4561-4569	Secondly	_	_	_	_
24-2	4570-4571	,	_	_	_	_
24-3	4572-4574	as	_	_	_	_
24-4	4575-4577	ML	quantity|abstract[216]	new|giv[216]	coref	25-18[227_216]
24-5	4578-4588	algorithms	abstract[216]	giv[216]	_	_
24-6	4589-4593	make	_	_	_	_
24-7	4594-4603	decisions	abstract	giv	coref	25-10[225_0]
24-8	4604-4610	mainly	_	_	_	_
24-9	4611-4616	based	_	_	_	_
24-10	4617-4619	on	_	_	_	_
24-11	4620-4623	the	abstract[219]	giv[219]	coref	25-45[234_219]
24-12	4624-4632	training	abstract|abstract[219]	new|giv[219]	_	_
24-13	4633-4637	data	abstract[219]	giv[219]	_	_
24-14	4638-4642	that	_	_	_	_
24-15	4643-4650	changes	_	_	_	_
24-16	4651-4655	over	_	_	_	_
24-17	4656-4660	time	_	_	_	_
24-18	4661-4662	,	_	_	_	_
24-19	4663-4665	it	abstract	new	cata	24-19[0_221]
24-20	4666-4668	is	_	_	_	_
24-21	4669-4678	difficult	_	_	_	_
24-22	4679-4681	to	abstract[221]	new[221]	_	_
24-23	4682-4689	predict	abstract[221]	new[221]	_	_
24-24	4690-4701	potentially	abstract[221]|abstract[222]	new[221]|giv[222]	_	_
24-25	4702-4716	discriminatory	abstract[221]|abstract[222]	new[221]|giv[222]	_	_
24-26	4717-4724	effects	abstract[221]|abstract[222]	new[221]|giv[222]	_	_
24-27	4725-4727	in	_	_	_	_
24-28	4728-4735	advance	abstract	new	_	_
24-29	4736-4737	.	_	_	_	_

#Text=Humans are also excessively trusting and insufficiently critical of algorithmic decisions due to the popular perception of algorithms as objective and fair , a problem referred to as “ automation bias ” and the seemingly “ objective ” correlations that the algorithm learns from the data makes it difficult to legally establish discriminatory intent in algorithms .
25-1	4738-4744	Humans	person	new	_	_
25-2	4745-4748	are	_	_	_	_
25-3	4749-4753	also	_	_	_	_
25-4	4754-4765	excessively	_	_	_	_
25-5	4766-4774	trusting	_	_	_	_
25-6	4775-4778	and	_	_	_	_
25-7	4779-4793	insufficiently	_	_	_	_
25-8	4794-4802	critical	_	_	_	_
25-9	4803-4805	of	_	_	_	_
25-10	4806-4817	algorithmic	abstract[225]	giv[225]	coref	26-33[248_225]
25-11	4818-4827	decisions	abstract[225]	giv[225]	_	_
25-12	4828-4831	due	_	_	_	_
25-13	4832-4834	to	_	_	_	_
25-14	4835-4838	the	abstract[226]	new[226]	_	_
25-15	4839-4846	popular	abstract[226]	new[226]	_	_
25-16	4847-4857	perception	abstract[226]	new[226]	_	_
25-17	4858-4860	of	abstract[226]	new[226]	_	_
25-18	4861-4871	algorithms	abstract[226]|abstract[227]	new[226]|giv[227]	coref	25-56[0_227]
25-19	4872-4874	as	abstract[226]|abstract[227]	new[226]|giv[227]	_	_
25-20	4875-4884	objective	abstract[226]|abstract[227]	new[226]|giv[227]	_	_
25-21	4885-4888	and	abstract[226]|abstract[227]	new[226]|giv[227]	_	_
25-22	4889-4893	fair	abstract[226]|abstract[227]	new[226]|giv[227]	_	_
25-23	4894-4895	,	_	_	_	_
25-24	4896-4897	a	abstract[228]	new[228]	_	_
25-25	4898-4905	problem	abstract[228]	new[228]	_	_
25-26	4906-4914	referred	_	_	_	_
25-27	4915-4917	to	_	_	_	_
25-28	4918-4920	as	_	_	_	_
25-29	4921-4922	“	_	_	_	_
25-30	4923-4933	automation	abstract|abstract[230]	new|giv[230]	_	_
25-31	4934-4938	bias	abstract[230]	giv[230]	_	_
25-32	4939-4940	”	_	_	_	_
25-33	4941-4944	and	_	_	_	_
25-34	4945-4948	the	abstract[231]	new[231]	_	_
25-35	4949-4958	seemingly	abstract[231]	new[231]	_	_
25-36	4959-4960	“	abstract[231]	new[231]	_	_
25-37	4961-4970	objective	abstract[231]	new[231]	_	_
25-38	4971-4972	”	abstract[231]	new[231]	_	_
25-39	4973-4985	correlations	abstract[231]|abstract	new[231]|new	_	_
25-40	4986-4990	that	_	_	_	_
25-41	4991-4994	the	abstract[233]	giv[233]	_	_
25-42	4995-5004	algorithm	abstract[233]	giv[233]	_	_
25-43	5005-5011	learns	_	_	_	_
25-44	5012-5016	from	_	_	_	_
25-45	5017-5020	the	abstract[234]	giv[234]	ana	25-48[0_234]
25-46	5021-5025	data	abstract[234]	giv[234]	_	_
25-47	5026-5031	makes	_	_	_	_
25-48	5032-5034	it	abstract	giv	_	_
25-49	5035-5044	difficult	_	_	_	_
25-50	5045-5047	to	_	_	_	_
25-51	5048-5055	legally	_	_	_	_
25-52	5056-5065	establish	_	_	_	_
25-53	5066-5080	discriminatory	abstract[236]	giv[236]	_	_
25-54	5081-5087	intent	abstract[236]	giv[236]	_	_
25-55	5088-5090	in	_	_	_	_
25-56	5091-5101	algorithms	abstract	giv	_	_
25-57	5102-5103	.	_	_	_	_

#Text=An emerging issue is the aggregation of individually biased outcomes when AVs with similar preferences are deployed on a large-scale , as doing so would centralise and replicate algorithmic preferences along with their individually biased risk allocation decisions .
26-1	5104-5106	An	abstract[238]	new[238]	coref	26-5[239_238]
26-2	5107-5115	emerging	abstract[238]	new[238]	_	_
26-3	5116-5121	issue	abstract[238]	new[238]	_	_
26-4	5122-5124	is	_	_	_	_
26-5	5125-5128	the	abstract[239]	giv[239]	_	_
26-6	5129-5140	aggregation	abstract[239]	giv[239]	_	_
26-7	5141-5143	of	abstract[239]	giv[239]	_	_
26-8	5144-5156	individually	abstract[239]|abstract[240]	giv[239]|giv[240]	coref	27-34[257_240]
26-9	5157-5163	biased	abstract[239]|abstract[240]	giv[239]|giv[240]	_	_
26-10	5164-5172	outcomes	abstract[239]|abstract[240]	giv[239]|giv[240]	_	_
26-11	5173-5177	when	_	_	_	_
26-12	5178-5181	AVs	abstract[241]	giv[241]	ana	27-1[0_241]
26-13	5182-5186	with	abstract[241]	giv[241]	_	_
26-14	5187-5194	similar	abstract[241]|abstract[242]	giv[241]|giv[242]	coref	26-29[244_242]
26-15	5195-5206	preferences	abstract[241]|abstract[242]	giv[241]|giv[242]	_	_
26-16	5207-5210	are	_	_	_	_
26-17	5211-5219	deployed	_	_	_	_
26-18	5220-5222	on	_	_	_	_
26-19	5223-5224	a	object[243]	new[243]	_	_
26-20	5225-5236	large-scale	object[243]	new[243]	_	_
26-21	5237-5238	,	_	_	_	_
26-22	5239-5241	as	_	_	_	_
26-23	5242-5247	doing	_	_	_	_
26-24	5248-5250	so	_	_	_	_
26-25	5251-5256	would	_	_	_	_
26-26	5257-5267	centralise	_	_	_	_
26-27	5268-5271	and	_	_	_	_
26-28	5272-5281	replicate	_	_	_	_
26-29	5282-5293	algorithmic	abstract[244]	giv[244]	ana	26-33[0_244]
26-30	5294-5305	preferences	abstract[244]	giv[244]	_	_
26-31	5306-5311	along	_	_	_	_
26-32	5312-5316	with	_	_	_	_
26-33	5317-5322	their	abstract|abstract[248]	giv|giv[248]	_	_
26-34	5323-5335	individually	abstract[248]	giv[248]	_	_
26-35	5336-5342	biased	abstract[248]	giv[248]	_	_
26-36	5343-5347	risk	abstract|abstract[248]	new|giv[248]	_	_
26-37	5348-5358	allocation	abstract|abstract[248]	new|giv[248]	_	_
26-38	5359-5368	decisions	abstract[248]	giv[248]	_	_
26-39	5369-5370	.	_	_	_	_

#Text=This could lead to the same groups of people being consistently allocated more safety risks and perpetuate systemic discrimination , which is more difficult to detect as it results from the accumulation of similar driving outcomes .
27-1	5371-5375	This	abstract	giv	ana	27-28
27-2	5376-5381	could	_	_	_	_
27-3	5382-5386	lead	_	_	_	_
27-4	5387-5389	to	_	_	_	_
27-5	5390-5393	the	person[250]	new[250]	_	_
27-6	5394-5398	same	person[250]	new[250]	_	_
27-7	5399-5405	groups	person[250]	new[250]	_	_
27-8	5406-5408	of	person[250]	new[250]	_	_
27-9	5409-5415	people	person[250]|person	new[250]|giv	_	_
27-10	5416-5421	being	_	_	_	_
27-11	5422-5434	consistently	_	_	_	_
27-12	5435-5444	allocated	_	_	_	_
27-13	5445-5449	more	abstract[253]	giv[253]	_	_
27-14	5450-5456	safety	abstract|abstract[253]	giv|giv[253]	_	_
27-15	5457-5462	risks	abstract[253]	giv[253]	_	_
27-16	5463-5466	and	_	_	_	_
27-17	5467-5477	perpetuate	_	_	_	_
27-18	5478-5486	systemic	abstract[254]	giv[254]	_	_
27-19	5487-5501	discrimination	abstract[254]	giv[254]	_	_
27-20	5502-5503	,	_	_	_	_
27-21	5504-5509	which	_	_	_	_
27-22	5510-5512	is	_	_	_	_
27-23	5513-5517	more	_	_	_	_
27-24	5518-5527	difficult	_	_	_	_
27-25	5528-5530	to	_	_	_	_
27-26	5531-5537	detect	_	_	_	_
27-27	5538-5540	as	_	_	_	_
27-28	5541-5543	it	abstract	giv	_	_
27-29	5544-5551	results	_	_	_	_
27-30	5552-5556	from	_	_	_	_
27-31	5557-5560	the	abstract[256]	new[256]	_	_
27-32	5561-5573	accumulation	abstract[256]	new[256]	_	_
27-33	5574-5576	of	abstract[256]	new[256]	_	_
27-34	5577-5584	similar	abstract[256]|abstract[257]	new[256]|giv[257]	_	_
27-35	5585-5592	driving	abstract[256]|abstract[257]	new[256]|giv[257]	_	_
27-36	5593-5601	outcomes	abstract[256]|abstract[257]	new[256]|giv[257]	_	_
27-37	5602-5603	.	_	_	_	_
