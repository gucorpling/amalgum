#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=1. Introduction
1-1	0-2	1.	_	_	_	_
1-2	3-15	Introduction	abstract	new	_	_

#Text=Significant technological progress in image processing algorithms and ability to improve perception of the world surrounding us using modern deep learning methods has led to invention and enablement of various applications that were previously much harder to implement , e. g. , face recognition , objects detection and segmentation or image resolution enhancement .
2-1	16-27	Significant	abstract[2]	new[2]	coref	4-9[33_2]
2-2	28-41	technological	abstract[2]	new[2]	_	_
2-3	42-50	progress	abstract[2]	new[2]	_	_
2-4	51-53	in	abstract[2]	new[2]	_	_
2-5	54-59	image	abstract[2]|object	new[2]|new	coref	2-51
2-6	60-70	processing	abstract[2]|abstract|abstract[5]	new[2]|new|new[5]	coref|coref	22-26[156_5]|22-26[156_5]
2-7	71-81	algorithms	abstract[2]|abstract[5]	new[2]|new[5]	_	_
2-8	82-85	and	abstract[2]	new[2]	_	_
2-9	86-93	ability	abstract[2]|abstract	new[2]|new	_	_
2-10	94-96	to	_	_	_	_
2-11	97-104	improve	_	_	_	_
2-12	105-115	perception	abstract[7]	new[7]	_	_
2-13	116-118	of	abstract[7]	new[7]	_	_
2-14	119-122	the	abstract[7]|place[8]	new[7]|new[8]	_	_
2-15	123-128	world	abstract[7]|place[8]	new[7]|new[8]	_	_
2-16	129-140	surrounding	_	_	_	_
2-17	141-143	us	person	acc	_	_
2-18	144-149	using	_	_	_	_
2-19	150-156	modern	abstract[11]	new[11]	coref	11-5[90_11]
2-20	157-161	deep	abstract[11]	new[11]	_	_
2-21	162-170	learning	abstract|abstract[11]	new|new[11]	_	_
2-22	171-178	methods	abstract[11]	new[11]	_	_
2-23	179-182	has	_	_	_	_
2-24	183-186	led	_	_	_	_
2-25	187-189	to	_	_	_	_
2-26	190-199	invention	event	new	_	_
2-27	200-203	and	_	_	_	_
2-28	204-214	enablement	event[13]	new[13]	_	_
2-29	215-217	of	event[13]	new[13]	_	_
2-30	218-225	various	event[13]|abstract[14]	new[13]|new[14]	coref	3-10[26_14]
2-31	226-238	applications	event[13]|abstract[14]	new[13]|new[14]	_	_
2-32	239-243	that	_	_	_	_
2-33	244-248	were	_	_	_	_
2-34	249-259	previously	_	_	_	_
2-35	260-264	much	_	_	_	_
2-36	265-271	harder	_	_	_	_
2-37	272-274	to	_	_	_	_
2-38	275-284	implement	_	_	_	_
2-39	285-286	,	_	_	_	_
2-40	287-289	e.	_	_	_	_
2-41	290-292	g.	_	_	_	_
2-42	293-294	,	_	_	_	_
2-43	295-299	face	object|abstract[16]	new|new[16]	coref|coref	22-9[150_0]|22-9[150_0]
2-44	300-311	recognition	abstract[16]	new[16]	_	_
2-45	312-313	,	_	_	_	_
2-46	314-321	objects	object|abstract[18]	new|new[18]	coref|coref	20-10[133_18]|20-10[133_18]
2-47	322-331	detection	abstract[18]	new[18]	_	_
2-48	332-335	and	_	_	_	_
2-49	336-348	segmentation	abstract	new	_	_
2-50	349-351	or	_	_	_	_
2-51	352-357	image	object|abstract[22]	giv|new[22]	_	_
2-52	358-368	resolution	abstract|abstract[22]	new|new[22]	coref	19-3[127_0]
2-53	369-380	enhancement	abstract[22]	new[22]	_	_
2-54	381-382	.	_	_	_	_

#Text=Another factor that steers the direction of advances in new applications is the increased capabilities of many electronic digital devices .
3-1	383-390	Another	abstract[23]	new[23]	coref	3-13[27_23]
3-2	391-397	factor	abstract[23]	new[23]	_	_
3-3	398-402	that	_	_	_	_
3-4	403-409	steers	_	_	_	_
3-5	410-413	the	abstract[24]	new[24]	_	_
3-6	414-423	direction	abstract[24]	new[24]	_	_
3-7	424-426	of	abstract[24]	new[24]	_	_
3-8	427-435	advances	abstract[24]|abstract[25]	new[24]|new[25]	_	_
3-9	436-438	in	abstract[24]|abstract[25]	new[24]|new[25]	_	_
3-10	439-442	new	abstract[24]|abstract[25]|abstract[26]	new[24]|new[25]|giv[26]	coref	5-7[40_26]
3-11	443-455	applications	abstract[24]|abstract[25]|abstract[26]	new[24]|new[25]|giv[26]	_	_
3-12	456-458	is	_	_	_	_
3-13	459-462	the	abstract[27]	giv[27]	_	_
3-14	463-472	increased	abstract[27]	giv[27]	_	_
3-15	473-485	capabilities	abstract[27]	giv[27]	_	_
3-16	486-488	of	abstract[27]	giv[27]	_	_
3-17	489-493	many	abstract[27]|object[28]	giv[27]|new[28]	coref	4-24[37_28]
3-18	494-504	electronic	abstract[27]|object[28]	giv[27]|new[28]	_	_
3-19	505-512	digital	abstract[27]|object[28]	giv[27]|new[28]	_	_
3-20	513-520	devices	abstract[27]|object[28]	giv[27]|new[28]	_	_
3-21	521-522	.	_	_	_	_

#Text=Medical diagnostics and reasoning systems also benefited from this progress , allowing for real-time vital signs analysis and tracking using standard cameras or wearable devices .
4-1	523-530	Medical	abstract[29]|abstract[30]	new[29]|new[30]	coref|coref|coref|coref	5-11[41_29]|5-11[42_30]|5-11[41_29]|5-11[42_30]
4-2	531-542	diagnostics	abstract[29]|abstract[30]	new[29]|new[30]	_	_
4-3	543-546	and	abstract[30]	new[30]	_	_
4-4	547-556	reasoning	abstract[30]|abstract|abstract[32]	new[30]|new|new[32]	_	_
4-5	557-564	systems	abstract[30]|abstract[32]	new[30]|new[32]	_	_
4-6	565-569	also	_	_	_	_
4-7	570-579	benefited	_	_	_	_
4-8	580-584	from	_	_	_	_
4-9	585-589	this	abstract[33]	giv[33]	_	_
4-10	590-598	progress	abstract[33]	giv[33]	_	_
4-11	599-600	,	_	_	_	_
4-12	601-609	allowing	_	_	_	_
4-13	610-613	for	_	_	_	_
4-14	614-623	real-time	abstract[35]	new[35]	coref	5-41[54_35]
4-15	624-629	vital	abstract[35]	new[35]	_	_
4-16	630-635	signs	abstract|abstract[35]	new|new[35]	_	_
4-17	636-644	analysis	abstract[35]	new[35]	_	_
4-18	645-648	and	_	_	_	_
4-19	649-657	tracking	_	_	_	_
4-20	658-663	using	_	_	_	_
4-21	664-672	standard	object[36]	new[36]	coref	6-4[57_36]
4-22	673-680	cameras	object[36]	new[36]	_	_
4-23	681-683	or	_	_	_	_
4-24	684-692	wearable	object[37]	giv[37]	_	_
4-25	693-700	devices	object[37]	giv[37]	_	_
4-26	701-702	.	_	_	_	_

#Text=The remote measurement of RR has many potential applications in medical diagnostics and screenings like monitoring of newborns or small children in incubators or hospital beds , monitoring of the severe acute respiratory syndrome ( SARS ) , support in emotion analysis , etc.
5-1	703-706	The	abstract[38]	new[38]	_	_
5-2	707-713	remote	abstract[38]	new[38]	_	_
5-3	714-725	measurement	abstract[38]	new[38]	_	_
5-4	726-728	of	abstract[38]	new[38]	_	_
5-5	729-731	RR	abstract[38]|abstract	new[38]|new	_	_
5-6	732-735	has	_	_	_	_
5-7	736-740	many	abstract[40]	giv[40]	_	_
5-8	741-750	potential	abstract[40]	giv[40]	_	_
5-9	751-763	applications	abstract[40]	giv[40]	_	_
5-10	764-766	in	abstract[40]	giv[40]	_	_
5-11	767-774	medical	abstract[40]|abstract[41]|abstract[42]	giv[40]|giv[41]|giv[42]	_	_
5-12	775-786	diagnostics	abstract[40]|abstract[41]|abstract[42]	giv[40]|giv[41]|giv[42]	_	_
5-13	787-790	and	abstract[40]|abstract[42]	giv[40]|giv[42]	_	_
5-14	791-801	screenings	abstract[40]|abstract[42]|event	giv[40]|giv[42]|new	_	_
5-15	802-806	like	abstract[40]	giv[40]	_	_
5-16	807-817	monitoring	abstract[40]|event[44]	giv[40]|new[44]	_	_
5-17	818-820	of	abstract[40]|event[44]	giv[40]|new[44]	_	_
5-18	821-829	newborns	abstract[40]|event[44]|person	giv[40]|new[44]|new	_	_
5-19	830-832	or	abstract[40]|event[44]	giv[40]|new[44]	_	_
5-20	833-838	small	abstract[40]|event[44]|person[46]	giv[40]|new[44]|new[46]	_	_
5-21	839-847	children	abstract[40]|event[44]|person[46]	giv[40]|new[44]|new[46]	_	_
5-22	848-850	in	abstract[40]|event[44]|person[46]	giv[40]|new[44]|new[46]	_	_
5-23	851-861	incubators	abstract[40]|event[44]|person[46]|object	giv[40]|new[44]|new[46]|new	_	_
5-24	862-864	or	abstract[40]|event[44]|person[46]	giv[40]|new[44]|new[46]	_	_
5-25	865-873	hospital	abstract[40]|event[44]|person[46]|place|place[49]	giv[40]|new[44]|new[46]|new|new[49]	_	_
5-26	874-878	beds	abstract[40]|event[44]|person[46]|place[49]	giv[40]|new[44]|new[46]|new[49]	_	_
5-27	879-880	,	_	_	_	_
5-28	881-891	monitoring	_	_	_	_
5-29	892-894	of	_	_	_	_
5-30	895-898	the	abstract[50]	new[50]	appos	5-36[0_50]
5-31	899-905	severe	abstract[50]	new[50]	_	_
5-32	906-911	acute	abstract[50]	new[50]	_	_
5-33	912-923	respiratory	abstract[50]	new[50]	_	_
5-34	924-932	syndrome	abstract[50]	new[50]	_	_
5-35	933-934	(	_	_	_	_
5-36	935-939	SARS	abstract	giv	appos	5-39[52_0]
5-37	940-941	)	_	_	_	_
5-38	942-943	,	_	_	_	_
5-39	944-951	support	abstract[52]	giv[52]	_	_
5-40	952-954	in	abstract[52]	giv[52]	_	_
5-41	955-962	emotion	abstract[52]|abstract|abstract[54]	giv[52]|new|giv[54]	_	_
5-42	963-971	analysis	abstract[52]|abstract[54]	giv[52]|giv[54]	_	_
5-43	972-973	,	_	_	_	_
5-44	974-978	etc.	_	_	_	_

#Text=The use of thermal cameras was proposed to analyze facial images and estimate RR based on a nasal heat flow and described in and other papers .
6-1	979-982	The	abstract[55]	new[55]	_	_
6-2	983-986	use	abstract[55]	new[55]	_	_
6-3	987-989	of	abstract[55]	new[55]	_	_
6-4	990-997	thermal	abstract[55]|animal|object[57]	new[55]|new|giv[57]	coref|coref|coref|coref	8-14|16-5[109_57]|8-14|16-5[109_57]
6-5	998-1005	cameras	abstract[55]|object[57]	new[55]|giv[57]	_	_
6-6	1006-1009	was	_	_	_	_
6-7	1010-1018	proposed	_	_	_	_
6-8	1019-1021	to	_	_	_	_
6-9	1022-1029	analyze	_	_	_	_
6-10	1030-1036	facial	object[58]	new[58]	coref	20-4[0_58]
6-11	1037-1043	images	object[58]	new[58]	_	_
6-12	1044-1047	and	_	_	_	_
6-13	1048-1056	estimate	_	_	_	_
6-14	1057-1059	RR	person	new	coref	7-5
6-15	1060-1065	based	_	_	_	_
6-16	1066-1068	on	_	_	_	_
6-17	1069-1070	a	abstract[61]	new[61]	_	_
6-18	1071-1076	nasal	abstract[61]	new[61]	_	_
6-19	1077-1081	heat	abstract|abstract[61]	new|new[61]	_	_
6-20	1082-1086	flow	abstract[61]	new[61]	_	_
6-21	1087-1090	and	_	_	_	_
6-22	1091-1100	described	_	_	_	_
6-23	1101-1103	in	_	_	_	_
6-24	1104-1107	and	_	_	_	_
6-25	1108-1113	other	object[62]	new[62]	_	_
6-26	1114-1120	papers	object[62]	new[62]	_	_
6-27	1121-1122	.	_	_	_	_

#Text=The typical estimation of RR requires a multi step procedure .
7-1	1123-1126	The	abstract[63]	new[63]	_	_
7-2	1127-1134	typical	abstract[63]	new[63]	_	_
7-3	1135-1145	estimation	abstract[63]	new[63]	_	_
7-4	1146-1148	of	abstract[63]	new[63]	_	_
7-5	1149-1151	RR	abstract[63]|abstract	new[63]|giv	_	_
7-6	1152-1160	requires	_	_	_	_
7-7	1161-1162	a	abstract[66]	new[66]	_	_
7-8	1163-1168	multi	abstract[66]	new[66]	_	_
7-9	1169-1173	step	event|abstract[66]	new|new[66]	coref	12-2[92_0]
7-10	1174-1183	procedure	abstract[66]	new[66]	_	_
7-11	1184-1185	.	_	_	_	_

#Text=First , a Region Of Interest ( ROI ) is detected for each thermal frame representing the source of thermal changes ( due to respiration ) in the area of nostrils or a mouth .
8-1	1186-1191	First	_	_	_	_
8-2	1192-1193	,	_	_	_	_
8-3	1194-1195	a	abstract[67]	new[67]	appos	8-8[0_67]
8-4	1196-1202	Region	abstract[67]	new[67]	_	_
8-5	1203-1205	Of	abstract[67]	new[67]	_	_
8-6	1206-1214	Interest	abstract[67]	new[67]	_	_
8-7	1215-1216	(	_	_	_	_
8-8	1217-1220	ROI	abstract	giv	coref	9-1[77_0]
8-9	1221-1222	)	_	_	_	_
8-10	1223-1225	is	_	_	_	_
8-11	1226-1234	detected	_	_	_	_
8-12	1235-1238	for	_	_	_	_
8-13	1239-1243	each	abstract[70]	new[70]	coref	9-14[78_70]
8-14	1244-1251	thermal	time|abstract[70]	giv|new[70]	coref	16-9
8-15	1252-1257	frame	abstract[70]	new[70]	_	_
8-16	1258-1270	representing	_	_	_	_
8-17	1271-1274	the	abstract[71]	new[71]	_	_
8-18	1275-1281	source	abstract[71]	new[71]	_	_
8-19	1282-1284	of	abstract[71]	new[71]	_	_
8-20	1285-1292	thermal	abstract[71]|abstract[72]	new[71]|new[72]	coref	10-22[87_72]
8-21	1293-1300	changes	abstract[71]|abstract[72]	new[71]|new[72]	_	_
8-22	1301-1302	(	_	_	_	_
8-23	1303-1306	due	_	_	_	_
8-24	1307-1309	to	_	_	_	_
8-25	1310-1321	respiration	abstract	new	_	_
8-26	1322-1323	)	_	_	_	_
8-27	1324-1326	in	_	_	_	_
8-28	1327-1330	the	place[74]	new[74]	_	_
8-29	1331-1335	area	place[74]	new[74]	_	_
8-30	1336-1338	of	place[74]	new[74]	_	_
8-31	1339-1347	nostrils	place[74]|object	new[74]|new	_	_
8-32	1348-1350	or	place[74]	new[74]	_	_
8-33	1351-1352	a	place[74]|object[76]	new[74]|new[76]	_	_
8-34	1353-1358	mouth	place[74]|object[76]	new[74]|new[76]	_	_
8-35	1359-1360	.	_	_	_	_

#Text=The ROI can be specified manually or can be automatically detected ( in a frame or for each frame ) and tracked ( between frames ) .
9-1	1361-1364	The	abstract[77]	giv[77]	coref	11-5[0_77]
9-2	1365-1368	ROI	abstract[77]	giv[77]	_	_
9-3	1369-1372	can	_	_	_	_
9-4	1373-1375	be	_	_	_	_
9-5	1376-1385	specified	_	_	_	_
9-6	1386-1394	manually	_	_	_	_
9-7	1395-1397	or	_	_	_	_
9-8	1398-1401	can	_	_	_	_
9-9	1402-1404	be	_	_	_	_
9-10	1405-1418	automatically	_	_	_	_
9-11	1419-1427	detected	_	_	_	_
9-12	1428-1429	(	_	_	_	_
9-13	1430-1432	in	_	_	_	_
9-14	1433-1434	a	abstract[78]	giv[78]	coref	9-18[79_78]
9-15	1435-1440	frame	abstract[78]	giv[78]	_	_
9-16	1441-1443	or	_	_	_	_
9-17	1444-1447	for	_	_	_	_
9-18	1448-1452	each	abstract[79]	giv[79]	_	_
9-19	1453-1458	frame	abstract[79]	giv[79]	_	_
9-20	1459-1460	)	_	_	_	_
9-21	1461-1464	and	_	_	_	_
9-22	1465-1472	tracked	_	_	_	_
9-23	1473-1474	(	_	_	_	_
9-24	1475-1482	between	_	_	_	_
9-25	1483-1489	frames	abstract	new	_	_
9-26	1490-1491	)	_	_	_	_
9-27	1492-1493	.	_	_	_	_

#Text=In , the authors described a particle filter tracker driven by a probabilistic template function that was capable of adapting to abrupt positional and physiological changes .
10-1	1494-1496	In	_	_	_	_
10-2	1497-1498	,	_	_	_	_
10-3	1499-1502	the	person[81]	new[81]	coref	11-1[88_81]
10-4	1503-1510	authors	person[81]	new[81]	_	_
10-5	1511-1520	described	_	_	_	_
10-6	1521-1522	a	object[84]	new[84]	_	_
10-7	1523-1531	particle	object|object[84]	new|new[84]	_	_
10-8	1532-1538	filter	object|object[84]	new|new[84]	_	_
10-9	1539-1546	tracker	object[84]	new[84]	_	_
10-10	1547-1553	driven	_	_	_	_
10-11	1554-1556	by	_	_	_	_
10-12	1557-1558	a	abstract[86]	new[86]	_	_
10-13	1559-1572	probabilistic	abstract[86]	new[86]	_	_
10-14	1573-1581	template	object|abstract[86]	new|new[86]	_	_
10-15	1582-1590	function	abstract[86]	new[86]	_	_
10-16	1591-1595	that	_	_	_	_
10-17	1596-1599	was	_	_	_	_
10-18	1600-1607	capable	_	_	_	_
10-19	1608-1610	of	_	_	_	_
10-20	1611-1619	adapting	_	_	_	_
10-21	1620-1622	to	_	_	_	_
10-22	1623-1629	abrupt	abstract[87]	giv[87]	coref	13-10[98_87]
10-23	1630-1640	positional	abstract[87]	giv[87]	_	_
10-24	1641-1644	and	abstract[87]	giv[87]	_	_
10-25	1645-1658	physiological	abstract[87]	giv[87]	_	_
10-26	1659-1666	changes	abstract[87]	giv[87]	_	_
10-27	1667-1668	.	_	_	_	_

#Text=Other authors also proposed ROI tracking methods ( e. g. , ) .
11-1	1669-1674	Other	person[88]	giv[88]	_	_
11-2	1675-1682	authors	person[88]	giv[88]	_	_
11-3	1683-1687	also	_	_	_	_
11-4	1688-1696	proposed	_	_	_	_
11-5	1697-1700	ROI	abstract|abstract[90]	giv|giv[90]	coref|coref|coref|coref	12-13[94_0]|21-1[137_90]|12-13[94_0]|21-1[137_90]
11-6	1701-1709	tracking	abstract[90]	giv[90]	_	_
11-7	1710-1717	methods	abstract[90]	giv[90]	_	_
11-8	1718-1719	(	_	_	_	_
11-9	1720-1722	e.	event[91]	new[91]	coref	18-26[123_91]
11-10	1723-1725	g.	event[91]	new[91]	_	_
11-11	1726-1727	,	_	_	_	_
11-12	1728-1729	)	_	_	_	_
11-13	1730-1731	.	_	_	_	_

#Text=In the next step , a single value is calculated to represent each ROI .
12-1	1732-1734	In	_	_	_	_
12-2	1735-1738	the	event[92]	giv[92]	_	_
12-3	1739-1743	next	event[92]	giv[92]	_	_
12-4	1744-1748	step	event[92]	giv[92]	_	_
12-5	1749-1750	,	_	_	_	_
12-6	1751-1752	a	abstract[93]	new[93]	_	_
12-7	1753-1759	single	abstract[93]	new[93]	_	_
12-8	1760-1765	value	abstract[93]	new[93]	_	_
12-9	1766-1768	is	_	_	_	_
12-10	1769-1779	calculated	_	_	_	_
12-11	1780-1782	to	_	_	_	_
12-12	1783-1792	represent	_	_	_	_
12-13	1793-1797	each	abstract[94]	giv[94]	coref	20-17[135_94]
12-14	1798-1801	ROI	abstract[94]	giv[94]	_	_
12-15	1802-1803	.	_	_	_	_

#Text=A collection of such values forms a signal representing local temperature changes in time .
13-1	1804-1805	A	object[95]	new[95]	_	_
13-2	1806-1816	collection	object[95]	new[95]	_	_
13-3	1817-1819	of	object[95]	new[95]	_	_
13-4	1820-1824	such	object[95]|abstract[96]	new[95]|new[96]	_	_
13-5	1825-1831	values	object[95]|abstract[96]	new[95]|new[96]	_	_
13-6	1832-1837	forms	_	_	_	_
13-7	1838-1839	a	abstract[97]	new[97]	coref	14-3[99_97]
13-8	1840-1846	signal	abstract[97]	new[97]	_	_
13-9	1847-1859	representing	_	_	_	_
13-10	1860-1865	local	abstract[98]	giv[98]	coref	14-19[103_98]
13-11	1866-1877	temperature	abstract[98]	giv[98]	_	_
13-12	1878-1885	changes	abstract[98]	giv[98]	_	_
13-13	1886-1888	in	_	_	_	_
13-14	1889-1893	time	_	_	_	_
13-15	1894-1895	.	_	_	_	_

#Text=Finally , a signal is filtered ( e. g. removing high frequency components ) and a frequency for dominated changes is calculated .
14-1	1896-1903	Finally	_	_	_	_
14-2	1904-1905	,	_	_	_	_
14-3	1906-1907	a	abstract[99]	giv[99]	_	_
14-4	1908-1914	signal	abstract[99]	giv[99]	_	_
14-5	1915-1917	is	_	_	_	_
14-6	1918-1926	filtered	_	_	_	_
14-7	1927-1928	(	_	_	_	_
14-8	1929-1931	e.	_	_	_	_
14-9	1932-1934	g.	_	_	_	_
14-10	1935-1943	removing	_	_	_	_
14-11	1944-1948	high	abstract[101]	new[101]	_	_
14-12	1949-1958	frequency	abstract|abstract[101]	new|new[101]	coref	14-16[102_0]
14-13	1959-1969	components	abstract[101]	new[101]	_	_
14-14	1970-1971	)	_	_	_	_
14-15	1972-1975	and	_	_	_	_
14-16	1976-1977	a	abstract[102]	giv[102]	ana	15-1[0_102]
14-17	1978-1987	frequency	abstract[102]	giv[102]	_	_
14-18	1988-1991	for	abstract[102]	giv[102]	_	_
14-19	1992-2001	dominated	abstract[102]|abstract[103]	giv[102]|giv[103]	coref	20-20[136_103]
14-20	2002-2009	changes	abstract[102]|abstract[103]	giv[102]|giv[103]	_	_
14-21	2010-2012	is	_	_	_	_
14-22	2013-2023	calculated	_	_	_	_
14-23	2024-2025	.	_	_	_	_

#Text=It is assumed , that this frequency represents the respiratory rate .
15-1	2026-2028	It	abstract	giv	coref	15-6[105_0]
15-2	2029-2031	is	_	_	_	_
15-3	2032-2039	assumed	_	_	_	_
15-4	2040-2041	,	_	_	_	_
15-5	2042-2046	that	_	_	_	_
15-6	2047-2051	this	abstract[105]	giv[105]	coref	23-9[0_105]
15-7	2052-2061	frequency	abstract[105]	giv[105]	_	_
15-8	2062-2072	represents	_	_	_	_
15-9	2073-2076	the	abstract[106]	new[106]	coref	24-5[164_106]
15-10	2077-2088	respiratory	abstract[106]	new[106]	_	_
15-11	2089-2093	rate	abstract[106]	new[106]	_	_
15-12	2094-2095	.	_	_	_	_

#Text=In recent years , new portable and cost-effective thermal cameras have been available .
16-1	2096-2098	In	_	_	_	_
16-2	2099-2105	recent	time[107]	new[107]	_	_
16-3	2106-2111	years	time[107]	new[107]	_	_
16-4	2112-2113	,	_	_	_	_
16-5	2114-2117	new	object[109]	giv[109]	coref	17-4[112_109]
16-6	2118-2126	portable	object[109]	giv[109]	_	_
16-7	2127-2130	and	object[109]	giv[109]	_	_
16-8	2131-2145	cost-effective	object[109]	giv[109]	_	_
16-9	2146-2153	thermal	animal|object[109]	giv|giv[109]	coref	18-10
16-10	2154-2161	cameras	object[109]	giv[109]	_	_
16-11	2162-2166	have	_	_	_	_
16-12	2167-2171	been	_	_	_	_
16-13	2172-2181	available	_	_	_	_
16-14	2182-2183	.	_	_	_	_

#Text=For example , FLIR® Lepton family cameras are very small ( e. g. , 10.5 × 11.7 × 6.4 mm , with an internal shutter ) and cost less that 200USD .
17-1	2184-2187	For	_	_	_	_
17-2	2188-2195	example	_	_	_	_
17-3	2196-2197	,	_	_	_	_
17-4	2198-2203	FLIR®	abstract|object[112]	new|giv[112]	coref|coref	19-7[129_112]|19-7[129_112]
17-5	2204-2210	Lepton	object[112]	giv[112]	_	_
17-6	2211-2217	family	abstract|object[112]	new|giv[112]	_	_
17-7	2218-2225	cameras	object[112]	giv[112]	_	_
17-8	2226-2229	are	_	_	_	_
17-9	2230-2234	very	_	_	_	_
17-10	2235-2240	small	_	_	_	_
17-11	2241-2242	(	_	_	_	_
17-12	2243-2245	e.	_	_	_	_
17-13	2246-2248	g.	_	_	_	_
17-14	2249-2250	,	_	_	_	_
17-15	2251-2255	10.5	_	_	_	_
17-16	2256-2257	×	_	_	_	_
17-17	2258-2262	11.7	_	_	_	_
17-18	2263-2264	×	_	_	_	_
17-19	2265-2268	6.4	quantity[113]	new[113]	_	_
17-20	2269-2271	mm	quantity[113]	new[113]	_	_
17-21	2272-2273	,	_	_	_	_
17-22	2274-2278	with	_	_	_	_
17-23	2279-2281	an	object[114]	new[114]	_	_
17-24	2282-2290	internal	object[114]	new[114]	_	_
17-25	2291-2298	shutter	object[114]	new[114]	_	_
17-26	2299-2300	)	_	_	_	_
17-27	2301-2304	and	_	_	_	_
17-28	2305-2309	cost	_	_	_	_
17-29	2310-2314	less	_	_	_	_
17-30	2315-2319	that	quantity[115]	new[115]	_	_
17-31	2320-2326	200USD	quantity[115]	new[115]	_	_
17-32	2327-2328	.	_	_	_	_

#Text=These features allow to think about wide application of thermal monitoring , e. g. , to support remote diagnosis of elderly people at home ( e. g. , during a video talk or as a self-diagnostics ) .
18-1	2329-2334	These	abstract[116]	new[116]	coref	20-12[134_116]
18-2	2335-2343	features	abstract[116]	new[116]	_	_
18-3	2344-2349	allow	_	_	_	_
18-4	2350-2352	to	_	_	_	_
18-5	2353-2358	think	_	_	_	_
18-6	2359-2364	about	_	_	_	_
18-7	2365-2369	wide	abstract[117]	new[117]	_	_
18-8	2370-2381	application	abstract[117]	new[117]	_	_
18-9	2382-2384	of	abstract[117]	new[117]	_	_
18-10	2385-2392	thermal	abstract[117]|animal|abstract[119]	new[117]|giv|new[119]	coref|coref	19-9|19-9
18-11	2393-2403	monitoring	abstract[117]|abstract[119]	new[117]|new[119]	_	_
18-12	2404-2405	,	abstract[117]	new[117]	_	_
18-13	2406-2408	e.	abstract[117]	new[117]	_	_
18-14	2409-2411	g.	abstract[117]	new[117]	_	_
18-15	2412-2413	,	_	_	_	_
18-16	2414-2416	to	_	_	_	_
18-17	2417-2424	support	_	_	_	_
18-18	2425-2431	remote	abstract[120]	new[120]	_	_
18-19	2432-2441	diagnosis	abstract[120]	new[120]	_	_
18-20	2442-2444	of	abstract[120]	new[120]	_	_
18-21	2445-2452	elderly	abstract[120]|person[121]	new[120]|new[121]	_	_
18-22	2453-2459	people	abstract[120]|person[121]	new[120]|new[121]	_	_
18-23	2460-2462	at	abstract[120]|person[121]	new[120]|new[121]	_	_
18-24	2463-2467	home	abstract[120]|person[121]|place	new[120]|new[121]|new	_	_
18-25	2468-2469	(	_	_	_	_
18-26	2470-2472	e.	place[123]	giv[123]	_	_
18-27	2473-2475	g.	place[123]	giv[123]	_	_
18-28	2476-2477	,	_	_	_	_
18-29	2478-2484	during	_	_	_	_
18-30	2485-2486	a	event[125]	new[125]	_	_
18-31	2487-2492	video	abstract|event[125]	new|new[125]	coref	26-12[171_0]
18-32	2493-2497	talk	event[125]	new[125]	_	_
18-33	2498-2500	or	_	_	_	_
18-34	2501-2503	as	_	_	_	_
18-35	2504-2505	a	abstract[126]	new[126]	_	_
18-36	2506-2522	self-diagnostics	abstract[126]	new[126]	_	_
18-37	2523-2524	)	_	_	_	_
18-38	2525-2526	.	_	_	_	_

#Text=However , a spatial resolution of these small thermal cameras is as low as 80 × 60 or 160 × 120 .
19-1	2527-2534	However	_	_	_	_
19-2	2535-2536	,	_	_	_	_
19-3	2537-2538	a	abstract[127]	giv[127]	_	_
19-4	2539-2546	spatial	abstract[127]	giv[127]	_	_
19-5	2547-2557	resolution	abstract[127]	giv[127]	_	_
19-6	2558-2560	of	abstract[127]	giv[127]	_	_
19-7	2561-2566	these	abstract[127]|object[129]	giv[127]|giv[129]	_	_
19-8	2567-2572	small	abstract[127]|object[129]	giv[127]|giv[129]	_	_
19-9	2573-2580	thermal	abstract[127]|animal|object[129]	giv[127]|giv|giv[129]	coref	22-6
19-10	2581-2588	cameras	abstract[127]|object[129]	giv[127]|giv[129]	_	_
19-11	2589-2591	is	_	_	_	_
19-12	2592-2594	as	_	_	_	_
19-13	2595-2598	low	_	_	_	_
19-14	2599-2601	as	_	_	_	_
19-15	2602-2604	80	_	_	_	_
19-16	2605-2606	×	_	_	_	_
19-17	2607-2609	60	_	_	_	_
19-18	2610-2612	or	_	_	_	_
19-19	2613-2616	160	_	_	_	_
19-20	2617-2618	×	_	_	_	_
19-21	2619-2622	120	_	_	_	_
19-22	2623-2624	.	_	_	_	_

#Text=Small resolution of images could be a problem for detection of facial features or detection of a ROI representing respiration-related temperature changes .
20-1	2625-2630	Small	abstract[130]	new[130]	coref	20-7[132_130]
20-2	2631-2641	resolution	abstract[130]	new[130]	_	_
20-3	2642-2644	of	abstract[130]	new[130]	_	_
20-4	2645-2651	images	abstract[130]|object	new[130]|giv	coref	21-17[143_0]
20-5	2652-2657	could	_	_	_	_
20-6	2658-2660	be	_	_	_	_
20-7	2661-2662	a	abstract[132]	giv[132]	coref	21-18[0_132]
20-8	2663-2670	problem	abstract[132]	giv[132]	_	_
20-9	2671-2674	for	abstract[132]	giv[132]	_	_
20-10	2675-2684	detection	abstract[132]|abstract[133]	giv[132]|giv[133]	_	_
20-11	2685-2687	of	abstract[132]|abstract[133]	giv[132]|giv[133]	_	_
20-12	2688-2694	facial	abstract[132]|abstract[133]|abstract[134]	giv[132]|giv[133]|giv[134]	_	_
20-13	2695-2703	features	abstract[132]|abstract[133]|abstract[134]	giv[132]|giv[133]|giv[134]	_	_
20-14	2704-2706	or	abstract[132]|abstract[133]|abstract[134]	giv[132]|giv[133]|giv[134]	_	_
20-15	2707-2716	detection	abstract[132]|abstract[133]|abstract[134]	giv[132]|giv[133]|giv[134]	_	_
20-16	2717-2719	of	abstract[132]|abstract[133]|abstract[134]	giv[132]|giv[133]|giv[134]	_	_
20-17	2720-2721	a	abstract[132]|abstract[133]|abstract[134]|abstract[135]	giv[132]|giv[133]|giv[134]|giv[135]	_	_
20-18	2722-2725	ROI	abstract[132]|abstract[133]|abstract[134]|abstract[135]	giv[132]|giv[133]|giv[134]|giv[135]	_	_
20-19	2726-2738	representing	_	_	_	_
20-20	2739-2758	respiration-related	abstract[136]	giv[136]	coref	21-29[144_136]
20-21	2759-2770	temperature	abstract[136]	giv[136]	_	_
20-22	2771-2778	changes	abstract[136]	giv[136]	_	_
20-23	2779-2780	.	_	_	_	_

#Text=Different methods have been proposed in ( a visible light spectrum ) computer vision to improve low resolution images or to detect ( and amplify ) small , local changes in videos .
21-1	2781-2790	Different	abstract[137]	giv[137]	_	_
21-2	2791-2798	methods	abstract[137]	giv[137]	_	_
21-3	2799-2803	have	_	_	_	_
21-4	2804-2808	been	_	_	_	_
21-5	2809-2817	proposed	_	_	_	_
21-6	2818-2820	in	_	_	_	_
21-7	2821-2822	(	abstract[141]	new[141]	_	_
21-8	2823-2824	a	abstract[139]|abstract[141]	new[139]|new[141]	coref	23-7[161_139]
21-9	2825-2832	visible	abstract[139]|abstract[141]	new[139]|new[141]	_	_
21-10	2833-2838	light	abstract|abstract[139]|abstract[141]	new|new[139]|new[141]	coref	29-23
21-11	2839-2847	spectrum	abstract[139]|abstract[141]	new[139]|new[141]	_	_
21-12	2848-2849	)	abstract[141]	new[141]	_	_
21-13	2850-2858	computer	object|abstract[141]	new|new[141]	_	_
21-14	2859-2865	vision	abstract[141]	new[141]	_	_
21-15	2866-2868	to	_	_	_	_
21-16	2869-2876	improve	_	_	_	_
21-17	2877-2880	low	object[143]	giv[143]	coref	29-23[185_143]
21-18	2881-2891	resolution	abstract|object[143]	giv|giv[143]	coref	28-8[177_0]
21-19	2892-2898	images	object[143]	giv[143]	_	_
21-20	2899-2901	or	_	_	_	_
21-21	2902-2904	to	_	_	_	_
21-22	2905-2911	detect	_	_	_	_
21-23	2912-2913	(	_	_	_	_
21-24	2914-2917	and	_	_	_	_
21-25	2918-2925	amplify	_	_	_	_
21-26	2926-2927	)	_	_	_	_
21-27	2928-2933	small	_	_	_	_
21-28	2934-2935	,	_	_	_	_
21-29	2936-2941	local	abstract[144]	giv[144]	_	_
21-30	2942-2949	changes	abstract[144]	giv[144]	_	_
21-31	2950-2952	in	abstract[144]	giv[144]	_	_
21-32	2953-2959	videos	abstract[144]|object	giv[144]|new	coref	22-6[149_0]
21-33	2960-2961	.	_	_	_	_

#Text=Subtle intensity variations introduced in thermal videos of a face due to respiratory activities can be enhanced using Eulerian Video Magnification ( EVM ) or related algorithms .
22-1	2962-2968	Subtle	abstract[147]	new[147]	_	_
22-2	2969-2978	intensity	abstract|abstract[147]	new|new[147]	coref	23-4
22-3	2979-2989	variations	abstract[147]	new[147]	_	_
22-4	2990-3000	introduced	_	_	_	_
22-5	3001-3003	in	_	_	_	_
22-6	3004-3011	thermal	animal|object[149]	giv|giv[149]	_	_
22-7	3012-3018	videos	object[149]	giv[149]	_	_
22-8	3019-3021	of	object[149]	giv[149]	_	_
22-9	3022-3023	a	object[149]|object[150]	giv[149]|giv[150]	_	_
22-10	3024-3028	face	object[149]|object[150]	giv[149]|giv[150]	_	_
22-11	3029-3032	due	_	_	_	_
22-12	3033-3035	to	_	_	_	_
22-13	3036-3047	respiratory	event[151]	new[151]	_	_
22-14	3048-3058	activities	event[151]	new[151]	_	_
22-15	3059-3062	can	_	_	_	_
22-16	3063-3065	be	_	_	_	_
22-17	3066-3074	enhanced	_	_	_	_
22-18	3075-3080	using	_	_	_	_
22-19	3081-3089	Eulerian	person|abstract[154]	new|new[154]	appos|appos	22-23[0_154]|22-23[0_154]
22-20	3090-3095	Video	person|abstract[154]	new|new[154]	_	_
22-21	3096-3109	Magnification	abstract[154]	new[154]	_	_
22-22	3110-3111	(	_	_	_	_
22-23	3112-3115	EVM	abstract	giv	coref	27-2
22-24	3116-3117	)	_	_	_	_
22-25	3118-3120	or	_	_	_	_
22-26	3121-3128	related	abstract[156]	giv[156]	coref	28-3[176_156]
22-27	3129-3139	algorithms	abstract[156]	giv[156]	_	_
22-28	3140-3141	.	_	_	_	_

#Text=This technique amplifies intensity differences within a particular frequency spectrum .
23-1	3142-3146	This	abstract[157]	new[157]	_	_
23-2	3147-3156	technique	abstract[157]	new[157]	_	_
23-3	3157-3166	amplifies	_	_	_	_
23-4	3167-3176	intensity	abstract|abstract[159]	giv|new[159]	_	_
23-5	3177-3188	differences	abstract[159]	new[159]	_	_
23-6	3189-3195	within	abstract[159]	new[159]	_	_
23-7	3196-3197	a	abstract[159]|abstract[161]	new[159]|giv[161]	ana	24-1[0_161]
23-8	3198-3208	particular	abstract[159]|abstract[161]	new[159]|giv[161]	_	_
23-9	3209-3218	frequency	abstract[159]|abstract|abstract[161]	new[159]|giv|giv[161]	_	_
23-10	3219-3227	spectrum	abstract[159]|abstract[161]	new[159]|giv[161]	_	_
23-11	3228-3229	.	_	_	_	_

#Text=This works well if the estimate respiratory rate ( frequency ) is known .
24-1	3230-3234	This	abstract	giv	_	_
24-2	3235-3240	works	_	_	_	_
24-3	3241-3245	well	_	_	_	_
24-4	3246-3248	if	_	_	_	_
24-5	3249-3252	the	abstract[164]	giv[164]	appos	24-10[0_164]
24-6	3253-3261	estimate	abstract|abstract[164]	new|giv[164]	_	_
24-7	3262-3273	respiratory	abstract[164]	giv[164]	_	_
24-8	3274-3278	rate	abstract[164]	giv[164]	_	_
24-9	3279-3280	(	_	_	_	_
24-10	3281-3290	frequency	abstract	giv	_	_
24-11	3291-3292	)	_	_	_	_
24-12	3293-3295	is	_	_	_	_
24-13	3296-3301	known	_	_	_	_
24-14	3302-3303	.	_	_	_	_

#Text=Otherwise , noise and motion artefacts are highly amplified .
25-1	3304-3313	Otherwise	_	_	_	_
25-2	3314-3315	,	_	_	_	_
25-3	3316-3321	noise	abstract	new	_	_
25-4	3322-3325	and	_	_	_	_
25-5	3326-3332	motion	abstract|abstract[168]	new|new[168]	_	_
25-6	3333-3342	artefacts	abstract[168]	new[168]	_	_
25-7	3343-3346	are	_	_	_	_
25-8	3347-3353	highly	_	_	_	_
25-9	3354-3363	amplified	_	_	_	_
25-10	3364-3365	.	_	_	_	_

#Text=Therefore , some researchers propose to magnify only selected segments within a video .
26-1	3366-3375	Therefore	_	_	_	_
26-2	3376-3377	,	_	_	_	_
26-3	3378-3382	some	person[169]	new[169]	_	_
26-4	3383-3394	researchers	person[169]	new[169]	_	_
26-5	3395-3402	propose	_	_	_	_
26-6	3403-3405	to	_	_	_	_
26-7	3406-3413	magnify	_	_	_	_
26-8	3414-3418	only	abstract[170]	new[170]	_	_
26-9	3419-3427	selected	abstract[170]	new[170]	_	_
26-10	3428-3436	segments	abstract[170]	new[170]	_	_
26-11	3437-3443	within	_	_	_	_
26-12	3444-3445	a	abstract[171]	giv[171]	_	_
26-13	3446-3451	video	abstract[171]	giv[171]	_	_
26-14	3452-3453	.	_	_	_	_

#Text=The EVM algorithm has been already successfully used for enhancing vital sign signals .
27-1	3454-3457	The	abstract[173]	new[173]	_	_
27-2	3458-3461	EVM	abstract|abstract[173]	giv|new[173]	_	_
27-3	3462-3471	algorithm	abstract[173]	new[173]	_	_
27-4	3472-3475	has	_	_	_	_
27-5	3476-3480	been	_	_	_	_
27-6	3481-3488	already	_	_	_	_
27-7	3489-3501	successfully	_	_	_	_
27-8	3502-3506	used	_	_	_	_
27-9	3507-3510	for	_	_	_	_
27-10	3511-3520	enhancing	_	_	_	_
27-11	3521-3526	vital	abstract[175]	new[175]	_	_
27-12	3527-3531	sign	abstract|abstract[175]	new|new[175]	_	_
27-13	3532-3539	signals	abstract[175]	new[175]	_	_
27-14	3540-3541	.	_	_	_	_

#Text=Recently , many different deep-learning algorithms for super resolution have been proposed .
28-1	3542-3550	Recently	_	_	_	_
28-2	3551-3552	,	_	_	_	_
28-3	3553-3557	many	abstract[176]	giv[176]	coref	29-6[179_176]
28-4	3558-3567	different	abstract[176]	giv[176]	_	_
28-5	3568-3581	deep-learning	abstract[176]	giv[176]	_	_
28-6	3582-3592	algorithms	abstract[176]	giv[176]	_	_
28-7	3593-3596	for	abstract[176]	giv[176]	_	_
28-8	3597-3602	super	abstract[176]|abstract[177]	giv[176]|giv[177]	ana	29-1[0_177]
28-9	3603-3613	resolution	abstract[176]|abstract[177]	giv[176]|giv[177]	_	_
28-10	3614-3618	have	_	_	_	_
28-11	3619-3623	been	_	_	_	_
28-12	3624-3632	proposed	_	_	_	_
28-13	3633-3634	.	_	_	_	_

#Text=It has been proved that such algorithms can efficiently improve the presentation of details in the processed low-resolution ( LR ) visible light images .
29-1	3635-3637	It	abstract	giv	coref	33-11[213_0]
29-2	3638-3641	has	_	_	_	_
29-3	3642-3646	been	_	_	_	_
29-4	3647-3653	proved	_	_	_	_
29-5	3654-3658	that	_	_	_	_
29-6	3659-3663	such	abstract[179]	giv[179]	coref	35-10[236_179]
29-7	3664-3674	algorithms	abstract[179]	giv[179]	_	_
29-8	3675-3678	can	_	_	_	_
29-9	3679-3690	efficiently	_	_	_	_
29-10	3691-3698	improve	_	_	_	_
29-11	3699-3702	the	abstract[180]	new[180]	_	_
29-12	3703-3715	presentation	abstract[180]	new[180]	_	_
29-13	3716-3718	of	abstract[180]	new[180]	_	_
29-14	3719-3726	details	abstract[180]|abstract[181]	new[180]|new[181]	_	_
29-15	3727-3729	in	abstract[180]|abstract[181]	new[180]|new[181]	_	_
29-16	3730-3733	the	abstract[180]|abstract[181]|abstract[182]	new[180]|new[181]|new[182]	appos	29-20[0_182]
29-17	3734-3743	processed	abstract[180]|abstract[181]|abstract[182]	new[180]|new[181]|new[182]	_	_
29-18	3744-3758	low-resolution	abstract[180]|abstract[181]|abstract[182]	new[180]|new[181]|new[182]	_	_
29-19	3759-3760	(	_	_	_	_
29-20	3761-3763	LR	abstract	giv	coref	33-8
29-21	3764-3765	)	_	_	_	_
29-22	3766-3773	visible	_	_	_	_
29-23	3774-3779	light	abstract|object[185]	giv|giv[185]	_	_
29-24	3780-3786	images	object[185]	giv[185]	_	_
29-25	3787-3788	.	_	_	_	_

#Text=One of the first method in this area was SRCNN , which implemented a single Convolutional Neural Network ( CNN ) achieving the state-of-the-art restoration quality .
30-1	3789-3792	One	abstract[186]	new[186]	coref	30-10[0_186]
30-2	3793-3795	of	abstract[186]	new[186]	_	_
30-3	3796-3799	the	abstract[186]|abstract[187]	new[186]|new[187]	_	_
30-4	3800-3805	first	abstract[186]|abstract[187]	new[186]|new[187]	_	_
30-5	3806-3812	method	abstract[186]|abstract[187]	new[186]|new[187]	_	_
30-6	3813-3815	in	abstract[186]|abstract[187]	new[186]|new[187]	_	_
30-7	3816-3820	this	abstract[186]|abstract[187]|abstract[188]	new[186]|new[187]|new[188]	_	_
30-8	3821-3825	area	abstract[186]|abstract[187]|abstract[188]	new[186]|new[187]|new[188]	_	_
30-9	3826-3829	was	_	_	_	_
30-10	3830-3835	SRCNN	abstract	giv	_	_
30-11	3836-3837	,	_	_	_	_
30-12	3838-3843	which	_	_	_	_
30-13	3844-3855	implemented	_	_	_	_
30-14	3856-3857	a	abstract[191]	new[191]	appos	30-20[0_191]
30-15	3858-3864	single	abstract[191]	new[191]	_	_
30-16	3865-3878	Convolutional	abstract[191]	new[191]	_	_
30-17	3879-3885	Neural	abstract|abstract[191]	new|new[191]	coref	31-5
30-18	3886-3893	Network	abstract[191]	new[191]	_	_
30-19	3894-3895	(	_	_	_	_
30-20	3896-3899	CNN	abstract	giv	coref	32-8[205_0]
30-21	3900-3901	)	_	_	_	_
30-22	3902-3911	achieving	_	_	_	_
30-23	3912-3915	the	abstract[194]	new[194]	coref	31-18[200_194]
30-24	3916-3932	state-of-the-art	abstract[194]	new[194]	_	_
30-25	3933-3944	restoration	abstract|abstract[194]	new|new[194]	coref	31-19
30-26	3945-3952	quality	abstract[194]	new[194]	_	_
30-27	3953-3954	.	_	_	_	_

#Text=Later , different Deep Neural Networks ( DNNs ) based solutions have been introduced to further improve the restoration quality ( or perception ) .
31-1	3955-3960	Later	_	_	_	_
31-2	3961-3962	,	_	_	_	_
31-3	3963-3972	different	place[196]	new[196]	coref	34-27[231_196]
31-4	3973-3977	Deep	place[196]	new[196]	_	_
31-5	3978-3984	Neural	abstract|place[196]	giv|new[196]	_	_
31-6	3985-3993	Networks	place[196]	new[196]	_	_
31-7	3994-3995	(	_	_	_	_
31-8	3996-4000	DNNs	abstract	new	_	_
31-9	4001-4002	)	_	_	_	_
31-10	4003-4008	based	_	_	_	_
31-11	4009-4018	solutions	abstract	new	_	_
31-12	4019-4023	have	_	_	_	_
31-13	4024-4028	been	_	_	_	_
31-14	4029-4039	introduced	_	_	_	_
31-15	4040-4042	to	_	_	_	_
31-16	4043-4050	further	_	_	_	_
31-17	4051-4058	improve	_	_	_	_
31-18	4059-4062	the	abstract[200]	giv[200]	_	_
31-19	4063-4074	restoration	abstract|abstract[200]	giv|giv[200]	_	_
31-20	4075-4082	quality	abstract[200]	giv[200]	_	_
31-21	4083-4084	(	_	_	_	_
31-22	4085-4087	or	_	_	_	_
31-23	4088-4098	perception	abstract	new	_	_
31-24	4099-4100	)	_	_	_	_
31-25	4101-4102	.	_	_	_	_

#Text=In Kim et al. introduced a novel Deeply Recursive Convolutional Network ( DRCN ) model .
32-1	4103-4105	In	_	_	_	_
32-2	4106-4109	Kim	person	new	_	_
32-3	4110-4112	et	_	_	_	_
32-4	4113-4116	al.	_	_	_	_
32-5	4117-4127	introduced	_	_	_	_
32-6	4128-4129	a	_	_	_	_
32-7	4130-4135	novel	_	_	_	_
32-8	4136-4142	Deeply	abstract[205]|abstract[207]	giv[205]|new[207]	appos|ana|appos|ana	32-13[0_205]|33-1[0_207]|32-13[0_205]|33-1[0_207]
32-9	4143-4152	Recursive	substance|abstract[205]|abstract[207]	new|giv[205]|new[207]	coref	34-16
32-10	4153-4166	Convolutional	person|abstract[205]|abstract[207]	new|giv[205]|new[207]	_	_
32-11	4167-4174	Network	abstract[205]|abstract[207]	giv[205]|new[207]	_	_
32-12	4175-4176	(	abstract[207]	new[207]	_	_
32-13	4177-4181	DRCN	abstract|abstract[207]	giv|new[207]	_	_
32-14	4182-4183	)	abstract[207]	new[207]	_	_
32-15	4184-4189	model	abstract[207]	new[207]	_	_
32-16	4190-4191	.	_	_	_	_

#Text=It utilizes a skip connection correlating a LR input with a high resolution ( HR ) reference data and uses recursive supervision to minimize the exploding/vanishing gradients problem .
33-1	4192-4194	It	abstract	giv	_	_
33-2	4195-4203	utilizes	_	_	_	_
33-3	4204-4205	a	abstract[210]	new[210]	_	_
33-4	4206-4210	skip	abstract|abstract[210]	new|new[210]	_	_
33-5	4211-4221	connection	abstract[210]	new[210]	_	_
33-6	4222-4233	correlating	_	_	_	_
33-7	4234-4235	a	abstract[212]	new[212]	_	_
33-8	4236-4238	LR	abstract|abstract[212]	giv|new[212]	_	_
33-9	4239-4244	input	abstract[212]	new[212]	_	_
33-10	4245-4249	with	abstract[212]	new[212]	_	_
33-11	4250-4251	a	abstract[212]|abstract[213]	new[212]|giv[213]	coref	33-25[218_213]
33-12	4252-4256	high	abstract[212]|abstract[213]	new[212]|giv[213]	_	_
33-13	4257-4267	resolution	abstract[212]|abstract[213]	new[212]|giv[213]	_	_
33-14	4268-4269	(	_	_	_	_
33-15	4270-4272	HR	time	new	_	_
33-16	4273-4274	)	_	_	_	_
33-17	4275-4284	reference	abstract[215]	new[215]	_	_
33-18	4285-4289	data	abstract[215]	new[215]	_	_
33-19	4290-4293	and	_	_	_	_
33-20	4294-4298	uses	_	_	_	_
33-21	4299-4308	recursive	abstract[216]	new[216]	_	_
33-22	4309-4320	supervision	abstract[216]	new[216]	_	_
33-23	4321-4323	to	_	_	_	_
33-24	4324-4332	minimize	_	_	_	_
33-25	4333-4336	the	abstract[218]	giv[218]	_	_
33-26	4337-4356	exploding/vanishing	abstract[218]	giv[218]	_	_
33-27	4357-4366	gradients	abstract|abstract[218]	new|giv[218]	_	_
33-28	4367-4374	problem	abstract[218]	giv[218]	_	_
33-29	4375-4376	.	_	_	_	_

#Text=Other improvements to SR include the application of residual mappings and gradient clipping ( Deeply Recursive Residual Network ( DRRN ) ) , the use of attention networks , the application of multi-scale residual hierarchical networks , etc.
34-1	4377-4382	Other	abstract[219]	new[219]	_	_
34-2	4383-4395	improvements	abstract[219]	new[219]	_	_
34-3	4396-4398	to	abstract[219]	new[219]	_	_
34-4	4399-4401	SR	abstract[219]|abstract	new[219]|new	_	_
34-5	4402-4409	include	_	_	_	_
34-6	4410-4413	the	abstract[221]	new[221]	_	_
34-7	4414-4425	application	abstract[221]	new[221]	_	_
34-8	4426-4428	of	abstract[221]	new[221]	_	_
34-9	4429-4437	residual	abstract[221]|abstract[222]	new[221]|new[222]	_	_
34-10	4438-4446	mappings	abstract[221]|abstract[222]	new[221]|new[222]	_	_
34-11	4447-4450	and	abstract[221]	new[221]	_	_
34-12	4451-4459	gradient	abstract[221]|substance|abstract[224]	new[221]|new|new[224]	appos|appos	34-15[227_224]|34-15[227_224]
34-13	4460-4468	clipping	abstract[221]|abstract[224]	new[221]|new[224]	_	_
34-14	4469-4470	(	_	_	_	_
34-15	4471-4477	Deeply	abstract[227]	giv[227]	_	_
34-16	4478-4487	Recursive	substance|abstract[227]	giv|giv[227]	_	_
34-17	4488-4496	Residual	person|abstract[227]	new|giv[227]	_	_
34-18	4497-4504	Network	abstract[227]	giv[227]	_	_
34-19	4505-4506	(	_	_	_	_
34-20	4507-4511	DRRN	object	new	_	_
34-21	4512-4513	)	_	_	_	_
34-22	4514-4515	)	_	_	_	_
34-23	4516-4517	,	_	_	_	_
34-24	4518-4521	the	abstract[229]	new[229]	_	_
34-25	4522-4525	use	abstract[229]	new[229]	_	_
34-26	4526-4528	of	abstract[229]	new[229]	_	_
34-27	4529-4538	attention	abstract[229]|abstract|place[231]	new[229]|new|giv[231]	coref|coref	34-33[233_231]|34-33[233_231]
34-28	4539-4547	networks	abstract[229]|place[231]	new[229]|giv[231]	_	_
34-29	4548-4549	,	_	_	_	_
34-30	4550-4553	the	abstract[232]	new[232]	_	_
34-31	4554-4565	application	abstract[232]	new[232]	_	_
34-32	4566-4568	of	abstract[232]	new[232]	_	_
34-33	4569-4580	multi-scale	abstract[232]|place[233]	new[232]|giv[233]	coref	35-14[237_233]
34-34	4581-4589	residual	abstract[232]|place[233]	new[232]|giv[233]	_	_
34-35	4590-4602	hierarchical	abstract[232]|place[233]	new[232]|giv[233]	_	_
34-36	4603-4611	networks	abstract[232]|place[233]	new[232]|giv[233]	_	_
34-37	4612-4613	,	abstract[232]	new[232]	_	_
34-38	4614-4618	etc.	abstract[232]	new[232]	_	_

#Text=The very good results have also been obtained using SR algorithms based on generative networks .
35-1	4619-4622	The	abstract[234]	new[234]	_	_
35-2	4623-4627	very	abstract[234]	new[234]	_	_
35-3	4628-4632	good	abstract[234]	new[234]	_	_
35-4	4633-4640	results	abstract[234]	new[234]	_	_
35-5	4641-4645	have	_	_	_	_
35-6	4646-4650	also	_	_	_	_
35-7	4651-4655	been	_	_	_	_
35-8	4656-4664	obtained	_	_	_	_
35-9	4665-4670	using	_	_	_	_
35-10	4671-4673	SR	person|abstract[236]	new|giv[236]	_	_
35-11	4674-4684	algorithms	abstract[236]	giv[236]	_	_
35-12	4685-4690	based	_	_	_	_
35-13	4691-4693	on	_	_	_	_
35-14	4694-4704	generative	place[237]	giv[237]	_	_
35-15	4705-4713	networks	place[237]	giv[237]	_	_
35-16	4714-4715	.	_	_	_	_
