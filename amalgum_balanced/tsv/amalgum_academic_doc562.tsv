#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=1. Introduction
1-1	0-2	1.	_	_	_	_
1-2	3-15	Introduction	abstract	new	_	_

#Text=Many applications in the real world , such as system identification , regression , and online kernel learning ( OKL ) , require complex nonlinear models .
2-1	16-20	Many	abstract[2]	new[2]	coref	3-13[16_2]
2-2	21-33	applications	abstract[2]	new[2]	_	_
2-3	34-36	in	abstract[2]	new[2]	_	_
2-4	37-40	the	abstract[2]|abstract[3]	new[2]|new[3]	_	_
2-5	41-45	real	abstract[2]|abstract[3]	new[2]|new[3]	_	_
2-6	46-51	world	abstract[2]|abstract[3]	new[2]|new[3]	_	_
2-7	52-53	,	abstract[2]	new[2]	_	_
2-8	54-58	such	abstract[2]	new[2]	_	_
2-9	59-61	as	abstract[2]	new[2]	_	_
2-10	62-68	system	abstract[2]|abstract|abstract[5]	new[2]|new|new[5]	_	_
2-11	69-83	identification	abstract[2]|abstract[5]	new[2]|new[5]	_	_
2-12	84-85	,	abstract[2]	new[2]	_	_
2-13	86-96	regression	abstract[2]|abstract	new[2]|new	_	_
2-14	97-98	,	abstract[2]	new[2]	_	_
2-15	99-102	and	abstract[2]	new[2]	_	_
2-16	103-109	online	abstract[2]|abstract[8]	new[2]|new[8]	appos	2-20[0_8]
2-17	110-116	kernel	abstract[2]|object|abstract[8]	new[2]|new|new[8]	coref	3-2
2-18	117-125	learning	abstract[2]|abstract[8]	new[2]|new[8]	_	_
2-19	126-127	(	_	_	_	_
2-20	128-131	OKL	abstract	giv	coref	4-18
2-21	132-133	)	_	_	_	_
2-22	134-135	,	_	_	_	_
2-23	136-143	require	_	_	_	_
2-24	144-151	complex	abstract[10]	new[10]	_	_
2-25	152-161	nonlinear	abstract[10]	new[10]	_	_
2-26	162-168	models	abstract[10]	new[10]	_	_
2-27	169-170	.	_	_	_	_

#Text=The kernel method using a Mercer kernel has attracted interests in tackling these complex nonlinear applications , which transforms nonlinear applications into linear ones in the reproducing kernel Hilbert space ( RKHS ) .
3-1	171-174	The	abstract[12]	new[12]	coref	5-10[0_12]
3-2	175-181	kernel	object|abstract[12]	giv|new[12]	coref	3-5[14_0]
3-3	182-188	method	abstract[12]	new[12]	_	_
3-4	189-194	using	_	_	_	_
3-5	195-196	a	object[14]	giv[14]	coref	3-28[0_14]
3-6	197-203	Mercer	person|object[14]	new|giv[14]	_	_
3-7	204-210	kernel	object[14]	giv[14]	_	_
3-8	211-214	has	_	_	_	_
3-9	215-224	attracted	_	_	_	_
3-10	225-234	interests	abstract	new	_	_
3-11	235-237	in	_	_	_	_
3-12	238-246	tackling	_	_	_	_
3-13	247-252	these	abstract[16]	giv[16]	coref	3-20[17_16]
3-14	253-260	complex	abstract[16]	giv[16]	_	_
3-15	261-270	nonlinear	abstract[16]	giv[16]	_	_
3-16	271-283	applications	abstract[16]	giv[16]	_	_
3-17	284-285	,	_	_	_	_
3-18	286-291	which	_	_	_	_
3-19	292-302	transforms	abstract	new	coref|none	14-30[132_0]|3-19[0_132]
3-20	303-312	nonlinear	abstract[17]	giv[17]	_	_
3-21	313-325	applications	abstract[17]	giv[17]	_	_
3-22	326-330	into	_	_	_	_
3-23	331-337	linear	abstract[18]	new[18]	_	_
3-24	338-342	ones	abstract[18]	new[18]	_	_
3-25	343-345	in	abstract[18]	new[18]	_	_
3-26	346-349	the	abstract[18]|abstract[21]	new[18]|new[21]	coref	14-20[127_21]
3-27	350-361	reproducing	abstract[18]|abstract[21]	new[18]|new[21]	_	_
3-28	362-368	kernel	abstract[18]|object|abstract[21]	new[18]|giv|new[21]	coref	4-6
3-29	369-376	Hilbert	abstract[18]|person|abstract[21]	new[18]|new|new[21]	_	_
3-30	377-382	space	abstract[18]|abstract[21]	new[18]|new[21]	_	_
3-31	383-384	(	_	_	_	_
3-32	385-389	RKHS	object	new	coref	4-3
3-33	390-391	)	_	_	_	_
3-34	392-393	.	_	_	_	_

#Text=Developed in RKHS , a kernel adaptive filter ( KAF ) is the most celebrated subfield of OKL algorithms .
4-1	394-403	Developed	_	_	_	_
4-2	404-406	in	_	_	_	_
4-3	407-411	RKHS	abstract	giv	_	_
4-4	412-413	,	_	_	_	_
4-5	414-415	a	abstract[25]	new[25]	appos	4-10[0_25]
4-6	416-422	kernel	person|abstract[25]	giv|new[25]	coref	5-17
4-7	423-431	adaptive	abstract[25]	new[25]	_	_
4-8	432-438	filter	abstract[25]	new[25]	_	_
4-9	439-440	(	_	_	_	_
4-10	441-444	KAF	abstract	giv	coref	4-13[27_0]
4-11	445-446	)	_	_	_	_
4-12	447-449	is	_	_	_	_
4-13	450-453	the	abstract[27]	giv[27]	_	_
4-14	454-458	most	abstract[27]	giv[27]	_	_
4-15	459-469	celebrated	abstract[27]	giv[27]	_	_
4-16	470-478	subfield	abstract[27]	giv[27]	_	_
4-17	479-481	of	abstract[27]	giv[27]	_	_
4-18	482-485	OKL	abstract[27]|abstract|abstract[29]	giv[27]|giv|new[29]	coref|coref|coref|coref	5-12|24-11[235_29]|5-12|24-11[235_29]
4-19	486-496	algorithms	abstract[27]|abstract[29]	giv[27]|new[29]	_	_
4-20	497-498	.	_	_	_	_

#Text=Using the simplest stochastic gradient descent ( SGD ) method for learning , KAFs including the kernel least mean square ( KLMS ) algorithm , kernel affine projection algorithm ( KAPA ) , and kernel recursive least squares ( KRLS ) algorithm have been proposed .
5-1	499-504	Using	_	_	_	_
5-2	505-508	the	abstract[31]	new[31]	appos	5-8[0_31]
5-3	509-517	simplest	abstract[31]	new[31]	_	_
5-4	518-528	stochastic	abstract[31]	new[31]	_	_
5-5	529-537	gradient	abstract|abstract[31]	new|new[31]	coref	16-36[152_0]
5-6	538-545	descent	abstract[31]	new[31]	_	_
5-7	546-547	(	_	_	_	_
5-8	548-551	SGD	abstract	giv	coref	25-9[246_0]
5-9	552-553	)	_	_	_	_
5-10	554-560	method	abstract	giv	appos	5-14
5-11	561-564	for	_	_	_	_
5-12	565-573	learning	abstract	giv	coref	21-5[200_0]
5-13	574-575	,	_	_	_	_
5-14	576-580	KAFs	abstract	giv	coref	6-43
5-15	581-590	including	_	_	_	_
5-16	591-594	the	place[37]|abstract[39]	new[37]|new[39]	appos|appos	5-22[0_37]|5-22[0_37]
5-17	595-601	kernel	person|place[37]|abstract[39]	giv|new[37]|new[39]	coref	5-26
5-18	602-607	least	place[37]|abstract[39]	new[37]|new[39]	_	_
5-19	608-612	mean	place[37]|abstract[39]	new[37]|new[39]	_	_
5-20	613-619	square	place[37]|abstract[39]	new[37]|new[39]	_	_
5-21	620-621	(	abstract[39]	new[39]	_	_
5-22	622-626	KLMS	place|abstract[39]	giv|new[39]	coref	17-27
5-23	627-628	)	abstract[39]	new[39]	_	_
5-24	629-638	algorithm	abstract[39]	new[39]	_	_
5-25	639-640	,	_	_	_	_
5-26	641-647	kernel	object|abstract[42]	giv|new[42]	coref|coref|coref|coref	5-35|5-42[0_42]|5-35|5-42[0_42]
5-27	648-654	affine	abstract[42]	new[42]	_	_
5-28	655-665	projection	object|abstract[42]	new|new[42]	_	_
5-29	666-675	algorithm	abstract[42]	new[42]	_	_
5-30	676-677	(	_	_	_	_
5-31	678-682	KAPA	abstract	new	_	_
5-32	683-684	)	_	_	_	_
5-33	685-686	,	_	_	_	_
5-34	687-690	and	_	_	_	_
5-35	691-697	kernel	object|abstract[45]	giv|new[45]	appos|coref|appos|coref	5-40|6-6|5-40|6-6
5-36	698-707	recursive	abstract[45]	new[45]	_	_
5-37	708-713	least	abstract[45]	new[45]	_	_
5-38	714-721	squares	abstract[45]	new[45]	_	_
5-39	722-723	(	_	_	_	_
5-40	724-728	KRLS	abstract	giv	coref	17-33[165_0]
5-41	729-730	)	_	_	_	_
5-42	731-740	algorithm	abstract	giv	coref	16-27[150_0]
5-43	741-745	have	_	_	_	_
5-44	746-750	been	_	_	_	_
5-45	751-759	proposed	_	_	_	_
5-46	760-761	.	_	_	_	_

#Text=However , allocating a new kernel unit as a radial basis function ( RBF ) center with the coming of new data , the linearly growing structure ( called “ dictionary ” hereafter ) will increase the computational and memory requirements in KAFs .
6-1	762-769	However	_	_	_	_
6-2	770-771	,	_	_	_	_
6-3	772-782	allocating	_	_	_	_
6-4	783-784	a	object[49]	new[49]	_	_
6-5	785-788	new	object[49]	new[49]	_	_
6-6	789-795	kernel	person|object[49]	giv|new[49]	coref	10-26
6-7	796-800	unit	object[49]	new[49]	_	_
6-8	801-803	as	_	_	_	_
6-9	804-805	a	_	_	_	_
6-10	806-812	radial	_	_	_	_
6-11	813-818	basis	abstract	new	coref	14-2[118_0]
6-12	819-827	function	_	_	_	_
6-13	828-829	(	_	_	_	_
6-14	830-833	RBF	abstract	new	_	_
6-15	834-835	)	_	_	_	_
6-16	836-842	center	person[52]	new[52]	_	_
6-17	843-847	with	person[52]	new[52]	_	_
6-18	848-851	the	person[52]|abstract[53]	new[52]|new[53]	_	_
6-19	852-858	coming	person[52]|abstract[53]	new[52]|new[53]	_	_
6-20	859-861	of	person[52]|abstract[53]	new[52]|new[53]	_	_
6-21	862-865	new	person[52]|abstract[53]|abstract[54]	new[52]|new[53]|new[54]	coref	8-5[64_54]
6-22	866-870	data	person[52]|abstract[53]|abstract[54]	new[52]|new[53]|new[54]	_	_
6-23	871-872	,	_	_	_	_
6-24	873-876	the	abstract[55]	new[55]	coref	14-38[134_55]
6-25	877-885	linearly	abstract[55]	new[55]	_	_
6-26	886-893	growing	abstract[55]	new[55]	_	_
6-27	894-903	structure	abstract[55]	new[55]	_	_
6-28	904-905	(	_	_	_	_
6-29	906-912	called	_	_	_	_
6-30	913-914	“	object[56]	new[56]	coref	7-6[60_56]
6-31	915-925	dictionary	object[56]	new[56]	_	_
6-32	926-927	”	object[56]	new[56]	_	_
6-33	928-937	hereafter	object[56]	new[56]	_	_
6-34	938-939	)	_	_	_	_
6-35	940-944	will	_	_	_	_
6-36	945-953	increase	_	_	_	_
6-37	954-957	the	abstract[57]	new[57]	_	_
6-38	958-971	computational	abstract[57]	new[57]	_	_
6-39	972-975	and	abstract[57]	new[57]	_	_
6-40	976-982	memory	abstract[57]	new[57]	_	_
6-41	983-995	requirements	abstract[57]	new[57]	_	_
6-42	996-998	in	abstract[57]	new[57]	_	_
6-43	999-1003	KAFs	abstract[57]|abstract	new[57]|giv	coref	10-33[92_0]
6-44	1004-1005	.	_	_	_	_

#Text=To curb the growth of the dictionary , two categories are chosen for sparsification .
7-1	1006-1008	To	_	_	_	_
7-2	1009-1013	curb	_	_	_	_
7-3	1014-1017	the	abstract[59]	new[59]	_	_
7-4	1018-1024	growth	abstract[59]	new[59]	_	_
7-5	1025-1027	of	abstract[59]	new[59]	_	_
7-6	1028-1031	the	abstract[59]|object[60]	new[59]|giv[60]	coref	8-10[0_60]
7-7	1032-1042	dictionary	abstract[59]|object[60]	new[59]|giv[60]	_	_
7-8	1043-1044	,	_	_	_	_
7-9	1045-1048	two	abstract[61]	new[61]	_	_
7-10	1049-1059	categories	abstract[61]	new[61]	_	_
7-11	1060-1063	are	_	_	_	_
7-12	1064-1070	chosen	_	_	_	_
7-13	1071-1074	for	_	_	_	_
7-14	1075-1089	sparsification	abstract	new	_	_
7-15	1090-1091	.	_	_	_	_

#Text=The first category accepts only informative data as new dictionary centers by using a threshold , including the surprise criterion ( SC ) , the coherence criterion ( CC ) , and the vector quantization ( VQ ) .
8-1	1092-1095	The	abstract[63]	new[63]	_	_
8-2	1096-1101	first	abstract[63]	new[63]	_	_
8-3	1102-1110	category	abstract[63]	new[63]	_	_
8-4	1111-1118	accepts	_	_	_	_
8-5	1119-1123	only	abstract[64]	giv[64]	coref	12-18[112_64]
8-6	1124-1135	informative	abstract[64]	giv[64]	_	_
8-7	1136-1140	data	abstract[64]	giv[64]	_	_
8-8	1141-1143	as	abstract[64]	giv[64]	_	_
8-9	1144-1147	new	abstract[64]	giv[64]	_	_
8-10	1148-1158	dictionary	abstract[64]|object	giv[64]|giv	_	_
8-11	1159-1166	centers	abstract[64]	giv[64]	_	_
8-12	1167-1169	by	_	_	_	_
8-13	1170-1175	using	_	_	_	_
8-14	1176-1177	a	abstract[66]	new[66]	_	_
8-15	1178-1187	threshold	abstract[66]	new[66]	_	_
8-16	1188-1189	,	abstract[66]	new[66]	_	_
8-17	1190-1199	including	abstract[66]	new[66]	_	_
8-18	1200-1203	the	abstract[66]|abstract[68]	new[66]|new[68]	appos	8-22[0_68]
8-19	1204-1212	surprise	abstract[66]|abstract|abstract[68]	new[66]|new|new[68]	_	_
8-20	1213-1222	criterion	abstract[66]|abstract[68]	new[66]|new[68]	_	_
8-21	1223-1224	(	_	_	_	_
8-22	1225-1227	SC	abstract	giv	_	_
8-23	1228-1229	)	_	_	_	_
8-24	1230-1231	,	_	_	_	_
8-25	1232-1235	the	abstract[71]	new[71]	coref	21-15[205_71]
8-26	1236-1245	coherence	quantity|abstract[71]	new|new[71]	_	_
8-27	1246-1255	criterion	abstract[71]	new[71]	_	_
8-28	1256-1257	(	_	_	_	_
8-29	1258-1260	CC	abstract	new	_	_
8-30	1261-1262	)	_	_	_	_
8-31	1263-1264	,	_	_	_	_
8-32	1265-1268	and	_	_	_	_
8-33	1269-1272	the	abstract[74]	new[74]	appos	8-37[0_74]
8-34	1273-1279	vector	person|abstract[74]	new|new[74]	coref	13-5
8-35	1280-1292	quantization	abstract[74]	new[74]	_	_
8-36	1293-1294	(	_	_	_	_
8-37	1295-1297	VQ	abstract	giv	_	_
8-38	1298-1299	)	_	_	_	_
8-39	1300-1301	.	_	_	_	_

#Text=However , these methods cannot fully address the growing problem and still introduce additional time consumption at each iteration .
9-1	1302-1309	However	_	_	_	_
9-2	1310-1311	,	_	_	_	_
9-3	1312-1317	these	abstract[76]	new[76]	coref	10-1[82_76]
9-4	1318-1325	methods	abstract[76]	new[76]	_	_
9-5	1326-1332	cannot	_	_	_	_
9-6	1333-1338	fully	_	_	_	_
9-7	1339-1346	address	_	_	_	_
9-8	1347-1350	the	abstract[77]	new[77]	coref	10-50[97_77]
9-9	1351-1358	growing	abstract[77]	new[77]	_	_
9-10	1359-1366	problem	abstract[77]	new[77]	_	_
9-11	1367-1370	and	_	_	_	_
9-12	1371-1376	still	_	_	_	_
9-13	1377-1386	introduce	_	_	_	_
9-14	1387-1397	additional	abstract[79]	new[79]	_	_
9-15	1398-1402	time	abstract|abstract[79]	new|new[79]	_	_
9-16	1403-1414	consumption	abstract[79]	new[79]	_	_
9-17	1415-1417	at	_	_	_	_
9-18	1418-1422	each	abstract[80]	new[80]	_	_
9-19	1423-1432	iteration	abstract[80]	new[80]	_	_
9-20	1433-1434	.	_	_	_	_

#Text=The fixed points methods as the second category , including the fixed-budget ( FB ) , the sliding window ( SW ) , and the kernel approximation methods ( e. g. , the Nystrm method and random Fourier features ( RFFs ) method ) , are used to overcome the sublinearly growing problem .
10-1	1435-1438	The	abstract[82]	giv[82]	coref	10-25[89_82]
10-2	1439-1444	fixed	abstract[82]	giv[82]	_	_
10-3	1445-1451	points	abstract|abstract[82]	new|giv[82]	_	_
10-4	1452-1459	methods	abstract[82]	giv[82]	_	_
10-5	1460-1462	as	abstract[82]	giv[82]	_	_
10-6	1463-1466	the	abstract[82]	giv[82]	_	_
10-7	1467-1473	second	abstract[82]	giv[82]	_	_
10-8	1474-1482	category	abstract[82]	giv[82]	_	_
10-9	1483-1484	,	abstract[82]	giv[82]	_	_
10-10	1485-1494	including	abstract[82]	giv[82]	_	_
10-11	1495-1498	the	abstract[82]	giv[82]	_	_
10-12	1499-1511	fixed-budget	abstract[82]	giv[82]	_	_
10-13	1512-1513	(	_	_	_	_
10-14	1514-1516	FB	abstract	new	coref	11-4
10-15	1517-1518	)	_	_	_	_
10-16	1519-1520	,	_	_	_	_
10-17	1521-1524	the	abstract[85]	new[85]	appos	10-21[0_85]
10-18	1525-1532	sliding	object|abstract[85]	new|new[85]	_	_
10-19	1533-1539	window	abstract[85]	new[85]	_	_
10-20	1540-1541	(	_	_	_	_
10-21	1542-1544	SW	abstract	giv	coref	11-8
10-22	1545-1546	)	_	_	_	_
10-23	1547-1548	,	_	_	_	_
10-24	1549-1552	and	_	_	_	_
10-25	1553-1556	the	abstract[89]	giv[89]	coref	27-28[270_89]
10-26	1557-1563	kernel	object|abstract[89]	giv|giv[89]	coref	14-31[130_0]
10-27	1564-1577	approximation	abstract|abstract[89]	new|giv[89]	_	_
10-28	1578-1585	methods	abstract[89]	giv[89]	_	_
10-29	1586-1587	(	_	_	_	_
10-30	1588-1590	e.	event[90]	new[90]	_	_
10-31	1591-1593	g.	event[90]	new[90]	_	_
10-32	1594-1595	,	_	_	_	_
10-33	1596-1599	the	abstract[92]|abstract[93]	giv[92]|new[93]	coref|coref|coref|coref	10-40[96_92]|11-3[100_93]|10-40[96_92]|11-3[100_93]
10-34	1600-1606	Nystrm	place|abstract[92]|abstract[93]	new|giv[92]|new[93]	coref	12-4
10-35	1607-1613	method	abstract[92]|abstract[93]	giv[92]|new[93]	_	_
10-36	1614-1617	and	abstract[93]	new[93]	_	_
10-37	1618-1624	random	abstract[93]|person[94]	new[93]|new[94]	coref	14-8[0_94]
10-38	1625-1632	Fourier	abstract[93]|person[94]	new[93]|new[94]	_	_
10-39	1633-1641	features	_	_	_	_
10-40	1642-1643	(	abstract[96]	giv[96]	coref	11-3[99_96]
10-41	1644-1648	RFFs	abstract|abstract[96]	new|giv[96]	coref	12-7
10-42	1649-1650	)	abstract[96]	giv[96]	_	_
10-43	1651-1657	method	abstract[96]	giv[96]	_	_
10-44	1658-1659	)	_	_	_	_
10-45	1660-1661	,	_	_	_	_
10-46	1662-1665	are	_	_	_	_
10-47	1666-1670	used	_	_	_	_
10-48	1671-1673	to	_	_	_	_
10-49	1674-1682	overcome	_	_	_	_
10-50	1683-1686	the	abstract[97]	giv[97]	_	_
10-51	1687-1698	sublinearly	abstract[97]	giv[97]	_	_
10-52	1699-1706	growing	abstract[97]	giv[97]	_	_
10-53	1707-1714	problem	abstract[97]	giv[97]	_	_
10-54	1715-1716	.	_	_	_	_

#Text=However , the FB method and the SW method cannot guarantee a good performance in specific environments with a small amount of time .
11-1	1717-1724	However	_	_	_	_
11-2	1725-1726	,	_	_	_	_
11-3	1727-1730	the	abstract[99]|abstract[100]	giv[99]|giv[100]	coref|coref|coref|coref	11-7[102_99]|27-4[260_100]|11-7[102_99]|27-4[260_100]
11-4	1731-1733	FB	abstract|abstract[99]|abstract[100]	giv|giv[99]|giv[100]	_	_
11-5	1734-1740	method	abstract[99]|abstract[100]	giv[99]|giv[100]	_	_
11-6	1741-1744	and	abstract[100]	giv[100]	_	_
11-7	1745-1748	the	abstract[100]|abstract[102]	giv[100]|giv[102]	coref	12-3[108_102]
11-8	1749-1751	SW	abstract[100]|place|abstract[102]	giv[100]|giv|giv[102]	_	_
11-9	1752-1758	method	abstract[100]|abstract[102]	giv[100]|giv[102]	_	_
11-10	1759-1765	cannot	_	_	_	_
11-11	1766-1775	guarantee	_	_	_	_
11-12	1776-1777	a	abstract[103]	new[103]	coref	15-14[138_103]
11-13	1778-1782	good	abstract[103]	new[103]	_	_
11-14	1783-1794	performance	abstract[103]	new[103]	_	_
11-15	1795-1797	in	abstract[103]	new[103]	_	_
11-16	1798-1806	specific	abstract[103]|place[104]	new[103]|new[104]	coref	20-42[196_104]
11-17	1807-1819	environments	abstract[103]|place[104]	new[103]|new[104]	_	_
11-18	1820-1824	with	abstract[103]|place[104]	new[103]|new[104]	_	_
11-19	1825-1826	a	abstract[103]|place[104]|abstract[105]	new[103]|new[104]|new[105]	_	_
11-20	1827-1832	small	abstract[103]|place[104]|abstract[105]	new[103]|new[104]|new[105]	_	_
11-21	1833-1839	amount	abstract[103]|place[104]|abstract[105]	new[103]|new[104]|new[105]	_	_
11-22	1840-1842	of	abstract[103]|place[104]|abstract[105]	new[103]|new[104]|new[105]	_	_
11-23	1843-1847	time	abstract[103]|place[104]|abstract[105]|time	new[103]|new[104]|new[105]|new	_	_
11-24	1848-1849	.	_	_	_	_

#Text=Compared with the Nystrm method , RFFs are drawn from a distribution that is randomly independent from the training data .
12-1	1850-1858	Compared	_	_	_	_
12-2	1859-1863	with	_	_	_	_
12-3	1864-1867	the	abstract[108]	giv[108]	coref	15-10[0_108]
12-4	1868-1874	Nystrm	place|abstract[108]	giv|giv[108]	_	_
12-5	1875-1881	method	abstract[108]	giv[108]	_	_
12-6	1882-1883	,	_	_	_	_
12-7	1884-1888	RFFs	abstract	giv	coref	13-8
12-8	1889-1892	are	_	_	_	_
12-9	1893-1898	drawn	_	_	_	_
12-10	1899-1903	from	_	_	_	_
12-11	1904-1905	a	abstract[110]	new[110]	_	_
12-12	1906-1918	distribution	abstract[110]	new[110]	_	_
12-13	1919-1923	that	_	_	_	_
12-14	1924-1926	is	_	_	_	_
12-15	1927-1935	randomly	_	_	_	_
12-16	1936-1947	independent	_	_	_	_
12-17	1948-1952	from	_	_	_	_
12-18	1953-1956	the	abstract[112]	giv[112]	coref	14-17[124_112]
12-19	1957-1965	training	abstract|abstract[112]	new|giv[112]	coref	18-33
12-20	1966-1970	data	abstract[112]	giv[112]	_	_
12-21	1971-1972	.	_	_	_	_

#Text=Due to a data-independent vector representation , RFFs can provide a good solution to non-stationary circumstances .
13-1	1973-1976	Due	_	_	_	_
13-2	1977-1979	to	_	_	_	_
13-3	1980-1981	a	abstract[114]	new[114]	_	_
13-4	1982-1998	data-independent	abstract[114]	new[114]	_	_
13-5	1999-2005	vector	person|abstract[114]	giv|new[114]	_	_
13-6	2006-2020	representation	abstract[114]	new[114]	_	_
13-7	2021-2022	,	_	_	_	_
13-8	2023-2027	RFFs	object	giv	coref	14-5
13-9	2028-2031	can	_	_	_	_
13-10	2032-2039	provide	_	_	_	_
13-11	2040-2041	a	abstract[116]	new[116]	coref	31-10[299_116]
13-12	2042-2046	good	abstract[116]	new[116]	_	_
13-13	2047-2055	solution	abstract[116]	new[116]	_	_
13-14	2056-2058	to	abstract[116]	new[116]	_	_
13-15	2059-2073	non-stationary	abstract[116]|abstract[117]	new[116]|new[117]	_	_
13-16	2074-2087	circumstances	abstract[116]|abstract[117]	new[116]|new[117]	_	_
13-17	2088-2089	.	_	_	_	_

#Text=On the basis of RFFs , random Fourier mapping ( RFM ) is proposed by mapping input data into a finite-dimensional random Fourier features space ( RFFS ) using a randomized feature kernel ’s Fourier transform in a fixed network structure .
14-1	2090-2092	On	_	_	_	_
14-2	2093-2096	the	abstract[118]	giv[118]	_	_
14-3	2097-2102	basis	abstract[118]	giv[118]	_	_
14-4	2103-2105	of	abstract[118]	giv[118]	_	_
14-5	2106-2110	RFFs	abstract[118]|abstract	giv[118]|giv	_	_
14-6	2111-2112	,	_	_	_	_
14-7	2113-2119	random	abstract[121]	new[121]	appos	14-11[0_121]
14-8	2120-2127	Fourier	person|abstract[121]	giv|new[121]	coref	14-23
14-9	2128-2135	mapping	abstract[121]	new[121]	_	_
14-10	2136-2137	(	_	_	_	_
14-11	2138-2141	RFM	abstract	giv	coref	15-1[135_0]
14-12	2142-2143	)	_	_	_	_
14-13	2144-2146	is	_	_	_	_
14-14	2147-2155	proposed	_	_	_	_
14-15	2156-2158	by	_	_	_	_
14-16	2159-2166	mapping	_	_	_	_
14-17	2167-2172	input	abstract|abstract[124]	new|giv[124]	coref|coref	18-32[176_124]|18-32[176_124]
14-18	2173-2177	data	abstract[124]	giv[124]	_	_
14-19	2178-2182	into	_	_	_	_
14-20	2183-2184	a	abstract[127]	giv[127]	appos	14-27[0_127]
14-21	2185-2203	finite-dimensional	abstract[127]	giv[127]	_	_
14-22	2204-2210	random	abstract[127]	giv[127]	_	_
14-23	2211-2218	Fourier	person|abstract[127]	giv|giv[127]	coref	14-35
14-24	2219-2227	features	abstract|abstract[127]	new|giv[127]	_	_
14-25	2228-2233	space	abstract[127]	giv[127]	_	_
14-26	2234-2235	(	_	_	_	_
14-27	2236-2240	RFFS	abstract	giv	_	_
14-28	2241-2242	)	_	_	_	_
14-29	2243-2248	using	_	_	_	_
14-30	2249-2250	a	abstract[132]	new[132]	_	_
14-31	2251-2261	randomized	object[130]|abstract[132]	giv[130]|new[132]	coref	16-13[0_130]
14-32	2262-2269	feature	abstract|object[130]|abstract[132]	new|giv[130]|new[132]	_	_
14-33	2270-2276	kernel	object[130]|abstract[132]	giv[130]|new[132]	_	_
14-34	2277-2279	’s	object[130]|abstract[132]	giv[130]|new[132]	_	_
14-35	2280-2287	Fourier	person|abstract[132]	giv|new[132]	coref	16-11
14-36	2288-2297	transform	abstract[132]	new[132]	_	_
14-37	2298-2300	in	abstract[132]	new[132]	_	_
14-38	2301-2302	a	abstract[132]|abstract[134]	new[132]|giv[134]	_	_
14-39	2303-2308	fixed	abstract[132]|abstract[134]	new[132]|giv[134]	_	_
14-40	2309-2316	network	abstract[132]|place|abstract[134]	new[132]|new|giv[134]	_	_
14-41	2317-2326	structure	abstract[132]|abstract[134]	new[132]|giv[134]	_	_
14-42	2327-2328	.	_	_	_	_

#Text=The RFM alleviates the computational and storage burdens of KAFs , and ensures a satisfactory performance under non-stationary conditions .
15-1	2329-2332	The	abstract[135]	giv[135]	coref	16-7[0_135]
15-2	2333-2336	RFM	abstract[135]	giv[135]	_	_
15-3	2337-2347	alleviates	_	_	_	_
15-4	2348-2351	the	abstract[136]	new[136]	_	_
15-5	2352-2365	computational	abstract[136]	new[136]	_	_
15-6	2366-2369	and	abstract[136]	new[136]	_	_
15-7	2370-2377	storage	abstract[136]	new[136]	_	_
15-8	2378-2385	burdens	abstract[136]	new[136]	_	_
15-9	2386-2388	of	abstract[136]	new[136]	_	_
15-10	2389-2393	KAFs	abstract[136]|abstract	new[136]|giv	coref	16-5
15-11	2394-2395	,	_	_	_	_
15-12	2396-2399	and	_	_	_	_
15-13	2400-2407	ensures	_	_	_	_
15-14	2408-2409	a	abstract[138]	giv[138]	coref	18-25[174_138]
15-15	2410-2422	satisfactory	abstract[138]	giv[138]	_	_
15-16	2423-2434	performance	abstract[138]	giv[138]	_	_
15-17	2435-2440	under	abstract[138]	giv[138]	_	_
15-18	2441-2455	non-stationary	abstract[138]|abstract[139]	giv[138]|new[139]	_	_
15-19	2456-2466	conditions	abstract[138]|abstract[139]	giv[138]|new[139]	_	_
15-20	2467-2468	.	_	_	_	_

#Text=The examples for developing KAFs with RFM are the random Fourier features kernel least mean square ( RFFKLMS ) algorithm , random Fourier features maximum correntropy ( RFFMC ) algorithm , and random Fourier features conjugate gradient ( RFFCG ) algorithm .
16-1	2469-2472	The	abstract[140]	new[140]	coref	16-9[144_140]
16-2	2473-2481	examples	abstract[140]	new[140]	_	_
16-3	2482-2485	for	_	_	_	_
16-4	2486-2496	developing	_	_	_	_
16-5	2497-2501	KAFs	abstract	giv	coref	17-40
16-6	2502-2506	with	_	_	_	_
16-7	2507-2510	RFM	abstract	giv	_	_
16-8	2511-2514	are	_	_	_	_
16-9	2515-2518	the	abstract[144]	giv[144]	ana	17-8[0_144]
16-10	2519-2525	random	abstract[144]	giv[144]	_	_
16-11	2526-2533	Fourier	person|abstract[144]	giv|giv[144]	coref	16-22[147_0]
16-12	2534-2542	features	abstract[144]	giv[144]	_	_
16-13	2543-2549	kernel	person	giv	coref	30-5
16-14	2550-2555	least	_	_	_	_
16-15	2556-2560	mean	_	_	_	_
16-16	2561-2567	square	_	_	_	_
16-17	2568-2569	(	_	_	_	_
16-18	2570-2577	RFFKLMS	abstract	new	_	_
16-19	2578-2579	)	_	_	_	_
16-20	2580-2589	algorithm	_	_	_	_
16-21	2590-2591	,	_	_	_	_
16-22	2592-2598	random	person[147]	giv[147]	coref	16-33[151_147]
16-23	2599-2606	Fourier	person[147]	giv[147]	_	_
16-24	2607-2615	features	_	_	_	_
16-25	2616-2623	maximum	abstract[148]	new[148]	coref	21-17[0_148]
16-26	2624-2635	correntropy	abstract[148]	new[148]	_	_
16-27	2636-2637	(	abstract[148]|abstract[150]	new[148]|giv[150]	coref	16-41[0_150]
16-28	2638-2643	RFFMC	abstract[148]|abstract|abstract[150]	new[148]|new|giv[150]	_	_
16-29	2644-2645	)	abstract[148]|abstract[150]	new[148]|giv[150]	_	_
16-30	2646-2655	algorithm	abstract[148]|abstract[150]	new[148]|giv[150]	_	_
16-31	2656-2657	,	_	_	_	_
16-32	2658-2661	and	_	_	_	_
16-33	2662-2668	random	person[151]	giv[151]	_	_
16-34	2669-2676	Fourier	person[151]	giv[151]	_	_
16-35	2677-2685	features	_	_	_	_
16-36	2686-2695	conjugate	abstract[152]	giv[152]	appos	16-39[0_152]
16-37	2696-2704	gradient	abstract[152]	giv[152]	_	_
16-38	2705-2706	(	_	_	_	_
16-39	2707-2712	RFFCG	abstract	giv	coref	25-11
16-40	2713-2714	)	_	_	_	_
16-41	2715-2724	algorithm	abstract	giv	_	_
16-42	2725-2726	.	_	_	_	_

#Text=For the loss function , due to their simplicity , smoothness , and mathematical tractability , the second-order statistical measures ( e. g. , minimum mean square error ( MMSE ) and least squares ) are widely utilized in KAFs .
17-1	2727-2730	For	_	_	_	_
17-2	2731-2734	the	abstract[156]	new[156]	_	_
17-3	2735-2739	loss	abstract|abstract[156]	new|new[156]	coref	23-18[226_0]
17-4	2740-2748	function	abstract[156]	new[156]	_	_
17-5	2749-2750	,	_	_	_	_
17-6	2751-2754	due	_	_	_	_
17-7	2755-2757	to	_	_	_	_
17-8	2758-2763	their	abstract|abstract[158]	giv|new[158]	_	_
17-9	2764-2774	simplicity	abstract[158]	new[158]	_	_
17-10	2775-2776	,	_	_	_	_
17-11	2777-2787	smoothness	abstract	new	_	_
17-12	2788-2789	,	_	_	_	_
17-13	2790-2793	and	_	_	_	_
17-14	2794-2806	mathematical	abstract[160]	new[160]	_	_
17-15	2807-2819	tractability	abstract[160]	new[160]	_	_
17-16	2820-2821	,	_	_	_	_
17-17	2822-2825	the	abstract[161]	new[161]	coref	18-6[168_161]
17-18	2826-2838	second-order	abstract[161]	new[161]	_	_
17-19	2839-2850	statistical	abstract[161]	new[161]	_	_
17-20	2851-2859	measures	abstract[161]	new[161]	_	_
17-21	2860-2861	(	_	_	_	_
17-22	2862-2864	e.	_	_	_	_
17-23	2865-2867	g.	_	_	_	_
17-24	2868-2869	,	_	_	_	_
17-25	2870-2877	minimum	abstract[163]	new[163]	appos	17-30[0_163]
17-26	2878-2882	mean	abstract[163]	new[163]	_	_
17-27	2883-2889	square	place|abstract[163]	giv|new[163]	coref	31-14
17-28	2890-2895	error	abstract[163]	new[163]	_	_
17-29	2896-2897	(	_	_	_	_
17-30	2898-2902	MMSE	abstract	giv	coref	19-17[181_0]
17-31	2903-2904	)	_	_	_	_
17-32	2905-2908	and	_	_	_	_
17-33	2909-2914	least	abstract[165]	giv[165]	coref	31-21[0_165]
17-34	2915-2922	squares	abstract[165]	giv[165]	_	_
17-35	2923-2924	)	_	_	_	_
17-36	2925-2928	are	_	_	_	_
17-37	2929-2935	widely	_	_	_	_
17-38	2936-2944	utilized	_	_	_	_
17-39	2945-2947	in	_	_	_	_
17-40	2948-2952	KAFs	abstract	giv	coref	18-3
17-41	2953-2954	.	_	_	_	_

#Text=However , KAFs based on the second-order statistical measures are sensitive to non-Gaussian noises including the sub-Gaussian and super-Gaussian noises , which means that their performance may be seriously degraded if the training data are contaminated by outliers .
18-1	2955-2962	However	_	_	_	_
18-2	2963-2964	,	_	_	_	_
18-3	2965-2969	KAFs	abstract	giv	coref	21-36[211_0]
18-4	2970-2975	based	_	_	_	_
18-5	2976-2978	on	_	_	_	_
18-6	2979-2982	the	abstract[168]	giv[168]	coref	19-6[179_168]
18-7	2983-2995	second-order	abstract[168]	giv[168]	_	_
18-8	2996-3007	statistical	abstract[168]	giv[168]	_	_
18-9	3008-3016	measures	abstract[168]	giv[168]	_	_
18-10	3017-3020	are	_	_	_	_
18-11	3021-3030	sensitive	_	_	_	_
18-12	3031-3033	to	_	_	_	_
18-13	3034-3046	non-Gaussian	abstract[169]	new[169]	_	_
18-14	3047-3053	noises	abstract[169]	new[169]	_	_
18-15	3054-3063	including	abstract[169]	new[169]	_	_
18-16	3064-3067	the	abstract[169]|abstract[170]	new[169]|new[170]	_	_
18-17	3068-3080	sub-Gaussian	abstract[169]|abstract[170]	new[169]|new[170]	_	_
18-18	3081-3084	and	abstract[169]	new[169]	_	_
18-19	3085-3099	super-Gaussian	abstract[169]|animal|abstract[172]	new[169]|new|new[172]	ana|ana	18-25[0_172]|18-25[0_172]
18-20	3100-3106	noises	abstract[169]|abstract[172]	new[169]|new[172]	_	_
18-21	3107-3108	,	_	_	_	_
18-22	3109-3114	which	_	_	_	_
18-23	3115-3120	means	_	_	_	_
18-24	3121-3125	that	_	_	_	_
18-25	3126-3131	their	abstract|abstract[174]	giv|giv[174]	coref|coref	20-16[189_0]|20-16[189_0]
18-26	3132-3143	performance	abstract[174]	giv[174]	_	_
18-27	3144-3147	may	_	_	_	_
18-28	3148-3150	be	_	_	_	_
18-29	3151-3160	seriously	_	_	_	_
18-30	3161-3169	degraded	_	_	_	_
18-31	3170-3172	if	_	_	_	_
18-32	3173-3176	the	abstract[176]	giv[176]	_	_
18-33	3177-3185	training	abstract|abstract[176]	giv|giv[176]	coref	22-24
18-34	3186-3190	data	abstract[176]	giv[176]	_	_
18-35	3191-3194	are	_	_	_	_
18-36	3195-3207	contaminated	_	_	_	_
18-37	3208-3210	by	_	_	_	_
18-38	3211-3219	outliers	abstract	new	_	_
18-39	3220-3221	.	_	_	_	_

#Text=To handle this issue , robust statistical measures have therefore gained more attention , among which the lower-order error measure and the higher-lower error measure are two typical examples .
19-1	3222-3224	To	_	_	_	_
19-2	3225-3231	handle	_	_	_	_
19-3	3232-3236	this	abstract[178]	new[178]	_	_
19-4	3237-3242	issue	abstract[178]	new[178]	_	_
19-5	3243-3244	,	_	_	_	_
19-6	3245-3251	robust	abstract[179]	giv[179]	coref	21-5[203_179]
19-7	3252-3263	statistical	abstract[179]	giv[179]	_	_
19-8	3264-3272	measures	abstract[179]	giv[179]	_	_
19-9	3273-3277	have	_	_	_	_
19-10	3278-3287	therefore	_	_	_	_
19-11	3288-3294	gained	_	_	_	_
19-12	3295-3299	more	abstract[180]	new[180]	_	_
19-13	3300-3309	attention	abstract[180]	new[180]	_	_
19-14	3310-3311	,	_	_	_	_
19-15	3312-3317	among	_	_	_	_
19-16	3318-3323	which	_	_	_	_
19-17	3324-3327	the	abstract[181]	giv[181]	coref	19-24[0_181]
19-18	3328-3339	lower-order	abstract[181]	giv[181]	_	_
19-19	3340-3345	error	abstract[181]	giv[181]	_	_
19-20	3346-3353	measure	abstract	new	coref|none	19-22[183_0]|19-20[0_229]
19-21	3354-3357	and	_	_	_	_
19-22	3358-3361	the	abstract[183]	new[183]	coref	19-27[184_183]
19-23	3362-3374	higher-lower	abstract[183]	new[183]	_	_
19-24	3375-3380	error	abstract|abstract[183]	giv|new[183]	coref	20-5
19-25	3381-3388	measure	abstract[183]	new[183]	_	_
19-26	3389-3392	are	_	_	_	_
19-27	3393-3396	two	abstract[184]	giv[184]	coref	20-3[186_184]
19-28	3397-3404	typical	abstract[184]	giv[184]	_	_
19-29	3405-3413	examples	abstract[184]	giv[184]	_	_
19-30	3414-3415	.	_	_	_	_

#Text=However , the higher-order error measure is not suitable for the mixture of Gaussian and super-Gaussian noises ( Laplace , -stable , etc. ) with poor stability and astringency , and the lower-order measure of error is usually more desirable in these noise environments with slow convergence rate .
20-1	3416-3423	However	_	_	_	_
20-2	3424-3425	,	_	_	_	_
20-3	3426-3429	the	abstract[186]	giv[186]	coref	20-32[193_186]
20-4	3430-3442	higher-order	abstract[186]	giv[186]	_	_
20-5	3443-3448	error	abstract|abstract[186]	giv|giv[186]	coref	20-36
20-6	3449-3456	measure	abstract[186]	giv[186]	_	_
20-7	3457-3459	is	_	_	_	_
20-8	3460-3463	not	_	_	_	_
20-9	3464-3472	suitable	_	_	_	_
20-10	3473-3476	for	_	_	_	_
20-11	3477-3480	the	abstract[187]	new[187]	_	_
20-12	3481-3488	mixture	abstract[187]	new[187]	_	_
20-13	3489-3491	of	abstract[187]	new[187]	_	_
20-14	3492-3500	Gaussian	abstract[187]|person	new[187]|new	_	_
20-15	3501-3504	and	_	_	_	_
20-16	3505-3519	super-Gaussian	abstract[189]	giv[189]	coref	22-14[216_189]
20-17	3520-3526	noises	abstract[189]	giv[189]	_	_
20-18	3527-3528	(	abstract[189]	giv[189]	_	_
20-19	3529-3536	Laplace	abstract[189]|person	giv[189]|new	_	_
20-20	3537-3538	,	abstract[189]	giv[189]	_	_
20-21	3539-3546	-stable	abstract[189]	giv[189]	_	_
20-22	3547-3548	,	abstract[189]	giv[189]	_	_
20-23	3549-3553	etc.	abstract[189]	giv[189]	_	_
20-24	3554-3555	)	abstract[189]	giv[189]	_	_
20-25	3556-3560	with	abstract[189]	giv[189]	_	_
20-26	3561-3565	poor	abstract[189]|abstract[191]	giv[189]|new[191]	_	_
20-27	3566-3575	stability	abstract[189]|abstract[191]	giv[189]|new[191]	_	_
20-28	3576-3579	and	abstract[189]	giv[189]	_	_
20-29	3580-3591	astringency	abstract[189]|abstract	giv[189]|new	_	_
20-30	3592-3593	,	_	_	_	_
20-31	3594-3597	and	_	_	_	_
20-32	3598-3601	the	abstract[193]	giv[193]	coref	23-12[224_193]
20-33	3602-3613	lower-order	abstract[193]	giv[193]	_	_
20-34	3614-3621	measure	abstract[193]	giv[193]	_	_
20-35	3622-3624	of	abstract[193]	giv[193]	_	_
20-36	3625-3630	error	abstract[193]|abstract	giv[193]|giv	coref	21-24
20-37	3631-3633	is	_	_	_	_
20-38	3634-3641	usually	_	_	_	_
20-39	3642-3646	more	_	_	_	_
20-40	3647-3656	desirable	_	_	_	_
20-41	3657-3659	in	_	_	_	_
20-42	3660-3665	these	place[196]	giv[196]	_	_
20-43	3666-3671	noise	abstract|place[196]	new|giv[196]	coref	24-8
20-44	3672-3684	environments	place[196]	giv[196]	_	_
20-45	3685-3689	with	place[196]	giv[196]	_	_
20-46	3690-3694	slow	place[196]|abstract[198]	giv[196]|new[198]	coref	29-10[284_198]
20-47	3695-3706	convergence	place[196]|abstract|abstract[198]	giv[196]|new|new[198]	coref	29-10
20-48	3707-3711	rate	place[196]|abstract[198]	giv[196]|new[198]	_	_
20-49	3712-3713	.	_	_	_	_

#Text=Recently , the information theoretic learning ( ITL ) similarity measures , such as the maximum correntropy criterion ( MCC ) and minimum error entropy criterion ( MEE ) , have been introduced to implement robust KAFs .
21-1	3714-3722	Recently	_	_	_	_
21-2	3723-3724	,	_	_	_	_
21-3	3725-3728	the	abstract[199]	new[199]	_	_
21-4	3729-3740	information	abstract[199]	new[199]	_	_
21-5	3741-3750	theoretic	abstract[199]|abstract[200]|abstract[203]	new[199]|giv[200]|giv[203]	appos|coref|appos|coref	21-8[0_200]|22-1[214_203]|21-8[0_200]|22-1[214_203]
21-6	3751-3759	learning	abstract[199]|abstract[200]|abstract[203]	new[199]|giv[200]|giv[203]	_	_
21-7	3760-3761	(	abstract[199]|abstract[203]	new[199]|giv[203]	_	_
21-8	3762-3765	ITL	abstract[199]|abstract|abstract[203]	new[199]|giv|giv[203]	coref	22-2
21-9	3766-3767	)	abstract[199]|abstract[203]	new[199]|giv[203]	_	_
21-10	3768-3778	similarity	abstract[199]|abstract|abstract[203]	new[199]|new|giv[203]	coref	22-3
21-11	3779-3787	measures	abstract[199]|abstract[203]	new[199]|giv[203]	_	_
21-12	3788-3789	,	abstract[199]|abstract[203]	new[199]|giv[203]	_	_
21-13	3790-3794	such	abstract[199]|abstract[203]	new[199]|giv[203]	_	_
21-14	3795-3797	as	abstract[199]|abstract[203]	new[199]|giv[203]	_	_
21-15	3798-3801	the	abstract[199]|abstract[203]|abstract[205]	new[199]|giv[203]|giv[205]	coref	21-23[209_205]
21-16	3802-3809	maximum	abstract[199]|abstract[203]|abstract[205]	new[199]|giv[203]|giv[205]	_	_
21-17	3810-3821	correntropy	abstract[199]|abstract[203]|abstract|abstract[205]	new[199]|giv[203]|giv|giv[205]	_	_
21-18	3822-3831	criterion	abstract[199]|abstract[203]|abstract[205]	new[199]|giv[203]|giv[205]	_	_
21-19	3832-3833	(	_	_	_	_
21-20	3834-3837	MCC	object	new	_	_
21-21	3838-3839	)	_	_	_	_
21-22	3840-3843	and	_	_	_	_
21-23	3844-3851	minimum	abstract[209]	giv[209]	coref	24-22[0_209]
21-24	3852-3857	error	abstract|abstract[209]	giv|giv[209]	coref	23-9[222_0]
21-25	3858-3865	entropy	quantity|abstract[209]	new|giv[209]	_	_
21-26	3866-3875	criterion	abstract[209]	giv[209]	_	_
21-27	3876-3877	(	_	_	_	_
21-28	3878-3881	MEE	object	new	_	_
21-29	3882-3883	)	_	_	_	_
21-30	3884-3885	,	_	_	_	_
21-31	3886-3890	have	_	_	_	_
21-32	3891-3895	been	_	_	_	_
21-33	3896-3906	introduced	_	_	_	_
21-34	3907-3909	to	_	_	_	_
21-35	3910-3919	implement	_	_	_	_
21-36	3920-3926	robust	abstract[211]	giv[211]	coref	25-5[244_211]
21-37	3927-3931	KAFs	abstract[211]	giv[211]	_	_
21-38	3932-3933	.	_	_	_	_

#Text=The ITL similarity measures have been shown to have a strong robustness against non-Gaussian noises at the expense of increasing computational burden in training processing .
22-1	3934-3937	The	abstract[214]	giv[214]	_	_
22-2	3938-3941	ITL	abstract|abstract[214]	giv|giv[214]	_	_
22-3	3942-3952	similarity	abstract|abstract[214]	giv|giv[214]	_	_
22-4	3953-3961	measures	abstract[214]	giv[214]	_	_
22-5	3962-3966	have	_	_	_	_
22-6	3967-3971	been	_	_	_	_
22-7	3972-3977	shown	_	_	_	_
22-8	3978-3980	to	_	_	_	_
22-9	3981-3985	have	_	_	_	_
22-10	3986-3987	a	abstract[215]	new[215]	_	_
22-11	3988-3994	strong	abstract[215]	new[215]	_	_
22-12	3995-4005	robustness	abstract[215]	new[215]	_	_
22-13	4006-4013	against	abstract[215]	new[215]	_	_
22-14	4014-4026	non-Gaussian	abstract[215]|abstract[216]	new[215]|giv[216]	coref	24-27[240_216]
22-15	4027-4033	noises	abstract[215]|abstract[216]	new[215]|giv[216]	_	_
22-16	4034-4036	at	abstract[215]|abstract[216]	new[215]|giv[216]	_	_
22-17	4037-4040	the	abstract[215]|abstract[216]|abstract[217]	new[215]|giv[216]|new[217]	_	_
22-18	4041-4048	expense	abstract[215]|abstract[216]|abstract[217]	new[215]|giv[216]|new[217]	_	_
22-19	4049-4051	of	_	_	_	_
22-20	4052-4062	increasing	_	_	_	_
22-21	4063-4076	computational	abstract[218]	new[218]	_	_
22-22	4077-4083	burden	abstract[218]	new[218]	_	_
22-23	4084-4086	in	abstract[218]	new[218]	_	_
22-24	4087-4095	training	abstract[218]|abstract|abstract[220]	new[218]|giv|new[220]	_	_
22-25	4096-4106	processing	abstract[218]|abstract[220]	new[218]|new[220]	_	_
22-26	4107-4108	.	_	_	_	_

#Text=In addition , minimizing the logarithmic moments of the error , the logarithmic error measure — including the Cauchy loss ( CL ) with low computational complexity — is an appropriate measure of optimality .
23-1	4109-4111	In	_	_	_	_
23-2	4112-4120	addition	_	_	_	_
23-3	4121-4122	,	_	_	_	_
23-4	4123-4133	minimizing	_	_	_	_
23-5	4134-4137	the	abstract[221]	new[221]	_	_
23-6	4138-4149	logarithmic	abstract[221]	new[221]	_	_
23-7	4150-4157	moments	abstract[221]	new[221]	_	_
23-8	4158-4160	of	abstract[221]	new[221]	_	_
23-9	4161-4164	the	abstract[221]|abstract[222]	new[221]|giv[222]	coref	23-14[0_222]
23-10	4165-4170	error	abstract[221]|abstract[222]	new[221]|giv[222]	_	_
23-11	4171-4172	,	_	_	_	_
23-12	4173-4176	the	abstract[224]	giv[224]	coref	23-30[229_224]
23-13	4177-4188	logarithmic	abstract[224]	giv[224]	_	_
23-14	4189-4194	error	abstract|abstract[224]	giv|giv[224]	_	_
23-15	4195-4202	measure	abstract[224]	giv[224]	_	_
23-16	4203-4204	—	abstract[224]	giv[224]	_	_
23-17	4205-4214	including	abstract[224]	giv[224]	_	_
23-18	4215-4218	the	abstract[224]|abstract[226]	giv[224]|giv[226]	appos	23-22[0_226]
23-19	4219-4225	Cauchy	abstract[224]|person|abstract[226]	giv[224]|new|giv[226]	coref	24-3
23-20	4226-4230	loss	abstract[224]|abstract[226]	giv[224]|giv[226]	_	_
23-21	4231-4232	(	_	_	_	_
23-22	4233-4235	CL	abstract	giv	coref	24-2[232_0]
23-23	4236-4237	)	_	_	_	_
23-24	4238-4242	with	_	_	_	_
23-25	4243-4246	low	abstract[228]	new[228]	coref	29-13[285_228]
23-26	4247-4260	computational	abstract[228]	new[228]	_	_
23-27	4261-4271	complexity	abstract[228]	new[228]	_	_
23-28	4272-4273	—	_	_	_	_
23-29	4274-4276	is	_	_	_	_
23-30	4277-4279	an	abstract[229]	giv[229]	_	_
23-31	4280-4291	appropriate	abstract[229]	giv[229]	_	_
23-32	4292-4299	measure	abstract[229]	giv[229]	_	_
23-33	4300-4302	of	abstract[229]	giv[229]	_	_
23-34	4303-4313	optimality	abstract[229]|abstract	giv[229]|new	_	_
23-35	4314-4315	.	_	_	_	_

#Text=Using the Cauchy loss to penalize the noise term , some algorithms based on the minimum Cauchy loss ( MCL ) criterion are efficient for combating non-Gaussian noises , especially for heavy-tailed - stable noises .
24-1	4316-4321	Using	_	_	_	_
24-2	4322-4325	the	abstract[232]	giv[232]	coref	24-15[237_232]
24-3	4326-4332	Cauchy	person|abstract[232]	giv|giv[232]	coref	24-17
24-4	4333-4337	loss	abstract[232]	giv[232]	_	_
24-5	4338-4340	to	_	_	_	_
24-6	4341-4349	penalize	_	_	_	_
24-7	4350-4353	the	abstract[234]	new[234]	_	_
24-8	4354-4359	noise	abstract|abstract[234]	giv|new[234]	_	_
24-9	4360-4364	term	abstract[234]	new[234]	_	_
24-10	4365-4366	,	_	_	_	_
24-11	4367-4371	some	abstract[235]	giv[235]	coref	25-14[247_235]
24-12	4372-4382	algorithms	abstract[235]	giv[235]	_	_
24-13	4383-4388	based	_	_	_	_
24-14	4389-4391	on	_	_	_	_
24-15	4392-4395	the	abstract[237]	giv[237]	coref	25-26[0_237]
24-16	4396-4403	minimum	abstract[237]	giv[237]	_	_
24-17	4404-4410	Cauchy	person|abstract[237]	giv|giv[237]	_	_
24-18	4411-4415	loss	abstract[237]	giv[237]	_	_
24-19	4416-4417	(	_	_	_	_
24-20	4418-4421	MCL	object	new	_	_
24-21	4422-4423	)	_	_	_	_
24-22	4424-4433	criterion	abstract	giv	_	_
24-23	4434-4437	are	_	_	_	_
24-24	4438-4447	efficient	_	_	_	_
24-25	4448-4451	for	_	_	_	_
24-26	4452-4461	combating	_	_	_	_
24-27	4462-4474	non-Gaussian	abstract[240]	giv[240]	coref	24-30[241_240]
24-28	4475-4481	noises	abstract[240]	giv[240]	_	_
24-29	4482-4483	,	_	_	_	_
24-30	4484-4494	especially	abstract[241]	giv[241]	_	_
24-31	4495-4498	for	abstract[241]	giv[241]	_	_
24-32	4499-4511	heavy-tailed	abstract[241]	giv[241]	_	_
24-33	4512-4513	-	abstract[241]	giv[241]	_	_
24-34	4514-4520	stable	abstract[241]	giv[241]	_	_
24-35	4521-4527	noises	abstract[241]	giv[241]	_	_
24-36	4528-4529	.	_	_	_	_

#Text=From the aspect of the optimization method , the stochastic gradient descent ( SGD)-based algorithms cannot find the minimum using the negative gradient in some loss functions .
25-1	4530-4534	From	_	_	_	_
25-2	4535-4538	the	abstract[242]	new[242]	_	_
25-3	4539-4545	aspect	abstract[242]	new[242]	_	_
25-4	4546-4548	of	abstract[242]	new[242]	_	_
25-5	4549-4552	the	abstract[242]|abstract[244]	new[242]|giv[244]	coref	27-4[259_244]
25-6	4553-4565	optimization	abstract[242]|abstract|abstract[244]	new[242]|new|giv[244]	coref	27-29
25-7	4566-4572	method	abstract[242]|abstract[244]	new[242]|giv[244]	_	_
25-8	4573-4574	,	_	_	_	_
25-9	4575-4578	the	abstract[246]	giv[246]	coref	27-5[0_246]
25-10	4579-4589	stochastic	abstract[246]	giv[246]	_	_
25-11	4590-4598	gradient	abstract|abstract[246]	giv|giv[246]	coref	25-21[249_0]
25-12	4599-4606	descent	abstract[246]	giv[246]	_	_
25-13	4607-4608	(	_	_	_	_
25-14	4609-4619	SGD)-based	abstract[247]	giv[247]	coref	26-5[253_247]
25-15	4620-4630	algorithms	abstract[247]	giv[247]	_	_
25-16	4631-4637	cannot	_	_	_	_
25-17	4638-4642	find	_	_	_	_
25-18	4643-4646	the	abstract[248]	new[248]	_	_
25-19	4647-4654	minimum	abstract[248]	new[248]	_	_
25-20	4655-4660	using	_	_	_	_
25-21	4661-4664	the	abstract[249]	giv[249]	coref	27-11[262_249]
25-22	4665-4673	negative	abstract[249]	giv[249]	_	_
25-23	4674-4682	gradient	abstract[249]	giv[249]	_	_
25-24	4683-4685	in	abstract[249]	giv[249]	_	_
25-25	4686-4690	some	abstract[249]|abstract[251]	giv[249]|new[251]	_	_
25-26	4691-4695	loss	abstract[249]|abstract|abstract[251]	giv[249]|giv|new[251]	_	_
25-27	4696-4705	functions	abstract[249]|abstract[251]	giv[249]|new[251]	_	_
25-28	4706-4707	.	_	_	_	_

#Text=Toward this end , recursive-based algorithms address these issues at the cost of increasing computational cost .
26-1	4708-4714	Toward	_	_	_	_
26-2	4715-4719	this	abstract[252]	new[252]	_	_
26-3	4720-4723	end	abstract[252]	new[252]	_	_
26-4	4724-4725	,	_	_	_	_
26-5	4726-4741	recursive-based	abstract[253]	giv[253]	coref	28-17[0_253]
26-6	4742-4752	algorithms	abstract[253]	giv[253]	_	_
26-7	4753-4760	address	_	_	_	_
26-8	4761-4766	these	abstract[254]	new[254]	_	_
26-9	4767-4773	issues	abstract[254]	new[254]	_	_
26-10	4774-4776	at	_	_	_	_
26-11	4777-4780	the	abstract[255]	new[255]	coref	26-15[256_255]
26-12	4781-4785	cost	abstract[255]	new[255]	_	_
26-13	4786-4788	of	_	_	_	_
26-14	4789-4799	increasing	_	_	_	_
26-15	4800-4813	computational	abstract[256]	giv[256]	_	_
26-16	4814-4818	cost	abstract[256]	giv[256]	_	_
26-17	4819-4820	.	_	_	_	_

#Text=In comparison with the SGD method and recursive method , the conjugate gradient ( CG ) method and Newton ’s method as developments of SGD have become alternative optimization methods in KAFs .
27-1	4821-4823	In	_	_	_	_
27-2	4824-4834	comparison	abstract[257]	new[257]	_	_
27-3	4835-4839	with	abstract[257]	new[257]	_	_
27-4	4840-4843	the	abstract[257]|abstract[259]|abstract[260]	new[257]|giv[259]|giv[260]	coref|coref|coref|coref	27-8[261_259]|27-11[265_260]|27-8[261_259]|27-11[265_260]
27-5	4844-4847	SGD	abstract[257]|abstract|abstract[259]|abstract[260]	new[257]|giv|giv[259]|giv[260]	coref	27-25
27-6	4848-4854	method	abstract[257]|abstract[259]|abstract[260]	new[257]|giv[259]|giv[260]	_	_
27-7	4855-4858	and	abstract[257]|abstract[260]	new[257]|giv[260]	_	_
27-8	4859-4868	recursive	abstract[257]|abstract[260]|abstract[261]	new[257]|giv[260]|giv[261]	coref	27-11[264_261]
27-9	4869-4875	method	abstract[257]|abstract[260]|abstract[261]	new[257]|giv[260]|giv[261]	_	_
27-10	4876-4877	,	_	_	_	_
27-11	4878-4881	the	abstract[262]|abstract[264]|abstract[265]	giv[262]|giv[264]|giv[265]	appos|coref|appos|coref|appos|coref	27-15[0_262]|27-19[267_264]|27-15[0_262]|27-19[267_264]|27-15[0_262]|27-19[267_264]
27-12	4882-4891	conjugate	abstract[262]|abstract[264]|abstract[265]	giv[262]|giv[264]|giv[265]	_	_
27-13	4892-4900	gradient	abstract[262]|abstract[264]|abstract[265]	giv[262]|giv[264]|giv[265]	_	_
27-14	4901-4902	(	abstract[264]|abstract[265]	giv[264]|giv[265]	_	_
27-15	4903-4905	CG	abstract|abstract[264]|abstract[265]	giv|giv[264]|giv[265]	coref	29-4
27-16	4906-4907	)	abstract[264]|abstract[265]	giv[264]|giv[265]	_	_
27-17	4908-4914	method	abstract[264]|abstract[265]	giv[264]|giv[265]	_	_
27-18	4915-4918	and	abstract[265]	giv[265]	_	_
27-19	4919-4925	Newton	abstract[265]|person[266]|abstract[267]	giv[265]|new[266]|giv[267]	coref|coref|coref|coref	27-32[0_267]|28-6[274_266]|27-32[0_267]|28-6[274_266]
27-20	4926-4928	’s	abstract[265]|person[266]|abstract[267]	giv[265]|new[266]|giv[267]	_	_
27-21	4929-4935	method	abstract[265]|abstract[267]	giv[265]|giv[267]	_	_
27-22	4936-4938	as	abstract[265]|abstract[267]	giv[265]|giv[267]	_	_
27-23	4939-4951	developments	abstract[265]|abstract[267]	giv[265]|giv[267]	_	_
27-24	4952-4954	of	abstract[265]|abstract[267]	giv[265]|giv[267]	_	_
27-25	4955-4958	SGD	abstract[265]|abstract[267]|abstract	giv[265]|giv[267]|giv	_	_
27-26	4959-4963	have	_	_	_	_
27-27	4964-4970	become	_	_	_	_
27-28	4971-4982	alternative	abstract[270]	giv[270]	_	_
27-29	4983-4995	optimization	abstract|abstract[270]	giv|giv[270]	coref	29-37[290_0]
27-30	4996-5003	methods	abstract[270]	giv[270]	_	_
27-31	5004-5006	in	abstract[270]	giv[270]	_	_
27-32	5007-5011	KAFs	abstract[270]|abstract	giv[270]|giv	coref	28-6[275_0]
27-33	5012-5013	.	_	_	_	_

#Text=The inverse of matrix of Newton ’s method increases the computation and causes the divergence of algorithms in some cases .
28-1	5014-5017	The	abstract[272]	new[272]	_	_
28-2	5018-5025	inverse	abstract[272]	new[272]	_	_
28-3	5026-5028	of	abstract[272]	new[272]	_	_
28-4	5029-5035	matrix	abstract[272]|abstract[273]	new[272]|new[273]	_	_
28-5	5036-5038	of	abstract[272]|abstract[273]	new[272]|new[273]	_	_
28-6	5039-5045	Newton	abstract[272]|abstract[273]|person[274]|abstract[275]	new[272]|new[273]|giv[274]|giv[275]	coref|coref	29-3[281_275]|29-3[281_275]
28-7	5046-5048	’s	abstract[272]|abstract[273]|person[274]|abstract[275]	new[272]|new[273]|giv[274]|giv[275]	_	_
28-8	5049-5055	method	abstract[272]|abstract[273]|abstract[275]	new[272]|new[273]|giv[275]	_	_
28-9	5056-5065	increases	_	_	_	_
28-10	5066-5069	the	abstract[276]	new[276]	coref	29-16[286_276]
28-11	5070-5081	computation	abstract[276]	new[276]	_	_
28-12	5082-5085	and	_	_	_	_
28-13	5086-5092	causes	_	_	_	_
28-14	5093-5096	the	abstract[277]	new[277]	_	_
28-15	5097-5107	divergence	abstract[277]	new[277]	_	_
28-16	5108-5110	of	abstract[277]	new[277]	_	_
28-17	5111-5121	algorithms	abstract[277]|abstract	new[277]|giv	_	_
28-18	5122-5124	in	_	_	_	_
28-19	5125-5129	some	abstract[279]	new[279]	_	_
28-20	5130-5135	cases	abstract[279]	new[279]	_	_
28-21	5136-5137	.	_	_	_	_

#Text=However , the CG method gives a trade-off between convergence rate and computational complexity without the inverse computation , and has been successfully applied in various fields , including compressed sensing , neural networks , and large-scale optimization .
29-1	5138-5145	However	_	_	_	_
29-2	5146-5147	,	_	_	_	_
29-3	5148-5151	the	abstract[281]	giv[281]	coref	30-11[0_281]
29-4	5152-5154	CG	abstract|abstract[281]	giv|giv[281]	coref	30-4[293_0]
29-5	5155-5161	method	abstract[281]	giv[281]	_	_
29-6	5162-5167	gives	_	_	_	_
29-7	5168-5169	a	abstract[282]	new[282]	_	_
29-8	5170-5179	trade-off	abstract[282]	new[282]	_	_
29-9	5180-5187	between	abstract[282]	new[282]	_	_
29-10	5188-5199	convergence	abstract[282]|abstract|abstract[284]	new[282]|giv|giv[284]	_	_
29-11	5200-5204	rate	abstract[282]|abstract[284]	new[282]|giv[284]	_	_
29-12	5205-5208	and	abstract[282]	new[282]	_	_
29-13	5209-5222	computational	abstract[282]|abstract[285]	new[282]|giv[285]	_	_
29-14	5223-5233	complexity	abstract[282]|abstract[285]	new[282]|giv[285]	_	_
29-15	5234-5241	without	abstract[282]|abstract[285]	new[282]|giv[285]	_	_
29-16	5242-5245	the	abstract[282]|abstract[285]|abstract[286]	new[282]|giv[285]|giv[286]	_	_
29-17	5246-5253	inverse	abstract[282]|abstract[285]|abstract[286]	new[282]|giv[285]|giv[286]	_	_
29-18	5254-5265	computation	abstract[282]|abstract[285]|abstract[286]	new[282]|giv[285]|giv[286]	_	_
29-19	5266-5267	,	_	_	_	_
29-20	5268-5271	and	_	_	_	_
29-21	5272-5275	has	_	_	_	_
29-22	5276-5280	been	_	_	_	_
29-23	5281-5293	successfully	_	_	_	_
29-24	5294-5301	applied	_	_	_	_
29-25	5302-5304	in	_	_	_	_
29-26	5305-5312	various	abstract[287]	new[287]	_	_
29-27	5313-5319	fields	abstract[287]	new[287]	_	_
29-28	5320-5321	,	abstract[287]	new[287]	_	_
29-29	5322-5331	including	abstract[287]	new[287]	_	_
29-30	5332-5342	compressed	abstract[287]|abstract[288]	new[287]|new[288]	_	_
29-31	5343-5350	sensing	abstract[287]|abstract[288]	new[287]|new[288]	_	_
29-32	5351-5352	,	abstract[287]	new[287]	_	_
29-33	5353-5359	neural	abstract[287]|abstract[289]	new[287]|new[289]	_	_
29-34	5360-5368	networks	abstract[287]|abstract[289]	new[287]|new[289]	_	_
29-35	5369-5370	,	abstract[287]	new[287]	_	_
29-36	5371-5374	and	abstract[287]	new[287]	_	_
29-37	5375-5386	large-scale	abstract[287]|abstract[290]	new[287]|giv[290]	_	_
29-38	5387-5399	optimization	abstract[287]|abstract[290]	new[287]|giv[290]	_	_
29-39	5400-5401	.	_	_	_	_

#Text=In addition , the kernel conjugate gradient ( KCG ) method is proposed for adaptive filtering .
30-1	5402-5404	In	_	_	_	_
30-2	5405-5413	addition	_	_	_	_
30-3	5414-5415	,	_	_	_	_
30-4	5416-5419	the	abstract[293]	giv[293]	appos	30-9[0_293]
30-5	5420-5426	kernel	person|abstract[293]	giv|giv[293]	_	_
30-6	5427-5436	conjugate	abstract|abstract[293]	new|giv[293]	_	_
30-7	5437-5445	gradient	abstract[293]	giv[293]	_	_
30-8	5446-5447	(	_	_	_	_
30-9	5448-5451	KCG	abstract	giv	coref	31-1[297_0]
30-10	5452-5453	)	_	_	_	_
30-11	5454-5460	method	abstract	giv	_	_
30-12	5461-5463	is	_	_	_	_
30-13	5464-5472	proposed	_	_	_	_
30-14	5473-5476	for	_	_	_	_
30-15	5477-5485	adaptive	abstract[296]	new[296]	_	_
30-16	5486-5495	filtering	abstract[296]	new[296]	_	_
30-17	5496-5497	.	_	_	_	_

#Text=KCG with low computational and space requirements can produce a better solution than KLMS , and has comparable accuracy to KRLS .
31-1	5498-5501	KCG	abstract[297]	giv[297]	_	_
31-2	5502-5506	with	abstract[297]	giv[297]	_	_
31-3	5507-5510	low	abstract[297]|abstract[298]	giv[297]|new[298]	_	_
31-4	5511-5524	computational	abstract[297]|abstract[298]	giv[297]|new[298]	_	_
31-5	5525-5528	and	abstract[297]|abstract[298]	giv[297]|new[298]	_	_
31-6	5529-5534	space	abstract[297]|abstract[298]	giv[297]|new[298]	_	_
31-7	5535-5547	requirements	abstract[297]|abstract[298]	giv[297]|new[298]	_	_
31-8	5548-5551	can	_	_	_	_
31-9	5552-5559	produce	_	_	_	_
31-10	5560-5561	a	abstract[299]	giv[299]	_	_
31-11	5562-5568	better	abstract[299]	giv[299]	_	_
31-12	5569-5577	solution	abstract[299]	giv[299]	_	_
31-13	5578-5582	than	abstract[299]	giv[299]	_	_
31-14	5583-5587	KLMS	abstract[299]|abstract	giv[299]|giv	_	_
31-15	5588-5589	,	_	_	_	_
31-16	5590-5593	and	_	_	_	_
31-17	5594-5597	has	_	_	_	_
31-18	5598-5608	comparable	abstract[301]	new[301]	_	_
31-19	5609-5617	accuracy	abstract[301]	new[301]	_	_
31-20	5618-5620	to	_	_	_	_
31-21	5621-5625	KRLS	abstract	giv	_	_
31-22	5626-5627	.	_	_	_	_
