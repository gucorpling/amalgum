<rst>
<header>
	<relations>
			<rel name="means" type="rst"/>
			<rel name="elaboration" type="rst"/>
			<rel name="circumstance" type="rst"/>
			<rel name="attribution" type="rst"/>
			<rel name="purpose" type="rst"/>
			<rel name="manner" type="rst"/>
			<rel name="preparation" type="rst"/>
			<rel name="same_unit" type="multinuc"/>
			<rel name="contrast" type="multinuc"/>
			<rel name="joint" type="multinuc"/>
		</relations>
</header>
<body>
<segment id="1" parent="1001" relname="preparation">5. Ethical Concerns from Algorithmic Decision-Making in AVs</segment>
<segment id="2" parent="1003" relname="span">This Section explores ethical issues</segment>
<segment id="3" parent="2" relname="elaboration">associated with algorithmic decision-making in AVs , their implications for AV safety risks and discrimination</segment>
<segment id="4" parent="1004" relname="span">and the steps</segment>
<segment id="5" parent="1005" relname="span">taken</segment>
<segment id="6" parent="5" relname="purpose">to tackle these issues .</segment>
<segment id="7" parent="1008" relname="span">Section 5.1 discusses the sources of bias in AVs ’ algorithms</segment>
<segment id="8" parent="7" relname="elaboration">that can yield discrimination</segment>
<segment id="9" parent="1008" relname="means">by disproportionately allocating more safety risks to some groups of individuals .</segment>
<segment id="10" parent="1010" relname="span">Next , Section 5.2 explores approaches</segment>
<segment id="11" parent="1011" relname="joint">to incorporate ethics into AV algorithms ’ decision-making</segment>
<segment id="12" parent="1011" relname="joint">and highlight their implications for AV safety and discrimination .</segment>
<segment id="13" parent="1013" relname="span">Lastly , Section 5.3 examines how the incentives of AV stakeholders shape AV algorithms</segment>
<segment id="14" parent="1014" relname="span">’ design and resulting decisions</segment>
<segment id="15" parent="14" relname="elaboration">that can introduce new safety risks and discrimination .</segment>
<segment id="16" parent="1016" relname="preparation">5.1 .</segment>
<segment id="17" parent="1017" relname="preparation">Bias</segment>
<segment id="18" parent="1018" relname="span">A system is considered biased</segment>
<segment id="19" parent="1019" relname="span">when it contains “ intended ” or “ unintended ” characteristics</segment>
<segment id="20" parent="19" relname="elaboration">that unfairly discriminate against certain individuals or groups of individuals in society .</segment>
<segment id="21" parent="1021" relname="span">In American anti-discrimination law , discrimination exists</segment>
<segment id="22" parent="1023" relname="span">when there is disparate treatment ,</segment>
<segment id="23" parent="22" relname="elaboration">which is the “ discriminatory intent or the formal application of different rules to people of different groups ” ,</segment>
<segment id="24" parent="1024" relname="span">and/or disparate impact ,</segment>
<segment id="25" parent="1025" relname="span">which is the result</segment>
<segment id="26" parent="25" relname="elaboration">that “ differ for different groups ” .</segment>
<segment id="27" parent="1027" relname="span">Bias can be introduced into AVs during the human designers ’ construction of the datasets , models , and the parameters of the algorithm ,</segment>
<segment id="28" parent="27" relname="elaboration">which potentially leads to unfair or discriminatory allocations of safety risks .</segment>
<segment id="29" parent="1029" relname="span">Firstly , statistical bias exists</segment>
<segment id="30" parent="29" relname="circumstance">when the input data are not statistically representative of the overall population .</segment>
<segment id="31" parent="1032" relname="span">For instance , training an AV</segment>
<segment id="32" parent="1033" relname="span">using data from only one country</segment>
<segment id="33" parent="1034" relname="joint">could result in the AV learning localised patterns</segment>
<segment id="34" parent="1035" relname="span">and not accurately modelling driving behaviours</segment>
<segment id="35" parent="34" relname="elaboration">that apply in other countries or contexts .</segment>
<segment id="36" parent="1017" relname="joint">Thus , the under- or overrepresentation of certain groups in the data can lead to inaccurate classifications and biased outcomes .</segment>
<segment id="37" parent="1037" relname="preparation">Secondly , the algorithm can be biased relative to legal and moral standards</segment>
<segment id="38" parent="1037" relname="joint">if it utilises sensitive input variables .</segment>
<segment id="39" parent="1041" relname="span">Individual-specific characteristics , such as a person ’s age and gender</segment>
<segment id="40" parent="39" relname="elaboration">that are used as decision-making criteria</segment>
<segment id="41" parent="1042" relname="span">can be penalised or privileged by the AVs ’ algorithms</segment>
<segment id="42" parent="41" relname="purpose">to meet the algorithm ’s pre-defined preferences ,</segment>
<segment id="43" parent="1044" relname="contrast">such as prioritising the safety of children</segment>
<segment id="44" parent="1044" relname="contrast">or minimising the total quantity of harm ,</segment>
<segment id="45" parent="1045" relname="span">causing more safety risks to be allocated to individuals</segment>
<segment id="46" parent="45" relname="elaboration">that share the penalised characteristics .</segment>
<segment id="47" parent="1048" relname="span">These forms of bias can be introduced unintentionally or intentionally by algorithm designers and AV manufacturers</segment>
<segment id="48" parent="47" relname="purpose">to maximise profits ,</segment>
<segment id="49" parent="1050" relname="span">such as prioritising the safety of AV passengers</segment>
<segment id="50" parent="49" relname="purpose">to maximise profits ,</segment>
<segment id="51" parent="1051" relname="span">and this is exacerbated by the lack of legal frameworks</segment>
<segment id="52" parent="51" relname="purpose">to hold these stakeholders accountable .</segment>
<segment id="53" parent="1054" relname="span">Section 5.2 explores various types of ethical preferences</segment>
<segment id="54" parent="53" relname="elaboration">to which AVs may be programmed to follow and their implications of AV safety risks in greater detail ,</segment>
<segment id="55" parent="1056" relname="attribution">and Section 5.3 explores</segment>
<segment id="56" parent="1056" relname="span">how perverse incentives influence the choice of preferences</segment>
<segment id="57" parent="56" relname="elaboration">that are programmed into AVs ’ algorithms .</segment>
<segment id="58" parent="1058" relname="span">Lessening bias in algorithms is therefore crucial</segment>
<segment id="59" parent="58" relname="purpose">to mitigate discriminatory outcomes from AVs .</segment>
<segment id="60" parent="1061" relname="span">In autonomous systems in general , scholars have recommended ways</segment>
<segment id="61" parent="60" relname="purpose">to detect and offset the effects of bias ,</segment>
<segment id="62" parent="1063" relname="span">such as modifying algorithmic outputs</segment>
<segment id="63" parent="62" relname="purpose">to balance the effects of bias between protected and unprotected groups ,</segment>
<segment id="64" parent="1064" relname="span">introducing minimally intrusive modification</segment>
<segment id="65" parent="1065" relname="span">to remove bias from the data ,</segment>
<segment id="66" parent="1066" relname="span">incorporating individuals from potentially discriminated groups ,</segment>
<segment id="67" parent="1068" relname="span">testing techniques</segment>
<segment id="68" parent="67" relname="purpose">to measure discrimination</segment>
<segment id="69" parent="1069" relname="span">and identify groups of users significantly</segment>
<segment id="70" parent="1070" relname="joint">affected by bias in software</segment>
<segment id="71" parent="1071" relname="span">and creating algorithms</segment>
<segment id="72" parent="71" relname="elaboration">that certify the absence of data bias .</segment>
<segment id="73" parent="1073" relname="span">Apart from bias</segment>
<segment id="74" parent="73" relname="elaboration">originating from the data and selection of variables and criterion ,</segment>
<segment id="75" parent="1075" relname="span">Danks and London recommend clarifying ethical standards such as fairness</segment>
<segment id="76" parent="75" relname="purpose">to evaluate bias .</segment>
<segment id="77" parent="1078" relname="span">Furthermore , scholars recommend increasing transparency</segment>
<segment id="78" parent="77" relname="purpose">to identify biases ,</segment>
<segment id="79" parent="1080" relname="span">such as designing algorithms</segment>
<segment id="80" parent="1081" relname="span">whose original input variables can be traced throughout the system</segment>
<segment id="81" parent="80" relname="elaboration">( i. e. , traceability )</segment>
<segment id="82" parent="1083" relname="span">and auditing algorithms</segment>
<segment id="83" parent="82" relname="purpose">to enhance their interpretability</segment>
<segment id="84" parent="1084" relname="joint">so that biases can be detected</segment>
<segment id="85" parent="1084" relname="joint">and the system ’s outputs can be verified against safety requirements .</segment>
<segment id="86" parent="1086" relname="span">However , there are challenges</segment>
<segment id="87" parent="86" relname="elaboration">in identifying bias in algorithms and their discriminatory effects .</segment>
<segment id="88" parent="1088" relname="preparation">Firstly , many algorithms are designed to be highly complex for greater accuracy ,</segment>
<segment id="89" parent="1089" relname="span">but this renders the algorithm opaque and difficult to interpret</segment>
<segment id="90" parent="1090" relname="span">even by the designers themselves ,</segment>
<segment id="91" parent="90" relname="elaboration">concealing the sources of bias .</segment>
<segment id="92" parent="1093" relname="span">Secondly ,</segment>
<segment id="93" parent="1094" relname="span">as ML algorithms make decisions mainly</segment>
<segment id="94" parent="1096" relname="span">based on the training data</segment>
<segment id="95" parent="94" relname="elaboration">that changes over time ,</segment>
<segment id="96" parent="1095" relname="span">it is difficult to predict potentially discriminatory effects in advance .</segment>
<segment id="97" parent="1099" relname="span">Humans are also excessively trusting and insufficiently critical of algorithmic decisions</segment>
<segment id="98" parent="97" relname="elaboration">due to the popular perception of algorithms as objective and fair ,</segment>
<segment id="99" parent="1101" relname="span">a problem</segment>
<segment id="100" parent="99" relname="elaboration">referred to as “ automation bias ”</segment>
<segment id="101" parent="1102" relname="span">and the seemingly “ objective ” correlations</segment>
<segment id="102" parent="1103" relname="span">that the algorithm learns from the data</segment>
<segment id="103" parent="102" relname="elaboration">makes it difficult to legally establish discriminatory intent in algorithms .</segment>
<segment id="104" parent="1104" relname="span">An emerging issue is the aggregation of individually biased outcomes</segment>
<segment id="105" parent="106" relname="circumstance">when AVs with similar preferences are deployed on a large-scale ,</segment>
<segment id="106" parent="1105" relname="span">as doing so would centralise and replicate algorithmic preferences along with their individually biased risk allocation decisions .</segment>
<segment id="107" parent="1088" relname="joint">This could lead to the same groups of people being consistently allocated more safety risks</segment>
<segment id="108" parent="1107" relname="span">and perpetuate systemic discrimination ,</segment>
<segment id="109" parent="1108" relname="span">which is more difficult to detect</segment>
<segment id="110" parent="109" relname="circumstance">as it results from the accumulation of similar driving outcomes .</segment>
<group id="1000" type="span" />
<group id="1001" type="multinuc" parent="1000" relname="span"/>
<group id="1002" type="multinuc" parent="1001" relname="joint"/>
<group id="1003" type="span" parent="1002" relname="same_unit"/>
<group id="1004" type="span" parent="1002" relname="same_unit"/>
<group id="1005" type="span" parent="4" relname="elaboration"/>
<group id="1007" type="span" parent="1001" relname="joint"/>
<group id="1008" type="span" parent="1007" relname="span"/>
<group id="1010" type="span" parent="1001" relname="joint"/>
<group id="1011" type="multinuc" parent="10" relname="purpose"/>
<group id="1013" type="span" parent="1001" relname="joint"/>
<group id="1014" type="span" parent="13" relname="elaboration"/>
<group id="1015" type="span" parent="1001" relname="joint"/>
<group id="1016" type="span" parent="1015" relname="span"/>
<group id="1017" type="multinuc" parent="1016" relname="span"/>
<group id="1018" type="span" parent="1017" relname="joint"/>
<group id="1019" type="span" parent="18" relname="circumstance"/>
<group id="1021" type="span" parent="1017" relname="joint"/>
<group id="1022" type="multinuc" parent="21" relname="circumstance"/>
<group id="1023" type="span" parent="1022" relname="same_unit"/>
<group id="1024" type="span" parent="1022" relname="same_unit"/>
<group id="1025" type="span" parent="24" relname="elaboration"/>
<group id="1027" type="span" parent="1017" relname="joint"/>
<group id="1029" type="span" parent="1017" relname="joint"/>
<group id="1032" type="span" parent="1017" relname="joint"/>
<group id="1033" type="span" parent="31" relname="means"/>
<group id="1034" type="multinuc" parent="32" relname="elaboration"/>
<group id="1035" type="span" parent="1034" relname="joint"/>
<group id="1036" type="span" parent="1017" relname="joint"/>
<group id="1037" type="multinuc" parent="1036" relname="span"/>
<group id="1039" type="span" parent="1037" relname="joint"/>
<group id="1040" type="multinuc" parent="1039" relname="span"/>
<group id="1041" type="span" parent="1040" relname="same_unit"/>
<group id="1042" type="span" parent="1040" relname="same_unit"/>
<group id="1043" type="span" parent="1040" relname="elaboration"/>
<group id="1044" type="multinuc" parent="1043" relname="span"/>
<group id="1045" type="span" parent="1044" relname="elaboration"/>
<group id="1047" type="multinuc" parent="1037" relname="joint"/>
<group id="1048" type="span" parent="1047" relname="same_unit"/>
<group id="1049" type="multinuc" parent="1047" relname="same_unit"/>
<group id="1050" type="span" parent="1049" relname="joint"/>
<group id="1051" type="span" parent="1049" relname="joint"/>
<group id="1054" type="span" parent="1037" relname="joint"/>
<group id="1055" type="span" parent="1037" relname="joint"/>
<group id="1056" type="span" parent="1055" relname="span"/>
<group id="1058" type="span" parent="1037" relname="joint"/>
<group id="1060" type="multinuc" parent="1037" relname="joint"/>
<group id="1061" type="span" parent="1060" relname="same_unit"/>
<group id="1062" type="span" parent="1060" relname="same_unit"/>
<group id="1063" type="span" parent="1064" relname="preparation"/>
<group id="1064" type="span" parent="1062" relname="span"/>
<group id="1065" type="span" parent="64" relname="purpose"/>
<group id="1066" type="span" parent="65" relname="elaboration"/>
<group id="1067" type="multinuc" parent="66" relname="elaboration"/>
<group id="1068" type="span" parent="1067" relname="joint"/>
<group id="1069" type="span" parent="1067" relname="joint"/>
<group id="1070" type="multinuc" parent="69" relname="elaboration"/>
<group id="1071" type="span" parent="1070" relname="joint"/>
<group id="1073" type="span" parent="1037" relname="joint"/>
<group id="1075" type="span" parent="1037" relname="joint"/>
<group id="1076" type="multinuc" parent="1037" relname="joint"/>
<group id="1077" type="multinuc" parent="1076" relname="contrast"/>
<group id="1078" type="span" parent="1077" relname="same_unit"/>
<group id="1079" type="multinuc" parent="1077" relname="same_unit"/>
<group id="1080" type="span" parent="1079" relname="joint"/>
<group id="1081" type="span" parent="79" relname="elaboration"/>
<group id="1082" type="span" parent="1079" relname="joint"/>
<group id="1083" type="span" parent="1082" relname="span"/>
<group id="1084" type="multinuc" parent="1083" relname="purpose"/>
<group id="1085" type="span" parent="1076" relname="contrast"/>
<group id="1086" type="span" parent="1087" relname="preparation"/>
<group id="1087" type="span" parent="1085" relname="span"/>
<group id="1088" type="multinuc" parent="1087" relname="span"/>
<group id="1089" type="span" parent="1088" relname="joint"/>
<group id="1090" type="span" parent="89" relname="elaboration"/>
<group id="1093" type="span" parent="1088" relname="joint"/>
<group id="1094" type="span" parent="92" relname="manner"/>
<group id="1095" type="span" parent="93" relname="elaboration"/>
<group id="1096" type="span" parent="96" relname="circumstance"/>
<group id="1098" type="span" parent="1088" relname="joint"/>
<group id="1099" type="span" parent="1098" relname="span"/>
<group id="1100" type="multinuc" parent="1099" relname="elaboration"/>
<group id="1101" type="span" parent="1100" relname="same_unit"/>
<group id="1102" type="span" parent="1100" relname="same_unit"/>
<group id="1103" type="span" parent="101" relname="elaboration"/>
<group id="1104" type="span" parent="1088" relname="joint"/>
<group id="1105" type="span" parent="104" relname="elaboration"/>
<group id="1107" type="span" parent="1088" relname="joint"/>
<group id="1108" type="span" parent="108" relname="elaboration"/>
	</body>
</rst>
