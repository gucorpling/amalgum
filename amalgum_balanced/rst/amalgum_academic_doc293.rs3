<rst>
<header>
	<relations>
			<rel name="elaboration" type="rst"/>
			<rel name="means" type="rst"/>
			<rel name="attribution" type="rst"/>
			<rel name="purpose" type="rst"/>
			<rel name="restatement" type="rst"/>
			<rel name="evidence" type="rst"/>
			<rel name="preparation" type="rst"/>
			<rel name="sequence" type="multinuc"/>
			<rel name="same_unit" type="multinuc"/>
			<rel name="contrast" type="multinuc"/>
			<rel name="joint" type="multinuc"/>
		</relations>
</header>
<body>
<segment id="1" parent="1001" relname="preparation">2. Proposed</segment>
<segment id="2" parent="1002" relname="preparation">Method</segment>
<segment id="3" parent="1003" relname="preparation">EFPN is our proposed object detection network .</segment>
<segment id="4" parent="1004" relname="preparation">Its architecture is shown in</segment>
<segment id="5" parent="1005" relname="span">Figure 1</segment>
<segment id="6" parent="5" relname="elaboration">.</segment>
<segment id="7" parent="1006" relname="joint">Firstly , in enhanced feature extraction subnet , we generate pyramid features in the same way as FPN .</segment>
<segment id="8" parent="1006" relname="joint">Features in each pyramid level are weighted by our proposed FWM ,</segment>
<segment id="9" parent="1006" relname="joint">and a new enhanced feature pyramid is reconstructed as the input for the following procedure .</segment>
<segment id="10" parent="1012" relname="span">Secondly , in the proposal extraction subnet , Region Proposal Network</segment>
<segment id="11" parent="10" relname="elaboration">( RPN )</segment>
<segment id="12" parent="1011" relname="same_unit">is used</segment>
<segment id="13" parent="1011" relname="purpose">to generate anchors of various shapes on the enhanced pyramidal feature map .</segment>
<segment id="14" parent="1014" relname="span">Thirdly , in adaptive parallel detection subnet , ACE is applied</segment>
<segment id="15" parent="14" relname="purpose">to extract the feature of ceRoI and RoI for each foreground RoI .</segment>
<segment id="16" parent="1016" relname="span">Two kinds of RoI features are , respectively , fed into PDB</segment>
<segment id="17" parent="16" relname="purpose">to predict classification and regression as the final detection results .</segment>
<segment id="18" parent="1018" relname="span">2.1 .</segment>
<segment id="19" parent="1020" relname="preparation">Enhanced Feature Extraction Subnet</segment>
<segment id="20" parent="1020" relname="sequence">Generally , FPN first builds the bottom-up layers by the feedforward computation of backbone ConvNet .</segment>
<segment id="21" parent="1021" relname="same_unit">Then , FPN constructs each top-down feature maps</segment>
<segment id="22" parent="1023" relname="preparation">by element-wised</segment>
<segment id="23" parent="1023" relname="span">adding the top-down feature maps of the last pyramid level with the bottom-up feature maps of the same pyramid level ,</segment>
<segment id="24" parent="23" relname="elaboration">which is shown in t</segment>
<segment id="25" parent="1025" relname="span">Figure 2</segment>
<segment id="26" parent="25" relname="restatement">( left ) .</segment>
<segment id="27" parent="1027" relname="span">The set of pyramidal feature maps</segment>
<segment id="28" parent="27" relname="elaboration">built by FPN is .</segment>
<segment id="29" parent="1029" relname="span">Despite such a careful design</segment>
<segment id="30" parent="1030" relname="span">for generating refined merged feature maps for different levels ,</segment>
<segment id="31" parent="30" relname="elaboration">it is not strong enough for the information of spatial and channel features to different scaled objects .</segment>
<segment id="32" parent="33" relname="attribution">We hypothesize</segment>
<segment id="33" parent="1032" relname="span">that both spatial-wise and channel-wise recalibrating merged feature maps can encourage current pyramid layer detection .</segment>
<segment id="34" parent="1035" relname="span">Hence , we propose FWM to enhance the pyramid feature .</segment>
<segment id="35" parent="34" relname="elaboration">The structure of FWM is shown in</segment>
<segment id="36" parent="1037" relname="span">Figure 2</segment>
<segment id="37" parent="36" relname="restatement">( right ) .</segment>
<segment id="38" parent="1038" relname="span">FWM starts</segment>
<segment id="39" parent="1039" relname="joint">by modeling the feature dependency of the feature maps in each pyramid level ,</segment>
<segment id="40" parent="1040" relname="span">and further learns the feature importance vector</segment>
<segment id="41" parent="1041" relname="span">to recalibrate the feature maps</segment>
<segment id="42" parent="41" relname="purpose">to emphasize the useful features .</segment>
<segment id="43" parent="1043" relname="contrast">Specially , FWM in each pyramid level is in the same structure</segment>
<segment id="44" parent="1044" relname="span">but has different learnable weights ,</segment>
<segment id="45" parent="44" relname="elaboration">which results in different calculated feature weights .</segment>
<segment id="46" parent="1046" relname="span">Each FWM consists of three sub-modules :</segment>
<segment id="47" parent="1048" relname="span">Feature Channel Weight Module</segment>
<segment id="48" parent="47" relname="elaboration">( FCWM ) ,</segment>
<segment id="49" parent="1050" relname="span">Feature Spatial Weight Module</segment>
<segment id="50" parent="49" relname="elaboration">( FSWM )</segment>
<segment id="51" parent="1051" relname="span">and Feature Channel Spatial Weight Module</segment>
<segment id="52" parent="51" relname="elaboration">( FCSWM ) .</segment>
<segment id="53" parent="1026" relname="joint">FCWM and FSWM calculate the feature importance vector along channel and spatial location .</segment>
<segment id="54" parent="1026" relname="joint">FCSWM combines the recalibrated weighted feature maps after FCWM and FSWM as the new pyramidal feature maps .</segment>
<segment id="55" parent="1026" relname="joint">The detailed design of the three submodules are described in the following subsections .</segment>
<segment id="56" parent="1026" relname="joint">2.1.1 .</segment>
<segment id="57" parent="1057" relname="span">Feature Channel Weight Module</segment>
<segment id="58" parent="57" relname="elaboration">( FCWM )</segment>
<segment id="59" parent="1026" relname="joint">FCWM focuses on enhancing features along channel of each pyramid level .</segment>
<segment id="60" parent="1026" relname="joint">FCWM first explicitly models the dependency of features along channel</segment>
<segment id="61" parent="1026" relname="joint">and learns a channel specific descriptor through the squeeze-and-excitation method .</segment>
<segment id="62" parent="1026" relname="joint">Then , it emphasizes the useful channels for more efficient global information expression of feature maps in each pyramid level .</segment>
<segment id="63" parent="1063" relname="span">Suppose the feature maps in n th pyramid level is ,</segment>
<segment id="64" parent="1064" relname="joint">which is generated by FPN .</segment>
<segment id="65" parent="1064" relname="joint">and are the spatial height and width of , respectively .</segment>
<segment id="66" parent="1066" relname="span">The i th channel feature is .</segment>
<segment id="67" parent="1068" relname="span">At the beginning , we do global average pooling on</segment>
<segment id="68" parent="1069" relname="span">to get the global distribution response :</segment>
<segment id="69" parent="68" relname="evidence">( 1 )</segment>
<segment id="70" parent="1070" relname="span">We use two fully connected layers</segment>
<segment id="71" parent="1071" relname="joint">to map the non-linear correlation between all global distribution responses</segment>
<segment id="72" parent="1073" relname="span">and obtain the feature importance vectors :</segment>
<segment id="73" parent="1074" relname="span">( 2 )</segment>
<segment id="74" parent="73" relname="elaboration">where is the weight of the first fully connected layer .</segment>
<segment id="75" parent="1075" relname="span">is the weight of the second fully connected layer .</segment>
<segment id="76" parent="75" relname="elaboration">represents the ReLU function .</segment>
<segment id="77" parent="1078" relname="span">Then , we normalize to as a weight vector :</segment>
<segment id="78" parent="77" relname="evidence">( 3 )</segment>
<segment id="79" parent="1078" relname="elaboration">where represents Sigmoid function .</segment>
<segment id="80" parent="1079" relname="joint">Finally , we assign the weight to the original feature</segment>
<segment id="81" parent="1081" relname="span">and get the new pyramid feature after channel-wised recalibration :</segment>
<segment id="82" parent="81" relname="evidence">( 4 )</segment>
<segment id="83" parent="1079" relname="joint">2.1.2 .</segment>
<segment id="84" parent="1084" relname="span">Feature Spatial Weight Module</segment>
<segment id="85" parent="84" relname="restatement">( FSWM )</segment>
<segment id="86" parent="1086" relname="preparation">Similar to the design of FCWM ,</segment>
<segment id="87" parent="1087" relname="span">FSWM enhances the features along spatial location of each pyramid level ,</segment>
<segment id="88" parent="1088" relname="joint">which emphasizes the effective pixels</segment>
<segment id="89" parent="1088" relname="joint">and depresses the ineffective or low-effect pixels .</segment>
<segment id="90" parent="1086" relname="joint">We define as the clipping of all channel features at each feature point of .</segment>
<segment id="91" parent="1091" relname="span">First , we integrate all the features of each point through a convolution operation</segment>
<segment id="92" parent="1093" relname="span">to get the spatial importance vector :</segment>
<segment id="93" parent="92" relname="evidence">( 5 )</segment>
<segment id="94" parent="1093" relname="elaboration">where is the convolution kernel weight .</segment>
<segment id="95" parent="1096" relname="span">Then , we normalize to as a weight vector</segment>
<segment id="96" parent="95" relname="evidence">( 6 )</segment>
<segment id="97" parent="1096" relname="elaboration">where represents Sigmoid function .</segment>
<segment id="98" parent="1098" relname="span">Finally , the normalized weights are spatially weighted to each pixel</segment>
<segment id="99" parent="1099" relname="span">to get the new feature :</segment>
<segment id="100" parent="99" relname="elaboration">( 7 )</segment>
<segment id="101" parent="1101" relname="preparation">2.1.3 .</segment>
<segment id="102" parent="1102" relname="span">Feature Channel Spatial Weight Module</segment>
<segment id="103" parent="102" relname="elaboration">( FCSWM )</segment>
<segment id="104" parent="1106" relname="span">FCSWM combines the channel-wised weighted</segment>
<segment id="105" parent="104" relname="elaboration">obtained by FCWM and the spatially weighted</segment>
<segment id="106" parent="1106" relname="elaboration">obtained by FSWM</segment>
<segment id="107" parent="1105" relname="purpose">to generate a new recalibrated feature .</segment>
<segment id="108" parent="1109" relname="span">The combination operation is implemented by addition :</segment>
<segment id="109" parent="108" relname="elaboration">( 8 )</segment>
<segment id="110" parent="1108" relname="same_unit">encourages original feature maps to be both spatial-wise and channel-wise more informative .</segment>
<segment id="111" parent="1108" relname="elaboration">In EFPN , we replace the initial feature pyramid features by the recalibrated enhanced pyramid features as the input feature of proposal extraction subnet and detection subnet .</segment>
<group id="1000" type="span" />
<group id="1001" type="span" parent="1000" relname="span"/>
<group id="1002" type="span" parent="1001" relname="span"/>
<group id="1003" type="span" parent="1002" relname="span"/>
<group id="1004" type="span" parent="1003" relname="span"/>
<group id="1005" type="span" parent="1006" relname="preparation"/>
<group id="1006" type="multinuc" parent="1004" relname="span"/>
<group id="1010" type="span" parent="1006" relname="joint"/>
<group id="1011" type="multinuc" parent="1010" relname="span"/>
<group id="1012" type="span" parent="1011" relname="same_unit"/>
<group id="1014" type="span" parent="1006" relname="joint"/>
<group id="1016" type="span" parent="1006" relname="joint"/>
<group id="1018" type="span" parent="1006" relname="joint"/>
<group id="1019" type="span" parent="18" relname="elaboration"/>
<group id="1020" type="multinuc" parent="1019" relname="span"/>
<group id="1021" type="multinuc" parent="1020" relname="sequence"/>
<group id="1022" type="span" parent="1021" relname="same_unit"/>
<group id="1023" type="span" parent="1022" relname="span"/>
<group id="1024" type="span" parent="1006" relname="joint"/>
<group id="1025" type="span" parent="1026" relname="preparation"/>
<group id="1026" type="multinuc" parent="1024" relname="span"/>
<group id="1027" type="span" parent="1026" relname="joint"/>
<group id="1029" type="span" parent="1026" relname="joint"/>
<group id="1030" type="span" parent="29" relname="purpose"/>
<group id="1032" type="span" parent="1026" relname="joint"/>
<group id="1034" type="span" parent="1026" relname="joint"/>
<group id="1035" type="span" parent="1034" relname="span"/>
<group id="1036" type="span" parent="1035" relname="elaboration"/>
<group id="1037" type="span" parent="1038" relname="preparation"/>
<group id="1038" type="span" parent="1036" relname="span"/>
<group id="1039" type="multinuc" parent="38" relname="means"/>
<group id="1040" type="span" parent="1039" relname="joint"/>
<group id="1041" type="span" parent="40" relname="purpose"/>
<group id="1043" type="multinuc" parent="1026" relname="joint"/>
<group id="1044" type="span" parent="1043" relname="contrast"/>
<group id="1046" type="span" parent="1026" relname="joint"/>
<group id="1047" type="multinuc" parent="46" relname="elaboration"/>
<group id="1048" type="span" parent="1047" relname="same_unit"/>
<group id="1049" type="multinuc" parent="1047" relname="same_unit"/>
<group id="1050" type="span" parent="1049" relname="joint"/>
<group id="1051" type="span" parent="1049" relname="joint"/>
<group id="1057" type="span" parent="1026" relname="joint"/>
<group id="1062" type="multinuc" parent="1026" relname="joint"/>
<group id="1063" type="span" parent="1062" relname="sequence"/>
<group id="1064" type="multinuc" parent="63" relname="elaboration"/>
<group id="1065" type="multinuc" parent="1062" relname="sequence"/>
<group id="1066" type="span" parent="1065" relname="joint"/>
<group id="1067" type="span" parent="66" relname="elaboration"/>
<group id="1068" type="span" parent="1067" relname="span"/>
<group id="1069" type="span" parent="67" relname="purpose"/>
<group id="1070" type="span" parent="1068" relname="elaboration"/>
<group id="1071" type="multinuc" parent="70" relname="purpose"/>
<group id="1072" type="multinuc" parent="1071" relname="joint"/>
<group id="1073" type="span" parent="1072" relname="same_unit"/>
<group id="1074" type="span" parent="72" relname="restatement"/>
<group id="1075" type="span" parent="1072" relname="same_unit"/>
<group id="1076" type="multinuc" parent="1065" relname="joint"/>
<group id="1077" type="span" parent="1076" relname="sequence"/>
<group id="1078" type="span" parent="1077" relname="span"/>
<group id="1079" type="multinuc" parent="1076" relname="sequence"/>
<group id="1081" type="span" parent="1079" relname="joint"/>
<group id="1084" type="span" parent="1079" relname="joint"/>
<group id="1085" type="span" parent="1079" relname="joint"/>
<group id="1086" type="multinuc" parent="1085" relname="span"/>
<group id="1087" type="span" parent="1086" relname="joint"/>
<group id="1088" type="multinuc" parent="87" relname="elaboration"/>
<group id="1090" type="multinuc" parent="1086" relname="joint"/>
<group id="1091" type="span" parent="1090" relname="sequence"/>
<group id="1092" type="span" parent="91" relname="purpose"/>
<group id="1093" type="span" parent="1092" relname="span"/>
<group id="1095" type="span" parent="1090" relname="sequence"/>
<group id="1096" type="span" parent="1095" relname="span"/>
<group id="1097" type="span" parent="1090" relname="sequence"/>
<group id="1098" type="span" parent="1100" relname="preparation"/>
<group id="1099" type="span" parent="98" relname="purpose"/>
<group id="1100" type="span" parent="1097" relname="span"/>
<group id="1101" type="span" parent="1100" relname="span"/>
<group id="1102" type="span" parent="1103" relname="preparation"/>
<group id="1103" type="multinuc" parent="1101" relname="span"/>
<group id="1104" type="span" parent="1103" relname="joint"/>
<group id="1105" type="span" parent="1104" relname="span"/>
<group id="1106" type="span" parent="1105" relname="span"/>
<group id="1107" type="span" parent="1103" relname="joint"/>
<group id="1108" type="multinuc" parent="1107" relname="span"/>
<group id="1109" type="span" parent="1108" relname="same_unit"/>
	</body>
</rst>
