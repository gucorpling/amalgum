<rst>
<header>
	<relations>
			<rel name="elaboration" type="rst"/>
			<rel name="attribution" type="rst"/>
			<rel name="circumstance" type="rst"/>
			<rel name="antithesis" type="rst"/>
			<rel name="concession" type="rst"/>
			<rel name="purpose" type="rst"/>
			<rel name="restatement" type="rst"/>
			<rel name="evidence" type="rst"/>
			<rel name="preparation" type="rst"/>
			<rel name="sequence" type="multinuc"/>
			<rel name="same_unit" type="multinuc"/>
			<rel name="contrast" type="multinuc"/>
			<rel name="joint" type="multinuc"/>
		</relations>
</header>
<body>
<segment id="1" parent="1001" relname="preparation">8. Results and Discussion</segment>
<segment id="2" parent="1002" relname="preparation">8.1 .</segment>
<segment id="3" parent="1003" relname="preparation">Transcription Normalization</segment>
<segment id="4" parent="1003" relname="joint">Table 11 shows the results of transcription normalization experiments .</segment>
<segment id="5" parent="1006" relname="span">Transcription normalization</segment>
<segment id="6" parent="5" relname="elaboration">based on Kirikae ’s lexicon achieved the highest scores for the Y9 – 13 dataset ,</segment>
<segment id="7" parent="1007" relname="span">which is not surprising ,</segment>
<segment id="8" parent="7" relname="circumstance">since the dictionary is based on yukar epics .</segment>
<segment id="9" parent="1010" relname="span">In the case of JK samples , however , performance with the combined dictionary</segment>
<segment id="10" parent="9" relname="elaboration">( JK+KK )</segment>
<segment id="11" parent="1009" relname="same_unit">was as good as with the JK dictionary only .</segment>
<segment id="12" parent="1011" relname="joint">Furthermore , the combined dictionary achieved the best overall results .</segment>
<segment id="13" parent="1012" relname="sequence">In all test configurations the results for texts with original word segmentation retained were slightly better .</segment>
<segment id="14" parent="1014" relname="span">Relatively low values of recall for normalization in JK samples ,</segment>
<segment id="15" parent="1015" relname="same_unit">observed across all combinations of dictionaries and input text versions ,</segment>
<segment id="16" parent="1016" relname="span">can be explained by a high occurrence of forms transcribed</segment>
<segment id="17" parent="1018" relname="span">according to non-standard rules</segment>
<segment id="18" parent="17" relname="elaboration">modified by Bugaeva et al. in the modernized version of the dictionary ,</segment>
<segment id="19" parent="1020" relname="span">but not included in the list of universal transcription change rules</segment>
<segment id="20" parent="1021" relname="span">applied in this research , such as ‘ ra’→‘r ’</segment>
<segment id="21" parent="20" relname="elaboration">( e. g. , arapa → arpa ) ,</segment>
<segment id="22" parent="1023" relname="span">‘ ri’→‘r ’</segment>
<segment id="23" parent="22" relname="elaboration">( e. g. , pirika → pirka ) ,</segment>
<segment id="24" parent="1025" relname="span">‘ ru’→‘r ’</segment>
<segment id="25" parent="24" relname="elaboration">( e. g. , kuru → kur ) ,</segment>
<segment id="26" parent="1027" relname="span">‘ ro’→‘r ’</segment>
<segment id="27" parent="26" relname="restatement">( e. g. , koro → kor )</segment>
<segment id="28" parent="1028" relname="span">or ‘ ei’→‘e ’</segment>
<segment id="29" parent="28" relname="elaboration">( e. g. , reihei → rehe ) .</segment>
<segment id="30" parent="1031" relname="span">This is due to the fact</segment>
<segment id="31" parent="30" relname="elaboration">that these rules are so far only observed in the dictionary of Jinbō and Kanazawa</segment>
<segment id="32" parent="1032" relname="span">and more importantly , initial tests</segment>
<segment id="33" parent="1034" relname="attribution">performed during the development of the algorithm showed</segment>
<segment id="34" parent="1034" relname="span">that including them in the algorithm can cause errors</segment>
<segment id="35" parent="34" relname="circumstance">when processing yukars and other texts .</segment>
<segment id="36" parent="1036" relname="preparation">8.2 .</segment>
<segment id="37" parent="1037" relname="span">Tokenization</segment>
<segment id="38" parent="1038" relname="span">The results of tokenization experiments are shown in Table 12 .</segment>
<segment id="39" parent="1041" relname="span">Table 13 shows a fragment from Y9 – 13</segment>
<segment id="40" parent="39" relname="restatement">( M-SR )</segment>
<segment id="41" parent="1041" relname="circumstance">before and after segmentation .</segment>
<segment id="42" parent="1042" relname="span">Similarly to transcription normalization , the tokenization algorithm also performed the best for yukar stories</segment>
<segment id="43" parent="1043" relname="span">( Y9 – 13 )</segment>
<segment id="44" parent="1044" relname="span">when coupled with the Ainu shin-yōshū jiten</segment>
<segment id="45" parent="44" relname="elaboration">( KK ) .</segment>
<segment id="46" parent="1036" relname="joint">Analogically , for JK samples , the JK dictionary was the best .</segment>
<segment id="47" parent="1047" relname="span">It shows a weak point of the presented segmentation algorithm :</segment>
<segment id="48" parent="1049" relname="span">while adding new forms to the lexicon improves its versatility</segment>
<segment id="49" parent="48" relname="elaboration">( ability to process texts from different domains ) ,</segment>
<segment id="50" parent="1050" relname="span">it also increases the number of possible mistakes</segment>
<segment id="51" parent="1051" relname="span">the tokenizer can make with texts</segment>
<segment id="52" parent="1052" relname="span">for which the original lexicon had been</segment>
<segment id="53" parent="52" relname="restatement">( nearly ) optimal .</segment>
<segment id="54" parent="1054" relname="span">The combined dictionary performed better than the other two dictionaries on test data</segment>
<segment id="55" parent="1056" relname="span">unrelated to the training data</segment>
<segment id="56" parent="55" relname="elaboration">( Shib . and Muk . ) ,</segment>
<segment id="57" parent="1057" relname="span">and also achieved the best overall results</segment>
<segment id="58" parent="57" relname="elaboration">( F-score ) .</segment>
<segment id="59" parent="1059" relname="span">On the other hand , overall recall was higher with the KK dictionary .</segment>
<segment id="60" parent="1062" relname="span">To some extent this might be explained by the differences in word segmentation between the two dictionaries</segment>
<segment id="61" parent="60" relname="elaboration">applied in this research :</segment>
<segment id="62" parent="1064" relname="span">many expressions</segment>
<segment id="63" parent="62" relname="elaboration">( e. g. , oro wa , ’ from ’ or pet turasi , ’ to go upstream ’ )</segment>
<segment id="64" parent="1065" relname="span">written as two separate segments by Kirikae</segment>
<segment id="65" parent="1066" relname="span">( both in the lexicon part of the Ainu shin-yōshū jiten , as well as in his modernized transcriptions of the yukar stories ,</segment>
<segment id="66" parent="65" relname="elaboration">which we use as the gold standard data ) ,</segment>
<segment id="67" parent="1068" relname="span">are transcribed as a single unit</segment>
<segment id="68" parent="67" relname="elaboration">( orowa , petturasi )</segment>
<segment id="69" parent="1069" relname="same_unit">by Bugaeva et al.</segment>
<segment id="70" parent="1071" relname="circumstance">Once these forms are added to the lexicon ,</segment>
<segment id="71" parent="1071" relname="span">the word segmentation algorithm ,</segment>
<segment id="72" parent="1072" relname="sequence">which prefers long tokens over shorter ones ,</segment>
<segment id="73" parent="1073" relname="span">stops applying segmentation to the tokens orowa and petturasi</segment>
<segment id="74" parent="73" relname="elaboration">( and that causes recall to drop ) .</segment>
<segment id="75" parent="1076" relname="preparation">This phenomenon occurs in the opposite direction as well :</segment>
<segment id="76" parent="1077" relname="span">The only two types of tokenization errors</segment>
<segment id="77" parent="1078" relname="span">made in the JK samples</segment>
<segment id="78" parent="77" relname="elaboration">( O/M )</segment>
<segment id="79" parent="1080" relname="circumstance">when the combined dictionary was used ,</segment>
<segment id="80" parent="1080" relname="same_unit">but not with the JK dictionary ,</segment>
<segment id="81" parent="1081" relname="span">were both of this type</segment>
<segment id="82" parent="1084" relname="span">— the expressions</segment>
<segment id="83" parent="82" relname="elaboration">transcribed by Bugaeva et al. as somo ki</segment>
<segment id="84" parent="1084" relname="elaboration">( ’ do not ’ )</segment>
<segment id="85" parent="1086" relname="span">and te ta</segment>
<segment id="86" parent="85" relname="elaboration">( ’ here ’ )</segment>
<segment id="87" parent="1085" relname="same_unit">are listed as somoki and teta in the Ainu shin-yōshū jiten .</segment>
<segment id="88" parent="1089" relname="span">Scores</segment>
<segment id="89" parent="88" relname="elaboration">achieved by the tokenizer on texts</segment>
<segment id="90" parent="1092" relname="span">with original word boundaries retained</segment>
<segment id="91" parent="1094" relname="span">( Y9 – 13</segment>
<segment id="92" parent="91" relname="restatement">( O/M )</segment>
<segment id="93" parent="1095" relname="span">and JK samples</segment>
<segment id="94" parent="93" relname="restatement">( O/M ) )</segment>
<segment id="95" parent="1091" relname="same_unit">were higher</segment>
<segment id="96" parent="1091" relname="antithesis">than with spaces removed .</segment>
<segment id="97" parent="1096" relname="span">This means that the original word segmentation ,</segment>
<segment id="98" parent="1098" relname="span">even if it causes some errors</segment>
<segment id="99" parent="1099" relname="span">( as with the word tuyka</segment>
<segment id="100" parent="99" relname="elaboration">— see Section 6.2 ) ,</segment>
<segment id="101" parent="1100" relname="span">still supports tokenization</segment>
<segment id="102" parent="101" relname="antithesis">rather than hindering it .</segment>
<group id="1000" type="span" />
<group id="1001" type="span" parent="1000" relname="span"/>
<group id="1002" type="span" parent="1001" relname="span"/>
<group id="1003" type="multinuc" parent="1002" relname="span"/>
<group id="1005" type="span" parent="1003" relname="joint"/>
<group id="1006" type="span" parent="1005" relname="span"/>
<group id="1007" type="span" parent="1006" relname="elaboration"/>
<group id="1008" type="multinuc" parent="1003" relname="joint"/>
<group id="1009" type="multinuc" parent="1008" relname="sequence"/>
<group id="1010" type="span" parent="1009" relname="same_unit"/>
<group id="1011" type="multinuc" parent="1008" relname="sequence"/>
<group id="1012" type="multinuc" parent="1011" relname="joint"/>
<group id="1014" type="span" parent="1012" relname="sequence"/>
<group id="1015" type="multinuc" parent="14" relname="elaboration"/>
<group id="1016" type="span" parent="1015" relname="same_unit"/>
<group id="1017" type="multinuc" parent="16" relname="attribution"/>
<group id="1018" type="span" parent="1017" relname="contrast"/>
<group id="1019" type="multinuc" parent="1017" relname="contrast"/>
<group id="1020" type="span" parent="1019" relname="same_unit"/>
<group id="1021" type="span" parent="19" relname="elaboration"/>
<group id="1022" type="multinuc" parent="1019" relname="same_unit"/>
<group id="1023" type="span" parent="1022" relname="same_unit"/>
<group id="1024" type="multinuc" parent="1022" relname="same_unit"/>
<group id="1025" type="span" parent="1024" relname="same_unit"/>
<group id="1026" type="multinuc" parent="1024" relname="same_unit"/>
<group id="1027" type="span" parent="1026" relname="contrast"/>
<group id="1028" type="span" parent="1026" relname="contrast"/>
<group id="1029" type="multinuc" parent="1012" relname="sequence"/>
<group id="1031" type="span" parent="1029" relname="joint"/>
<group id="1032" type="span" parent="1029" relname="joint"/>
<group id="1033" type="span" parent="32" relname="elaboration"/>
<group id="1034" type="span" parent="1033" relname="span"/>
<group id="1035" type="span" parent="1029" relname="joint"/>
<group id="1036" type="multinuc" parent="1035" relname="span"/>
<group id="1037" type="span" parent="1036" relname="joint"/>
<group id="1038" type="span" parent="37" relname="elaboration"/>
<group id="1039" type="span" parent="38" relname="evidence"/>
<group id="1040" type="span" parent="1039" relname="span"/>
<group id="1041" type="span" parent="1040" relname="span"/>
<group id="1042" type="span" parent="1040" relname="evidence"/>
<group id="1043" type="span" parent="42" relname="elaboration"/>
<group id="1044" type="span" parent="43" relname="circumstance"/>
<group id="1047" type="span" parent="1036" relname="joint"/>
<group id="1048" type="multinuc" parent="47" relname="circumstance"/>
<group id="1049" type="span" parent="1048" relname="joint"/>
<group id="1050" type="span" parent="1048" relname="joint"/>
<group id="1051" type="span" parent="50" relname="elaboration"/>
<group id="1052" type="span" parent="51" relname="elaboration"/>
<group id="1054" type="span" parent="1036" relname="joint"/>
<group id="1055" type="multinuc" parent="54" relname="elaboration"/>
<group id="1056" type="span" parent="1055" relname="joint"/>
<group id="1057" type="span" parent="1055" relname="joint"/>
<group id="1058" type="multinuc" parent="1036" relname="joint"/>
<group id="1059" type="span" parent="1058" relname="sequence"/>
<group id="1060" type="multinuc" parent="59" relname="purpose"/>
<group id="1061" type="span" parent="1060" relname="same_unit"/>
<group id="1062" type="span" parent="1061" relname="span"/>
<group id="1063" type="span" parent="1062" relname="elaboration"/>
<group id="1064" type="span" parent="1063" relname="span"/>
<group id="1065" type="span" parent="1064" relname="elaboration"/>
<group id="1066" type="span" parent="64" relname="elaboration"/>
<group id="1067" type="multinuc" parent="1060" relname="same_unit"/>
<group id="1068" type="span" parent="1067" relname="same_unit"/>
<group id="1069" type="multinuc" parent="1067" relname="same_unit"/>
<group id="1070" type="span" parent="1069" relname="same_unit"/>
<group id="1071" type="span" parent="1070" relname="span"/>
<group id="1072" type="multinuc" parent="71" relname="elaboration"/>
<group id="1073" type="span" parent="1072" relname="sequence"/>
<group id="1074" type="multinuc" parent="1058" relname="sequence"/>
<group id="1075" type="span" parent="1074" relname="joint"/>
<group id="1076" type="multinuc" parent="1075" relname="span"/>
<group id="1077" type="span" parent="1076" relname="same_unit"/>
<group id="1078" type="span" parent="76" relname="elaboration"/>
<group id="1079" type="span" parent="1076" relname="same_unit"/>
<group id="1080" type="multinuc" parent="1079" relname="span"/>
<group id="1081" type="span" parent="1080" relname="same_unit"/>
<group id="1082" type="multinuc" parent="81" relname="elaboration"/>
<group id="1083" type="span" parent="1082" relname="joint"/>
<group id="1084" type="span" parent="1083" relname="span"/>
<group id="1085" type="multinuc" parent="1082" relname="joint"/>
<group id="1086" type="span" parent="1085" relname="same_unit"/>
<group id="1088" type="multinuc" parent="1074" relname="joint"/>
<group id="1089" type="span" parent="1088" relname="same_unit"/>
<group id="1090" type="span" parent="1088" relname="same_unit"/>
<group id="1091" type="multinuc" parent="1090" relname="span"/>
<group id="1092" type="span" parent="1091" relname="same_unit"/>
<group id="1093" type="multinuc" parent="90" relname="elaboration"/>
<group id="1094" type="span" parent="1093" relname="joint"/>
<group id="1095" type="span" parent="1093" relname="joint"/>
<group id="1096" type="span" parent="1074" relname="joint"/>
<group id="1097" type="multinuc" parent="97" relname="concession"/>
<group id="1098" type="span" parent="1097" relname="same_unit"/>
<group id="1099" type="span" parent="98" relname="elaboration"/>
<group id="1100" type="span" parent="1097" relname="same_unit"/>
	</body>
</rst>
