#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=2. Related Works
1-1	0-2	2.	_	_	_	_
1-2	3-10	Related	object[1]	new[1]	coref	2-14[7_1]
1-3	11-16	Works	object[1]	new[1]	_	_

#Text=In this section , we put our focus on the relevant introduction of the two mainstream camera-based works , i. e. , appearance-based methods and model-based methods .
2-1	17-19	In	_	_	_	_
2-2	20-24	this	abstract[2]	new[2]	_	_
2-3	25-32	section	abstract[2]	new[2]	_	_
2-4	33-34	,	_	_	_	_
2-5	35-37	we	person	acc	ana	2-7
2-6	38-41	put	_	_	_	_
2-7	42-45	our	person|abstract[5]	giv|new[5]	ana	3-1
2-8	46-51	focus	abstract[5]	new[5]	_	_
2-9	52-54	on	_	_	_	_
2-10	55-58	the	abstract[6]	new[6]	_	_
2-11	59-67	relevant	abstract[6]	new[6]	_	_
2-12	68-80	introduction	abstract[6]	new[6]	_	_
2-13	81-83	of	abstract[6]	new[6]	_	_
2-14	84-87	the	abstract[6]|object[7]	new[6]|giv[7]	coref	4-11[21_7]
2-15	88-91	two	abstract[6]|object[7]	new[6]|giv[7]	_	_
2-16	92-102	mainstream	abstract[6]|object[7]	new[6]|giv[7]	_	_
2-17	103-115	camera-based	abstract[6]|object[7]	new[6]|giv[7]	_	_
2-18	116-121	works	abstract[6]|object[7]	new[6]|giv[7]	_	_
2-19	122-123	,	abstract[6]	new[6]	_	_
2-20	124-126	i.	abstract[6]	new[6]	_	_
2-21	127-129	e.	abstract[6]	new[6]	_	_
2-22	130-131	,	abstract[6]	new[6]	_	_
2-23	132-148	appearance-based	abstract[6]|abstract[8]	new[6]|new[8]	_	_
2-24	149-156	methods	abstract[6]|abstract[8]	new[6]|new[8]	_	_
2-25	157-160	and	abstract[6]	new[6]	_	_
2-26	161-172	model-based	abstract[6]|abstract[9]	new[6]|new[9]	coref	3-5[11_9]
2-27	173-180	methods	abstract[6]|abstract[9]	new[6]|new[9]	_	_
2-28	181-182	.	_	_	_	_

#Text=We also briefly introduce some multi-model methods . Dipietro et al. have done elaborate research for all kinds of data gloves and relevant applications .
3-1	183-185	We	person	giv	ana	4-1
3-2	186-190	also	_	_	_	_
3-3	191-198	briefly	_	_	_	_
3-4	199-208	introduce	_	_	_	_
3-5	209-213	some	abstract[11]	giv[11]	coref	6-1[23_11]
3-6	214-225	multi-model	abstract[11]	giv[11]	_	_
3-7	226-233	methods	abstract[11]	giv[11]	_	_
3-8	234-235	.	_	_	_	_
3-9	236-244	Dipietro	person	new	_	_
3-10	245-247	et	_	_	_	_
3-11	248-251	al.	_	_	_	_
3-12	252-256	have	_	_	_	_
3-13	257-261	done	_	_	_	_
3-14	262-271	elaborate	abstract[13]	new[13]	_	_
3-15	272-280	research	abstract[13]	new[13]	_	_
3-16	281-284	for	_	_	_	_
3-17	285-288	all	abstract[14]	new[14]	_	_
3-18	289-294	kinds	abstract[14]	new[14]	_	_
3-19	295-297	of	abstract[14]	new[14]	_	_
3-20	298-302	data	abstract[14]|abstract|object[16]	new[14]|new|new[16]	_	_
3-21	303-309	gloves	abstract[14]|object[16]	new[14]|new[16]	_	_
3-22	310-313	and	abstract[14]	new[14]	_	_
3-23	314-322	relevant	abstract[14]|abstract[17]	new[14]|new[17]	_	_
3-24	323-335	applications	abstract[14]|abstract[17]	new[14]|new[17]	_	_
3-25	336-337	.	_	_	_	_

#Text=We refer the readers to for a detailed review of glove-based works .
4-1	338-340	We	person	giv	ana	11-15
4-2	341-346	refer	_	_	_	_
4-3	347-350	the	person[19]	new[19]	coref	11-17[60_19]
4-4	351-358	readers	person[19]	new[19]	_	_
4-5	359-361	to	_	_	_	_
4-6	362-365	for	_	_	_	_
4-7	366-367	a	abstract[20]	new[20]	_	_
4-8	368-376	detailed	abstract[20]	new[20]	_	_
4-9	377-383	review	abstract[20]	new[20]	_	_
4-10	384-386	of	abstract[20]	new[20]	_	_
4-11	387-398	glove-based	abstract[20]|object[21]	new[20]|giv[21]	coref	8-11[34_21]
4-12	399-404	works	abstract[20]|object[21]	new[20]|giv[21]	_	_
4-13	405-406	.	_	_	_	_

#Text=2.1 .
5-1	407-410	2.1	abstract	new	_	_
5-2	411-412	.	_	_	_	_

#Text=Appearance-Based Methods
6-1	413-429	Appearance-Based	abstract[23]	giv[23]	coref	7-1[24_23]
6-2	430-437	Methods	abstract[23]	giv[23]	_	_

#Text=Appearance-based methods train a classifier or a regressor to map image features to hand poses .
7-1	438-454	Appearance-based	abstract[24]	giv[24]	coref	9-9[37_24]
7-2	455-462	methods	abstract[24]	giv[24]	_	_
7-3	463-468	train	_	_	_	_
7-4	469-470	a	abstract[25]	new[25]	coref	27-42[138_25]
7-5	471-481	classifier	abstract[25]	new[25]	_	_
7-6	482-484	or	_	_	_	_
7-7	485-486	a	abstract[26]	new[26]	_	_
7-8	487-496	regressor	abstract[26]	new[26]	_	_
7-9	497-499	to	abstract[26]	new[26]	_	_
7-10	500-503	map	abstract[26]	new[26]	_	_
7-11	504-509	image	object	new	coref	27-15
7-12	510-518	features	_	_	_	_
7-13	519-521	to	_	_	_	_
7-14	522-526	hand	object|abstract[29]	new|new[29]	coref	10-23
7-15	527-532	poses	abstract[29]	new[29]	_	_
7-16	533-534	.	_	_	_	_

#Text=Nearest neighbor search and decision trees are widely used in early works .
8-1	535-542	Nearest	abstract[31]	new[31]	_	_
8-2	543-551	neighbor	person|abstract[31]	new|new[31]	_	_
8-3	552-558	search	abstract[31]	new[31]	_	_
8-4	559-562	and	_	_	_	_
8-5	563-571	decision	abstract|object[33]	new|new[33]	coref	27-40[137_0]
8-6	572-577	trees	object[33]	new[33]	_	_
8-7	578-581	are	_	_	_	_
8-8	582-588	widely	_	_	_	_
8-9	589-593	used	_	_	_	_
8-10	594-596	in	_	_	_	_
8-11	597-602	early	object[34]	giv[34]	coref	24-1[113_34]
8-12	603-608	works	object[34]	giv[34]	_	_
8-13	609-610	.	_	_	_	_

#Text=In recent years , convolutional neural network ( CNN)-based discriminative methods are state-of-the-art which estimate 3D joint positions directly from depth images .
9-1	611-613	In	_	_	_	_
9-2	614-620	recent	time[35]	new[35]	_	_
9-3	621-626	years	time[35]	new[35]	_	_
9-4	627-628	,	_	_	_	_
9-5	629-642	convolutional	abstract[36]	new[36]	coref	27-60[144_36]
9-6	643-649	neural	abstract[36]	new[36]	_	_
9-7	650-657	network	abstract[36]	new[36]	_	_
9-8	658-659	(	_	_	_	_
9-9	660-670	CNN)-based	abstract[37]	giv[37]	coref	12-5[62_37]
9-10	671-685	discriminative	abstract[37]	giv[37]	_	_
9-11	686-693	methods	abstract[37]	giv[37]	_	_
9-12	694-697	are	_	_	_	_
9-13	698-714	state-of-the-art	_	_	_	_
9-14	715-720	which	_	_	_	_
9-15	721-729	estimate	_	_	_	_
9-16	730-732	3D	person|abstract[39]	new|new[39]	coref|coref	10-33[52_39]|19-31
9-17	733-738	joint	abstract[39]	new[39]	_	_
9-18	739-748	positions	abstract[39]	new[39]	_	_
9-19	749-757	directly	object[41]	new[41]	coref	27-70[0_41]
9-20	758-762	from	object[41]	new[41]	_	_
9-21	763-768	depth	abstract|object[41]	new|new[41]	_	_
9-22	769-775	images	object[41]	new[41]	_	_
9-23	776-777	.	_	_	_	_

#Text=Besides , kinematics and geometric constraints are considered to avoid joint estimations violating kinematic constraints . Malik et al. embedded a novel hand pose and shape layer inside CNN to produce not only 3D joint positions but also hand mesh information .
10-1	778-785	Besides	_	_	_	_
10-2	786-787	,	_	_	_	_
10-3	788-798	kinematics	abstract|abstract[43]	new|new[43]	coref|coref	18-16[85_0]|18-16[86_43]
10-4	799-802	and	abstract[43]	new[43]	_	_
10-5	803-812	geometric	abstract[43]|abstract[44]	new[43]|new[44]	coref	10-14[46_44]
10-6	813-824	constraints	abstract[43]|abstract[44]	new[43]|new[44]	_	_
10-7	825-828	are	_	_	_	_
10-8	829-839	considered	_	_	_	_
10-9	840-842	to	_	_	_	_
10-10	843-848	avoid	_	_	_	_
10-11	849-854	joint	abstract[45]	new[45]	_	_
10-12	855-866	estimations	abstract[45]	new[45]	_	_
10-13	867-876	violating	_	_	_	_
10-14	877-886	kinematic	abstract[46]	giv[46]	_	_
10-15	887-898	constraints	abstract[46]	giv[46]	_	_
10-16	899-900	.	_	_	_	_
10-17	901-906	Malik	person	new	_	_
10-18	907-909	et	_	_	_	_
10-19	910-913	al.	_	_	_	_
10-20	914-922	embedded	_	_	_	_
10-21	923-924	a	abstract[49]	new[49]	coref	27-53[0_49]
10-22	925-930	novel	abstract[49]	new[49]	_	_
10-23	931-935	hand	object|abstract[49]	giv|new[49]	coref	10-39
10-24	936-940	pose	abstract[49]	new[49]	_	_
10-25	941-944	and	_	_	_	_
10-26	945-950	shape	_	_	_	_
10-27	951-956	layer	abstract	new	_	_
10-28	957-963	inside	_	_	_	_
10-29	964-967	CNN	object	new	_	_
10-30	968-970	to	_	_	_	_
10-31	971-978	produce	_	_	_	_
10-32	979-982	not	_	_	_	_
10-33	983-987	only	abstract[52]	giv[52]	_	_
10-34	988-990	3D	abstract[52]	giv[52]	_	_
10-35	991-996	joint	abstract[52]	giv[52]	_	_
10-36	997-1006	positions	abstract[52]	giv[52]	_	_
10-37	1007-1010	but	abstract[52]	giv[52]	_	_
10-38	1011-1015	also	abstract[52]	giv[52]	_	_
10-39	1016-1020	hand	abstract[52]|object|abstract[55]	giv[52]|giv|new[55]	coref	13-13
10-40	1021-1025	mesh	abstract[52]|abstract|abstract[55]	giv[52]|new|new[55]	_	_
10-41	1026-1037	information	abstract[52]|abstract[55]	giv[52]|new[55]	_	_
10-42	1038-1039	.	_	_	_	_

#Text=For a more comprehensive analysis and investigation of the state-of-the-art along-with future challenges , we refer the readers to .
11-1	1040-1043	For	_	_	_	_
11-2	1044-1045	a	abstract[56]	new[56]	coref	14-5[69_56]
11-3	1046-1050	more	abstract[56]	new[56]	_	_
11-4	1051-1064	comprehensive	abstract[56]	new[56]	_	_
11-5	1065-1073	analysis	abstract[56]	new[56]	_	_
11-6	1074-1077	and	_	_	_	_
11-7	1078-1091	investigation	abstract[57]	new[57]	_	_
11-8	1092-1094	of	abstract[57]	new[57]	_	_
11-9	1095-1098	the	abstract[57]|abstract[58]	new[57]|new[58]	_	_
11-10	1099-1115	state-of-the-art	abstract[57]|abstract[58]	new[57]|new[58]	_	_
11-11	1116-1126	along-with	abstract[57]|abstract[58]	new[57]|new[58]	_	_
11-12	1127-1133	future	abstract[57]|abstract[58]	new[57]|new[58]	_	_
11-13	1134-1144	challenges	abstract[57]|abstract[58]	new[57]|new[58]	_	_
11-14	1145-1146	,	_	_	_	_
11-15	1147-1149	we	person	giv	ana	14-1
11-16	1150-1155	refer	_	_	_	_
11-17	1156-1159	the	person[60]	giv[60]	_	_
11-18	1160-1167	readers	person[60]	giv[60]	_	_
11-19	1168-1170	to	_	_	_	_
11-20	1171-1172	.	_	_	_	_

#Text=The biggest limitation of appearance-based methods is the training data .
12-1	1173-1176	The	abstract[61]	new[61]	coref	12-8[64_61]
12-2	1177-1184	biggest	abstract[61]	new[61]	_	_
12-3	1185-1195	limitation	abstract[61]	new[61]	_	_
12-4	1196-1198	of	abstract[61]	new[61]	_	_
12-5	1199-1215	appearance-based	abstract[61]|abstract[62]	new[61]|giv[62]	coref	17-1[78_62]
12-6	1216-1223	methods	abstract[61]|abstract[62]	new[61]|giv[62]	_	_
12-7	1224-1226	is	_	_	_	_
12-8	1227-1230	the	abstract[64]	giv[64]	coref	15-2[72_64]
12-9	1231-1239	training	abstract|abstract[64]	new|giv[64]	coref	27-47
12-10	1240-1244	data	abstract[64]	giv[64]	_	_
12-11	1245-1246	.	_	_	_	_

#Text=Existing benchmarks are not perfect enough to ensure well generalize to unseen hand shapes .
13-1	1247-1255	Existing	_	_	_	_
13-2	1256-1266	benchmarks	abstract	new	_	_
13-3	1267-1270	are	_	_	_	_
13-4	1271-1274	not	_	_	_	_
13-5	1275-1282	perfect	_	_	_	_
13-6	1283-1289	enough	_	_	_	_
13-7	1290-1292	to	_	_	_	_
13-8	1293-1299	ensure	_	_	_	_
13-9	1300-1304	well	_	_	_	_
13-10	1305-1315	generalize	_	_	_	_
13-11	1316-1318	to	_	_	_	_
13-12	1319-1325	unseen	abstract[67]	new[67]	_	_
13-13	1326-1330	hand	object|abstract[67]	giv|new[67]	coref	18-7
13-14	1331-1337	shapes	abstract[67]	new[67]	_	_
13-15	1338-1339	.	_	_	_	_

#Text=We refer to for a detailed analysis of the drawbacks of existing data-sets .
14-1	1340-1342	We	person	giv	ana	15-5
14-2	1343-1348	refer	_	_	_	_
14-3	1349-1351	to	_	_	_	_
14-4	1352-1355	for	_	_	_	_
14-5	1356-1357	a	abstract[69]	giv[69]	_	_
14-6	1358-1366	detailed	abstract[69]	giv[69]	_	_
14-7	1367-1375	analysis	abstract[69]	giv[69]	_	_
14-8	1376-1378	of	abstract[69]	giv[69]	_	_
14-9	1379-1382	the	abstract[69]|abstract[70]	giv[69]|new[70]	_	_
14-10	1383-1392	drawbacks	abstract[69]|abstract[70]	giv[69]|new[70]	_	_
14-11	1393-1395	of	abstract[69]|abstract[70]	giv[69]|new[70]	_	_
14-12	1396-1404	existing	abstract[69]|abstract[70]|abstract[71]	giv[69]|new[70]|new[71]	coref	15-16[76_71]
14-13	1405-1414	data-sets	abstract[69]|abstract[70]|abstract[71]	giv[69]|new[70]|new[71]	_	_
14-14	1415-1416	.	_	_	_	_

#Text=Considering this limitation , our system follows the model-based approaches that do not rely on massive data-sets .
15-1	1417-1428	Considering	_	_	_	_
15-2	1429-1433	this	abstract[72]	giv[72]	coref	18-28[0_72]
15-3	1434-1444	limitation	abstract[72]	giv[72]	_	_
15-4	1445-1446	,	_	_	_	_
15-5	1447-1450	our	person|abstract[74]	giv|new[74]	ana|coref	29-2|29-2[160_74]
15-6	1451-1457	system	abstract[74]	new[74]	_	_
15-7	1458-1465	follows	_	_	_	_
15-8	1466-1469	the	abstract[75]	new[75]	_	_
15-9	1470-1481	model-based	abstract[75]	new[75]	_	_
15-10	1482-1492	approaches	abstract[75]	new[75]	_	_
15-11	1493-1497	that	_	_	_	_
15-12	1498-1500	do	_	_	_	_
15-13	1501-1504	not	_	_	_	_
15-14	1505-1509	rely	_	_	_	_
15-15	1510-1512	on	_	_	_	_
15-16	1513-1520	massive	abstract[76]	giv[76]	coref	28-9[156_76]
15-17	1521-1530	data-sets	abstract[76]	giv[76]	_	_
15-18	1531-1532	.	_	_	_	_

#Text=2.2 .
16-1	1533-1536	2.2	abstract	new	_	_
16-2	1537-1538	.	_	_	_	_

#Text=Model-Based Methods
17-1	1539-1550	Model-Based	abstract[78]	giv[78]	coref	19-6[94_78]
17-2	1551-1558	Methods	abstract[78]	giv[78]	_	_

#Text=Despite the considerable advance in learning-based hand tracking , systems that employ generative models of explicit hand kinematics and surface geometry and fit these models to depth data using local optimization have produced the most compelling results .
18-1	1559-1566	Despite	_	_	_	_
18-2	1567-1570	the	abstract[79]	new[79]	_	_
18-3	1571-1583	considerable	abstract[79]	new[79]	_	_
18-4	1584-1591	advance	abstract[79]	new[79]	_	_
18-5	1592-1594	in	abstract[79]	new[79]	_	_
18-6	1595-1609	learning-based	abstract[79]|event[81]	new[79]|new[81]	_	_
18-7	1610-1614	hand	abstract[79]|object|event[81]	new[79]|giv|new[81]	coref	18-17
18-8	1615-1623	tracking	abstract[79]|event[81]	new[79]|new[81]	_	_
18-9	1624-1625	,	_	_	_	_
18-10	1626-1633	systems	abstract	new	_	_
18-11	1634-1638	that	_	_	_	_
18-12	1639-1645	employ	_	_	_	_
18-13	1646-1656	generative	abstract[83]	new[83]	coref	18-24[89_83]
18-14	1657-1663	models	abstract[83]	new[83]	_	_
18-15	1664-1666	of	abstract[83]	new[83]	_	_
18-16	1667-1675	explicit	abstract[83]|abstract[85]|abstract[86]	new[83]|giv[85]|giv[86]	_	_
18-17	1676-1680	hand	abstract[83]|object|abstract[85]|abstract[86]	new[83]|giv|giv[85]|giv[86]	coref	19-18
18-18	1681-1691	kinematics	abstract[83]|abstract[85]|abstract[86]	new[83]|giv[85]|giv[86]	_	_
18-19	1692-1695	and	abstract[83]|abstract[86]	new[83]|giv[86]	_	_
18-20	1696-1703	surface	abstract[83]|abstract[86]|place|abstract[88]	new[83]|giv[86]|new|new[88]	_	_
18-21	1704-1712	geometry	abstract[83]|abstract[86]|abstract[88]	new[83]|giv[86]|new[88]	_	_
18-22	1713-1716	and	_	_	_	_
18-23	1717-1720	fit	_	_	_	_
18-24	1721-1726	these	abstract[89]	giv[89]	coref	34-1[181_89]
18-25	1727-1733	models	abstract[89]	giv[89]	_	_
18-26	1734-1736	to	_	_	_	_
18-27	1737-1742	depth	_	_	_	_
18-28	1743-1747	data	abstract	giv	coref	19-35[105_0]
18-29	1748-1753	using	_	_	_	_
18-30	1754-1759	local	abstract[91]	new[91]	_	_
18-31	1760-1772	optimization	abstract[91]	new[91]	_	_
18-32	1773-1777	have	_	_	_	_
18-33	1778-1786	produced	_	_	_	_
18-34	1787-1790	the	abstract[92]	new[92]	coref	32-15[174_92]
18-35	1791-1795	most	abstract[92]	new[92]	_	_
18-36	1796-1806	compelling	abstract[92]	new[92]	_	_
18-37	1807-1814	results	abstract[92]	new[92]	_	_
18-38	1815-1816	.	_	_	_	_

#Text=The most common problems for model-based methods are a good enough initialization point , an expressive enough hand model and a discriminative object function that minimizes the error between the 3D hand model and the observed data .
19-1	1817-1820	The	abstract[93]	new[93]	coref	19-9[96_93]
19-2	1821-1825	most	abstract[93]	new[93]	_	_
19-3	1826-1832	common	abstract[93]	new[93]	_	_
19-4	1833-1841	problems	abstract[93]	new[93]	_	_
19-5	1842-1845	for	abstract[93]	new[93]	_	_
19-6	1846-1857	model-based	abstract[93]|abstract[94]	new[93]|giv[94]	coref	23-3[112_94]
19-7	1858-1865	methods	abstract[93]|abstract[94]	new[93]|giv[94]	_	_
19-8	1866-1869	are	_	_	_	_
19-9	1870-1871	a	abstract[96]	giv[96]	_	_
19-10	1872-1876	good	abstract[96]	giv[96]	_	_
19-11	1877-1883	enough	abstract[96]	giv[96]	_	_
19-12	1884-1898	initialization	abstract|abstract[96]	new|giv[96]	coref	21-1
19-13	1899-1904	point	abstract[96]	giv[96]	_	_
19-14	1905-1906	,	abstract[96]	giv[96]	_	_
19-15	1907-1909	an	abstract[96]|abstract[98]	giv[96]|new[98]	coref	19-30[104_98]
19-16	1910-1920	expressive	abstract[96]|abstract[98]	giv[96]|new[98]	_	_
19-17	1921-1927	enough	abstract[96]|abstract[98]	giv[96]|new[98]	_	_
19-18	1928-1932	hand	abstract[96]|object|abstract[98]	giv[96]|giv|new[98]	coref	19-32
19-19	1933-1938	model	abstract[96]|abstract[98]	giv[96]|new[98]	_	_
19-20	1939-1942	and	abstract[96]	giv[96]	_	_
19-21	1943-1944	a	abstract[96]|abstract[100]	giv[96]|new[100]	_	_
19-22	1945-1959	discriminative	abstract[96]|abstract[100]	giv[96]|new[100]	_	_
19-23	1960-1966	object	abstract[96]|object|abstract[100]	giv[96]|new|new[100]	_	_
19-24	1967-1975	function	abstract[96]|abstract[100]	giv[96]|new[100]	_	_
19-25	1976-1980	that	_	_	_	_
19-26	1981-1990	minimizes	_	_	_	_
19-27	1991-1994	the	abstract[101]	new[101]	_	_
19-28	1995-2000	error	abstract[101]	new[101]	_	_
19-29	2001-2008	between	abstract[101]	new[101]	_	_
19-30	2009-2012	the	abstract[101]|abstract[104]	new[101]|giv[104]	coref	27-83[152_104]
19-31	2013-2015	3D	abstract[101]|object|abstract[104]	new[101]|giv|giv[104]	coref	37-58
19-32	2016-2020	hand	abstract[101]|object|abstract[104]	new[101]|giv|giv[104]	coref	26-21
19-33	2021-2026	model	abstract[101]|abstract[104]	new[101]|giv[104]	_	_
19-34	2027-2030	and	abstract[101]	new[101]	_	_
19-35	2031-2034	the	abstract[101]|abstract[105]	new[101]|giv[105]	coref	27-13[130_105]
19-36	2035-2043	observed	abstract[101]|abstract[105]	new[101]|giv[105]	_	_
19-37	2044-2048	data	abstract[101]|abstract[105]	new[101]|giv[105]	_	_
19-38	2049-2050	.	_	_	_	_

#Text=2.2.1 .
20-1	2051-2056	2.2.1	abstract	new	_	_
20-2	2057-2058	.	_	_	_	_

#Text=Initialization
21-1	2059-2073	Initialization	abstract	giv	coref	22-1[108_0]

#Text=A good enough Initialization has been proven critical to the robustness , which enables faster converge and better resistant to local optima .
22-1	2074-2075	A	abstract[108]	giv[108]	coref	23-4[0_108]
22-2	2076-2080	good	abstract[108]	giv[108]	_	_
22-3	2081-2087	enough	abstract[108]	giv[108]	_	_
22-4	2088-2102	Initialization	abstract[108]	giv[108]	_	_
22-5	2103-2106	has	_	_	_	_
22-6	2107-2111	been	_	_	_	_
22-7	2112-2118	proven	_	_	_	_
22-8	2119-2127	critical	_	_	_	_
22-9	2128-2130	to	_	_	_	_
22-10	2131-2134	the	abstract[109]	new[109]	_	_
22-11	2135-2145	robustness	abstract[109]	new[109]	_	_
22-12	2146-2147	,	_	_	_	_
22-13	2148-2153	which	_	_	_	_
22-14	2154-2161	enables	_	_	_	_
22-15	2162-2168	faster	_	_	_	_
22-16	2169-2177	converge	_	_	_	_
22-17	2178-2181	and	_	_	_	_
22-18	2182-2188	better	_	_	_	_
22-19	2189-2198	resistant	_	_	_	_
22-20	2199-2201	to	_	_	_	_
22-21	2202-2207	local	abstract[110]	new[110]	_	_
22-22	2208-2214	optima	abstract[110]	new[110]	_	_
22-23	2215-2216	.	_	_	_	_

#Text=There exist many initialization methods .
23-1	2217-2222	There	_	_	_	_
23-2	2223-2228	exist	_	_	_	_
23-3	2229-2233	many	abstract[112]	giv[112]	coref	27-18[131_112]
23-4	2234-2248	initialization	abstract|abstract[112]	giv|giv[112]	coref	26-8
23-5	2249-2256	methods	abstract[112]	giv[112]	_	_
23-6	2257-2258	.	_	_	_	_

#Text=Some works were initialized by the fingertip detection .
24-1	2259-2263	Some	object[113]	giv[113]	coref	37-1[183_113]
24-2	2264-2269	works	object[113]	giv[113]	_	_
24-3	2270-2274	were	_	_	_	_
24-4	2275-2286	initialized	_	_	_	_
24-5	2287-2289	by	_	_	_	_
24-6	2290-2293	the	abstract[115]	new[115]	_	_
24-7	2294-2303	fingertip	abstract|abstract[115]	new|new[115]	_	_
24-8	2304-2313	detection	abstract[115]	new[115]	_	_
24-9	2314-2315	.	_	_	_	_

#Text=Besides , Tagliasacchi et al. and Tkach et al. also detected a color wristband as a first alignment .
25-1	2316-2323	Besides	_	_	_	_
25-2	2324-2325	,	_	_	_	_
25-3	2326-2338	Tagliasacchi	person	new	_	_
25-4	2339-2341	et	_	_	_	_
25-5	2342-2345	al.	_	_	_	_
25-6	2346-2349	and	_	_	_	_
25-7	2350-2355	Tkach	person	new	coref	39-11
25-8	2356-2358	et	_	_	_	_
25-9	2359-2362	al.	_	_	_	_
25-10	2363-2367	also	_	_	_	_
25-11	2368-2376	detected	_	_	_	_
25-12	2377-2378	a	object[119]	new[119]	_	_
25-13	2379-2384	color	abstract|object[119]	new|new[119]	_	_
25-14	2385-2394	wristband	object[119]	new[119]	_	_
25-15	2395-2397	as	_	_	_	_
25-16	2398-2399	a	_	_	_	_
25-17	2400-2405	first	_	_	_	_
25-18	2406-2415	alignment	_	_	_	_
25-19	2416-2417	.	_	_	_	_

#Text=The use of simple geometric heuristics for initialization can sometimes be impractical for those gestures which contain occlusions or difficult hand orientations .
26-1	2418-2421	The	abstract[120]	new[120]	_	_
26-2	2422-2425	use	abstract[120]	new[120]	_	_
26-3	2426-2428	of	abstract[120]	new[120]	_	_
26-4	2429-2435	simple	abstract[120]|abstract[121]	new[120]|new[121]	_	_
26-5	2436-2445	geometric	abstract[120]|abstract[121]	new[120]|new[121]	_	_
26-6	2446-2456	heuristics	abstract[120]|abstract[121]	new[120]|new[121]	_	_
26-7	2457-2460	for	abstract[120]|abstract[121]	new[120]|new[121]	_	_
26-8	2461-2475	initialization	abstract[120]|abstract[121]|abstract	new[120]|new[121]|giv	coref	27-65[145_0]
26-9	2476-2479	can	_	_	_	_
26-10	2480-2489	sometimes	_	_	_	_
26-11	2490-2492	be	_	_	_	_
26-12	2493-2504	impractical	_	_	_	_
26-13	2505-2508	for	_	_	_	_
26-14	2509-2514	those	abstract[123]	new[123]	_	_
26-15	2515-2523	gestures	abstract[123]	new[123]	_	_
26-16	2524-2529	which	_	_	_	_
26-17	2530-2537	contain	_	_	_	_
26-18	2538-2548	occlusions	abstract	new	_	_
26-19	2549-2551	or	_	_	_	_
26-20	2552-2561	difficult	abstract[126]	new[126]	_	_
26-21	2562-2566	hand	object|abstract[126]	giv|new[126]	coref	27-26[134_0]
26-22	2567-2579	orientations	abstract[126]	new[126]	_	_
26-23	2580-2581	.	_	_	_	_

#Text=For this reason , most of the previous studies concentrated on exploiting the given image data with the train-based methods . Taylor et al. generated candidate ’s hand poses quickly by a retrieval forest . Taylor et al. trained a decision forest classifier on a synthetic training set to generate an initial pose estimate . Sanchez-Riera et al. trained a convolutional neural network for initialization with 243,000 tuples of images . Sharp et al. inferred a hierarchical distribution over hand pose with a layered discriminative model .
27-1	2582-2585	For	_	_	_	_
27-2	2586-2590	this	abstract[127]	new[127]	_	_
27-3	2591-2597	reason	abstract[127]	new[127]	_	_
27-4	2598-2599	,	_	_	_	_
27-5	2600-2604	most	abstract[128]	new[128]	_	_
27-6	2605-2607	of	abstract[128]	new[128]	_	_
27-7	2608-2611	the	abstract[128]	new[128]	_	_
27-8	2612-2620	previous	abstract[128]	new[128]	_	_
27-9	2621-2628	studies	abstract[128]	new[128]	_	_
27-10	2629-2641	concentrated	_	_	_	_
27-11	2642-2644	on	_	_	_	_
27-12	2645-2655	exploiting	_	_	_	_
27-13	2656-2659	the	abstract[130]	giv[130]	coref	29-19[0_130]
27-14	2660-2665	given	abstract[130]	giv[130]	_	_
27-15	2666-2671	image	abstract|abstract[130]	giv|giv[130]	coref	40-21
27-16	2672-2676	data	abstract[130]	giv[130]	_	_
27-17	2677-2681	with	abstract[130]	giv[130]	_	_
27-18	2682-2685	the	abstract[130]|abstract[131]	giv[130]|giv[131]	_	_
27-19	2686-2697	train-based	abstract[130]|abstract[131]	giv[130]|giv[131]	_	_
27-20	2698-2705	methods	abstract[130]|abstract[131]	giv[130]|giv[131]	_	_
27-21	2706-2707	.	_	_	_	_
27-22	2708-2714	Taylor	person	new	coref	27-36
27-23	2715-2717	et	_	_	_	_
27-24	2718-2721	al.	_	_	_	_
27-25	2722-2731	generated	_	_	_	_
27-26	2732-2741	candidate	person[133]|object[134]	new[133]|giv[134]	coref	27-80[0_134]
27-27	2742-2744	’s	person[133]|object[134]	new[133]|giv[134]	_	_
27-28	2745-2749	hand	object[134]	giv[134]	_	_
27-29	2750-2755	poses	_	_	_	_
27-30	2756-2763	quickly	_	_	_	_
27-31	2764-2766	by	_	_	_	_
27-32	2767-2768	a	object[135]	new[135]	_	_
27-33	2769-2778	retrieval	object[135]	new[135]	_	_
27-34	2779-2785	forest	object[135]	new[135]	_	_
27-35	2786-2787	.	_	_	_	_
27-36	2788-2794	Taylor	person	giv	coref	43-16
27-37	2795-2797	et	_	_	_	_
27-38	2798-2801	al.	_	_	_	_
27-39	2802-2809	trained	_	_	_	_
27-40	2810-2811	a	abstract[137]	giv[137]	_	_
27-41	2812-2820	decision	abstract[137]	giv[137]	_	_
27-42	2821-2827	forest	abstract[138]	giv[138]	_	_
27-43	2828-2838	classifier	abstract[138]	giv[138]	_	_
27-44	2839-2841	on	abstract[138]	giv[138]	_	_
27-45	2842-2843	a	abstract[138]|abstract[140]	giv[138]|new[140]	_	_
27-46	2844-2853	synthetic	abstract[138]|abstract[140]	giv[138]|new[140]	_	_
27-47	2854-2862	training	abstract[138]|abstract|abstract[140]	giv[138]|giv|new[140]	coref	28-10
27-48	2863-2866	set	abstract[138]|abstract[140]	giv[138]|new[140]	_	_
27-49	2867-2869	to	_	_	_	_
27-50	2870-2878	generate	_	_	_	_
27-51	2879-2881	an	abstract[142]	new[142]	_	_
27-52	2882-2889	initial	abstract[142]	new[142]	_	_
27-53	2890-2894	pose	abstract|abstract[142]	giv|new[142]	coref	27-80[151_0]
27-54	2895-2903	estimate	abstract[142]	new[142]	_	_
27-55	2904-2905	.	_	_	_	_
27-56	2906-2919	Sanchez-Riera	person	new	_	_
27-57	2920-2922	et	_	_	_	_
27-58	2923-2926	al.	_	_	_	_
27-59	2927-2934	trained	_	_	_	_
27-60	2935-2936	a	abstract[144]	giv[144]	_	_
27-61	2937-2950	convolutional	abstract[144]	giv[144]	_	_
27-62	2951-2957	neural	abstract[144]	giv[144]	_	_
27-63	2958-2965	network	abstract[144]	giv[144]	_	_
27-64	2966-2969	for	abstract[144]	giv[144]	_	_
27-65	2970-2984	initialization	abstract[144]|abstract[145]	giv[144]|giv[145]	coref	28-3[0_145]
27-66	2985-2989	with	abstract[144]|abstract[145]	giv[144]|giv[145]	_	_
27-67	2990-2997	243,000	abstract[144]|abstract[145]|quantity[146]	giv[144]|giv[145]|new[146]	_	_
27-68	2998-3004	tuples	abstract[144]|abstract[145]|quantity[146]	giv[144]|giv[145]|new[146]	_	_
27-69	3005-3007	of	abstract[144]|abstract[145]|quantity[146]	giv[144]|giv[145]|new[146]	_	_
27-70	3008-3014	images	abstract[144]|abstract[145]|quantity[146]|object	giv[144]|giv[145]|new[146]|giv	_	_
27-71	3015-3016	.	_	_	_	_
27-72	3017-3022	Sharp	person	new	_	_
27-73	3023-3025	et	_	_	_	_
27-74	3026-3029	al.	_	_	_	_
27-75	3030-3038	inferred	_	_	_	_
27-76	3039-3040	a	abstract[149]	new[149]	_	_
27-77	3041-3053	hierarchical	abstract[149]	new[149]	_	_
27-78	3054-3066	distribution	abstract[149]	new[149]	_	_
27-79	3067-3071	over	abstract[149]	new[149]	_	_
27-80	3072-3076	hand	abstract[149]|object|abstract[151]	new[149]|giv|giv[151]	coref	32-3
27-81	3077-3081	pose	abstract[149]|abstract[151]	new[149]|giv[151]	_	_
27-82	3082-3086	with	abstract[149]|abstract[151]	new[149]|giv[151]	_	_
27-83	3087-3088	a	abstract[149]|abstract[151]|abstract[152]	new[149]|giv[151]|giv[152]	coref	32-1[169_152]
27-84	3089-3096	layered	abstract[149]|abstract[151]|abstract[152]	new[149]|giv[151]|giv[152]	_	_
27-85	3097-3111	discriminative	abstract[149]|abstract[151]|abstract[152]	new[149]|giv[151]|giv[152]	_	_
27-86	3112-3117	model	abstract[149]|abstract[151]|abstract[152]	new[149]|giv[151]|giv[152]	_	_
27-87	3118-3119	.	_	_	_	_

#Text=However , initialization errors often occur due to imperfect training data-sets , mentioned in Section 2.1 , which may cause tracking failure .
28-1	3120-3127	However	_	_	_	_
28-2	3128-3129	,	_	_	_	_
28-3	3130-3144	initialization	abstract|abstract[154]	giv|new[154]	coref	29-13[163_0]
28-4	3145-3151	errors	abstract[154]	new[154]	_	_
28-5	3152-3157	often	_	_	_	_
28-6	3158-3163	occur	_	_	_	_
28-7	3164-3167	due	_	_	_	_
28-8	3168-3170	to	_	_	_	_
28-9	3171-3180	imperfect	abstract[156]	giv[156]	_	_
28-10	3181-3189	training	abstract|abstract[156]	giv|giv[156]	_	_
28-11	3190-3199	data-sets	abstract[156]	giv[156]	_	_
28-12	3200-3201	,	_	_	_	_
28-13	3202-3211	mentioned	_	_	_	_
28-14	3212-3214	in	_	_	_	_
28-15	3215-3222	Section	abstract[157]	new[157]	_	_
28-16	3223-3226	2.1	abstract[157]	new[157]	_	_
28-17	3227-3228	,	_	_	_	_
28-18	3229-3234	which	_	_	_	_
28-19	3235-3238	may	_	_	_	_
28-20	3239-3244	cause	_	_	_	_
28-21	3245-3253	tracking	abstract[158]	new[158]	ana	29-5[0_158]
28-22	3254-3261	failure	abstract[158]	new[158]	_	_
28-23	3262-3263	.	_	_	_	_

#Text=In our system , it is more reliable and robust to provide an approximate initialization by a simple data glove .
29-1	3264-3266	In	_	_	_	_
29-2	3267-3270	our	person|abstract[160]	giv|giv[160]	ana|coref	44-14|44-14[248_160]
29-3	3271-3277	system	abstract[160]	giv[160]	_	_
29-4	3278-3279	,	_	_	_	_
29-5	3280-3282	it	abstract	giv	_	_
29-6	3283-3285	is	_	_	_	_
29-7	3286-3290	more	_	_	_	_
29-8	3291-3299	reliable	_	_	_	_
29-9	3300-3303	and	_	_	_	_
29-10	3304-3310	robust	_	_	_	_
29-11	3311-3313	to	abstract[162]	new[162]	_	_
29-12	3314-3321	provide	abstract[162]	new[162]	_	_
29-13	3322-3324	an	abstract[162]|abstract[163]	new[162]|giv[163]	_	_
29-14	3325-3336	approximate	abstract[162]|abstract[163]	new[162]|giv[163]	_	_
29-15	3337-3351	initialization	abstract[162]|abstract[163]	new[162]|giv[163]	_	_
29-16	3352-3354	by	_	_	_	_
29-17	3355-3356	a	object[165]	new[165]	_	_
29-18	3357-3363	simple	object[165]	new[165]	_	_
29-19	3364-3368	data	abstract|object[165]	giv|new[165]	coref	40-21[226_0]
29-20	3369-3374	glove	object[165]	new[165]	_	_
29-21	3375-3376	.	_	_	_	_

#Text=2.2.2 .
30-1	3377-3382	2.2.2	abstract	new	_	_
30-2	3383-3384	.	_	_	_	_

#Text=Hand Model
31-1	3385-3389	Hand	abstract[167]	new[167]	_	_
31-2	3390-3395	Model	abstract[167]	new[167]	_	_

#Text=The human hand model serves as the medium of computation and the presentation of algorithm results .
32-1	3396-3399	The	abstract[169]	giv[169]	coref	33-1[175_169]
32-2	3400-3405	human	abstract[169]	giv[169]	_	_
32-3	3406-3410	hand	object|abstract[169]	giv|giv[169]	coref	34-2
32-4	3411-3416	model	abstract[169]	giv[169]	_	_
32-5	3417-3423	serves	_	_	_	_
32-6	3424-3426	as	_	_	_	_
32-7	3427-3430	the	_	_	_	_
32-8	3431-3437	medium	_	_	_	_
32-9	3438-3440	of	_	_	_	_
32-10	3441-3452	computation	abstract|abstract[171]	new|new[171]	ana	33-16[0_171]
32-11	3453-3456	and	abstract[171]	new[171]	_	_
32-12	3457-3460	the	abstract[171]|abstract[172]	new[171]|new[172]	_	_
32-13	3461-3473	presentation	abstract[171]|abstract[172]	new[171]|new[172]	_	_
32-14	3474-3476	of	abstract[171]|abstract[172]	new[171]|new[172]	_	_
32-15	3477-3486	algorithm	abstract[171]|abstract[172]|abstract|abstract[174]	new[171]|new[172]|new|giv[174]	_	_
32-16	3487-3494	results	abstract[171]|abstract[172]|abstract[174]	new[171]|new[172]|giv[174]	_	_
32-17	3495-3496	.	_	_	_	_

#Text=A detailed and accurate generative model tends to deepen the good local minima and widen their basins of convergence .
33-1	3497-3498	A	abstract[175]	giv[175]	coref	37-24[191_175]
33-2	3499-3507	detailed	abstract[175]	giv[175]	_	_
33-3	3508-3511	and	abstract[175]	giv[175]	_	_
33-4	3512-3520	accurate	abstract[175]	giv[175]	_	_
33-5	3521-3531	generative	abstract[175]	giv[175]	_	_
33-6	3532-3537	model	abstract[175]	giv[175]	_	_
33-7	3538-3543	tends	_	_	_	_
33-8	3544-3546	to	_	_	_	_
33-9	3547-3553	deepen	_	_	_	_
33-10	3554-3557	the	abstract[176]	new[176]	_	_
33-11	3558-3562	good	abstract[176]	new[176]	_	_
33-12	3563-3568	local	abstract[176]	new[176]	_	_
33-13	3569-3575	minima	abstract[176]	new[176]	_	_
33-14	3576-3579	and	_	_	_	_
33-15	3580-3585	widen	_	_	_	_
33-16	3586-3591	their	abstract|abstract[178]	giv|new[178]	_	_
33-17	3592-3598	basins	abstract[178]	new[178]	_	_
33-18	3599-3601	of	abstract[178]	new[178]	_	_
33-19	3602-3613	convergence	abstract[178]|abstract	new[178]|new	_	_
33-20	3614-3615	.	_	_	_	_

#Text=Many hand models have been proposed , see
34-1	3616-3620	Many	abstract[181]	giv[181]	coref	42-8[231_181]
34-2	3621-3625	hand	object|abstract[181]	giv|giv[181]	coref	37-25
34-3	3626-3632	models	abstract[181]	giv[181]	_	_
34-4	3633-3637	have	_	_	_	_
34-5	3638-3642	been	_	_	_	_
34-6	3643-3651	proposed	_	_	_	_
34-7	3652-3653	,	_	_	_	_
34-8	3654-3657	see	_	_	_	_

#Text=Figure 1
35-1	3658-3664	Figure	object[182]	new[182]	_	_
35-2	3665-3666	1	object[182]	new[182]	_	_

#Text=.
36-1	3667-3668	.	_	_	_	_

#Text=Early works used the capsule mode made by two basic geometric primitives : a sphere and a cylinder . Qian et al. built the hand model using a number of spheres . Melax et al. used a union of convex bodies for hand tracking . Sridhar et al. modeled the volumetric extent of the hand as a 3D sum of an-isotropic Gaussian model .
37-1	3669-3674	Early	object[183]	giv[183]	_	_
37-2	3675-3680	works	object[183]	giv[183]	_	_
37-3	3681-3685	used	_	_	_	_
37-4	3686-3689	the	abstract[185]	new[185]	_	_
37-5	3690-3697	capsule	object|abstract[185]	new|new[185]	_	_
37-6	3698-3702	mode	abstract[185]	new[185]	_	_
37-7	3703-3707	made	_	_	_	_
37-8	3708-3710	by	_	_	_	_
37-9	3711-3714	two	abstract[186]	new[186]	_	_
37-10	3715-3720	basic	abstract[186]	new[186]	_	_
37-11	3721-3730	geometric	abstract[186]	new[186]	_	_
37-12	3731-3741	primitives	abstract[186]	new[186]	_	_
37-13	3742-3743	:	_	_	_	_
37-14	3744-3745	a	object[187]	new[187]	_	_
37-15	3746-3752	sphere	object[187]	new[187]	_	_
37-16	3753-3756	and	_	_	_	_
37-17	3757-3758	a	object[188]	new[188]	_	_
37-18	3759-3767	cylinder	object[188]	new[188]	_	_
37-19	3768-3769	.	_	_	_	_
37-20	3770-3774	Qian	person	new	_	_
37-21	3775-3777	et	_	_	_	_
37-22	3778-3781	al.	_	_	_	_
37-23	3782-3787	built	_	_	_	_
37-24	3788-3791	the	abstract[191]	giv[191]	coref	37-61[202_191]
37-25	3792-3796	hand	object|abstract[191]	giv|giv[191]	coref	37-43
37-26	3797-3802	model	abstract[191]	giv[191]	_	_
37-27	3803-3808	using	_	_	_	_
37-28	3809-3810	a	object[192]	new[192]	_	_
37-29	3811-3817	number	object[192]	new[192]	_	_
37-30	3818-3820	of	object[192]	new[192]	_	_
37-31	3821-3828	spheres	object[192]	new[192]	_	_
37-32	3829-3830	.	_	_	_	_
37-33	3831-3836	Melax	person	new	_	_
37-34	3837-3839	et	_	_	_	_
37-35	3840-3843	al.	_	_	_	_
37-36	3844-3848	used	_	_	_	_
37-37	3849-3850	a	organization[194]	new[194]	_	_
37-38	3851-3856	union	organization[194]	new[194]	_	_
37-39	3857-3859	of	organization[194]	new[194]	_	_
37-40	3860-3866	convex	organization[194]|object[195]	new[194]|new[195]	_	_
37-41	3867-3873	bodies	organization[194]|object[195]	new[194]|new[195]	_	_
37-42	3874-3877	for	organization[194]|object[195]	new[194]|new[195]	_	_
37-43	3878-3882	hand	organization[194]|object[195]|object	new[194]|new[195]|giv	coref	37-54[199_0]
37-44	3883-3891	tracking	_	_	_	_
37-45	3892-3893	.	_	_	_	_
37-46	3894-3901	Sridhar	person	new	_	_
37-47	3902-3904	et	_	_	_	_
37-48	3905-3908	al.	_	_	_	_
37-49	3909-3916	modeled	_	_	_	_
37-50	3917-3920	the	abstract[198]	new[198]	_	_
37-51	3921-3931	volumetric	abstract[198]	new[198]	_	_
37-52	3932-3938	extent	abstract[198]	new[198]	_	_
37-53	3939-3941	of	abstract[198]	new[198]	_	_
37-54	3942-3945	the	abstract[198]|object[199]	new[198]|giv[199]	coref	38-9[0_199]
37-55	3946-3950	hand	abstract[198]|object[199]	new[198]|giv[199]	_	_
37-56	3951-3953	as	_	_	_	_
37-57	3954-3955	a	_	_	_	_
37-58	3956-3958	3D	abstract	giv	_	_
37-59	3959-3962	sum	_	_	_	_
37-60	3963-3965	of	_	_	_	_
37-61	3966-3978	an-isotropic	abstract[202]	giv[202]	_	_
37-62	3979-3987	Gaussian	person|abstract[202]	new|giv[202]	_	_
37-63	3988-3993	model	abstract[202]	giv[202]	_	_
37-64	3994-3995	.	_	_	_	_

#Text=These approaches can model a broad spectrum of hand shape variations and enable fast evaluation of distances and a high degree of computational parallelism .
38-1	3996-4001	These	abstract[203]	new[203]	_	_
38-2	4002-4012	approaches	abstract[203]	new[203]	_	_
38-3	4013-4016	can	_	_	_	_
38-4	4017-4022	model	_	_	_	_
38-5	4023-4024	a	abstract[204]	new[204]	_	_
38-6	4025-4030	broad	abstract[204]	new[204]	_	_
38-7	4031-4039	spectrum	abstract[204]	new[204]	_	_
38-8	4040-4042	of	abstract[204]	new[204]	_	_
38-9	4043-4047	hand	abstract[204]|object|abstract[207]	new[204]|giv|new[207]	coref	39-7
38-10	4048-4053	shape	abstract[204]|abstract|abstract[207]	new[204]|new|new[207]	coref	39-4[215_0]
38-11	4054-4064	variations	abstract[204]|abstract[207]	new[204]|new[207]	_	_
38-12	4065-4068	and	_	_	_	_
38-13	4069-4075	enable	_	_	_	_
38-14	4076-4080	fast	abstract[208]|abstract[209]	new[208]|new[209]	ana	39-3[0_209]
38-15	4081-4091	evaluation	abstract[208]|abstract[209]	new[208]|new[209]	_	_
38-16	4092-4094	of	abstract[208]|abstract[209]	new[208]|new[209]	_	_
38-17	4095-4104	distances	abstract[208]|abstract[209]|abstract	new[208]|new[209]|new	_	_
38-18	4105-4108	and	abstract[209]	new[209]	_	_
38-19	4109-4110	a	abstract[209]|abstract[211]	new[209]|new[211]	_	_
38-20	4111-4115	high	abstract[209]|abstract[211]	new[209]|new[211]	_	_
38-21	4116-4122	degree	abstract[209]|abstract[211]	new[209]|new[211]	_	_
38-22	4123-4125	of	abstract[209]|abstract[211]	new[209]|new[211]	_	_
38-23	4126-4139	computational	abstract[209]|abstract[211]|abstract[212]	new[209]|new[211]|new[212]	_	_
38-24	4140-4151	parallelism	abstract[209]|abstract[211]|abstract[212]	new[209]|new[211]|new[212]	_	_
38-25	4152-4153	.	_	_	_	_

#Text=However , they only roughly approximate hand shape even if Tkach et al. proposed the use of sphere-meshes as a novel geometric representation .
39-1	4154-4161	However	_	_	_	_
39-2	4162-4163	,	_	_	_	_
39-3	4164-4168	they	abstract	giv	_	_
39-4	4169-4173	only	abstract[215]	giv[215]	_	_
39-5	4174-4181	roughly	abstract[215]	giv[215]	_	_
39-6	4182-4193	approximate	abstract[215]	giv[215]	_	_
39-7	4194-4198	hand	object|abstract[215]	giv|giv[215]	coref	43-20[238_0]
39-8	4199-4204	shape	abstract[215]	giv[215]	_	_
39-9	4205-4209	even	_	_	_	_
39-10	4210-4212	if	_	_	_	_
39-11	4213-4218	Tkach	person	giv	_	_
39-12	4219-4221	et	_	_	_	_
39-13	4222-4225	al.	_	_	_	_
39-14	4226-4234	proposed	_	_	_	_
39-15	4235-4238	the	abstract[217]	new[217]	_	_
39-16	4239-4242	use	abstract[217]	new[217]	_	_
39-17	4243-4245	of	abstract[217]	new[217]	_	_
39-18	4246-4259	sphere-meshes	abstract[217]|object	new[217]|new	_	_
39-19	4260-4262	as	_	_	_	_
39-20	4263-4264	a	_	_	_	_
39-21	4265-4270	novel	_	_	_	_
39-22	4271-4280	geometric	_	_	_	_
39-23	4281-4295	representation	_	_	_	_
39-24	4296-4297	.	_	_	_	_

#Text=An alternative is a triangulated mesh model with linear blend skinning ( LBS ) that is more realistic and fits image data better .
40-1	4298-4300	An	abstract[219]	new[219]	coref	40-4[221_219]
40-2	4301-4312	alternative	abstract[219]	new[219]	_	_
40-3	4313-4315	is	_	_	_	_
40-4	4316-4317	a	abstract[221]	giv[221]	coref	44-17[251_221]
40-5	4318-4330	triangulated	abstract[221]	giv[221]	_	_
40-6	4331-4335	mesh	object|abstract[221]	new|giv[221]	coref	44-20
40-7	4336-4341	model	abstract[221]	giv[221]	_	_
40-8	4342-4346	with	abstract[221]	giv[221]	_	_
40-9	4347-4353	linear	abstract[221]|object[223]	giv[221]|new[223]	_	_
40-10	4354-4359	blend	abstract[221]|substance|object[223]	giv[221]|new|new[223]	_	_
40-11	4360-4368	skinning	abstract[221]|object[223]	giv[221]|new[223]	_	_
40-12	4369-4370	(	_	_	_	_
40-13	4371-4374	LBS	abstract	new	_	_
40-14	4375-4376	)	_	_	_	_
40-15	4377-4381	that	_	_	_	_
40-16	4382-4384	is	_	_	_	_
40-17	4385-4389	more	_	_	_	_
40-18	4390-4399	realistic	_	_	_	_
40-19	4400-4403	and	_	_	_	_
40-20	4404-4408	fits	_	_	_	_
40-21	4409-4414	image	object|abstract[226]	giv|giv[226]	coref	44-3[245_226]
40-22	4415-4419	data	abstract[226]	giv[226]	_	_
40-23	4420-4426	better	_	_	_	_
40-24	4427-4428	.	_	_	_	_

#Text=But these triangulated meshes cost more computational effort and are hard to deal with the collision .
41-1	4429-4432	But	_	_	_	_
41-2	4433-4438	these	object[227]	new[227]	_	_
41-3	4439-4451	triangulated	object[227]	new[227]	_	_
41-4	4452-4458	meshes	object[227]	new[227]	_	_
41-5	4459-4463	cost	_	_	_	_
41-6	4464-4468	more	abstract[228]	new[228]	_	_
41-7	4469-4482	computational	abstract[228]	new[228]	_	_
41-8	4483-4489	effort	abstract[228]	new[228]	_	_
41-9	4490-4493	and	_	_	_	_
41-10	4494-4497	are	_	_	_	_
41-11	4498-4502	hard	_	_	_	_
41-12	4503-4505	to	_	_	_	_
41-13	4506-4510	deal	_	_	_	_
41-14	4511-4515	with	_	_	_	_
41-15	4516-4519	the	event[229]	new[229]	_	_
41-16	4520-4529	collision	event[229]	new[229]	_	_
41-17	4530-4531	.	_	_	_	_

#Text=There also exist some implicit templates except these explicit models . Schmidt et al.
42-1	4532-4537	There	_	_	_	_
42-2	4538-4542	also	_	_	_	_
42-3	4543-4548	exist	_	_	_	_
42-4	4549-4553	some	abstract[230]	new[230]	_	_
42-5	4554-4562	implicit	abstract[230]	new[230]	_	_
42-6	4563-4572	templates	abstract[230]	new[230]	_	_
42-7	4573-4579	except	abstract[230]	new[230]	_	_
42-8	4580-4585	these	abstract[230]|abstract[231]	new[230]|giv[231]	_	_
42-9	4586-4594	explicit	abstract[230]|abstract[231]	new[230]|giv[231]	_	_
42-10	4595-4601	models	abstract[230]|abstract[231]	new[230]|giv[231]	_	_
42-11	4602-4603	.	_	_	_	_
42-12	4604-4611	Schmidt	person	new	_	_
42-13	4612-4614	et	_	_	_	_
42-14	4615-4618	al.	_	_	_	_

#Text=voxelized each shape-primitive and computed a signed distance function for the local coordinate frame . Taylor et al. constructed the hand as an articulated signed distance function that allows fast calculation of the distance to the hand surface .
43-1	4619-4628	voxelized	_	_	_	_
43-2	4629-4633	each	_	_	_	_
43-3	4634-4649	shape-primitive	_	_	_	_
43-4	4650-4653	and	_	_	_	_
43-5	4654-4662	computed	_	_	_	_
43-6	4663-4664	a	abstract[234]	new[234]	_	_
43-7	4665-4671	signed	abstract[234]	new[234]	_	_
43-8	4672-4680	distance	abstract|abstract[234]	new|new[234]	coref	43-26
43-9	4681-4689	function	abstract[234]	new[234]	_	_
43-10	4690-4693	for	abstract[234]	new[234]	_	_
43-11	4694-4697	the	abstract[234]|abstract[236]	new[234]|new[236]	_	_
43-12	4698-4703	local	abstract[234]|abstract[236]	new[234]|new[236]	_	_
43-13	4704-4714	coordinate	abstract[234]|abstract|abstract[236]	new[234]|new|new[236]	_	_
43-14	4715-4720	frame	abstract[234]|abstract[236]	new[234]|new[236]	_	_
43-15	4721-4722	.	_	_	_	_
43-16	4723-4729	Taylor	person	giv	_	_
43-17	4730-4732	et	_	_	_	_
43-18	4733-4736	al.	_	_	_	_
43-19	4737-4748	constructed	_	_	_	_
43-20	4749-4752	the	object[238]	giv[238]	coref	43-37[0_238]
43-21	4753-4757	hand	object[238]	giv[238]	_	_
43-22	4758-4760	as	_	_	_	_
43-23	4761-4763	an	_	_	_	_
43-24	4764-4775	articulated	_	_	_	_
43-25	4776-4782	signed	_	_	_	_
43-26	4783-4791	distance	abstract	giv	coref	43-33[241_0]
43-27	4792-4800	function	_	_	_	_
43-28	4801-4805	that	_	_	_	_
43-29	4806-4812	allows	_	_	_	_
43-30	4813-4817	fast	abstract[240]	new[240]	_	_
43-31	4818-4829	calculation	abstract[240]	new[240]	_	_
43-32	4830-4832	of	abstract[240]	new[240]	_	_
43-33	4833-4836	the	abstract[240]|abstract[241]	new[240]|giv[241]	_	_
43-34	4837-4845	distance	abstract[240]|abstract[241]	new[240]|giv[241]	_	_
43-35	4846-4848	to	abstract[240]|abstract[241]	new[240]|giv[241]	_	_
43-36	4849-4852	the	abstract[240]|abstract[241]|object[243]	new[240]|giv[241]|new[243]	_	_
43-37	4853-4857	hand	abstract[240]|abstract[241]|object|object[243]	new[240]|giv[241]|giv|new[243]	coref	44-21
43-38	4858-4865	surface	abstract[240]|abstract[241]|object[243]	new[240]|giv[241]|new[243]	_	_
43-39	4866-4867	.	_	_	_	_

#Text=To explain the input data better and explicitly visualize the tracking result , our system uses an expressive triangular mesh hand model .
44-1	4868-4870	To	_	_	_	_
44-2	4871-4878	explain	_	_	_	_
44-3	4879-4882	the	abstract[245]	giv[245]	_	_
44-4	4883-4888	input	abstract|abstract[245]	new|giv[245]	_	_
44-5	4889-4893	data	abstract[245]	giv[245]	_	_
44-6	4894-4900	better	_	_	_	_
44-7	4901-4904	and	_	_	_	_
44-8	4905-4915	explicitly	_	_	_	_
44-9	4916-4925	visualize	_	_	_	_
44-10	4926-4929	the	abstract[246]	new[246]	_	_
44-11	4930-4938	tracking	abstract[246]	new[246]	_	_
44-12	4939-4945	result	abstract[246]	new[246]	_	_
44-13	4946-4947	,	_	_	_	_
44-14	4948-4951	our	person|abstract[248]	giv|giv[248]	_	_
44-15	4952-4958	system	abstract[248]	giv[248]	_	_
44-16	4959-4963	uses	_	_	_	_
44-17	4964-4966	an	abstract[251]	giv[251]	_	_
44-18	4967-4977	expressive	abstract[251]	giv[251]	_	_
44-19	4978-4988	triangular	abstract[251]	giv[251]	_	_
44-20	4989-4993	mesh	object|abstract[251]	giv|giv[251]	_	_
44-21	4994-4998	hand	object|abstract[251]	giv|giv[251]	_	_
44-22	4999-5004	model	abstract[251]	giv[251]	_	_
44-23	5005-5006	.	_	_	_	_
