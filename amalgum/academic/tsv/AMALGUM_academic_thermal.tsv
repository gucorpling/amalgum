#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=1. Introduction
1-1	0-2	1.	_	_	_	_
1-2	3-15	Introduction	abstract	new	_	_

#Text=Significant technological progress in image processing algorithms and ability to improve perception of the world surrounding us using modern deep learning methods has led to invention and enablement of various applications that were previously much harder to implement , e.g. , face recognition , objects detection and segmentation or image resolution enhancement .
2-1	16-27	Significant	abstract[2]	new[2]	coref	4-9[35_2]
2-2	28-41	technological	abstract[2]	new[2]	_	_
2-3	42-50	progress	abstract[2]	new[2]	_	_
2-4	51-53	in	abstract[2]	new[2]	_	_
2-5	54-59	image	abstract[2]|abstract|abstract[4]|abstract[5]	new[2]|new|new[4]|new[5]	coref|coref	2-50|22-26[162_5]
2-6	60-70	processing	abstract[2]|abstract[4]|abstract[5]	new[2]|new[4]|new[5]	_	_
2-7	71-81	algorithms	abstract[2]|abstract[5]	new[2]|new[5]	_	_
2-8	82-85	and	_	_	_	_
2-9	86-93	ability	abstract[6]	new[6]	_	_
2-10	94-96	to	abstract[6]	new[6]	_	_
2-11	97-104	improve	abstract[6]	new[6]	_	_
2-12	105-115	perception	abstract[6]|abstract[7]	new[6]|new[7]	_	_
2-13	116-118	of	abstract[6]|abstract[7]	new[6]|new[7]	_	_
2-14	119-122	the	abstract[6]|abstract[7]|place[8]	new[6]|new[7]|new[8]	_	_
2-15	123-128	world	abstract[6]|abstract[7]|place[8]	new[6]|new[7]|new[8]	_	_
2-16	129-140	surrounding	abstract[6]|abstract[7]|place[8]	new[6]|new[7]|new[8]	_	_
2-17	141-143	us	abstract[6]|abstract[7]|place[8]|person	new[6]|new[7]|new[8]|acc	_	_
2-18	144-149	using	abstract[6]|abstract[7]|place[8]	new[6]|new[7]|new[8]	_	_
2-19	150-156	modern	abstract[6]|abstract[7]|place[8]|abstract[11]	new[6]|new[7]|new[8]|new[11]	coref	11-5[93_11]
2-20	157-161	deep	abstract[6]|abstract[7]|place[8]|abstract[10]|abstract[11]	new[6]|new[7]|new[8]|new[10]|new[11]	_	_
2-21	162-170	learning	abstract[6]|abstract[7]|place[8]|abstract[10]|abstract[11]	new[6]|new[7]|new[8]|new[10]|new[11]	_	_
2-22	171-178	methods	abstract[6]|abstract[7]|place[8]|abstract[11]	new[6]|new[7]|new[8]|new[11]	_	_
2-23	179-182	has	_	_	_	_
2-24	183-186	led	_	_	_	_
2-25	187-189	to	_	_	_	_
2-26	190-199	invention	event	new	_	_
2-27	200-203	and	_	_	_	_
2-28	204-214	enablement	abstract[13]	new[13]	_	_
2-29	215-217	of	abstract[13]	new[13]	_	_
2-30	218-225	various	abstract[13]|abstract[14]	new[13]|new[14]	appos	2-40[16_14]
2-31	226-238	applications	abstract[13]|abstract[14]	new[13]|new[14]	_	_
2-32	239-243	that	abstract[13]|abstract[14]	new[13]|new[14]	_	_
2-33	244-248	were	abstract[13]|abstract[14]	new[13]|new[14]	_	_
2-34	249-259	previously	abstract[13]|abstract[14]	new[13]|new[14]	_	_
2-35	260-264	much	abstract[13]|abstract[14]	new[13]|new[14]	_	_
2-36	265-271	harder	abstract[13]|abstract[14]	new[13]|new[14]	_	_
2-37	272-274	to	abstract[13]|abstract[14]	new[13]|new[14]	_	_
2-38	275-284	implement	abstract[13]|abstract[14]	new[13]|new[14]	_	_
2-39	285-286	,	_	_	_	_
2-40	287-291	e.g.	abstract[16]|abstract[17]	giv[16]|giv[17]	appos|appos	2-40[17_16]|2-45[19_17]
2-41	292-293	,	abstract[16]|abstract[17]	giv[16]|giv[17]	_	_
2-42	294-298	face	object|abstract[16]|abstract[17]	new|giv[16]|giv[17]	coref	22-9[156_0]
2-43	299-310	recognition	abstract[16]|abstract[17]	giv[16]|giv[17]	_	_
2-44	311-312	,	abstract[17]	giv[17]	_	_
2-45	313-320	objects	abstract[17]|abstract|abstract[19]|abstract[20]	giv[17]|new|giv[19]|giv[20]	appos|appos	2-45[20_19]|2-48[0_20]
2-46	321-330	detection	abstract[17]|abstract[19]|abstract[20]	giv[17]|giv[19]|giv[20]	_	_
2-47	331-334	and	abstract[17]|abstract[20]	giv[17]|giv[20]	_	_
2-48	335-347	segmentation	abstract[17]|abstract[20]|abstract	giv[17]|giv[20]|giv	appos	2-50[24_0]
2-49	348-350	or	abstract[17]	giv[17]	_	_
2-50	351-356	image	abstract[17]|abstract|abstract[23]|abstract[24]	giv[17]|giv|new[23]|giv[24]	coref|coref	3-10[28_24]|19-3[129_23]
2-51	357-367	resolution	abstract[17]|abstract[23]|abstract[24]	giv[17]|new[23]|giv[24]	_	_
2-52	368-379	enhancement	abstract[17]|abstract[24]	giv[17]|giv[24]	_	_
2-53	380-381	.	_	_	_	_

#Text=Another factor that steers the direction of advances in new applications is the increased capabilities of many electronic digital devices .
3-1	382-389	Another	abstract[25]	new[25]	coref	3-13[29_25]
3-2	390-396	factor	abstract[25]	new[25]	_	_
3-3	397-401	that	abstract[25]	new[25]	_	_
3-4	402-408	steers	abstract[25]	new[25]	_	_
3-5	409-412	the	abstract[25]|abstract[26]	new[25]|new[26]	_	_
3-6	413-422	direction	abstract[25]|abstract[26]	new[25]|new[26]	_	_
3-7	423-425	of	abstract[25]|abstract[26]	new[25]|new[26]	_	_
3-8	426-434	advances	abstract[25]|abstract[26]|abstract[27]	new[25]|new[26]|new[27]	_	_
3-9	435-437	in	abstract[25]|abstract[26]|abstract[27]	new[25]|new[26]|new[27]	_	_
3-10	438-441	new	abstract[25]|abstract[26]|abstract[27]|abstract[28]	new[25]|new[26]|new[27]|giv[28]	coref	5-7[43_28]
3-11	442-454	applications	abstract[25]|abstract[26]|abstract[27]|abstract[28]	new[25]|new[26]|new[27]|giv[28]	_	_
3-12	455-457	is	_	_	_	_
3-13	458-461	the	abstract[29]	giv[29]	_	_
3-14	462-471	increased	abstract[29]	giv[29]	_	_
3-15	472-484	capabilities	abstract[29]	giv[29]	_	_
3-16	485-487	of	abstract[29]	giv[29]	_	_
3-17	488-492	many	abstract[29]|object[30]	giv[29]|new[30]	coref	4-24[40_30]
3-18	493-503	electronic	abstract[29]|object[30]	giv[29]|new[30]	_	_
3-19	504-511	digital	abstract[29]|object[30]	giv[29]|new[30]	_	_
3-20	512-519	devices	abstract[29]|object[30]	giv[29]|new[30]	_	_
3-21	520-521	.	_	_	_	_

#Text=Medical diagnostics and reasoning systems also benefited from this progress , allowing for real-time vital signs analysis and tracking using standard cameras or wearable devices .
4-1	522-529	Medical	abstract[31]|abstract[32]	new[31]|new[32]	coref|coref	5-11[44_31]|5-11[45_32]
4-2	530-541	diagnostics	abstract[31]|abstract[32]	new[31]|new[32]	_	_
4-3	542-545	and	abstract[32]	new[32]	_	_
4-4	546-555	reasoning	abstract[32]|abstract	new[32]|new	_	_
4-5	556-563	systems	abstract	new	_	_
4-6	564-568	also	_	_	_	_
4-7	569-578	benefited	_	_	_	_
4-8	579-583	from	_	_	_	_
4-9	584-588	this	abstract[35]	giv[35]	_	_
4-10	589-597	progress	abstract[35]	giv[35]	_	_
4-11	598-599	,	_	_	_	_
4-12	600-608	allowing	_	_	_	_
4-13	609-612	for	_	_	_	_
4-14	613-622	real-time	abstract[37]	new[37]	coref	5-41[58_37]
4-15	623-628	vital	abstract[36]|abstract[37]	new[36]|new[37]	_	_
4-16	629-634	signs	abstract[36]|abstract[37]	new[36]|new[37]	_	_
4-17	635-643	analysis	abstract[37]	new[37]	_	_
4-18	644-647	and	_	_	_	_
4-19	648-656	tracking	abstract	new	coref	11-5[92_0]
4-20	657-662	using	_	_	_	_
4-21	663-671	standard	object[39]	new[39]	coref	6-4[60_39]
4-22	672-679	cameras	object[39]	new[39]	_	_
4-23	680-682	or	_	_	_	_
4-24	683-691	wearable	object[40]	giv[40]	_	_
4-25	692-699	devices	object[40]	giv[40]	_	_
4-26	700-701	.	_	_	_	_

#Text=The remote measurement of RR has many potential applications in medical diagnostics and screenings like monitoring of newborns or small children in incubators or hospital beds , monitoring of the severe acute respiratory syndrome ( SARS ) , support in emotion analysis , etc.
5-1	702-705	The	abstract[41]	new[41]	_	_
5-2	706-712	remote	abstract[41]	new[41]	_	_
5-3	713-724	measurement	abstract[41]	new[41]	_	_
5-4	725-727	of	abstract[41]	new[41]	_	_
5-5	728-730	RR	abstract[41]|person	new[41]|new	coref	6-14
5-6	731-734	has	_	_	_	_
5-7	735-739	many	abstract[43]	giv[43]	coref	20-10[139_43]
5-8	740-749	potential	abstract[43]	giv[43]	_	_
5-9	750-762	applications	abstract[43]	giv[43]	_	_
5-10	763-765	in	abstract[43]	giv[43]	_	_
5-11	766-773	medical	abstract[43]|abstract[44]|abstract[45]	giv[43]|giv[44]|giv[45]	_	_
5-12	774-785	diagnostics	abstract[43]|abstract[44]|abstract[45]	giv[43]|giv[44]|giv[45]	_	_
5-13	786-789	and	abstract[43]|abstract[45]	giv[43]|giv[45]	_	_
5-14	790-800	screenings	abstract[43]|abstract[45]|organization[46]	giv[43]|giv[45]|new[46]	_	_
5-15	801-805	like	abstract[43]|abstract[45]|organization[46]	giv[43]|giv[45]|new[46]	_	_
5-16	806-816	monitoring	abstract[43]|abstract[45]|organization[46]|event[47]	giv[43]|giv[45]|new[46]|new[47]	_	_
5-17	817-819	of	abstract[43]|abstract[45]|organization[46]|event[47]	giv[43]|giv[45]|new[46]|new[47]	_	_
5-18	820-828	newborns	abstract[43]|abstract[45]|organization[46]|event[47]|person	giv[43]|giv[45]|new[46]|new[47]|new	_	_
5-19	829-831	or	abstract[43]|abstract[45]|organization[46]|event[47]	giv[43]|giv[45]|new[46]|new[47]	_	_
5-20	832-837	small	abstract[43]|abstract[45]|organization[46]|event[47]|person[49]	giv[43]|giv[45]|new[46]|new[47]|new[49]	_	_
5-21	838-846	children	abstract[43]|abstract[45]|organization[46]|event[47]|person[49]	giv[43]|giv[45]|new[46]|new[47]|new[49]	_	_
5-22	847-849	in	abstract[43]|abstract[45]|organization[46]|event[47]	giv[43]|giv[45]|new[46]|new[47]	_	_
5-23	850-860	incubators	abstract[43]|abstract[45]|organization[46]|event[47]|place	giv[43]|giv[45]|new[46]|new[47]|new	_	_
5-24	861-863	or	abstract[43]|abstract[45]|organization[46]|event[47]	giv[43]|giv[45]|new[46]|new[47]	_	_
5-25	864-872	hospital	abstract[43]|abstract[45]|organization[46]|event[47]|place|place[52]	giv[43]|giv[45]|new[46]|new[47]|new|new[52]	_	_
5-26	873-877	beds	abstract[43]|abstract[45]|organization[46]|event[47]|place[52]	giv[43]|giv[45]|new[46]|new[47]|new[52]	_	_
5-27	878-879	,	abstract[43]|abstract[45]|organization[46]	giv[43]|giv[45]|new[46]	_	_
5-28	880-890	monitoring	abstract[43]|abstract[45]|organization[46]|event[53]	giv[43]|giv[45]|new[46]|new[53]	coref	18-10[122_53]
5-29	891-893	of	abstract[43]|abstract[45]|organization[46]|event[53]	giv[43]|giv[45]|new[46]|new[53]	_	_
5-30	894-897	the	abstract[43]|abstract[45]|organization[46]|event[53]|abstract[54]	giv[43]|giv[45]|new[46]|new[53]|new[54]	appos	5-36[0_54]
5-31	898-904	severe	abstract[43]|abstract[45]|organization[46]|event[53]|abstract[54]	giv[43]|giv[45]|new[46]|new[53]|new[54]	_	_
5-32	905-910	acute	abstract[43]|abstract[45]|organization[46]|event[53]|abstract[54]	giv[43]|giv[45]|new[46]|new[53]|new[54]	_	_
5-33	911-922	respiratory	abstract[43]|abstract[45]|organization[46]|event[53]|abstract[54]	giv[43]|giv[45]|new[46]|new[53]|new[54]	_	_
5-34	923-931	syndrome	abstract[43]|abstract[45]|organization[46]|event[53]|abstract[54]	giv[43]|giv[45]|new[46]|new[53]|new[54]	_	_
5-35	932-933	(	abstract[43]|abstract[45]|organization[46]	giv[43]|giv[45]|new[46]	_	_
5-36	934-938	SARS	abstract[43]|abstract[45]|organization[46]|abstract	giv[43]|giv[45]|new[46]|giv	_	_
5-37	939-940	)	abstract[43]|abstract[45]|organization[46]	giv[43]|giv[45]|new[46]	_	_
5-38	941-942	,	abstract[43]|abstract[45]|organization[46]	giv[43]|giv[45]|new[46]	_	_
5-39	943-950	support	abstract[43]|abstract[45]|organization[46]|abstract[56]	giv[43]|giv[45]|new[46]|new[56]	_	_
5-40	951-953	in	abstract[43]|abstract[45]|organization[46]|abstract[56]	giv[43]|giv[45]|new[46]|new[56]	_	_
5-41	954-961	emotion	abstract[43]|abstract[45]|organization[46]|abstract[56]|abstract|abstract[58]	giv[43]|giv[45]|new[46]|new[56]|new|giv[58]	_	_
5-42	962-970	analysis	abstract[43]|abstract[45]|organization[46]|abstract[56]|abstract[58]	giv[43]|giv[45]|new[46]|new[56]|giv[58]	_	_
5-43	971-972	,	abstract[43]|abstract[45]|organization[46]	giv[43]|giv[45]|new[46]	_	_
5-44	973-977	etc.	abstract[43]|abstract[45]|organization[46]	giv[43]|giv[45]|new[46]	_	_

#Text=The use of thermal cameras was proposed to analyze facial images and estimate RR based on a nasal heat flow and described in and other papers .
6-1	978-981	The	event[59]	new[59]	_	_
6-2	982-985	use	event[59]	new[59]	_	_
6-3	986-988	of	event[59]	new[59]	_	_
6-4	989-996	thermal	event[59]|object[60]	new[59]|giv[60]	coref	16-5[111_60]
6-5	997-1004	cameras	event[59]|object[60]	new[59]|giv[60]	_	_
6-6	1005-1008	was	_	_	_	_
6-7	1009-1017	proposed	_	_	_	_
6-8	1018-1020	to	_	_	_	_
6-9	1021-1028	analyze	_	_	_	_
6-10	1029-1035	facial	object[61]	new[61]	coref	20-4[0_61]
6-11	1036-1042	images	object[61]	new[61]	_	_
6-12	1043-1046	and	_	_	_	_
6-13	1047-1055	estimate	_	_	_	_
6-14	1056-1058	RR	person	giv	_	_
6-15	1059-1064	based	_	_	_	_
6-16	1065-1067	on	_	_	_	_
6-17	1068-1069	a	abstract[64]	new[64]	_	_
6-18	1070-1075	nasal	abstract[64]	new[64]	_	_
6-19	1076-1080	heat	abstract|abstract[64]	new|new[64]	_	_
6-20	1081-1085	flow	abstract[64]	new[64]	_	_
6-21	1086-1089	and	_	_	_	_
6-22	1090-1099	described	_	_	_	_
6-23	1100-1102	in	_	_	_	_
6-24	1103-1106	and	_	_	_	_
6-25	1107-1112	other	_	_	_	_
6-26	1113-1119	papers	abstract	new	_	_
6-27	1120-1121	.	_	_	_	_

#Text=The typical estimation of RR requires a multi step procedure .
7-1	1122-1125	The	abstract[66]	new[66]	_	_
7-2	1126-1133	typical	abstract[66]	new[66]	_	_
7-3	1134-1144	estimation	abstract[66]	new[66]	_	_
7-4	1145-1147	of	abstract[66]	new[66]	_	_
7-5	1148-1150	RR	abstract[66]|abstract	new[66]|new	_	_
7-6	1151-1159	requires	_	_	_	_
7-7	1160-1161	a	event[69]	new[69]	_	_
7-8	1162-1167	multi	event[68]|event[69]	new[68]|new[69]	coref	12-2[94_68]
7-9	1168-1172	step	event[68]|event[69]	new[68]|new[69]	_	_
7-10	1173-1182	procedure	event[69]	new[69]	_	_
7-11	1183-1184	.	_	_	_	_

#Text=First , a Region Of Interest ( ROI ) is detected for each thermal frame representing the source of thermal changes ( due to respiration ) in the area of nostrils or a mouth .
8-1	1185-1190	First	_	_	_	_
8-2	1191-1192	,	_	_	_	_
8-3	1193-1194	a	abstract[70]	new[70]	appos	8-8[0_70]
8-4	1195-1201	Region	abstract[70]	new[70]	_	_
8-5	1202-1204	Of	abstract[70]	new[70]	_	_
8-6	1205-1213	Interest	abstract[70]	new[70]	_	_
8-7	1214-1215	(	_	_	_	_
8-8	1216-1219	ROI	abstract	giv	coref	9-1[79_0]
8-9	1220-1221	)	_	_	_	_
8-10	1222-1224	is	_	_	_	_
8-11	1225-1233	detected	_	_	_	_
8-12	1234-1237	for	_	_	_	_
8-13	1238-1242	each	abstract[72]	new[72]	coref	9-14[80_72]
8-14	1243-1250	thermal	abstract[72]	new[72]	_	_
8-15	1251-1256	frame	abstract[72]	new[72]	_	_
8-16	1257-1269	representing	abstract[72]	new[72]	_	_
8-17	1270-1273	the	abstract[72]|abstract[73]	new[72]|new[73]	_	_
8-18	1274-1280	source	abstract[72]|abstract[73]	new[72]|new[73]	_	_
8-19	1281-1283	of	abstract[72]|abstract[73]	new[72]|new[73]	_	_
8-20	1284-1291	thermal	abstract[72]|abstract[73]|abstract[74]	new[72]|new[73]|new[74]	coref	10-22[89_74]
8-21	1292-1299	changes	abstract[72]|abstract[73]|abstract[74]	new[72]|new[73]|new[74]	_	_
8-22	1300-1301	(	abstract[72]|abstract[73]|abstract[74]	new[72]|new[73]|new[74]	_	_
8-23	1302-1305	due	abstract[72]|abstract[73]|abstract[74]	new[72]|new[73]|new[74]	_	_
8-24	1306-1308	to	abstract[72]|abstract[73]|abstract[74]	new[72]|new[73]|new[74]	_	_
8-25	1309-1320	respiration	abstract[72]|abstract[73]|abstract[74]|abstract	new[72]|new[73]|new[74]|new	_	_
8-26	1321-1322	)	abstract[72]|abstract[73]|abstract[74]	new[72]|new[73]|new[74]	_	_
8-27	1323-1325	in	abstract[72]|abstract[73]|abstract[74]	new[72]|new[73]|new[74]	_	_
8-28	1326-1329	the	abstract[72]|abstract[73]|abstract[74]|place[76]	new[72]|new[73]|new[74]|new[76]	_	_
8-29	1330-1334	area	abstract[72]|abstract[73]|abstract[74]|place[76]	new[72]|new[73]|new[74]|new[76]	_	_
8-30	1335-1337	of	abstract[72]|abstract[73]|abstract[74]|place[76]	new[72]|new[73]|new[74]|new[76]	_	_
8-31	1338-1346	nostrils	abstract[72]|abstract[73]|abstract[74]|place[76]|object	new[72]|new[73]|new[74]|new[76]|new	_	_
8-32	1347-1349	or	abstract[72]|abstract[73]|abstract[74]|place[76]	new[72]|new[73]|new[74]|new[76]	_	_
8-33	1350-1351	a	abstract[72]|abstract[73]|abstract[74]|place[76]|object[78]	new[72]|new[73]|new[74]|new[76]|new[78]	_	_
8-34	1352-1357	mouth	abstract[72]|abstract[73]|abstract[74]|place[76]|object[78]	new[72]|new[73]|new[74]|new[76]|new[78]	_	_
8-35	1358-1359	.	_	_	_	_

#Text=The ROI can be specified manually or can be automatically detected ( in a frame or for each frame ) and tracked ( between frames ) .
9-1	1360-1363	The	abstract[79]	giv[79]	coref	11-5[0_79]
9-2	1364-1367	ROI	abstract[79]	giv[79]	_	_
9-3	1368-1371	can	_	_	_	_
9-4	1372-1374	be	_	_	_	_
9-5	1375-1384	specified	_	_	_	_
9-6	1385-1393	manually	_	_	_	_
9-7	1394-1396	or	_	_	_	_
9-8	1397-1400	can	_	_	_	_
9-9	1401-1403	be	_	_	_	_
9-10	1404-1417	automatically	_	_	_	_
9-11	1418-1426	detected	_	_	_	_
9-12	1427-1428	(	_	_	_	_
9-13	1429-1431	in	_	_	_	_
9-14	1432-1433	a	abstract[80]	giv[80]	coref	9-18[81_80]
9-15	1434-1439	frame	abstract[80]	giv[80]	_	_
9-16	1440-1442	or	_	_	_	_
9-17	1443-1446	for	_	_	_	_
9-18	1447-1451	each	abstract[81]	giv[81]	_	_
9-19	1452-1457	frame	abstract[81]	giv[81]	_	_
9-20	1458-1459	)	_	_	_	_
9-21	1460-1463	and	_	_	_	_
9-22	1464-1471	tracked	_	_	_	_
9-23	1472-1473	(	_	_	_	_
9-24	1474-1481	between	_	_	_	_
9-25	1482-1488	frames	abstract	new	_	_
9-26	1489-1490	)	_	_	_	_
9-27	1491-1492	.	_	_	_	_

#Text=In , the authors described a particle filter tracker driven by a probabilistic template function that was capable of adapting to abrupt positional and physiological changes .
10-1	1493-1495	In	_	_	_	_
10-2	1496-1497	,	_	_	_	_
10-3	1498-1501	the	person[83]	new[83]	coref	11-1[90_83]
10-4	1502-1509	authors	person[83]	new[83]	_	_
10-5	1510-1519	described	_	_	_	_
10-6	1520-1521	a	person[86]	new[86]	_	_
10-7	1522-1530	particle	abstract|object[85]|person[86]	new|new[85]|new[86]	_	_
10-8	1531-1537	filter	object[85]|person[86]	new[85]|new[86]	_	_
10-9	1538-1545	tracker	person[86]	new[86]	_	_
10-10	1546-1552	driven	person[86]	new[86]	_	_
10-11	1553-1555	by	person[86]	new[86]	_	_
10-12	1556-1557	a	person[86]|abstract[88]	new[86]|new[88]	_	_
10-13	1558-1571	probabilistic	person[86]|abstract[88]	new[86]|new[88]	_	_
10-14	1572-1580	template	person[86]|abstract|abstract[88]	new[86]|new|new[88]	_	_
10-15	1581-1589	function	person[86]|abstract[88]	new[86]|new[88]	_	_
10-16	1590-1594	that	person[86]|abstract[88]	new[86]|new[88]	_	_
10-17	1595-1598	was	person[86]|abstract[88]	new[86]|new[88]	_	_
10-18	1599-1606	capable	person[86]|abstract[88]	new[86]|new[88]	_	_
10-19	1607-1609	of	_	_	_	_
10-20	1610-1618	adapting	_	_	_	_
10-21	1619-1621	to	_	_	_	_
10-22	1622-1628	abrupt	abstract[89]	giv[89]	coref	13-10[101_89]
10-23	1629-1639	positional	abstract[89]	giv[89]	_	_
10-24	1640-1643	and	abstract[89]	giv[89]	_	_
10-25	1644-1657	physiological	abstract[89]	giv[89]	_	_
10-26	1658-1665	changes	abstract[89]	giv[89]	_	_
10-27	1666-1667	.	_	_	_	_

#Text=Other authors also proposed ROI tracking methods ( e.g. , ) .
11-1	1668-1673	Other	person[90]	giv[90]	_	_
11-2	1674-1681	authors	person[90]	giv[90]	_	_
11-3	1682-1686	also	_	_	_	_
11-4	1687-1695	proposed	_	_	_	_
11-5	1696-1699	ROI	abstract|abstract[92]|abstract[93]	giv|giv[92]|giv[93]	coref|coref	12-13[96_0]|21-1[144_93]
11-6	1700-1708	tracking	abstract[92]|abstract[93]	giv[92]|giv[93]	_	_
11-7	1709-1716	methods	abstract[93]	giv[93]	_	_
11-8	1717-1718	(	abstract[93]	giv[93]	_	_
11-9	1719-1723	e.g.	abstract[93]	giv[93]	_	_
11-10	1724-1725	,	_	_	_	_
11-11	1726-1727	)	_	_	_	_
11-12	1728-1729	.	_	_	_	_

#Text=In the next step , a single value is calculated to represent each ROI .
12-1	1730-1732	In	_	_	_	_
12-2	1733-1736	the	event[94]	giv[94]	_	_
12-3	1737-1741	next	event[94]	giv[94]	_	_
12-4	1742-1746	step	event[94]	giv[94]	_	_
12-5	1747-1748	,	_	_	_	_
12-6	1749-1750	a	abstract[95]	new[95]	_	_
12-7	1751-1757	single	abstract[95]	new[95]	_	_
12-8	1758-1763	value	abstract[95]	new[95]	_	_
12-9	1764-1766	is	_	_	_	_
12-10	1767-1777	calculated	_	_	_	_
12-11	1778-1780	to	_	_	_	_
12-12	1781-1790	represent	_	_	_	_
12-13	1791-1795	each	abstract[96]	giv[96]	coref	20-17[142_96]
12-14	1796-1799	ROI	abstract[96]	giv[96]	_	_
12-15	1800-1801	.	_	_	_	_

#Text=A collection of such values forms a signal representing local temperature changes in time .
13-1	1802-1803	A	abstract[97]	new[97]	_	_
13-2	1804-1814	collection	abstract[97]	new[97]	_	_
13-3	1815-1817	of	abstract[97]	new[97]	_	_
13-4	1818-1822	such	abstract[97]|abstract[98]	new[97]|new[98]	_	_
13-5	1823-1829	values	abstract[97]|abstract[98]	new[97]|new[98]	_	_
13-6	1830-1835	forms	_	_	_	_
13-7	1836-1837	a	abstract[99]	new[99]	coref	14-3[102_99]
13-8	1838-1844	signal	abstract[99]	new[99]	_	_
13-9	1845-1857	representing	abstract[99]	new[99]	_	_
13-10	1858-1863	local	abstract[99]|abstract[101]	new[99]|giv[101]	coref	14-18[106_101]
13-11	1864-1875	temperature	abstract[99]|abstract|abstract[101]	new[99]|new|giv[101]	_	_
13-12	1876-1883	changes	abstract[99]|abstract[101]	new[99]|giv[101]	_	_
13-13	1884-1886	in	abstract[99]|abstract[101]	new[99]|giv[101]	_	_
13-14	1887-1891	time	abstract[99]|abstract[101]	new[99]|giv[101]	_	_
13-15	1892-1893	.	_	_	_	_

#Text=Finally , a signal is filtered ( e.g. removing high frequency components ) and a frequency for dominated changes is calculated .
14-1	1894-1901	Finally	_	_	_	_
14-2	1902-1903	,	_	_	_	_
14-3	1904-1905	a	abstract[102]	giv[102]	ana	15-1[0_102]
14-4	1906-1912	signal	abstract[102]	giv[102]	_	_
14-5	1913-1915	is	_	_	_	_
14-6	1916-1924	filtered	_	_	_	_
14-7	1925-1926	(	_	_	_	_
14-8	1927-1931	e.g.	_	_	_	_
14-9	1932-1940	removing	_	_	_	_
14-10	1941-1945	high	place[103]|abstract[104]	new[103]|new[104]	coref	14-15[105_103]
14-11	1946-1955	frequency	place[103]|abstract[104]	new[103]|new[104]	_	_
14-12	1956-1966	components	abstract[104]	new[104]	_	_
14-13	1967-1968	)	_	_	_	_
14-14	1969-1972	and	_	_	_	_
14-15	1973-1974	a	place[105]	giv[105]	coref	15-6[108_105]
14-16	1975-1984	frequency	place[105]	giv[105]	_	_
14-17	1985-1988	for	place[105]	giv[105]	_	_
14-18	1989-1998	dominated	place[105]|abstract[106]	giv[105]|giv[106]	coref	20-20[143_106]
14-19	1999-2006	changes	place[105]|abstract[106]	giv[105]|giv[106]	_	_
14-20	2007-2009	is	_	_	_	_
14-21	2010-2020	calculated	_	_	_	_
14-22	2021-2022	.	_	_	_	_

#Text=It is assumed , that this frequency represents the respiratory rate .
15-1	2023-2025	It	abstract	giv	_	_
15-2	2026-2028	is	_	_	_	_
15-3	2029-2036	assumed	_	_	_	_
15-4	2037-2038	,	_	_	_	_
15-5	2039-2043	that	_	_	_	_
15-6	2044-2048	this	place[108]	giv[108]	coref	23-9[0_108]
15-7	2049-2058	frequency	place[108]	giv[108]	_	_
15-8	2059-2069	represents	_	_	_	_
15-9	2070-2073	the	abstract[109]	new[109]	coref	24-5[170_109]
15-10	2074-2085	respiratory	abstract[109]	new[109]	_	_
15-11	2086-2090	rate	abstract[109]	new[109]	_	_
15-12	2091-2092	.	_	_	_	_

#Text=In recent years , new portable and cost-effective thermal cameras have been available .
16-1	2093-2095	In	_	_	_	_
16-2	2096-2102	recent	time[110]	new[110]	_	_
16-3	2103-2108	years	time[110]	new[110]	_	_
16-4	2109-2110	,	_	_	_	_
16-5	2111-2114	new	object[111]	giv[111]	coref	17-4[115_111]
16-6	2115-2123	portable	object[111]	giv[111]	_	_
16-7	2124-2127	and	object[111]	giv[111]	_	_
16-8	2128-2142	cost-effective	object[111]	giv[111]	_	_
16-9	2143-2150	thermal	object[111]	giv[111]	_	_
16-10	2151-2158	cameras	object[111]	giv[111]	_	_
16-11	2159-2163	have	_	_	_	_
16-12	2164-2168	been	_	_	_	_
16-13	2169-2178	available	_	_	_	_
16-14	2179-2180	.	_	_	_	_

#Text=For example , FLIR® Lepton family cameras are very small ( e.g. , 10.5 × 11.7 × 6.4 mm , with an internal shutter ) and cost less that 200USD .
17-1	2181-2184	For	_	_	_	_
17-2	2185-2192	example	_	_	_	_
17-3	2193-2194	,	_	_	_	_
17-4	2195-2200	FLIR®	abstract|abstract[114]|object[115]	new|new[114]|giv[115]	coref	19-7[130_115]
17-5	2201-2207	Lepton	person|abstract[114]|object[115]	new|new[114]|giv[115]	_	_
17-6	2208-2214	family	abstract[114]|object[115]	new[114]|giv[115]	_	_
17-7	2215-2222	cameras	object[115]	giv[115]	_	_
17-8	2223-2226	are	_	_	_	_
17-9	2227-2231	very	_	_	_	_
17-10	2232-2237	small	_	_	_	_
17-11	2238-2239	(	_	_	_	_
17-12	2240-2244	e.g.	person[117]	new[117]	_	_
17-13	2245-2246	,	person[117]	new[117]	_	_
17-14	2247-2251	10.5	person[117]	new[117]	_	_
17-15	2252-2253	×	person[117]	new[117]	_	_
17-16	2254-2258	11.7	abstract|person[117]	new|new[117]	_	_
17-17	2259-2260	×	person[117]	new[117]	_	_
17-18	2261-2264	6.4	person[117]	new[117]	_	_
17-19	2265-2267	mm	person[117]	new[117]	_	_
17-20	2268-2269	,	person[117]	new[117]	_	_
17-21	2270-2274	with	person[117]	new[117]	_	_
17-22	2275-2277	an	person[117]|object[118]	new[117]|new[118]	_	_
17-23	2278-2286	internal	person[117]|object[118]	new[117]|new[118]	_	_
17-24	2287-2294	shutter	person[117]|object[118]	new[117]|new[118]	_	_
17-25	2295-2296	)	_	_	_	_
17-26	2297-2300	and	_	_	_	_
17-27	2301-2305	cost	_	_	_	_
17-28	2306-2310	less	_	_	_	_
17-29	2311-2315	that	_	_	_	_
17-30	2316-2322	200USD	abstract	new	_	_
17-31	2323-2324	.	_	_	_	_

#Text=These features allow to think about wide application of thermal monitoring , e.g. , to support remote diagnosis of elderly people at home ( e.g. , during a video talk or as a self-diagnostics ) .
18-1	2325-2330	These	abstract[120]	new[120]	coref	20-12[140_120]
18-2	2331-2339	features	abstract[120]	new[120]	_	_
18-3	2340-2345	allow	_	_	_	_
18-4	2346-2348	to	_	_	_	_
18-5	2349-2354	think	_	_	_	_
18-6	2355-2360	about	_	_	_	_
18-7	2361-2365	wide	abstract[121]	new[121]	_	_
18-8	2366-2377	application	abstract[121]	new[121]	_	_
18-9	2378-2380	of	abstract[121]	new[121]	_	_
18-10	2381-2388	thermal	abstract[121]|event[122]	new[121]|giv[122]	_	_
18-11	2389-2399	monitoring	abstract[121]|event[122]	new[121]|giv[122]	_	_
18-12	2400-2401	,	_	_	_	_
18-13	2402-2406	e.g.	_	_	_	_
18-14	2407-2408	,	_	_	_	_
18-15	2409-2411	to	_	_	_	_
18-16	2412-2419	support	_	_	_	_
18-17	2420-2426	remote	event[123]	new[123]	_	_
18-18	2427-2436	diagnosis	event[123]	new[123]	_	_
18-19	2437-2439	of	event[123]	new[123]	_	_
18-20	2440-2447	elderly	event[123]|person[124]	new[123]|new[124]	_	_
18-21	2448-2454	people	event[123]|person[124]	new[123]|new[124]	_	_
18-22	2455-2457	at	event[123]|person[124]	new[123]|new[124]	_	_
18-23	2458-2462	home	event[123]|person[124]|place	new[123]|new[124]|new	_	_
18-24	2463-2464	(	_	_	_	_
18-25	2465-2469	e.g.	event[127]	new[127]	_	_
18-26	2470-2471	,	event[127]	new[127]	_	_
18-27	2472-2478	during	event[127]	new[127]	_	_
18-28	2479-2480	a	event[127]	new[127]	_	_
18-29	2481-2486	video	abstract|event[127]	new|new[127]	coref	26-12[177_0]
18-30	2487-2491	talk	event[127]	new[127]	_	_
18-31	2492-2494	or	_	_	_	_
18-32	2495-2497	as	_	_	_	_
18-33	2498-2499	a	abstract[128]	new[128]	_	_
18-34	2500-2516	self-diagnostics	abstract[128]	new[128]	_	_
18-35	2517-2518	)	_	_	_	_
18-36	2519-2520	.	_	_	_	_

#Text=However , a spatial resolution of these small thermal cameras is as low as 80 × 60 or 160 × 120 .
19-1	2521-2528	However	_	_	_	_
19-2	2529-2530	,	_	_	_	_
19-3	2531-2532	a	abstract[129]	giv[129]	_	_
19-4	2533-2540	spatial	abstract[129]	giv[129]	_	_
19-5	2541-2551	resolution	abstract[129]	giv[129]	_	_
19-6	2552-2554	of	abstract[129]	giv[129]	_	_
19-7	2555-2560	these	abstract[129]|object[130]	giv[129]|giv[130]	_	_
19-8	2561-2566	small	abstract[129]|object[130]	giv[129]|giv[130]	_	_
19-9	2567-2574	thermal	abstract[129]|object[130]	giv[129]|giv[130]	_	_
19-10	2575-2582	cameras	abstract[129]|object[130]	giv[129]|giv[130]	_	_
19-11	2583-2585	is	_	_	_	_
19-12	2586-2588	as	_	_	_	_
19-13	2589-2592	low	_	_	_	_
19-14	2593-2595	as	_	_	_	_
19-15	2596-2598	80	abstract[131]	new[131]	_	_
19-16	2599-2600	×	abstract[131]	new[131]	_	_
19-17	2601-2603	60	abstract[131]|abstract	new[131]|new	_	_
19-18	2604-2606	or	_	_	_	_
19-19	2607-2610	160	abstract[133]	new[133]	_	_
19-20	2611-2612	×	abstract[133]	new[133]	_	_
19-21	2613-2616	120	abstract[133]|abstract	new[133]|new	_	_
19-22	2617-2618	.	_	_	_	_

#Text=Small resolution of images could be a problem for detection of facial features or detection of a ROI representing respiration-related temperature changes .
20-1	2619-2624	Small	abstract[135]	new[135]	coref	20-7[137_135]
20-2	2625-2635	resolution	abstract[135]	new[135]	_	_
20-3	2636-2638	of	abstract[135]	new[135]	_	_
20-4	2639-2645	images	abstract[135]|object	new[135]|giv	coref	21-17[150_0]
20-5	2646-2651	could	_	_	_	_
20-6	2652-2654	be	_	_	_	_
20-7	2655-2656	a	abstract[137]	giv[137]	coref	21-17[149_137]
20-8	2657-2664	problem	abstract[137]	giv[137]	_	_
20-9	2665-2668	for	abstract[137]	giv[137]	_	_
20-10	2669-2678	detection	abstract[137]|event[138]|abstract[139]	giv[137]|new[138]|giv[139]	_	_
20-11	2679-2681	of	abstract[137]|event[138]|abstract[139]	giv[137]|new[138]|giv[139]	_	_
20-12	2682-2688	facial	abstract[137]|event[138]|abstract[139]|abstract[140]	giv[137]|new[138]|giv[139]|giv[140]	_	_
20-13	2689-2697	features	abstract[137]|event[138]|abstract[139]|abstract[140]	giv[137]|new[138]|giv[139]|giv[140]	_	_
20-14	2698-2700	or	abstract[137]|abstract[139]	giv[137]|giv[139]	_	_
20-15	2701-2710	detection	abstract[137]|abstract[139]|event[141]	giv[137]|giv[139]|new[141]	_	_
20-16	2711-2713	of	abstract[137]|abstract[139]|event[141]	giv[137]|giv[139]|new[141]	_	_
20-17	2714-2715	a	abstract[137]|abstract[139]|event[141]|abstract[142]	giv[137]|giv[139]|new[141]|giv[142]	_	_
20-18	2716-2719	ROI	abstract[137]|abstract[139]|event[141]|abstract[142]	giv[137]|giv[139]|new[141]|giv[142]	_	_
20-19	2720-2732	representing	abstract[137]|abstract[139]|event[141]|abstract[142]	giv[137]|giv[139]|new[141]|giv[142]	_	_
20-20	2733-2752	respiration-related	abstract[137]|abstract[139]|event[141]|abstract[142]|abstract[143]	giv[137]|giv[139]|new[141]|giv[142]|giv[143]	coref	21-27[151_143]
20-21	2753-2764	temperature	abstract[137]|abstract[139]|event[141]|abstract[142]|abstract[143]	giv[137]|giv[139]|new[141]|giv[142]|giv[143]	_	_
20-22	2765-2772	changes	abstract[137]|abstract[139]|event[141]|abstract[142]|abstract[143]	giv[137]|giv[139]|new[141]|giv[142]|giv[143]	_	_
20-23	2773-2774	.	_	_	_	_

#Text=Different methods have been proposed in ( a visible light spectrum ) computer vision to improve low resolution images or to detect ( and amplify ) small , local changes in videos .
21-1	2775-2784	Different	abstract[144]	giv[144]	_	_
21-2	2785-2792	methods	abstract[144]	giv[144]	_	_
21-3	2793-2797	have	_	_	_	_
21-4	2798-2802	been	_	_	_	_
21-5	2803-2811	proposed	_	_	_	_
21-6	2812-2814	in	_	_	_	_
21-7	2815-2816	(	abstract[148]	new[148]	_	_
21-8	2817-2818	a	abstract[146]|abstract[148]	new[146]|new[148]	coref	23-7[167_146]
21-9	2819-2826	visible	abstract[145]|abstract[146]|abstract[148]	new[145]|new[146]|new[148]	coref	29-22[190_145]
21-10	2827-2832	light	abstract[145]|abstract[146]|abstract[148]	new[145]|new[146]|new[148]	_	_
21-11	2833-2841	spectrum	abstract[146]|abstract[148]	new[146]|new[148]	_	_
21-12	2842-2843	)	abstract[148]	new[148]	_	_
21-13	2844-2852	computer	object|abstract[148]	new|new[148]	_	_
21-14	2853-2859	vision	abstract[148]	new[148]	_	_
21-15	2860-2862	to	_	_	_	_
21-16	2863-2870	improve	_	_	_	_
21-17	2871-2874	low	abstract[149]|object[150]	giv[149]|giv[150]	coref|coref	28-8[184_149]|29-16[191_150]
21-18	2875-2885	resolution	abstract[149]|object[150]	giv[149]|giv[150]	_	_
21-19	2886-2892	images	object[150]	giv[150]	_	_
21-20	2893-2895	or	_	_	_	_
21-21	2896-2898	to	_	_	_	_
21-22	2899-2905	detect	_	_	_	_
21-23	2906-2907	(	_	_	_	_
21-24	2908-2911	and	_	_	_	_
21-25	2912-2919	amplify	_	_	_	_
21-26	2920-2921	)	_	_	_	_
21-27	2922-2927	small	abstract[151]	giv[151]	_	_
21-28	2928-2929	,	abstract[151]	giv[151]	_	_
21-29	2930-2935	local	abstract[151]	giv[151]	_	_
21-30	2936-2943	changes	abstract[151]	giv[151]	_	_
21-31	2944-2946	in	abstract[151]	giv[151]	_	_
21-32	2947-2953	videos	abstract[151]|abstract	giv[151]|new	coref	22-6[155_0]
21-33	2954-2955	.	_	_	_	_

#Text=Subtle intensity variations introduced in thermal videos of a face due to respiratory activities can be enhanced using Eulerian Video Magnification ( EVM ) or related algorithms .
22-1	2956-2962	Subtle	abstract[154]	new[154]	_	_
22-2	2963-2972	intensity	abstract|abstract[154]	new|new[154]	coref	23-4
22-3	2973-2983	variations	abstract[154]	new[154]	_	_
22-4	2984-2994	introduced	abstract[154]	new[154]	_	_
22-5	2995-2997	in	abstract[154]	new[154]	_	_
22-6	2998-3005	thermal	abstract[154]|abstract[155]	new[154]|giv[155]	_	_
22-7	3006-3012	videos	abstract[154]|abstract[155]	new[154]|giv[155]	_	_
22-8	3013-3015	of	abstract[154]|abstract[155]	new[154]|giv[155]	_	_
22-9	3016-3017	a	abstract[154]|abstract[155]|object[156]	new[154]|giv[155]|giv[156]	_	_
22-10	3018-3022	face	abstract[154]|abstract[155]|object[156]	new[154]|giv[155]|giv[156]	_	_
22-11	3023-3026	due	abstract[154]	new[154]	_	_
22-12	3027-3029	to	abstract[154]	new[154]	_	_
22-13	3030-3041	respiratory	abstract[154]|event[157]	new[154]|new[157]	_	_
22-14	3042-3052	activities	abstract[154]|event[157]	new[154]|new[157]	_	_
22-15	3053-3056	can	_	_	_	_
22-16	3057-3059	be	_	_	_	_
22-17	3060-3068	enhanced	_	_	_	_
22-18	3069-3074	using	_	_	_	_
22-19	3075-3083	Eulerian	abstract|abstract[160]	new|new[160]	appos	22-23[0_160]
22-20	3084-3089	Video	person|abstract[160]	new|new[160]	_	_
22-21	3090-3103	Magnification	abstract[160]	new[160]	_	_
22-22	3104-3105	(	_	_	_	_
22-23	3106-3109	EVM	abstract	giv	coref	27-2
22-24	3110-3111	)	_	_	_	_
22-25	3112-3114	or	_	_	_	_
22-26	3115-3122	related	abstract[162]	giv[162]	coref	28-3[183_162]
22-27	3123-3133	algorithms	abstract[162]	giv[162]	_	_
22-28	3134-3135	.	_	_	_	_

#Text=This technique amplifies intensity differences within a particular frequency spectrum .
23-1	3136-3140	This	abstract[163]	new[163]	_	_
23-2	3141-3150	technique	abstract[163]	new[163]	_	_
23-3	3151-3160	amplifies	_	_	_	_
23-4	3161-3170	intensity	abstract|abstract[165]	giv|new[165]	_	_
23-5	3171-3182	differences	abstract[165]	new[165]	_	_
23-6	3183-3189	within	abstract[165]	new[165]	_	_
23-7	3190-3191	a	abstract[165]|abstract[167]	new[165]|giv[167]	ana	24-1[0_167]
23-8	3192-3202	particular	abstract[165]|abstract[167]	new[165]|giv[167]	_	_
23-9	3203-3212	frequency	abstract[165]|place|abstract[167]	new[165]|giv|giv[167]	_	_
23-10	3213-3221	spectrum	abstract[165]|abstract[167]	new[165]|giv[167]	_	_
23-11	3222-3223	.	_	_	_	_

#Text=This works well if the estimate respiratory rate ( frequency ) is known .
24-1	3224-3228	This	abstract	giv	_	_
24-2	3229-3234	works	_	_	_	_
24-3	3235-3239	well	_	_	_	_
24-4	3240-3242	if	_	_	_	_
24-5	3243-3246	the	abstract[170]	giv[170]	appos	24-10[0_170]
24-6	3247-3255	estimate	abstract|abstract[170]	new|giv[170]	_	_
24-7	3256-3267	respiratory	abstract[170]	giv[170]	_	_
24-8	3268-3272	rate	abstract[170]	giv[170]	_	_
24-9	3273-3274	(	_	_	_	_
24-10	3275-3284	frequency	abstract	giv	_	_
24-11	3285-3286	)	_	_	_	_
24-12	3287-3289	is	_	_	_	_
24-13	3290-3295	known	_	_	_	_
24-14	3296-3297	.	_	_	_	_

#Text=Otherwise , noise and motion artefacts are highly amplified .
25-1	3298-3307	Otherwise	_	_	_	_
25-2	3308-3309	,	_	_	_	_
25-3	3310-3315	noise	abstract	new	_	_
25-4	3316-3319	and	_	_	_	_
25-5	3320-3326	motion	abstract|abstract[174]	new|new[174]	_	_
25-6	3327-3336	artefacts	abstract[174]	new[174]	_	_
25-7	3337-3340	are	_	_	_	_
25-8	3341-3347	highly	_	_	_	_
25-9	3348-3357	amplified	_	_	_	_
25-10	3358-3359	.	_	_	_	_

#Text=Therefore , some researchers propose to magnify only selected segments within a video .
26-1	3360-3369	Therefore	_	_	_	_
26-2	3370-3371	,	_	_	_	_
26-3	3372-3376	some	person[175]	new[175]	_	_
26-4	3377-3388	researchers	person[175]	new[175]	_	_
26-5	3389-3396	propose	_	_	_	_
26-6	3397-3399	to	_	_	_	_
26-7	3400-3407	magnify	_	_	_	_
26-8	3408-3412	only	abstract[176]	new[176]	_	_
26-9	3413-3421	selected	abstract[176]	new[176]	_	_
26-10	3422-3430	segments	abstract[176]	new[176]	_	_
26-11	3431-3437	within	abstract[176]	new[176]	_	_
26-12	3438-3439	a	abstract[176]|abstract[177]	new[176]|giv[177]	_	_
26-13	3440-3445	video	abstract[176]|abstract[177]	new[176]|giv[177]	_	_
26-14	3446-3447	.	_	_	_	_

#Text=The EVM algorithm has been already successfully used for enhancing vital sign signals .
27-1	3448-3451	The	abstract[179]	new[179]	_	_
27-2	3452-3455	EVM	abstract|abstract[179]	giv|new[179]	_	_
27-3	3456-3465	algorithm	abstract[179]	new[179]	_	_
27-4	3466-3469	has	_	_	_	_
27-5	3470-3474	been	_	_	_	_
27-6	3475-3482	already	_	_	_	_
27-7	3483-3495	successfully	_	_	_	_
27-8	3496-3500	used	_	_	_	_
27-9	3501-3504	for	_	_	_	_
27-10	3505-3514	enhancing	_	_	_	_
27-11	3515-3520	vital	abstract[180]|abstract[181]	new[180]|new[181]	_	_
27-12	3521-3525	sign	abstract[180]|abstract[181]	new[180]|new[181]	_	_
27-13	3526-3533	signals	abstract[181]	new[181]	_	_
27-14	3534-3535	.	_	_	_	_

#Text=Recently , many different deep-learning algorithms for super resolution have been proposed .
28-1	3536-3544	Recently	_	_	_	_
28-2	3545-3546	,	_	_	_	_
28-3	3547-3551	many	abstract[183]	giv[183]	coref	29-6[186_183]
28-4	3552-3561	different	abstract[183]	giv[183]	_	_
28-5	3562-3575	deep-learning	abstract|abstract[183]	new|giv[183]	_	_
28-6	3576-3586	algorithms	abstract[183]	giv[183]	_	_
28-7	3587-3590	for	abstract[183]	giv[183]	_	_
28-8	3591-3596	super	abstract[183]|abstract[184]	giv[183]|giv[184]	ana	29-1[0_184]
28-9	3597-3607	resolution	abstract[183]|abstract[184]	giv[183]|giv[184]	_	_
28-10	3608-3612	have	_	_	_	_
28-11	3613-3617	been	_	_	_	_
28-12	3618-3626	proposed	_	_	_	_
28-13	3627-3628	.	_	_	_	_

#Text=It has been proved that such algorithms can efficiently improve the presentation of details in the processed low-resolution ( LR ) visible light images .
29-1	3629-3631	It	abstract	giv	coref	33-12[219_0]
29-2	3632-3635	has	_	_	_	_
29-3	3636-3640	been	_	_	_	_
29-4	3641-3647	proved	_	_	_	_
29-5	3648-3652	that	_	_	_	_
29-6	3653-3657	such	abstract[186]	giv[186]	coref	35-10[242_186]
29-7	3658-3668	algorithms	abstract[186]	giv[186]	_	_
29-8	3669-3672	can	_	_	_	_
29-9	3673-3684	efficiently	_	_	_	_
29-10	3685-3692	improve	_	_	_	_
29-11	3693-3696	the	abstract[187]	new[187]	_	_
29-12	3697-3709	presentation	abstract[187]	new[187]	_	_
29-13	3710-3712	of	abstract[187]	new[187]	_	_
29-14	3713-3720	details	abstract[187]|abstract	new[187]|new	_	_
29-15	3721-3723	in	abstract[187]	new[187]	_	_
29-16	3724-3727	the	abstract[187]|object[191]	new[187]|giv[191]	_	_
29-17	3728-3737	processed	abstract[187]|object[191]	new[187]|giv[191]	_	_
29-18	3738-3752	low-resolution	abstract[187]|object[191]	new[187]|giv[191]	_	_
29-19	3753-3754	(	abstract[187]|object[191]	new[187]|giv[191]	_	_
29-20	3755-3757	LR	abstract[187]|abstract|object[191]	new[187]|new|giv[191]	coref	33-8
29-21	3758-3759	)	abstract[187]|object[191]	new[187]|giv[191]	_	_
29-22	3760-3767	visible	abstract[187]|abstract[190]|object[191]	new[187]|giv[190]|giv[191]	_	_
29-23	3768-3773	light	abstract[187]|abstract[190]|object[191]	new[187]|giv[190]|giv[191]	_	_
29-24	3774-3780	images	abstract[187]|object[191]	new[187]|giv[191]	_	_
29-25	3781-3782	.	_	_	_	_

#Text=One of the first method in this area was SRCNN , which implemented a single Convolutional Neural Network ( CNN ) achieving the state-of-the-art restoration quality .
30-1	3783-3786	One	organization[192]	new[192]	coref	30-10[195_192]
30-2	3787-3789	of	organization[192]	new[192]	_	_
30-3	3790-3793	the	organization[192]|abstract[193]	new[192]|new[193]	_	_
30-4	3794-3799	first	organization[192]|abstract[193]	new[192]|new[193]	_	_
30-5	3800-3806	method	organization[192]|abstract[193]	new[192]|new[193]	_	_
30-6	3807-3809	in	organization[192]|abstract[193]	new[192]|new[193]	_	_
30-7	3810-3814	this	organization[192]|abstract[193]|place[194]	new[192]|new[193]|new[194]	_	_
30-8	3815-3819	area	organization[192]|abstract[193]|place[194]	new[192]|new[193]|new[194]	_	_
30-9	3820-3823	was	_	_	_	_
30-10	3824-3829	SRCNN	organization[195]	giv[195]	_	_
30-11	3830-3831	,	organization[195]	giv[195]	_	_
30-12	3832-3837	which	organization[195]	giv[195]	_	_
30-13	3838-3849	implemented	organization[195]	giv[195]	_	_
30-14	3850-3851	a	organization[195]|abstract[198]	giv[195]|new[198]	coref	32-10[211_198]
30-15	3852-3858	single	organization[195]|abstract[198]	giv[195]|new[198]	_	_
30-16	3859-3872	Convolutional	organization[195]|person|abstract[198]	giv[195]|new|new[198]	coref	32-10
30-17	3873-3879	Neural	organization[195]|abstract|abstract[198]	giv[195]|new|new[198]	coref	31-5
30-18	3880-3887	Network	organization[195]|abstract[198]	giv[195]|new[198]	_	_
30-19	3888-3889	(	_	_	_	_
30-20	3890-3893	CNN	organization	new	_	_
30-21	3894-3895	)	_	_	_	_
30-22	3896-3905	achieving	_	_	_	_
30-23	3906-3909	the	abstract[201]	new[201]	coref	31-18[207_201]
30-24	3910-3926	state-of-the-art	abstract[201]	new[201]	_	_
30-25	3927-3938	restoration	abstract|abstract[201]	new|new[201]	coref	31-19
30-26	3939-3946	quality	abstract[201]	new[201]	_	_
30-27	3947-3948	.	_	_	_	_

#Text=Later , different Deep Neural Networks ( DNNs ) based solutions have been introduced to further improve the restoration quality ( or perception ) .
31-1	3949-3954	Later	_	_	_	_
31-2	3955-3956	,	_	_	_	_
31-3	3957-3966	different	place[203]	new[203]	_	_
31-4	3967-3971	Deep	place[203]	new[203]	_	_
31-5	3972-3978	Neural	abstract|place[203]	giv|new[203]	_	_
31-6	3979-3987	Networks	place[203]	new[203]	_	_
31-7	3988-3989	(	_	_	_	_
31-8	3990-3994	DNNs	abstract	new	_	_
31-9	3995-3996	)	_	_	_	_
31-10	3997-4002	based	abstract[205]	new[205]	_	_
31-11	4003-4012	solutions	abstract[205]	new[205]	_	_
31-12	4013-4017	have	_	_	_	_
31-13	4018-4022	been	_	_	_	_
31-14	4023-4033	introduced	_	_	_	_
31-15	4034-4036	to	_	_	_	_
31-16	4037-4044	further	_	_	_	_
31-17	4045-4052	improve	_	_	_	_
31-18	4053-4056	the	abstract[207]	giv[207]	_	_
31-19	4057-4068	restoration	abstract|abstract[207]	giv|giv[207]	_	_
31-20	4069-4076	quality	abstract[207]	giv[207]	_	_
31-21	4077-4078	(	_	_	_	_
31-22	4079-4081	or	_	_	_	_
31-23	4082-4092	perception	abstract	new	_	_
31-24	4093-4094	)	_	_	_	_
31-25	4095-4096	.	_	_	_	_

#Text=In Kim et al. introduced a novel Deeply Recursive Convolutional Network ( DRCN ) model .
32-1	4097-4099	In	_	_	_	_
32-2	4100-4103	Kim	_	_	_	_
32-3	4104-4106	et	_	_	_	_
32-4	4107-4110	al.	person	new	_	_
32-5	4111-4121	introduced	_	_	_	_
32-6	4122-4123	a	abstract[213]	new[213]	ana	33-1[0_213]
32-7	4124-4129	novel	abstract[213]	new[213]	_	_
32-8	4130-4136	Deeply	abstract[213]	new[213]	_	_
32-9	4137-4146	Recursive	abstract[213]	new[213]	_	_
32-10	4147-4160	Convolutional	person|abstract[211]|abstract[213]	giv|giv[211]|new[213]	appos	32-13[0_211]
32-11	4161-4168	Network	abstract[211]|abstract[213]	giv[211]|new[213]	_	_
32-12	4169-4170	(	abstract[213]	new[213]	_	_
32-13	4171-4175	DRCN	abstract|abstract[213]	giv|new[213]	_	_
32-14	4176-4177	)	abstract[213]	new[213]	_	_
32-15	4178-4183	model	abstract[213]	new[213]	_	_
32-16	4184-4185	.	_	_	_	_

#Text=It utilizes a skip connection correlating a LR input with a high resolution ( HR ) reference data and uses recursive supervision to minimize the exploding/vanishing gradients problem .
33-1	4186-4188	It	abstract	giv	_	_
33-2	4189-4197	utilizes	_	_	_	_
33-3	4198-4199	a	abstract[216]	new[216]	_	_
33-4	4200-4204	skip	abstract|abstract[216]	new|new[216]	_	_
33-5	4205-4215	connection	abstract[216]	new[216]	_	_
33-6	4216-4227	correlating	abstract[216]	new[216]	_	_
33-7	4228-4229	a	abstract[216]|abstract[218]	new[216]|new[218]	_	_
33-8	4230-4232	LR	abstract[216]|abstract|abstract[218]	new[216]|giv|new[218]	_	_
33-9	4233-4238	input	abstract[216]|abstract[218]	new[216]|new[218]	_	_
33-10	4239-4243	with	abstract[216]	new[216]	_	_
33-11	4244-4245	a	abstract[216]|abstract[222]	new[216]|new[222]	_	_
33-12	4246-4250	high	abstract[216]|abstract[219]|abstract[222]	new[216]|giv[219]|new[222]	appos	33-15[0_219]
33-13	4251-4261	resolution	abstract[216]|abstract[219]|abstract[222]	new[216]|giv[219]|new[222]	_	_
33-14	4262-4263	(	abstract[216]|abstract[222]	new[216]|new[222]	_	_
33-15	4264-4266	HR	abstract[216]|abstract|abstract[222]	new[216]|giv|new[222]	coref	33-25[225_0]
33-16	4267-4268	)	abstract[216]|abstract[222]	new[216]|new[222]	_	_
33-17	4269-4278	reference	abstract[216]|abstract|abstract[222]	new[216]|new|new[222]	_	_
33-18	4279-4283	data	abstract[216]|abstract[222]	new[216]|new[222]	_	_
33-19	4284-4287	and	_	_	_	_
33-20	4288-4292	uses	_	_	_	_
33-21	4293-4302	recursive	abstract[223]	new[223]	_	_
33-22	4303-4314	supervision	abstract[223]	new[223]	_	_
33-23	4315-4317	to	_	_	_	_
33-24	4318-4326	minimize	_	_	_	_
33-25	4327-4330	the	abstract[225]	giv[225]	_	_
33-26	4331-4350	exploding/vanishing	abstract[224]|abstract[225]	new[224]|giv[225]	_	_
33-27	4351-4360	gradients	abstract[224]|abstract[225]	new[224]|giv[225]	_	_
33-28	4361-4368	problem	abstract[225]	giv[225]	_	_
33-29	4369-4370	.	_	_	_	_

#Text=Other improvements to SR include the application of residual mappings and gradient clipping ( Deeply Recursive Residual Network ( DRRN ) ) , the use of attention networks , the application of multi-scale residual hierarchical networks , etc.
34-1	4371-4376	Other	abstract[226]	new[226]	_	_
34-2	4377-4389	improvements	abstract[226]	new[226]	_	_
34-3	4390-4392	to	abstract[226]	new[226]	_	_
34-4	4393-4395	SR	abstract[226]|person	new[226]|new	coref	35-10
34-5	4396-4403	include	_	_	_	_
34-6	4404-4407	the	abstract[228]	new[228]	_	_
34-7	4408-4419	application	abstract[228]	new[228]	_	_
34-8	4420-4422	of	abstract[228]	new[228]	_	_
34-9	4423-4431	residual	abstract[228]|abstract[229]	new[228]|new[229]	_	_
34-10	4432-4440	mappings	abstract[228]|abstract[229]	new[228]|new[229]	_	_
34-11	4441-4444	and	abstract[228]	new[228]	_	_
34-12	4445-4453	gradient	abstract[228]|substance|object[231]	new[228]|new|new[231]	_	_
34-13	4454-4462	clipping	abstract[228]|object[231]	new[228]|new[231]	_	_
34-14	4463-4464	(	abstract[228]	new[228]	_	_
34-15	4465-4471	Deeply	abstract[228]|substance[232]	new[228]|new[232]	_	_
34-16	4472-4481	Recursive	abstract[228]|substance[232]	new[228]|new[232]	_	_
34-17	4482-4490	Residual	abstract[228]|person	new[228]|new	_	_
34-18	4491-4498	Network	abstract[228]	new[228]	_	_
34-19	4499-4500	(	abstract[228]	new[228]	_	_
34-20	4501-4505	DRRN	abstract[228]|abstract	new[228]|new	_	_
34-21	4506-4507	)	abstract[228]	new[228]	_	_
34-22	4508-4509	)	abstract[228]	new[228]	_	_
34-23	4510-4511	,	abstract[228]	new[228]	_	_
34-24	4512-4515	the	abstract[228]|abstract[235]	new[228]|new[235]	_	_
34-25	4516-4519	use	abstract[228]|abstract[235]	new[228]|new[235]	_	_
34-26	4520-4522	of	abstract[228]|abstract[235]	new[228]|new[235]	_	_
34-27	4523-4532	attention	abstract[228]|abstract[235]|abstract|abstract[237]	new[228]|new[235]|new|new[237]	coref	34-33[239_237]
34-28	4533-4541	networks	abstract[228]|abstract[235]|abstract[237]	new[228]|new[235]|new[237]	_	_
34-29	4542-4543	,	abstract[228]	new[228]	_	_
34-30	4544-4547	the	abstract[228]|abstract[238]	new[228]|new[238]	_	_
34-31	4548-4559	application	abstract[228]|abstract[238]	new[228]|new[238]	_	_
34-32	4560-4562	of	abstract[228]|abstract[238]	new[228]|new[238]	_	_
34-33	4563-4574	multi-scale	abstract[228]|abstract[238]|abstract[239]	new[228]|new[238]|giv[239]	coref	35-14[243_239]
34-34	4575-4583	residual	abstract[228]|abstract[238]|abstract[239]	new[228]|new[238]|giv[239]	_	_
34-35	4584-4596	hierarchical	abstract[228]|abstract[238]|abstract[239]	new[228]|new[238]|giv[239]	_	_
34-36	4597-4605	networks	abstract[228]|abstract[238]|abstract[239]	new[228]|new[238]|giv[239]	_	_
34-37	4606-4607	,	abstract[228]	new[228]	_	_
34-38	4608-4612	etc.	abstract[228]	new[228]	_	_

#Text=The very good results have also been obtained using SR algorithms based on generative networks .
35-1	4613-4616	The	abstract[240]	new[240]	_	_
35-2	4617-4621	very	abstract[240]	new[240]	_	_
35-3	4622-4626	good	abstract[240]	new[240]	_	_
35-4	4627-4634	results	abstract[240]	new[240]	_	_
35-5	4635-4639	have	_	_	_	_
35-6	4640-4644	also	_	_	_	_
35-7	4645-4649	been	_	_	_	_
35-8	4650-4658	obtained	_	_	_	_
35-9	4659-4664	using	_	_	_	_
35-10	4665-4667	SR	person|abstract[242]	giv|giv[242]	_	_
35-11	4668-4678	algorithms	abstract[242]	giv[242]	_	_
35-12	4679-4684	based	abstract[242]	giv[242]	_	_
35-13	4685-4687	on	abstract[242]	giv[242]	_	_
35-14	4688-4698	generative	abstract[242]|abstract[243]	giv[242]|giv[243]	_	_
35-15	4699-4707	networks	abstract[242]|abstract[243]	giv[242]|giv[243]	_	_
35-16	4708-4709	.	_	_	_	_
