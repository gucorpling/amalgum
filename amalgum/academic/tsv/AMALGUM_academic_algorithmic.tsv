#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=5. Ethical Concerns from Algorithmic Decision-Making in AVs
1-1	0-2	5.	_	_	_	_
1-2	3-10	Ethical	abstract[1]	new[1]	_	_
1-3	11-19	Concerns	abstract[1]	new[1]	_	_
1-4	20-24	from	abstract[1]	new[1]	_	_
1-5	25-36	Algorithmic	abstract[1]|abstract[2]	new[1]|new[2]	coref	2-8[7_2]
1-6	37-52	Decision-Making	abstract[1]|abstract[2]	new[1]|new[2]	_	_
1-7	53-55	in	abstract[1]|abstract[2]	new[1]|new[2]	_	_
1-8	56-59	AVs	abstract[1]|abstract[2]|abstract	new[1]|new[2]|new	coref	2-11

#Text=This Section explores ethical issues associated with algorithmic decision-making in AVs , their implications for AV safety risks and discrimination and the steps taken to tackle these issues .
2-1	60-64	This	abstract[4]	new[4]	coref	3-1[18_4]
2-2	65-72	Section	abstract[4]	new[4]	_	_
2-3	73-81	explores	_	_	_	_
2-4	82-89	ethical	abstract[5]|abstract[6]	new[5]|new[6]	ana|coref	2-13[0_6]|2-27[17_5]
2-5	90-96	issues	abstract[5]|abstract[6]	new[5]|new[6]	_	_
2-6	97-107	associated	abstract[5]|abstract[6]	new[5]|new[6]	_	_
2-7	108-112	with	abstract[5]|abstract[6]	new[5]|new[6]	_	_
2-8	113-124	algorithmic	abstract[5]|abstract[6]|abstract[7]	new[5]|new[6]|giv[7]	coref	4-11[33_7]
2-9	125-140	decision-making	abstract[5]|abstract[6]|abstract[7]	new[5]|new[6]|giv[7]	_	_
2-10	141-143	in	abstract[5]|abstract[6]|abstract[7]	new[5]|new[6]|giv[7]	_	_
2-11	144-147	AVs	abstract[5]|abstract[6]|abstract[7]|abstract	new[5]|new[6]|giv[7]|giv	coref	3-9[21_0]
2-12	148-149	,	abstract[6]	new[6]	_	_
2-13	150-155	their	abstract[6]|abstract|abstract[10]	new[6]|giv|new[10]	coref	4-17[35_10]
2-14	156-168	implications	abstract[6]|abstract[10]	new[6]|new[10]	_	_
2-15	169-172	for	abstract[6]|abstract[10]	new[6]|new[10]	_	_
2-16	173-175	AV	abstract[6]|abstract[10]|abstract|abstract[13]|abstract[14]	new[6]|new[10]|new|new[13]|new[14]	coref|coref|coref	3-19[25_13]|4-11|5-23[49_14]
2-17	176-182	safety	abstract[6]|abstract[10]|abstract|abstract[13]|abstract[14]	new[6]|new[10]|new|new[13]|new[14]	coref	3-20
2-18	183-188	risks	abstract[6]|abstract[10]|abstract[13]|abstract[14]	new[6]|new[10]|new[13]|new[14]	_	_
2-19	189-192	and	abstract[6]|abstract[10]|abstract[14]	new[6]|new[10]|new[14]	_	_
2-20	193-207	discrimination	abstract[6]|abstract[10]|abstract[14]|abstract	new[6]|new[10]|new[14]|new	coref	3-15
2-21	208-211	and	abstract[6]	new[6]	_	_
2-22	212-215	the	abstract[6]|abstract[16]	new[6]|new[16]	_	_
2-23	216-221	steps	abstract[6]|abstract[16]	new[6]|new[16]	_	_
2-24	222-227	taken	abstract[6]|abstract[16]	new[6]|new[16]	_	_
2-25	228-230	to	abstract[6]|abstract[16]	new[6]|new[16]	_	_
2-26	231-237	tackle	abstract[6]|abstract[16]	new[6]|new[16]	_	_
2-27	238-243	these	abstract[6]|abstract[16]|abstract[17]	new[6]|new[16]|giv[17]	_	_
2-28	244-250	issues	abstract[6]|abstract[16]|abstract[17]	new[6]|new[16]|giv[17]	_	_
2-29	251-252	.	_	_	_	_

#Text=Section 5.1 discusses the sources of bias in AVs ’ algorithms that can yield discrimination by disproportionately allocating more safety risks to some groups of individuals .
3-1	253-260	Section	abstract[18]	giv[18]	coref	4-3[28_18]
3-2	261-264	5.1	abstract[18]	giv[18]	_	_
3-3	265-274	discusses	_	_	_	_
3-4	275-278	the	abstract[19]	new[19]	_	_
3-5	279-286	sources	abstract[19]	new[19]	_	_
3-6	287-289	of	abstract[19]	new[19]	_	_
3-7	290-294	bias	abstract[19]|abstract[20]	new[19]|new[20]	coref	9-1[0_20]
3-8	295-297	in	abstract[19]|abstract[20]	new[19]|new[20]	_	_
3-9	298-301	AVs	abstract[19]|abstract[20]|abstract[21]|abstract[22]	new[19]|new[20]|giv[21]|new[22]	coref|coref	4-11[32_22]|9-6[0_21]
3-10	302-303	’	abstract[19]|abstract[20]|abstract[21]|abstract[22]	new[19]|new[20]|giv[21]|new[22]	_	_
3-11	304-314	algorithms	abstract[19]|abstract[20]|abstract[22]	new[19]|new[20]|new[22]	_	_
3-12	315-319	that	abstract[19]|abstract[20]	new[19]|new[20]	_	_
3-13	320-323	can	abstract[19]|abstract[20]	new[19]|new[20]	_	_
3-14	324-329	yield	abstract[19]|abstract[20]	new[19]|new[20]	_	_
3-15	330-344	discrimination	abstract[19]|abstract[20]|abstract	new[19]|new[20]|giv	coref	4-23
3-16	345-347	by	_	_	_	_
3-17	348-366	disproportionately	_	_	_	_
3-18	367-377	allocating	_	_	_	_
3-19	378-382	more	abstract[25]	giv[25]	coref	5-23[48_25]
3-20	383-389	safety	abstract|abstract[25]	giv|giv[25]	coref	4-20[37_0]
3-21	390-395	risks	abstract[25]	giv[25]	_	_
3-22	396-398	to	_	_	_	_
3-23	399-403	some	person[26]	new[26]	_	_
3-24	404-410	groups	person[26]	new[26]	_	_
3-25	411-413	of	person[26]	new[26]	_	_
3-26	414-425	individuals	person[26]|person	new[26]|new	coref	7-21[55_0]
3-27	426-427	.	_	_	_	_

#Text=Next , Section 5.2 explores approaches to incorporate ethics into AV algorithms ’ decision-making and highlight their implications for AV safety and discrimination .
4-1	428-432	Next	_	_	_	_
4-2	433-434	,	_	_	_	_
4-3	435-442	Section	abstract[28]	giv[28]	coref	5-3[39_28]
4-4	443-446	5.2	abstract[28]	giv[28]	_	_
4-5	447-455	explores	_	_	_	_
4-6	456-466	approaches	abstract[29]	new[29]	ana	4-17[0_29]
4-7	467-469	to	abstract[29]	new[29]	_	_
4-8	470-481	incorporate	abstract[29]	new[29]	_	_
4-9	482-488	ethics	abstract[29]|abstract	new[29]|new	_	_
4-10	489-493	into	abstract[29]	new[29]	_	_
4-11	494-496	AV	abstract[29]|abstract|abstract[32]|abstract[33]	new[29]|giv|giv[32]|giv[33]	coref|coref	4-20|5-13[44_32]
4-12	497-507	algorithms	abstract[29]|abstract[32]|abstract[33]	new[29]|giv[32]|giv[33]	_	_
4-13	508-509	’	abstract[29]|abstract[33]	new[29]|giv[33]	_	_
4-14	510-525	decision-making	abstract[29]|abstract[33]	new[29]|giv[33]	_	_
4-15	526-529	and	abstract[29]	new[29]	_	_
4-16	530-539	highlight	abstract[29]	new[29]	_	_
4-17	540-545	their	abstract[29]|abstract|abstract[35]	new[29]|giv|giv[35]	coref	16-18[145_35]
4-18	546-558	implications	abstract[29]|abstract[35]	new[29]|giv[35]	_	_
4-19	559-562	for	abstract[29]|abstract[35]	new[29]|giv[35]	_	_
4-20	563-565	AV	abstract[29]|abstract[35]|abstract|abstract[37]	new[29]|giv[35]|giv|giv[37]	coref|coref	5-10|5-24[0_37]
4-21	566-572	safety	abstract[29]|abstract[35]|abstract[37]	new[29]|giv[35]|giv[37]	_	_
4-22	573-576	and	abstract[29]|abstract[35]	new[29]|giv[35]	_	_
4-23	577-591	discrimination	abstract[29]|abstract[35]|abstract	new[29]|giv[35]|giv	coref	5-27
4-24	592-593	.	_	_	_	_

#Text=Lastly , Section 5.3 examines how the incentives of AV stakeholders shape AV algorithms ’ design and resulting decisions that can introduce new safety risks and discrimination .
5-1	594-600	Lastly	_	_	_	_
5-2	601-602	,	_	_	_	_
5-3	603-610	Section	abstract[39]	giv[39]	coref	16-1[139_39]
5-4	611-614	5.3	abstract[39]	giv[39]	_	_
5-5	615-623	examines	_	_	_	_
5-6	624-627	how	_	_	_	_
5-7	628-631	the	abstract[40]	new[40]	coref	16-33[151_40]
5-8	632-642	incentives	abstract[40]	new[40]	_	_
5-9	643-645	of	abstract[40]	new[40]	_	_
5-10	646-648	AV	abstract[40]|abstract|person[42]	new[40]|giv|new[42]	coref|coref	5-13|15-45[138_42]
5-11	649-661	stakeholders	abstract[40]|person[42]	new[40]|new[42]	_	_
5-12	662-667	shape	_	_	_	_
5-13	668-670	AV	abstract|abstract[44]|abstract[45]	giv|giv[44]|new[45]	coref|coref	11-5[86_0]|14-24[112_44]
5-14	671-681	algorithms	abstract[44]|abstract[45]	giv[44]|new[45]	_	_
5-15	682-683	’	abstract[44]|abstract[45]	giv[44]|new[45]	_	_
5-16	684-690	design	abstract[45]	new[45]	_	_
5-17	691-694	and	_	_	_	_
5-18	695-704	resulting	abstract[46]	new[46]	coref	23-7[0_46]
5-19	705-714	decisions	abstract[46]	new[46]	_	_
5-20	715-719	that	abstract[46]	new[46]	_	_
5-21	720-723	can	abstract[46]	new[46]	_	_
5-22	724-733	introduce	abstract[46]	new[46]	_	_
5-23	734-737	new	abstract[46]|abstract[48]|abstract[49]	new[46]|giv[48]|giv[49]	coref	9-35[81_48]
5-24	738-744	safety	abstract[46]|abstract|abstract[48]|abstract[49]	new[46]|giv|giv[48]|giv[49]	coref	9-35
5-25	745-750	risks	abstract[46]|abstract[48]|abstract[49]	new[46]|giv[48]|giv[49]	_	_
5-26	751-754	and	abstract[46]|abstract[49]	new[46]|giv[49]	_	_
5-27	755-769	discrimination	abstract[46]|abstract[49]|abstract	new[46]|giv[49]|giv	coref	8-6
5-28	770-771	.	_	_	_	_

#Text=5.1. Bias
6-1	772-776	5.1.	_	_	_	_
6-2	777-781	Bias	person	new	_	_

#Text=A system is considered biased when it contains “ intended ” or “ unintended ” characteristics that unfairly discriminate against certain individuals or groups of individuals in society .
7-1	782-783	A	abstract[52]	new[52]	ana	7-7[0_52]
7-2	784-790	system	abstract[52]	new[52]	_	_
7-3	791-793	is	_	_	_	_
7-4	794-804	considered	_	_	_	_
7-5	805-811	biased	_	_	_	_
7-6	812-816	when	_	_	_	_
7-7	817-819	it	abstract	giv	coref	20-23[202_0]
7-8	820-828	contains	_	_	_	_
7-9	829-830	“	abstract[54]	new[54]	coref	14-1[106_54]
7-10	831-839	intended	abstract[54]	new[54]	_	_
7-11	840-841	”	abstract[54]	new[54]	_	_
7-12	842-844	or	abstract[54]	new[54]	_	_
7-13	845-846	“	abstract[54]	new[54]	_	_
7-14	847-857	unintended	abstract[54]	new[54]	_	_
7-15	858-859	”	abstract[54]	new[54]	_	_
7-16	860-875	characteristics	abstract[54]	new[54]	_	_
7-17	876-880	that	abstract[54]	new[54]	_	_
7-18	881-889	unfairly	abstract[54]	new[54]	_	_
7-19	890-902	discriminate	abstract[54]	new[54]	_	_
7-20	903-910	against	abstract[54]	new[54]	_	_
7-21	911-918	certain	abstract[54]|person[55]|person[56]	new[54]|giv[55]|giv[56]	coref|coref	7-21[56_55]|7-26[0_56]
7-22	919-930	individuals	abstract[54]|person[55]|person[56]	new[54]|giv[55]|giv[56]	_	_
7-23	931-933	or	abstract[54]|person[56]	new[54]|giv[56]	_	_
7-24	934-940	groups	abstract[54]|person[56]|person[57]	new[54]|giv[56]|new[57]	coref	8-30[67_57]
7-25	941-943	of	abstract[54]|person[56]|person[57]	new[54]|giv[56]|new[57]	_	_
7-26	944-955	individuals	abstract[54]|person[56]|person[57]|person	new[54]|giv[56]|new[57]|giv	coref	14-59[121_0]
7-27	956-958	in	abstract[54]|person[56]|person[57]	new[54]|giv[56]|new[57]	_	_
7-28	959-966	society	abstract[54]|person[56]|person[57]|abstract	new[54]|giv[56]|new[57]|new	_	_
7-29	967-968	.	_	_	_	_

#Text=In American anti-discrimination law , discrimination exists when there is disparate treatment , which is the “ discriminatory intent or the formal application of different rules to people of different groups ” , and/or disparate impact , which is the result that “ differ for different groups ” .
8-1	969-971	In	_	_	_	_
8-2	972-980	American	abstract[60]	new[60]	_	_
8-3	981-1000	anti-discrimination	abstract[60]	new[60]	_	_
8-4	1001-1004	law	abstract[60]	new[60]	_	_
8-5	1005-1006	,	_	_	_	_
8-6	1007-1021	discrimination	abstract	giv	coref	18-59
8-7	1022-1028	exists	_	_	_	_
8-8	1029-1033	when	_	_	_	_
8-9	1034-1039	there	_	_	_	_
8-10	1040-1042	is	_	_	_	_
8-11	1043-1052	disparate	abstract[62]	new[62]	_	_
8-12	1053-1062	treatment	abstract[62]	new[62]	_	_
8-13	1063-1064	,	abstract[62]	new[62]	_	_
8-14	1065-1070	which	abstract[62]|abstract[63]	new[62]|new[63]	coref	24-53[244_63]
8-15	1071-1073	is	abstract[62]|abstract[63]	new[62]|new[63]	_	_
8-16	1074-1077	the	abstract[62]|abstract[63]	new[62]|new[63]	_	_
8-17	1078-1079	“	abstract[62]|abstract[63]	new[62]|new[63]	_	_
8-18	1080-1094	discriminatory	abstract[62]|abstract[63]	new[62]|new[63]	_	_
8-19	1095-1101	intent	abstract[62]|abstract[63]	new[62]|new[63]	_	_
8-20	1102-1104	or	abstract[62]	new[62]	_	_
8-21	1105-1108	the	abstract[62]|event[64]	new[62]|new[64]	_	_
8-22	1109-1115	formal	abstract[62]|event[64]	new[62]|new[64]	_	_
8-23	1116-1127	application	abstract[62]|event[64]	new[62]|new[64]	_	_
8-24	1128-1130	of	abstract[62]|event[64]	new[62]|new[64]	_	_
8-25	1131-1140	different	abstract[62]|event[64]|abstract[65]	new[62]|new[64]|new[65]	_	_
8-26	1141-1146	rules	abstract[62]|event[64]|abstract[65]	new[62]|new[64]|new[65]	_	_
8-27	1147-1149	to	abstract[62]|event[64]	new[62]|new[64]	_	_
8-28	1150-1156	people	abstract[62]|event[64]|person[66]	new[62]|new[64]|new[66]	coref	26-9[0_66]
8-29	1157-1159	of	abstract[62]|event[64]|person[66]	new[62]|new[64]|new[66]	_	_
8-30	1160-1169	different	abstract[62]|event[64]|person[66]|person[67]	new[62]|new[64]|new[66]|giv[67]	coref	8-46[70_67]
8-31	1170-1176	groups	abstract[62]|event[64]|person[66]|person[67]	new[62]|new[64]|new[66]|giv[67]	_	_
8-32	1177-1178	”	abstract[62]	new[62]	_	_
8-33	1179-1180	,	_	_	_	_
8-34	1181-1187	and/or	_	_	_	_
8-35	1188-1197	disparate	abstract[68]	new[68]	_	_
8-36	1198-1204	impact	abstract[68]	new[68]	_	_
8-37	1205-1206	,	abstract[68]	new[68]	_	_
8-38	1207-1212	which	abstract[68]|abstract[69]	new[68]|new[69]	_	_
8-39	1213-1215	is	abstract[68]|abstract[69]	new[68]|new[69]	_	_
8-40	1216-1219	the	abstract[68]|abstract[69]	new[68]|new[69]	_	_
8-41	1220-1226	result	abstract[68]|abstract[69]	new[68]|new[69]	_	_
8-42	1227-1231	that	abstract[68]|abstract[69]	new[68]|new[69]	_	_
8-43	1232-1233	“	abstract[68]|abstract[69]	new[68]|new[69]	_	_
8-44	1234-1240	differ	abstract[68]|abstract[69]	new[68]|new[69]	_	_
8-45	1241-1244	for	abstract[68]|abstract[69]	new[68]|new[69]	_	_
8-46	1245-1254	different	abstract[68]|abstract[69]|person[70]	new[68]|new[69]|giv[70]	coref	12-8[97_70]
8-47	1255-1261	groups	abstract[68]|abstract[69]|person[70]	new[68]|new[69]|giv[70]	_	_
8-48	1262-1263	”	abstract[68]|abstract[69]	new[68]|new[69]	_	_
8-49	1264-1265	.	_	_	_	_

#Text=Bias can be introduced into AVs during the human designers ’ construction of the datasets , models , and the parameters of the algorithm , which potentially leads to unfair or discriminatory allocations of safety risks .
9-1	1266-1270	Bias	abstract	giv	coref	10-3[82_0]
9-2	1271-1274	can	_	_	_	_
9-3	1275-1277	be	_	_	_	_
9-4	1278-1288	introduced	_	_	_	_
9-5	1289-1293	into	_	_	_	_
9-6	1294-1297	AVs	abstract	giv	coref	14-25[111_0]
9-7	1298-1304	during	_	_	_	_
9-8	1305-1308	the	place[74]	new[74]	_	_
9-9	1309-1314	human	person[73]|place[74]	new[73]|new[74]	coref	15-12[126_73]
9-10	1315-1324	designers	person[73]|place[74]	new[73]|new[74]	_	_
9-11	1325-1326	’	person[73]|place[74]	new[73]|new[74]	_	_
9-12	1327-1339	construction	place[74]	new[74]	_	_
9-13	1340-1342	of	place[74]	new[74]	_	_
9-14	1343-1346	the	place[74]|abstract[75]	new[74]|new[75]	_	_
9-15	1347-1355	datasets	place[74]|abstract[75]	new[74]|new[75]	_	_
9-16	1356-1357	,	place[74]	new[74]	_	_
9-17	1358-1364	models	place[74]|abstract	new[74]|new	_	_
9-18	1365-1366	,	place[74]	new[74]	_	_
9-19	1367-1370	and	place[74]	new[74]	_	_
9-20	1371-1374	the	place[74]|abstract[77]	new[74]|new[77]	_	_
9-21	1375-1385	parameters	place[74]|abstract[77]	new[74]|new[77]	_	_
9-22	1386-1388	of	place[74]|abstract[77]	new[74]|new[77]	_	_
9-23	1389-1392	the	place[74]|abstract[77]|abstract[78]	new[74]|new[77]|new[78]	coref	13-3[101_78]
9-24	1393-1402	algorithm	place[74]|abstract[77]|abstract[78]	new[74]|new[77]|new[78]	_	_
9-25	1403-1404	,	place[74]	new[74]	_	_
9-26	1405-1410	which	place[74]	new[74]	_	_
9-27	1411-1422	potentially	place[74]	new[74]	_	_
9-28	1423-1428	leads	place[74]	new[74]	_	_
9-29	1429-1431	to	place[74]	new[74]	_	_
9-30	1432-1438	unfair	place[74]|abstract[79]	new[74]|new[79]	_	_
9-31	1439-1441	or	place[74]|abstract[79]	new[74]|new[79]	_	_
9-32	1442-1456	discriminatory	place[74]|abstract[79]	new[74]|new[79]	_	_
9-33	1457-1468	allocations	place[74]|abstract[79]	new[74]|new[79]	_	_
9-34	1469-1471	of	place[74]|abstract[79]	new[74]|new[79]	_	_
9-35	1472-1478	safety	place[74]|abstract[79]|abstract|abstract[81]	new[74]|new[79]|giv|giv[81]	coref|coref	14-39[115_0]|14-52[120_81]
9-36	1479-1484	risks	place[74]|abstract[79]|abstract[81]	new[74]|new[79]|giv[81]	_	_
9-37	1485-1486	.	_	_	_	_

#Text=Firstly , statistical bias exists when the input data are not statistically representative of the overall population .
10-1	1487-1494	Firstly	_	_	_	_
10-2	1495-1496	,	_	_	_	_
10-3	1497-1508	statistical	abstract[82]	giv[82]	coref	15-4[0_82]
10-4	1509-1513	bias	abstract[82]	giv[82]	_	_
10-5	1514-1520	exists	_	_	_	_
10-6	1521-1525	when	_	_	_	_
10-7	1526-1529	the	abstract[84]	new[84]	coref	11-8[87_84]
10-8	1530-1535	input	abstract|abstract[84]	new|new[84]	coref	13-18
10-9	1536-1540	data	abstract[84]	new[84]	_	_
10-10	1541-1544	are	_	_	_	_
10-11	1545-1548	not	_	_	_	_
10-12	1549-1562	statistically	_	_	_	_
10-13	1563-1577	representative	_	_	_	_
10-14	1578-1580	of	_	_	_	_
10-15	1581-1584	the	person[85]	new[85]	coref	14-7[107_85]
10-16	1585-1592	overall	person[85]	new[85]	_	_
10-17	1593-1603	population	person[85]	new[85]	_	_
10-18	1604-1605	.	_	_	_	_

#Text=For instance , training an AV using data from only one country could result in the AV learning localised patterns and not accurately modelling driving behaviours that apply in other countries or contexts .
11-1	1606-1609	For	_	_	_	_
11-2	1610-1618	instance	_	_	_	_
11-3	1619-1620	,	_	_	_	_
11-4	1621-1629	training	_	_	_	_
11-5	1630-1632	an	abstract[86]	giv[86]	coref	11-16[89_86]
11-6	1633-1635	AV	abstract[86]	giv[86]	_	_
11-7	1636-1641	using	_	_	_	_
11-8	1642-1646	data	abstract[87]	giv[87]	coref	12-11[98_87]
11-9	1647-1651	from	abstract[87]	giv[87]	_	_
11-10	1652-1656	only	abstract[87]|place[88]	giv[87]|new[88]	_	_
11-11	1657-1660	one	abstract[87]|place[88]	giv[87]|new[88]	_	_
11-12	1661-1668	country	abstract[87]|place[88]	giv[87]|new[88]	_	_
11-13	1669-1674	could	_	_	_	_
11-14	1675-1681	result	_	_	_	_
11-15	1682-1684	in	_	_	_	_
11-16	1685-1688	the	abstract[89]	giv[89]	coref	15-15[0_89]
11-17	1689-1691	AV	abstract[89]	giv[89]	_	_
11-18	1692-1700	learning	_	_	_	_
11-19	1701-1710	localised	abstract[90]	new[90]	_	_
11-20	1711-1719	patterns	abstract[90]	new[90]	_	_
11-21	1720-1723	and	_	_	_	_
11-22	1724-1727	not	_	_	_	_
11-23	1728-1738	accurately	_	_	_	_
11-24	1739-1748	modelling	_	_	_	_
11-25	1749-1756	driving	person|abstract[92]	new|new[92]	coref	26-35
11-26	1757-1767	behaviours	abstract[92]	new[92]	_	_
11-27	1768-1772	that	abstract[92]	new[92]	_	_
11-28	1773-1778	apply	abstract[92]	new[92]	_	_
11-29	1779-1781	in	abstract[92]	new[92]	_	_
11-30	1782-1787	other	abstract[92]|place[93]	new[92]|new[93]	_	_
11-31	1788-1797	countries	abstract[92]|place[93]	new[92]|new[93]	_	_
11-32	1798-1800	or	abstract[92]	new[92]	_	_
11-33	1801-1809	contexts	abstract[92]|abstract	new[92]|new	_	_
11-34	1810-1811	.	_	_	_	_

#Text=Thus , the under- or overrepresentation of certain groups in the data can lead to inaccurate classifications and biased outcomes .
12-1	1812-1816	Thus	_	_	_	_
12-2	1817-1818	,	_	_	_	_
12-3	1819-1822	the	abstract[95]	new[95]	_	_
12-4	1823-1829	under-	abstract[95]	new[95]	_	_
12-5	1830-1832	or	_	_	_	_
12-6	1833-1851	overrepresentation	abstract[96]	new[96]	_	_
12-7	1852-1854	of	abstract[96]	new[96]	_	_
12-8	1855-1862	certain	abstract[96]|person[97]	new[96]|giv[97]	coref	18-32[168_97]
12-9	1863-1869	groups	abstract[96]|person[97]	new[96]|giv[97]	_	_
12-10	1870-1872	in	abstract[96]|person[97]	new[96]|giv[97]	_	_
12-11	1873-1876	the	abstract[96]|person[97]|abstract[98]	new[96]|giv[97]|giv[98]	coref	18-45[171_98]
12-12	1877-1881	data	abstract[96]|person[97]|abstract[98]	new[96]|giv[97]|giv[98]	_	_
12-13	1882-1885	can	_	_	_	_
12-14	1886-1890	lead	_	_	_	_
12-15	1891-1893	to	_	_	_	_
12-16	1894-1904	inaccurate	abstract[99]	new[99]	_	_
12-17	1905-1920	classifications	abstract[99]	new[99]	_	_
12-18	1921-1924	and	_	_	_	_
12-19	1925-1931	biased	abstract[100]	new[100]	coref	17-10[158_100]
12-20	1932-1940	outcomes	abstract[100]	new[100]	_	_
12-21	1941-1942	.	_	_	_	_

#Text=Secondly , the algorithm can be biased relative to legal and moral standards if it utilises sensitive input variables .
13-1	1943-1951	Secondly	_	_	_	_
13-2	1952-1953	,	_	_	_	_
13-3	1954-1957	the	abstract[101]	giv[101]	ana	13-15[0_101]
13-4	1958-1967	algorithm	abstract[101]	giv[101]	_	_
13-5	1968-1971	can	_	_	_	_
13-6	1972-1974	be	_	_	_	_
13-7	1975-1981	biased	_	_	_	_
13-8	1982-1990	relative	_	_	_	_
13-9	1991-1993	to	_	_	_	_
13-10	1994-1999	legal	abstract[102]	new[102]	coref	19-20[193_102]
13-11	2000-2003	and	abstract[102]	new[102]	_	_
13-12	2004-2009	moral	abstract[102]	new[102]	_	_
13-13	2010-2019	standards	abstract[102]	new[102]	_	_
13-14	2020-2022	if	_	_	_	_
13-15	2023-2025	it	abstract	giv	coref	14-31[113_0]
13-16	2026-2034	utilises	_	_	_	_
13-17	2035-2044	sensitive	abstract[105]	new[105]	coref	19-11[0_105]
13-18	2045-2050	input	abstract|abstract[105]	giv|new[105]	coref	20-17
13-19	2051-2060	variables	abstract[105]	new[105]	_	_
13-20	2061-2062	.	_	_	_	_

#Text=Individual-specific characteristics , such as a person ’s age and gender that are used as decision-making criteria can be penalised or privileged by the AVs ’ algorithms to meet the algorithm ’s pre-defined preferences , such as prioritising the safety of children or minimising the total quantity of harm , causing more safety risks to be allocated to individuals that share the penalised characteristics .
14-1	2063-2082	Individual-specific	abstract[106]	giv[106]	coref	14-62[122_106]
14-2	2083-2098	characteristics	abstract[106]	giv[106]	_	_
14-3	2099-2100	,	abstract[106]	giv[106]	_	_
14-4	2101-2105	such	abstract[106]	giv[106]	_	_
14-5	2106-2108	as	abstract[106]	giv[106]	_	_
14-6	2109-2110	a	abstract[106]|abstract[108]	giv[106]|new[108]	_	_
14-7	2111-2117	person	abstract[106]|person[107]|abstract[108]	giv[106]|giv[107]|new[108]	_	_
14-8	2118-2120	’s	abstract[106]|person[107]|abstract[108]	giv[106]|giv[107]|new[108]	_	_
14-9	2121-2124	age	abstract[106]|abstract[108]	giv[106]|new[108]	_	_
14-10	2125-2128	and	abstract[106]	giv[106]	_	_
14-11	2129-2135	gender	abstract[106]|abstract[109]	giv[106]|new[109]	_	_
14-12	2136-2140	that	abstract[106]|abstract[109]	giv[106]|new[109]	_	_
14-13	2141-2144	are	abstract[106]|abstract[109]	giv[106]|new[109]	_	_
14-14	2145-2149	used	abstract[106]|abstract[109]	giv[106]|new[109]	_	_
14-15	2150-2152	as	abstract[106]|abstract[109]	giv[106]|new[109]	_	_
14-16	2153-2168	decision-making	abstract[106]|abstract[109]|abstract[110]	giv[106]|new[109]|new[110]	_	_
14-17	2169-2177	criteria	abstract[106]|abstract[109]|abstract[110]	giv[106]|new[109]|new[110]	_	_
14-18	2178-2181	can	_	_	_	_
14-19	2182-2184	be	_	_	_	_
14-20	2185-2194	penalised	_	_	_	_
14-21	2195-2197	or	_	_	_	_
14-22	2198-2208	privileged	_	_	_	_
14-23	2209-2211	by	_	_	_	_
14-24	2212-2215	the	abstract[112]	giv[112]	coref	16-44[155_112]
14-25	2216-2219	AVs	abstract[111]|abstract[112]	giv[111]|giv[112]	coref	16-11[0_111]
14-26	2220-2221	’	abstract[111]|abstract[112]	giv[111]|giv[112]	_	_
14-27	2222-2232	algorithms	abstract[112]	giv[112]	_	_
14-28	2233-2235	to	_	_	_	_
14-29	2236-2240	meet	_	_	_	_
14-30	2241-2244	the	abstract[114]	new[114]	coref	16-7[142_114]
14-31	2245-2254	algorithm	abstract[113]|abstract[114]	giv[113]|new[114]	coref	15-12[0_113]
14-32	2255-2257	’s	abstract[113]|abstract[114]	giv[113]|new[114]	_	_
14-33	2258-2269	pre-defined	abstract[114]	new[114]	_	_
14-34	2270-2281	preferences	abstract[114]	new[114]	_	_
14-35	2282-2283	,	abstract[114]	new[114]	_	_
14-36	2284-2288	such	abstract[114]	new[114]	_	_
14-37	2289-2291	as	abstract[114]	new[114]	_	_
14-38	2292-2304	prioritising	abstract[114]	new[114]	_	_
14-39	2305-2308	the	abstract[114]|abstract[115]	new[114]|giv[115]	coref	14-53[0_115]
14-40	2309-2315	safety	abstract[114]|abstract[115]	new[114]|giv[115]	_	_
14-41	2316-2318	of	abstract[114]|abstract[115]	new[114]|giv[115]	_	_
14-42	2319-2327	children	abstract[114]|abstract[115]|person	new[114]|giv[115]|new	_	_
14-43	2328-2330	or	abstract[114]	new[114]	_	_
14-44	2331-2341	minimising	abstract[114]	new[114]	_	_
14-45	2342-2345	the	abstract[114]|abstract[117]	new[114]|new[117]	_	_
14-46	2346-2351	total	abstract[114]|abstract[117]	new[114]|new[117]	_	_
14-47	2352-2360	quantity	abstract[114]|abstract[117]	new[114]|new[117]	_	_
14-48	2361-2363	of	abstract[114]|abstract[117]	new[114]|new[117]	_	_
14-49	2364-2368	harm	abstract[114]|abstract[117]|abstract	new[114]|new[117]|new	_	_
14-50	2369-2370	,	_	_	_	_
14-51	2371-2378	causing	_	_	_	_
14-52	2379-2383	more	abstract[120]	giv[120]	coref	16-21[148_120]
14-53	2384-2390	safety	abstract|abstract[120]	giv|giv[120]	_	_
14-54	2391-2396	risks	abstract[120]	giv[120]	_	_
14-55	2397-2399	to	_	_	_	_
14-56	2400-2402	be	_	_	_	_
14-57	2403-2412	allocated	_	_	_	_
14-58	2413-2415	to	_	_	_	_
14-59	2416-2427	individuals	person[121]	giv[121]	coref	18-49[172_121]
14-60	2428-2432	that	person[121]	giv[121]	_	_
14-61	2433-2438	share	person[121]	giv[121]	_	_
14-62	2439-2442	the	person[121]|abstract[122]	giv[121]|giv[122]	_	_
14-63	2443-2452	penalised	person[121]|abstract[122]	giv[121]|giv[122]	_	_
14-64	2453-2468	characteristics	person[121]|abstract[122]	giv[121]|giv[122]	_	_
14-65	2469-2470	.	_	_	_	_

#Text=These forms of bias can be introduced unintentionally or intentionally by algorithm designers and AV manufacturers to maximise profits , such as prioritising the safety of AV passengers to maximise profits , and this is exacerbated by the lack of legal frameworks to hold these stakeholders accountable .
15-1	2471-2476	These	abstract[123]	new[123]	_	_
15-2	2477-2482	forms	abstract[123]	new[123]	_	_
15-3	2483-2485	of	abstract[123]	new[123]	_	_
15-4	2486-2490	bias	abstract[123]|abstract	new[123]|giv	coref	17-2[156_0]
15-5	2491-2494	can	_	_	_	_
15-6	2495-2497	be	_	_	_	_
15-7	2498-2508	introduced	_	_	_	_
15-8	2509-2524	unintentionally	_	_	_	_
15-9	2525-2527	or	_	_	_	_
15-10	2528-2541	intentionally	_	_	_	_
15-11	2542-2544	by	_	_	_	_
15-12	2545-2554	algorithm	abstract|person[126]|person[127]	giv|giv[126]|giv[127]	coref|coref|coref	15-12[127_126]|22-18[221_0]|22-25[222_127]
15-13	2555-2564	designers	person[126]|person[127]	giv[126]|giv[127]	_	_
15-14	2565-2568	and	person[127]	giv[127]	_	_
15-15	2569-2571	AV	person[127]|abstract|organization[129]	giv[127]|giv|new[129]	coref	15-27
15-16	2572-2585	manufacturers	person[127]|organization[129]	giv[127]|new[129]	_	_
15-17	2586-2588	to	person[127]|organization[129]	giv[127]|new[129]	_	_
15-18	2589-2597	maximise	person[127]|organization[129]	giv[127]|new[129]	_	_
15-19	2598-2605	profits	person[127]|organization[129]|abstract	giv[127]|new[129]|new	coref	15-31
15-20	2606-2607	,	person[127]|organization[129]	giv[127]|new[129]	_	_
15-21	2608-2612	such	person[127]|organization[129]	giv[127]|new[129]	_	_
15-22	2613-2615	as	person[127]|organization[129]	giv[127]|new[129]	_	_
15-23	2616-2628	prioritising	person[127]|organization[129]	giv[127]|new[129]	_	_
15-24	2629-2632	the	person[127]|organization[129]|abstract[131]	giv[127]|new[129]|new[131]	ana	15-34[0_131]
15-25	2633-2639	safety	person[127]|organization[129]|abstract[131]	giv[127]|new[129]|new[131]	_	_
15-26	2640-2642	of	person[127]|organization[129]|abstract[131]	giv[127]|new[129]|new[131]	_	_
15-27	2643-2645	AV	person[127]|organization[129]|abstract[131]|abstract|person[133]	giv[127]|new[129]|new[131]|giv|new[133]	coref	16-21
15-28	2646-2656	passengers	person[127]|organization[129]|abstract[131]|person[133]	giv[127]|new[129]|new[131]|new[133]	_	_
15-29	2657-2659	to	_	_	_	_
15-30	2660-2668	maximise	_	_	_	_
15-31	2669-2676	profits	abstract	giv	_	_
15-32	2677-2678	,	_	_	_	_
15-33	2679-2682	and	_	_	_	_
15-34	2683-2687	this	abstract	giv	coref	16-22
15-35	2688-2690	is	_	_	_	_
15-36	2691-2702	exacerbated	_	_	_	_
15-37	2703-2705	by	_	_	_	_
15-38	2706-2709	the	abstract[136]	new[136]	_	_
15-39	2710-2714	lack	abstract[136]	new[136]	_	_
15-40	2715-2717	of	abstract[136]	new[136]	_	_
15-41	2718-2723	legal	abstract[136]|abstract[137]	new[136]|new[137]	_	_
15-42	2724-2734	frameworks	abstract[136]|abstract[137]	new[136]|new[137]	_	_
15-43	2735-2737	to	abstract[136]|abstract[137]	new[136]|new[137]	_	_
15-44	2738-2742	hold	abstract[136]|abstract[137]	new[136]|new[137]	_	_
15-45	2743-2748	these	abstract[136]|abstract[137]|person[138]	new[136]|new[137]|giv[138]	_	_
15-46	2749-2761	stakeholders	abstract[136]|abstract[137]|person[138]	new[136]|new[137]|giv[138]	_	_
15-47	2762-2773	accountable	abstract[136]|abstract[137]	new[136]|new[137]	_	_
15-48	2774-2775	.	_	_	_	_

#Text=Section 5.2 explores various types of ethical preferences to which AVs may be programmed to follow and their implications of AV safety risks in greater detail , and Section 5.3 explores how perverse incentives influence the choice of preferences that are programmed into AVs ’ algorithms .
16-1	2776-2783	Section	abstract[139]	giv[139]	coref	16-29[150_139]
16-2	2784-2787	5.2	abstract[139]	giv[139]	_	_
16-3	2788-2796	explores	_	_	_	_
16-4	2797-2804	various	abstract[140]|abstract[141]	new[140]|new[141]	ana	16-18[0_141]
16-5	2805-2810	types	abstract[140]|abstract[141]	new[140]|new[141]	_	_
16-6	2811-2813	of	abstract[140]|abstract[141]	new[140]|new[141]	_	_
16-7	2814-2821	ethical	abstract[140]|abstract[141]|abstract[142]	new[140]|new[141]|giv[142]	coref	16-39[153_142]
16-8	2822-2833	preferences	abstract[140]|abstract[141]|abstract[142]	new[140]|new[141]|giv[142]	_	_
16-9	2834-2836	to	abstract[140]|abstract[141]|abstract[142]	new[140]|new[141]|giv[142]	_	_
16-10	2837-2842	which	abstract[140]|abstract[141]|abstract[142]	new[140]|new[141]|giv[142]	_	_
16-11	2843-2846	AVs	abstract[140]|abstract[141]|abstract[142]|abstract	new[140]|new[141]|giv[142]|giv	coref	16-44[154_0]
16-12	2847-2850	may	abstract[140]|abstract[141]|abstract[142]	new[140]|new[141]|giv[142]	_	_
16-13	2851-2853	be	abstract[140]|abstract[141]|abstract[142]	new[140]|new[141]|giv[142]	_	_
16-14	2854-2864	programmed	abstract[140]|abstract[141]|abstract[142]	new[140]|new[141]|giv[142]	_	_
16-15	2865-2867	to	abstract[140]|abstract[141]|abstract[142]	new[140]|new[141]|giv[142]	_	_
16-16	2868-2874	follow	abstract[140]|abstract[141]|abstract[142]	new[140]|new[141]|giv[142]	_	_
16-17	2875-2878	and	abstract[141]	new[141]	_	_
16-18	2879-2884	their	abstract[141]|abstract|abstract[145]	new[141]|giv|giv[145]	_	_
16-19	2885-2897	implications	abstract[141]|abstract[145]	new[141]|giv[145]	_	_
16-20	2898-2900	of	abstract[141]|abstract[145]	new[141]|giv[145]	_	_
16-21	2901-2903	AV	abstract[141]|abstract[145]|abstract|abstract[148]	new[141]|giv[145]|giv|giv[148]	coref	26-13[260_148]
16-22	2904-2910	safety	abstract[141]|abstract[145]|abstract|abstract[148]	new[141]|giv[145]|giv|giv[148]	coref	20-52
16-23	2911-2916	risks	abstract[141]|abstract[145]|abstract[148]	new[141]|giv[145]|giv[148]	_	_
16-24	2917-2919	in	_	_	_	_
16-25	2920-2927	greater	abstract[149]	new[149]	_	_
16-26	2928-2934	detail	abstract[149]	new[149]	_	_
16-27	2935-2936	,	_	_	_	_
16-28	2937-2940	and	_	_	_	_
16-29	2941-2948	Section	abstract[150]	giv[150]	_	_
16-30	2949-2952	5.3	abstract[150]	giv[150]	_	_
16-31	2953-2961	explores	_	_	_	_
16-32	2962-2965	how	_	_	_	_
16-33	2966-2974	perverse	abstract[151]	giv[151]	_	_
16-34	2975-2985	incentives	abstract[151]	giv[151]	_	_
16-35	2986-2995	influence	_	_	_	_
16-36	2996-2999	the	abstract[152]	new[152]	_	_
16-37	3000-3006	choice	abstract[152]	new[152]	_	_
16-38	3007-3009	of	abstract[152]	new[152]	_	_
16-39	3010-3021	preferences	abstract[152]|abstract[153]	new[152]|giv[153]	coref	25-14[250_153]
16-40	3022-3026	that	abstract[152]|abstract[153]	new[152]|giv[153]	_	_
16-41	3027-3030	are	abstract[152]|abstract[153]	new[152]|giv[153]	_	_
16-42	3031-3041	programmed	abstract[152]|abstract[153]	new[152]|giv[153]	_	_
16-43	3042-3046	into	abstract[152]|abstract[153]	new[152]|giv[153]	_	_
16-44	3047-3050	AVs	abstract[152]|abstract[153]|abstract[154]|abstract[155]	new[152]|giv[153]|giv[154]|giv[155]	coref|coref	17-4[0_155]|17-13[0_154]
16-45	3051-3052	’	abstract[152]|abstract[153]|abstract[154]|abstract[155]	new[152]|giv[153]|giv[154]|giv[155]	_	_
16-46	3053-3063	algorithms	abstract[152]|abstract[153]|abstract[155]	new[152]|giv[153]|giv[155]	_	_
16-47	3064-3065	.	_	_	_	_

#Text=Lessening bias in algorithms is therefore crucial to mitigate discriminatory outcomes from AVs .
17-1	3066-3075	Lessening	_	_	_	_
17-2	3076-3080	bias	abstract[156]	giv[156]	coref	18-18[0_156]
17-3	3081-3083	in	abstract[156]	giv[156]	_	_
17-4	3084-3094	algorithms	abstract[156]|abstract	giv[156]|giv	coref	18-73[180_0]
17-5	3095-3097	is	_	_	_	_
17-6	3098-3107	therefore	_	_	_	_
17-7	3108-3115	crucial	_	_	_	_
17-8	3116-3118	to	_	_	_	_
17-9	3119-3127	mitigate	_	_	_	_
17-10	3128-3142	discriminatory	abstract[158]	giv[158]	coref	25-8[248_158]
17-11	3143-3151	outcomes	abstract[158]	giv[158]	_	_
17-12	3152-3156	from	abstract[158]	giv[158]	_	_
17-13	3157-3160	AVs	abstract[158]|abstract	giv[158]|giv	coref	25-12[249_0]
17-14	3161-3162	.	_	_	_	_

#Text=In autonomous systems in general , scholars have recommended ways to detect and offset the effects of bias , such as modifying algorithmic outputs to balance the effects of bias between protected and unprotected groups , introducing minimally intrusive modification to remove bias from the data , incorporating individuals from potentially discriminated groups , testing techniques to measure discrimination and identify groups of users significantly affected by bias in software and creating algorithms that certify the absence of data bias .
18-1	3163-3165	In	_	_	_	_
18-2	3166-3176	autonomous	abstract[160]	new[160]	_	_
18-3	3177-3184	systems	abstract[160]	new[160]	_	_
18-4	3185-3187	in	abstract[160]	new[160]	_	_
18-5	3188-3195	general	abstract[160]	new[160]	_	_
18-6	3196-3197	,	_	_	_	_
18-7	3198-3206	scholars	person	new	coref	20-3
18-8	3207-3211	have	_	_	_	_
18-9	3212-3223	recommended	_	_	_	_
18-10	3224-3228	ways	abstract[162]	new[162]	_	_
18-11	3229-3231	to	abstract[162]	new[162]	_	_
18-12	3232-3238	detect	abstract[162]	new[162]	_	_
18-13	3239-3242	and	abstract[162]	new[162]	_	_
18-14	3243-3249	offset	abstract[162]	new[162]	_	_
18-15	3250-3253	the	abstract[162]|abstract[163]	new[162]|new[163]	coref	18-27[166_163]
18-16	3254-3261	effects	abstract[162]|abstract[163]	new[162]|new[163]	_	_
18-17	3262-3264	of	abstract[162]|abstract[163]	new[162]|new[163]	_	_
18-18	3265-3269	bias	abstract[162]|abstract[163]|abstract	new[162]|new[163]|giv	coref	18-30
18-19	3270-3271	,	abstract[162]	new[162]	_	_
18-20	3272-3276	such	abstract[162]	new[162]	_	_
18-21	3277-3279	as	abstract[162]	new[162]	_	_
18-22	3280-3289	modifying	abstract[162]	new[162]	_	_
18-23	3290-3301	algorithmic	abstract[162]|abstract[165]	new[162]|new[165]	coref	20-44[209_165]
18-24	3302-3309	outputs	abstract[162]|abstract[165]	new[162]|new[165]	_	_
18-25	3310-3312	to	abstract[162]	new[162]	_	_
18-26	3313-3320	balance	abstract[162]	new[162]	_	_
18-27	3321-3324	the	abstract[162]|abstract[166]	new[162]|giv[166]	coref	21-12[217_166]
18-28	3325-3332	effects	abstract[162]|abstract[166]	new[162]|giv[166]	_	_
18-29	3333-3335	of	abstract[162]|abstract[166]	new[162]|giv[166]	_	_
18-30	3336-3340	bias	abstract[162]|abstract[166]|abstract	new[162]|giv[166]|giv	coref	18-43
18-31	3341-3348	between	abstract[162]	new[162]	_	_
18-32	3349-3358	protected	abstract[162]|person[168]	new[162]|giv[168]	coref	18-51[173_168]
18-33	3359-3362	and	abstract[162]|person[168]	new[162]|giv[168]	_	_
18-34	3363-3374	unprotected	abstract[162]|person[168]	new[162]|giv[168]	_	_
18-35	3375-3381	groups	abstract[162]|person[168]	new[162]|giv[168]	_	_
18-36	3382-3383	,	abstract[162]	new[162]	_	_
18-37	3384-3395	introducing	abstract[162]	new[162]	_	_
18-38	3396-3405	minimally	abstract[162]|abstract[169]	new[162]|new[169]	_	_
18-39	3406-3415	intrusive	abstract[162]|abstract[169]	new[162]|new[169]	_	_
18-40	3416-3428	modification	abstract[162]|abstract[169]	new[162]|new[169]	_	_
18-41	3429-3431	to	abstract[162]|abstract[169]	new[162]|new[169]	_	_
18-42	3432-3438	remove	abstract[162]|abstract[169]	new[162]|new[169]	_	_
18-43	3439-3443	bias	abstract[162]|abstract[169]|abstract	new[162]|new[169]|giv	coref	18-68[178_0]
18-44	3444-3448	from	abstract[162]|abstract[169]	new[162]|new[169]	_	_
18-45	3449-3452	the	abstract[162]|abstract[169]|abstract[171]	new[162]|new[169]|giv[171]	coref	18-79[0_171]
18-46	3453-3457	data	abstract[162]|abstract[169]|abstract[171]	new[162]|new[169]|giv[171]	_	_
18-47	3458-3459	,	abstract[162]	new[162]	_	_
18-48	3460-3473	incorporating	abstract[162]	new[162]	_	_
18-49	3474-3485	individuals	abstract[162]|person[172]	new[162]|giv[172]	_	_
18-50	3486-3490	from	abstract[162]|person[172]	new[162]|giv[172]	_	_
18-51	3491-3502	potentially	abstract[162]|person[172]|person[173]	new[162]|giv[172]|giv[173]	_	_
18-52	3503-3516	discriminated	abstract[162]|person[172]|person[173]	new[162]|giv[172]|giv[173]	_	_
18-53	3517-3523	groups	abstract[162]|person[172]|person[173]	new[162]|giv[172]|giv[173]	_	_
18-54	3524-3525	,	abstract[162]	new[162]	_	_
18-55	3526-3533	testing	abstract[162]	new[162]	_	_
18-56	3534-3544	techniques	abstract[162]|abstract[174]	new[162]|new[174]	_	_
18-57	3545-3547	to	abstract[162]|abstract[174]	new[162]|new[174]	_	_
18-58	3548-3555	measure	abstract[162]|abstract[174]	new[162]|new[174]	_	_
18-59	3556-3570	discrimination	abstract[162]|abstract[174]|abstract	new[162]|new[174]|giv	coref	26-18[261_0]
18-60	3571-3574	and	abstract[162]|abstract[174]	new[162]|new[174]	_	_
18-61	3575-3583	identify	abstract[162]|abstract[174]	new[162]|new[174]	_	_
18-62	3584-3590	groups	abstract[162]|abstract[174]|person[176]	new[162]|new[174]|new[176]	_	_
18-63	3591-3593	of	abstract[162]|abstract[174]|person[176]	new[162]|new[174]|new[176]	_	_
18-64	3594-3599	users	abstract[162]|abstract[174]|person[176]|person[177]	new[162]|new[174]|new[176]|new[177]	_	_
18-65	3600-3613	significantly	abstract[162]|abstract[174]|person[176]|person[177]	new[162]|new[174]|new[176]|new[177]	_	_
18-66	3614-3622	affected	abstract[162]|abstract[174]|person[176]|person[177]	new[162]|new[174]|new[176]|new[177]	_	_
18-67	3623-3625	by	abstract[162]|abstract[174]|person[176]|person[177]	new[162]|new[174]|new[176]|new[177]	_	_
18-68	3626-3630	bias	abstract[162]|abstract[174]|person[176]|person[177]|abstract[178]	new[162]|new[174]|new[176]|new[177]|giv[178]	coref	18-79[183_178]
18-69	3631-3633	in	abstract[162]|abstract[174]|person[176]|person[177]|abstract[178]	new[162]|new[174]|new[176]|new[177]|giv[178]	_	_
18-70	3634-3642	software	abstract[162]|abstract[174]|person[176]|person[177]|abstract[178]|abstract	new[162]|new[174]|new[176]|new[177]|giv[178]|new	_	_
18-71	3643-3646	and	abstract[162]	new[162]	_	_
18-72	3647-3655	creating	abstract[162]	new[162]	_	_
18-73	3656-3666	algorithms	abstract[162]|abstract[180]	new[162]|giv[180]	coref	20-14[199_180]
18-74	3667-3671	that	abstract[162]|abstract[180]	new[162]|giv[180]	_	_
18-75	3672-3679	certify	abstract[162]|abstract[180]	new[162]|giv[180]	_	_
18-76	3680-3683	the	abstract[162]|abstract[180]|abstract[181]	new[162]|giv[180]|new[181]	_	_
18-77	3684-3691	absence	abstract[162]|abstract[180]|abstract[181]	new[162]|giv[180]|new[181]	_	_
18-78	3692-3694	of	abstract[162]|abstract[180]|abstract[181]	new[162]|giv[180]|new[181]	_	_
18-79	3695-3699	data	abstract[162]|abstract[180]|abstract[181]|abstract|abstract[183]	new[162]|giv[180]|new[181]|giv|giv[183]	coref|coref	19-3[184_183]|19-6[185_0]
18-80	3700-3704	bias	abstract[162]|abstract[180]|abstract[181]|abstract[183]	new[162]|giv[180]|new[181]|giv[183]	_	_
18-81	3705-3706	.	_	_	_	_

#Text=Apart from bias originating from the data and selection of variables and criterion , Danks and London recommend clarifying ethical standards such as fairness to evaluate bias .
19-1	3707-3712	Apart	_	_	_	_
19-2	3713-3717	from	_	_	_	_
19-3	3718-3722	bias	abstract[184]	giv[184]	coref	19-27[0_184]
19-4	3723-3734	originating	abstract[184]	giv[184]	_	_
19-5	3735-3739	from	abstract[184]	giv[184]	_	_
19-6	3740-3743	the	abstract[184]|abstract[185]|abstract[186]	giv[184]|giv[185]|giv[186]	coref|coref	19-6[186_185]|23-11[230_186]
19-7	3744-3748	data	abstract[184]|abstract[185]|abstract[186]	giv[184]|giv[185]|giv[186]	_	_
19-8	3749-3752	and	abstract[184]|abstract[186]	giv[184]|giv[186]	_	_
19-9	3753-3762	selection	abstract[184]|abstract[186]|abstract[187]	giv[184]|giv[186]|new[187]	_	_
19-10	3763-3765	of	abstract[184]|abstract[186]|abstract[187]	giv[184]|giv[186]|new[187]	_	_
19-11	3766-3775	variables	abstract[184]|abstract[186]|abstract[187]|abstract|abstract[189]	giv[184]|giv[186]|new[187]|giv|giv[189]	coref|coref	19-11[189_0]|20-15[201_189]
19-12	3776-3779	and	abstract[184]|abstract[186]|abstract[187]|abstract[189]	giv[184]|giv[186]|new[187]|giv[189]	_	_
19-13	3780-3789	criterion	abstract[184]|abstract[186]|abstract[187]|abstract[189]|abstract	giv[184]|giv[186]|new[187]|giv[189]|new	_	_
19-14	3790-3791	,	_	_	_	_
19-15	3792-3797	Danks	person	new	_	_
19-16	3798-3801	and	_	_	_	_
19-17	3802-3808	London	person	new	_	_
19-18	3809-3818	recommend	_	_	_	_
19-19	3819-3829	clarifying	_	_	_	_
19-20	3830-3837	ethical	abstract[193]	giv[193]	_	_
19-21	3838-3847	standards	abstract[193]	giv[193]	_	_
19-22	3848-3852	such	abstract[193]	giv[193]	_	_
19-23	3853-3855	as	abstract[193]	giv[193]	_	_
19-24	3856-3864	fairness	abstract[193]|abstract	giv[193]|new	_	_
19-25	3865-3867	to	_	_	_	_
19-26	3868-3876	evaluate	_	_	_	_
19-27	3877-3881	bias	abstract	giv	coref	21-8[213_0]
19-28	3882-3883	.	_	_	_	_

#Text=Furthermore , scholars recommend increasing transparency to identify biases , such as designing algorithms whose original input variables can be traced throughout the system ( i.e. , traceability ) and auditing algorithms to enhance their interpretability so that biases can be detected and the system ’s outputs can be verified against safety requirements .
20-1	3884-3895	Furthermore	_	_	_	_
20-2	3896-3897	,	_	_	_	_
20-3	3898-3906	scholars	person	giv	_	_
20-4	3907-3916	recommend	_	_	_	_
20-5	3917-3927	increasing	abstract[197]	new[197]	_	_
20-6	3928-3940	transparency	abstract[197]	new[197]	_	_
20-7	3941-3943	to	abstract[197]	new[197]	_	_
20-8	3944-3952	identify	abstract[197]	new[197]	_	_
20-9	3953-3959	biases	abstract[197]|abstract	new[197]|new	coref	20-39
20-10	3960-3961	,	abstract[197]	new[197]	_	_
20-11	3962-3966	such	abstract[197]	new[197]	_	_
20-12	3967-3969	as	abstract[197]	new[197]	_	_
20-13	3970-3979	designing	abstract[197]	new[197]	_	_
20-14	3980-3990	algorithms	abstract[197]|abstract[199]	new[197]|giv[199]	appos	20-26[203_199]
20-15	3991-3996	whose	abstract[197]|abstract[199]|abstract[201]	new[197]|giv[199]|giv[201]	_	_
20-16	3997-4005	original	abstract[197]|abstract[199]|abstract[201]	new[197]|giv[199]|giv[201]	_	_
20-17	4006-4011	input	abstract[197]|abstract[199]|abstract|abstract[201]	new[197]|giv[199]|giv|giv[201]	_	_
20-18	4012-4021	variables	abstract[197]|abstract[199]|abstract[201]	new[197]|giv[199]|giv[201]	_	_
20-19	4022-4025	can	abstract[197]|abstract[199]	new[197]|giv[199]	_	_
20-20	4026-4028	be	abstract[197]|abstract[199]	new[197]|giv[199]	_	_
20-21	4029-4035	traced	abstract[197]|abstract[199]	new[197]|giv[199]	_	_
20-22	4036-4046	throughout	abstract[197]|abstract[199]	new[197]|giv[199]	_	_
20-23	4047-4050	the	abstract[197]|abstract[199]|abstract[202]	new[197]|giv[199]|giv[202]	coref	20-45[208_202]
20-24	4051-4057	system	abstract[197]|abstract[199]|abstract[202]	new[197]|giv[199]|giv[202]	_	_
20-25	4058-4059	(	abstract[197]	new[197]	_	_
20-26	4060-4064	i.e.	abstract[197]|abstract[203]	new[197]|giv[203]	coref	20-32[0_203]
20-27	4065-4066	,	abstract[197]|abstract[203]	new[197]|giv[203]	_	_
20-28	4067-4079	traceability	abstract[197]|abstract[203]	new[197]|giv[203]	_	_
20-29	4080-4081	)	abstract[197]	new[197]	_	_
20-30	4082-4085	and	abstract[197]	new[197]	_	_
20-31	4086-4094	auditing	abstract[197]	new[197]	_	_
20-32	4095-4105	algorithms	abstract[197]|abstract	new[197]|giv	ana	20-35
20-33	4106-4108	to	_	_	_	_
20-34	4109-4116	enhance	_	_	_	_
20-35	4117-4122	their	abstract|abstract[206]	giv|new[206]	coref	21-10
20-36	4123-4139	interpretability	abstract[206]	new[206]	_	_
20-37	4140-4142	so	_	_	_	_
20-38	4143-4147	that	_	_	_	_
20-39	4148-4154	biases	abstract	giv	_	_
20-40	4155-4158	can	_	_	_	_
20-41	4159-4161	be	_	_	_	_
20-42	4162-4170	detected	_	_	_	_
20-43	4171-4174	and	_	_	_	_
20-44	4175-4178	the	abstract[209]	giv[209]	_	_
20-45	4179-4185	system	abstract[208]|abstract[209]	giv[208]|giv[209]	_	_
20-46	4186-4188	’s	abstract[208]|abstract[209]	giv[208]|giv[209]	_	_
20-47	4189-4196	outputs	abstract[209]	giv[209]	_	_
20-48	4197-4200	can	_	_	_	_
20-49	4201-4203	be	_	_	_	_
20-50	4204-4212	verified	_	_	_	_
20-51	4213-4220	against	_	_	_	_
20-52	4221-4227	safety	abstract|abstract[211]	giv|new[211]	coref	26-14
20-53	4228-4240	requirements	abstract[211]	new[211]	_	_
20-54	4241-4242	.	_	_	_	_

#Text=However , there are challenges in identifying bias in algorithms and their discriminatory effects .
21-1	4243-4250	However	_	_	_	_
21-2	4251-4252	,	_	_	_	_
21-3	4253-4258	there	_	_	_	_
21-4	4259-4262	are	_	_	_	_
21-5	4263-4273	challenges	abstract[212]	new[212]	_	_
21-6	4274-4276	in	abstract[212]	new[212]	_	_
21-7	4277-4288	identifying	abstract[212]	new[212]	_	_
21-8	4289-4293	bias	abstract[212]|abstract[213]|abstract[214]	new[212]|giv[213]|new[214]	ana|coref	21-12[0_214]|22-35[0_213]
21-9	4294-4296	in	abstract[212]|abstract[213]|abstract[214]	new[212]|giv[213]|new[214]	_	_
21-10	4297-4307	algorithms	abstract[212]|abstract[213]|abstract[214]|abstract	new[212]|giv[213]|new[214]|giv	coref	22-3[218_0]
21-11	4308-4311	and	abstract[212]|abstract[214]	new[212]|new[214]	_	_
21-12	4312-4317	their	abstract[212]|abstract[214]|abstract|abstract[217]	new[212]|new[214]|giv|giv[217]	coref	23-24[232_217]
21-13	4318-4332	discriminatory	abstract[212]|abstract[214]|abstract[217]	new[212]|new[214]|giv[217]	_	_
21-14	4333-4340	effects	abstract[212]|abstract[214]|abstract[217]	new[212]|new[214]|giv[217]	_	_
21-15	4341-4342	.	_	_	_	_

#Text=Firstly , many algorithms are designed to be highly complex for greater accuracy , but this renders the algorithm opaque and difficult to interpret even by the designers themselves , concealing the sources of bias .
22-1	4343-4350	Firstly	_	_	_	_
22-2	4351-4352	,	_	_	_	_
22-3	4353-4357	many	abstract[218]	giv[218]	ana	22-29[0_218]
22-4	4358-4368	algorithms	abstract[218]	giv[218]	_	_
22-5	4369-4372	are	_	_	_	_
22-6	4373-4381	designed	_	_	_	_
22-7	4382-4384	to	_	_	_	_
22-8	4385-4387	be	_	_	_	_
22-9	4388-4394	highly	_	_	_	_
22-10	4395-4402	complex	_	_	_	_
22-11	4403-4406	for	_	_	_	_
22-12	4407-4414	greater	abstract[219]	new[219]	ana	22-16[0_219]
22-13	4415-4423	accuracy	abstract[219]	new[219]	_	_
22-14	4424-4425	,	_	_	_	_
22-15	4426-4429	but	_	_	_	_
22-16	4430-4434	this	abstract	giv	_	_
22-17	4435-4442	renders	_	_	_	_
22-18	4443-4446	the	abstract[221]	giv[221]	coref	24-41[241_221]
22-19	4447-4456	algorithm	abstract[221]	giv[221]	_	_
22-20	4457-4463	opaque	_	_	_	_
22-21	4464-4467	and	_	_	_	_
22-22	4468-4477	difficult	_	_	_	_
22-23	4478-4480	to	_	_	_	_
22-24	4481-4490	interpret	_	_	_	_
22-25	4491-4495	even	person[222]	giv[222]	_	_
22-26	4496-4498	by	person[222]	giv[222]	_	_
22-27	4499-4502	the	person[222]	giv[222]	_	_
22-28	4503-4512	designers	person[222]	giv[222]	_	_
22-29	4513-4523	themselves	person[222]|abstract	giv[222]|giv	coref	23-4[227_0]
22-30	4524-4525	,	_	_	_	_
22-31	4526-4536	concealing	_	_	_	_
22-32	4537-4540	the	abstract[224]	new[224]	_	_
22-33	4541-4548	sources	abstract[224]	new[224]	_	_
22-34	4549-4551	of	abstract[224]	new[224]	_	_
22-35	4552-4556	bias	abstract[224]|abstract	new[224]|giv	ana	23-19
22-36	4557-4558	.	_	_	_	_

#Text=Secondly , as ML algorithms make decisions mainly based on the training data that changes over time , it is difficult to predict potentially discriminatory effects in advance .
23-1	4559-4567	Secondly	_	_	_	_
23-2	4568-4569	,	_	_	_	_
23-3	4570-4572	as	_	_	_	_
23-4	4573-4575	ML	abstract|abstract[227]	new|giv[227]	coref	24-18[0_227]
23-5	4576-4586	algorithms	abstract[227]	giv[227]	_	_
23-6	4587-4591	make	_	_	_	_
23-7	4592-4601	decisions	abstract	giv	coref	24-10[234_0]
23-8	4602-4608	mainly	_	_	_	_
23-9	4609-4614	based	_	_	_	_
23-10	4615-4617	on	_	_	_	_
23-11	4618-4621	the	abstract[230]	giv[230]	coref	24-45[242_230]
23-12	4622-4630	training	abstract|abstract[230]	new|giv[230]	_	_
23-13	4631-4635	data	abstract[230]	giv[230]	_	_
23-14	4636-4640	that	abstract[230]	giv[230]	_	_
23-15	4641-4648	changes	abstract[230]	giv[230]	_	_
23-16	4649-4653	over	abstract[230]	giv[230]	_	_
23-17	4654-4658	time	abstract[230]	giv[230]	_	_
23-18	4659-4660	,	_	_	_	_
23-19	4661-4663	it	abstract	giv	coref	24-30[239_0]
23-20	4664-4666	is	_	_	_	_
23-21	4667-4676	difficult	_	_	_	_
23-22	4677-4679	to	_	_	_	_
23-23	4680-4687	predict	_	_	_	_
23-24	4688-4699	potentially	abstract[232]	giv[232]	_	_
23-25	4700-4714	discriminatory	abstract[232]	giv[232]	_	_
23-26	4715-4722	effects	abstract[232]	giv[232]	_	_
23-27	4723-4725	in	_	_	_	_
23-28	4726-4733	advance	_	_	_	_
23-29	4734-4735	.	_	_	_	_

#Text=Humans are also excessively trusting and insufficiently critical of algorithmic decisions due to the popular perception of algorithms as objective and fair , a problem referred to as “ automation bias ” and the seemingly “ objective ” correlations that the algorithm learns from the data makes it difficult to legally establish discriminatory intent in algorithms .
24-1	4736-4742	Humans	person	new	ana	25-33
24-2	4743-4746	are	_	_	_	_
24-3	4747-4751	also	_	_	_	_
24-4	4752-4763	excessively	_	_	_	_
24-5	4764-4772	trusting	_	_	_	_
24-6	4773-4776	and	_	_	_	_
24-7	4777-4791	insufficiently	_	_	_	_
24-8	4792-4800	critical	_	_	_	_
24-9	4801-4803	of	_	_	_	_
24-10	4804-4815	algorithmic	abstract[234]	giv[234]	coref	25-33[255_234]
24-11	4816-4825	decisions	abstract[234]	giv[234]	_	_
24-12	4826-4829	due	_	_	_	_
24-13	4830-4832	to	_	_	_	_
24-14	4833-4836	the	abstract[235]	new[235]	appos	24-24[237_235]
24-15	4837-4844	popular	abstract[235]	new[235]	_	_
24-16	4845-4855	perception	abstract[235]	new[235]	_	_
24-17	4856-4858	of	abstract[235]	new[235]	_	_
24-18	4859-4869	algorithms	abstract[235]|abstract	new[235]|giv	coref	24-56
24-19	4870-4872	as	abstract[235]	new[235]	_	_
24-20	4873-4882	objective	abstract[235]	new[235]	_	_
24-21	4883-4886	and	abstract[235]	new[235]	_	_
24-22	4887-4891	fair	abstract[235]	new[235]	_	_
24-23	4892-4893	,	_	_	_	_
24-24	4894-4895	a	abstract[237]	giv[237]	_	_
24-25	4896-4903	problem	abstract[237]	giv[237]	_	_
24-26	4904-4912	referred	abstract[237]	giv[237]	_	_
24-27	4913-4915	to	abstract[237]	giv[237]	_	_
24-28	4916-4918	as	abstract[237]	giv[237]	_	_
24-29	4919-4920	“	abstract[237]	giv[237]	_	_
24-30	4921-4931	automation	abstract[237]|abstract|abstract[239]	giv[237]|new|giv[239]	_	_
24-31	4932-4936	bias	abstract[237]|abstract[239]	giv[237]|giv[239]	_	_
24-32	4937-4938	”	abstract[237]	giv[237]	_	_
24-33	4939-4942	and	_	_	_	_
24-34	4943-4946	the	abstract[240]	new[240]	_	_
24-35	4947-4956	seemingly	abstract[240]	new[240]	_	_
24-36	4957-4958	“	abstract[240]	new[240]	_	_
24-37	4959-4968	objective	abstract[240]	new[240]	_	_
24-38	4969-4970	”	abstract[240]	new[240]	_	_
24-39	4971-4983	correlations	abstract[240]	new[240]	_	_
24-40	4984-4988	that	abstract[240]	new[240]	_	_
24-41	4989-4992	the	abstract[240]|abstract[241]	new[240]|giv[241]	ana	24-48[0_241]
24-42	4993-5002	algorithm	abstract[240]|abstract[241]	new[240]|giv[241]	_	_
24-43	5003-5009	learns	abstract[240]	new[240]	_	_
24-44	5010-5014	from	abstract[240]	new[240]	_	_
24-45	5015-5018	the	abstract[240]|abstract[242]	new[240]|giv[242]	_	_
24-46	5019-5023	data	abstract[240]|abstract[242]	new[240]|giv[242]	_	_
24-47	5024-5029	makes	_	_	_	_
24-48	5030-5032	it	abstract	giv	_	_
24-49	5033-5042	difficult	_	_	_	_
24-50	5043-5045	to	_	_	_	_
24-51	5046-5053	legally	_	_	_	_
24-52	5054-5063	establish	_	_	_	_
24-53	5064-5078	discriminatory	abstract[244]	giv[244]	_	_
24-54	5079-5085	intent	abstract[244]	giv[244]	_	_
24-55	5086-5088	in	_	_	_	_
24-56	5089-5099	algorithms	abstract	giv	_	_
24-57	5100-5101	.	_	_	_	_

#Text=An emerging issue is the aggregation of individually biased outcomes when AVs with similar preferences are deployed on a large-scale , as doing so would centralise and replicate algorithmic preferences along with their individually biased risk allocation decisions .
25-1	5102-5104	An	abstract[246]	new[246]	coref	25-5[247_246]
25-2	5105-5113	emerging	abstract[246]	new[246]	_	_
25-3	5114-5119	issue	abstract[246]	new[246]	_	_
25-4	5120-5122	is	_	_	_	_
25-5	5123-5126	the	abstract[247]	giv[247]	ana	26-1[0_247]
25-6	5127-5138	aggregation	abstract[247]	giv[247]	_	_
25-7	5139-5141	of	abstract[247]	giv[247]	_	_
25-8	5142-5154	individually	abstract[247]|abstract[248]	giv[247]|giv[248]	coref	26-34[265_248]
25-9	5155-5161	biased	abstract[247]|abstract[248]	giv[247]|giv[248]	_	_
25-10	5162-5170	outcomes	abstract[247]|abstract[248]	giv[247]|giv[248]	_	_
25-11	5171-5175	when	_	_	_	_
25-12	5176-5179	AVs	abstract[249]	giv[249]	_	_
25-13	5180-5184	with	abstract[249]	giv[249]	_	_
25-14	5185-5192	similar	abstract[249]|abstract[250]	giv[249]|giv[250]	coref	25-29[251_250]
25-15	5193-5204	preferences	abstract[249]|abstract[250]	giv[249]|giv[250]	_	_
25-16	5205-5208	are	_	_	_	_
25-17	5209-5217	deployed	_	_	_	_
25-18	5218-5220	on	_	_	_	_
25-19	5221-5222	a	_	_	_	_
25-20	5223-5234	large-scale	_	_	_	_
25-21	5235-5236	,	_	_	_	_
25-22	5237-5239	as	_	_	_	_
25-23	5240-5245	doing	_	_	_	_
25-24	5246-5248	so	_	_	_	_
25-25	5249-5254	would	_	_	_	_
25-26	5255-5265	centralise	_	_	_	_
25-27	5266-5269	and	_	_	_	_
25-28	5270-5279	replicate	_	_	_	_
25-29	5280-5291	algorithmic	abstract[251]	giv[251]	_	_
25-30	5292-5303	preferences	abstract[251]	giv[251]	_	_
25-31	5304-5309	along	_	_	_	_
25-32	5310-5314	with	_	_	_	_
25-33	5315-5320	their	person|abstract[255]	giv|giv[255]	_	_
25-34	5321-5333	individually	abstract[255]	giv[255]	_	_
25-35	5334-5340	biased	abstract[255]	giv[255]	_	_
25-36	5341-5345	risk	abstract|abstract[254]|abstract[255]	new|new[254]|giv[255]	_	_
25-37	5346-5356	allocation	abstract[254]|abstract[255]	new[254]|giv[255]	_	_
25-38	5357-5366	decisions	abstract[255]	giv[255]	_	_
25-39	5367-5368	.	_	_	_	_

#Text=This could lead to the same groups of people being consistently allocated more safety risks and perpetuate systemic discrimination , which is more difficult to detect as it results from the accumulation of similar driving outcomes .
26-1	5369-5373	This	abstract	giv	ana	26-28
26-2	5374-5379	could	_	_	_	_
26-3	5380-5384	lead	_	_	_	_
26-4	5385-5387	to	_	_	_	_
26-5	5388-5391	the	person[257]	new[257]	_	_
26-6	5392-5396	same	person[257]	new[257]	_	_
26-7	5397-5403	groups	person[257]	new[257]	_	_
26-8	5404-5406	of	person[257]	new[257]	_	_
26-9	5407-5413	people	person[257]|person	new[257]|giv	_	_
26-10	5414-5419	being	_	_	_	_
26-11	5420-5432	consistently	_	_	_	_
26-12	5433-5442	allocated	_	_	_	_
26-13	5443-5447	more	abstract[260]	giv[260]	_	_
26-14	5448-5454	safety	abstract|abstract[260]	giv|giv[260]	_	_
26-15	5455-5460	risks	abstract[260]	giv[260]	_	_
26-16	5461-5464	and	_	_	_	_
26-17	5465-5475	perpetuate	_	_	_	_
26-18	5476-5484	systemic	abstract[261]	giv[261]	_	_
26-19	5485-5499	discrimination	abstract[261]	giv[261]	_	_
26-20	5500-5501	,	abstract[261]	giv[261]	_	_
26-21	5502-5507	which	abstract[261]	giv[261]	_	_
26-22	5508-5510	is	abstract[261]	giv[261]	_	_
26-23	5511-5515	more	abstract[261]	giv[261]	_	_
26-24	5516-5525	difficult	abstract[261]	giv[261]	_	_
26-25	5526-5528	to	abstract[261]	giv[261]	_	_
26-26	5529-5535	detect	abstract[261]	giv[261]	_	_
26-27	5536-5538	as	_	_	_	_
26-28	5539-5541	it	abstract	giv	_	_
26-29	5542-5549	results	_	_	_	_
26-30	5550-5554	from	_	_	_	_
26-31	5555-5558	the	event[263]	new[263]	_	_
26-32	5559-5571	accumulation	event[263]	new[263]	_	_
26-33	5572-5574	of	event[263]	new[263]	_	_
26-34	5575-5582	similar	event[263]|abstract[265]	new[263]|giv[265]	_	_
26-35	5583-5590	driving	event[263]|person|abstract[265]	new[263]|giv|giv[265]	_	_
26-36	5591-5599	outcomes	event[263]|abstract[265]	new[263]|giv[265]	_	_
26-37	5600-5601	.	_	_	_	_
