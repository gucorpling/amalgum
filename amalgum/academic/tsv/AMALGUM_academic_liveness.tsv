#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=2.
1-1	0-2	2.	_	_	_	_

#Text=Related Works
2-1	3-10	Related	abstract[1]	new[1]	_	_
2-2	11-16	Works	abstract[1]	new[1]	_	_

#Text=Face recognition has gradually become an important encryption and decryption method because of its rapidity , effectiveness , and user friendliness .
3-1	17-21	Face	object|abstract[3]	new|new[3]	ana|coref	3-14[0_3]|4-7
3-2	22-33	recognition	abstract[3]	new[3]	_	_
3-3	34-37	has	_	_	_	_
3-4	38-47	gradually	_	_	_	_
3-5	48-54	become	_	_	_	_
3-6	55-57	an	_	_	_	_
3-7	58-67	important	_	_	_	_
3-8	68-78	encryption	abstract	new	_	_
3-9	79-82	and	_	_	_	_
3-10	83-93	decryption	abstract	new	_	_
3-11	94-100	method	_	_	_	_
3-12	101-108	because	_	_	_	_
3-13	109-111	of	_	_	_	_
3-14	112-115	its	abstract	giv	coref	4-7[13_0]
3-15	116-124	rapidity	_	_	_	_
3-16	125-126	,	_	_	_	_
3-17	127-140	effectiveness	abstract	new	_	_
3-18	141-142	,	_	_	_	_
3-19	143-146	and	_	_	_	_
3-20	147-151	user	person|abstract[9]	new|new[9]	coref	6-10
3-21	152-164	friendliness	abstract[9]	new[9]	_	_
3-22	165-166	.	_	_	_	_

#Text=However , the security issues of face recognition technology are becoming increasingly prominent .
4-1	167-174	However	_	_	_	_
4-2	175-176	,	_	_	_	_
4-3	177-180	the	abstract[11]	new[11]	_	_
4-4	181-189	security	abstract|abstract[11]	new|new[11]	_	_
4-5	190-196	issues	abstract[11]	new[11]	_	_
4-6	197-199	of	abstract[11]	new[11]	_	_
4-7	200-204	face	abstract[11]|object|abstract[13]|abstract[14]	new[11]|giv|giv[13]|new[14]	coref|coref	6-11|8-7[32_13]
4-8	205-216	recognition	abstract[11]|abstract[13]|abstract[14]	new[11]|giv[13]|new[14]	_	_
4-9	217-227	technology	abstract[11]|abstract[14]	new[11]|new[14]	_	_
4-10	228-231	are	_	_	_	_
4-11	232-240	becoming	_	_	_	_
4-12	241-253	increasingly	_	_	_	_
4-13	254-263	prominent	_	_	_	_
4-14	264-265	.	_	_	_	_

#Text=Therefore , liveness detection has become an important part for reliable authentication systems .
5-1	266-275	Therefore	_	_	_	_
5-2	276-277	,	_	_	_	_
5-3	278-286	liveness	person|abstract[16]	new|new[16]	coref|coref	11-8|11-8[67_16]
5-4	287-296	detection	abstract[16]	new[16]	_	_
5-5	297-300	has	_	_	_	_
5-6	301-307	become	_	_	_	_
5-7	308-310	an	_	_	_	_
5-8	311-320	important	_	_	_	_
5-9	321-325	part	_	_	_	_
5-10	326-329	for	_	_	_	_
5-11	330-338	reliable	object[18]	new[18]	coref	8-5[33_18]
5-12	339-353	authentication	abstract|object[18]	new|new[18]	coref	6-23
5-13	354-361	systems	object[18]	new[18]	_	_
5-14	362-363	.	_	_	_	_

#Text=With the development of the Internet , criminals collect user face images from the Internet and produce fake faces to attack an authentication system .
6-1	364-368	With	_	_	_	_
6-2	369-372	the	event[19]	new[19]	_	_
6-3	373-384	development	event[19]	new[19]	_	_
6-4	385-387	of	event[19]	new[19]	_	_
6-5	388-391	the	event[19]|abstract[20]	new[19]|new[20]	coref	6-14[25_20]
6-6	392-400	Internet	event[19]|abstract[20]	new[19]|new[20]	_	_
6-7	401-402	,	_	_	_	_
6-8	403-412	criminals	person	new	_	_
6-9	413-420	collect	_	_	_	_
6-10	421-425	user	person|abstract[24]	giv|new[24]	coref	15-7
6-11	426-430	face	object|abstract[24]	giv|new[24]	coref	8-7
6-12	431-437	images	abstract[24]	new[24]	_	_
6-13	438-442	from	_	_	_	_
6-14	443-446	the	abstract[25]	giv[25]	_	_
6-15	447-455	Internet	abstract[25]	giv[25]	_	_
6-16	456-459	and	_	_	_	_
6-17	460-467	produce	_	_	_	_
6-18	468-472	fake	object[26]	new[26]	coref	9-1[47_26]
6-19	473-478	faces	object[26]	new[26]	_	_
6-20	479-481	to	_	_	_	_
6-21	482-488	attack	_	_	_	_
6-22	489-491	an	abstract[28]	new[28]	_	_
6-23	492-506	authentication	abstract|abstract[28]	giv|new[28]	coref	8-2[30_0]
6-24	507-513	system	abstract[28]	new[28]	_	_
6-25	514-515	.	_	_	_	_

#Text=Ref .
7-1	516-519	Ref	person	new	_	_
7-2	520-521	.	_	_	_	_

#Text=passed the authentication of six commercial face recognition systems , namely , Face Unlock , Facelock Pro , Visidon , Veriface , Luxand Blink , and FastAccess , by using photos of valid users .
8-1	522-528	passed	_	_	_	_
8-2	529-532	the	abstract[30]	giv[30]	coref	11-11[69_30]
8-3	533-547	authentication	abstract[30]	giv[30]	_	_
8-4	548-550	of	abstract[30]	giv[30]	_	_
8-5	551-554	six	abstract[30]|object[33]	giv[30]|giv[33]	appos	8-11[35_33]
8-6	555-565	commercial	abstract[30]|object[33]	giv[30]|giv[33]	_	_
8-7	566-570	face	abstract[30]|object|abstract[32]|object[33]	giv[30]|giv|giv[32]|giv[33]	coref|coref	9-20|11-21[74_32]
8-8	571-582	recognition	abstract[30]|abstract[32]|object[33]	giv[30]|giv[32]|giv[33]	_	_
8-9	583-590	systems	abstract[30]|object[33]	giv[30]|giv[33]	_	_
8-10	591-592	,	_	_	_	_
8-11	593-599	namely	object[35]|object[36]	giv[35]|giv[36]	appos|appos	8-11[36_35]|8-16[38_36]
8-12	600-601	,	object[35]|object[36]	giv[35]|giv[36]	_	_
8-13	602-606	Face	person|object[35]|object[36]	new|giv[35]|giv[36]	_	_
8-14	607-613	Unlock	object[35]|object[36]	giv[35]|giv[36]	_	_
8-15	614-615	,	object[36]	giv[36]	_	_
8-16	616-624	Facelock	object[36]|abstract|object[38]	giv[36]|new|giv[38]	appos	8-19[0_38]
8-17	625-628	Pro	object[36]|object[38]	giv[36]|giv[38]	_	_
8-18	629-630	,	object[36]	giv[36]	_	_
8-19	631-638	Visidon	object[36]|object	giv[36]|giv	appos	8-21
8-20	639-640	,	object[36]	giv[36]	_	_
8-21	641-649	Veriface	object[36]|object	giv[36]|giv	appos	8-23[42_0]
8-22	650-651	,	object[36]	giv[36]	_	_
8-23	652-658	Luxand	object[36]|place|object[42]	giv[36]|new|giv[42]	appos	8-27[0_42]
8-24	659-664	Blink	object[36]|object[42]	giv[36]|giv[42]	_	_
8-25	665-666	,	object[36]	giv[36]	_	_
8-26	667-670	and	object[36]	giv[36]	_	_
8-27	671-681	FastAccess	object[36]|object	giv[36]|giv	coref	11-11[70_0]
8-28	682-683	,	_	_	_	_
8-29	684-686	by	_	_	_	_
8-30	687-692	using	_	_	_	_
8-31	693-699	photos	object[44]	new[44]	coref	9-5[0_44]
8-32	700-702	of	object[44]	new[44]	_	_
8-33	703-708	valid	object[44]|person[45]	new[44]|new[45]	coref	14-10[0_45]
8-34	709-714	users	object[44]|person[45]	new[44]|new[45]	_	_
8-35	715-716	.	_	_	_	_

#Text=Common spoof faces include photos ( print ) , videos ( replay ) , masks , and synthetic 3D face models .
9-1	717-723	Common	object[47]	giv[47]	_	_
9-2	724-729	spoof	abstract|object[47]	new|giv[47]	coref	10-16
9-3	730-735	faces	object[47]	giv[47]	_	_
9-4	736-743	include	_	_	_	_
9-5	744-750	photos	object	giv	coref	10-4
9-6	751-752	(	_	_	_	_
9-7	753-758	print	abstract	new	_	_
9-8	759-760	)	_	_	_	_
9-9	761-762	,	_	_	_	_
9-10	763-769	videos	object	new	appos	9-12
9-11	770-771	(	_	_	_	_
9-12	772-778	replay	object	giv	coref	10-6
9-13	779-780	)	_	_	_	_
9-14	781-782	,	_	_	_	_
9-15	783-788	masks	object	new	_	_
9-16	789-790	,	_	_	_	_
9-17	791-794	and	_	_	_	_
9-18	795-804	synthetic	abstract[54]	new[54]	ana	10-2[0_54]
9-19	805-807	3D	abstract[54]	new[54]	_	_
9-20	808-812	face	object|abstract[54]	giv|new[54]	coref	11-21
9-21	813-819	models	abstract[54]	new[54]	_	_
9-22	820-821	.	_	_	_	_

#Text=Among them , photos and videos are 2D fake faces that are less expensive for spoof attacks and are the two most popular forms of deception .
10-1	822-827	Among	_	_	_	_
10-2	828-832	them	abstract	giv	_	_
10-3	833-834	,	_	_	_	_
10-4	835-841	photos	object|object[57]	giv|giv[57]	coref	10-4[57_0]
10-5	842-845	and	object[57]	giv[57]	_	_
10-6	846-852	videos	object[57]|object	giv[57]|giv	coref	10-8[59_0]
10-7	853-856	are	_	_	_	_
10-8	857-859	2D	object[59]|object[60]	giv[59]|giv[60]	coref|coref	10-8[60_59]|18-1[122_60]
10-9	860-864	fake	object[59]|object[60]	giv[59]|giv[60]	_	_
10-10	865-870	faces	object[59]|object[60]	giv[59]|giv[60]	_	_
10-11	871-875	that	object[59]|object[60]	giv[59]|giv[60]	_	_
10-12	876-879	are	object[59]|object[60]	giv[59]|giv[60]	_	_
10-13	880-884	less	object[59]|object[60]	giv[59]|giv[60]	_	_
10-14	885-894	expensive	object[59]|object[60]	giv[59]|giv[60]	_	_
10-15	895-898	for	object[59]|object[60]	giv[59]|giv[60]	_	_
10-16	899-904	spoof	object[59]|object[60]|abstract|abstract[62]	giv[59]|giv[60]|giv|new[62]	coref	18-9[126_62]
10-17	905-912	attacks	object[59]|object[60]|abstract[62]	giv[59]|giv[60]|new[62]	_	_
10-18	913-916	and	object[60]	giv[60]	_	_
10-19	917-920	are	object[60]	giv[60]	_	_
10-20	921-924	the	object[60]|abstract[63]	giv[60]|new[63]	coref	13-3[84_63]
10-21	925-928	two	object[60]|abstract[63]	giv[60]|new[63]	_	_
10-22	929-933	most	object[60]|abstract[63]	giv[60]|new[63]	_	_
10-23	934-941	popular	object[60]|abstract[63]	giv[60]|new[63]	_	_
10-24	942-947	forms	object[60]|abstract[63]	giv[60]|new[63]	_	_
10-25	948-950	of	object[60]|abstract[63]	giv[60]|new[63]	_	_
10-26	951-960	deception	object[60]|abstract[63]|abstract	giv[60]|new[63]|new	ana	11-3
10-27	961-962	.	_	_	_	_

#Text=Therefore , it is urgent to introduce liveness detection into identity authentication systems to improve the practicality and safety of face recognition .
11-1	963-972	Therefore	_	_	_	_
11-2	973-974	,	_	_	_	_
11-3	975-977	it	abstract	giv	_	_
11-4	978-980	is	_	_	_	_
11-5	981-987	urgent	_	_	_	_
11-6	988-990	to	_	_	_	_
11-7	991-1000	introduce	_	_	_	_
11-8	1001-1009	liveness	person|abstract[67]	giv|giv[67]	coref|coref	12-1|12-1[76_67]
11-9	1010-1019	detection	abstract[67]	giv[67]	_	_
11-10	1020-1024	into	_	_	_	_
11-11	1025-1033	identity	abstract|abstract[69]|object[70]	new|giv[69]|giv[70]	coref	12-6[79_70]
11-12	1034-1048	authentication	abstract[69]|object[70]	giv[69]|giv[70]	_	_
11-13	1049-1056	systems	object[70]	giv[70]	_	_
11-14	1057-1059	to	_	_	_	_
11-15	1060-1067	improve	_	_	_	_
11-16	1068-1071	the	abstract[71]	new[71]	_	_
11-17	1072-1084	practicality	abstract[71]	new[71]	_	_
11-18	1085-1088	and	_	_	_	_
11-19	1089-1095	safety	abstract[72]	new[72]	_	_
11-20	1096-1098	of	abstract[72]	new[72]	_	_
11-21	1099-1103	face	abstract[72]|object|abstract[74]	new[72]|giv|giv[74]	coref|coref	16-7|28-3[0_74]
11-22	1104-1115	recognition	abstract[72]|abstract[74]	new[72]|giv[74]	_	_
11-23	1116-1117	.	_	_	_	_

#Text=Liveness detection methods can obtain different classification systems depending on different classification criteria .
12-1	1118-1126	Liveness	person|abstract[76]|abstract[77]	giv|giv[76]|new[77]	coref|coref|coref	13-9|13-9[86_76]|13-7[87_77]
12-2	1127-1136	detection	abstract[76]|abstract[77]	giv[76]|new[77]	_	_
12-3	1137-1144	methods	abstract[77]	new[77]	_	_
12-4	1145-1148	can	_	_	_	_
12-5	1149-1155	obtain	_	_	_	_
12-6	1156-1165	different	object[79]	giv[79]	coref	27-8[185_79]
12-7	1166-1180	classification	abstract|object[79]	new|giv[79]	coref	12-12
12-8	1181-1188	systems	object[79]	giv[79]	_	_
12-9	1189-1198	depending	_	_	_	_
12-10	1199-1201	on	_	_	_	_
12-11	1202-1211	different	abstract[81]	new[81]	ana	13-3[0_81]
12-12	1212-1226	classification	abstract|abstract[81]	giv|new[81]	coref	29-19
12-13	1227-1235	criteria	abstract[81]	new[81]	_	_
12-14	1236-1237	.	_	_	_	_

#Text=According to their application forms , current mainstream liveness detection methods are divided into interactive and noninteractive categories .
13-1	1238-1247	According	_	_	_	_
13-2	1248-1250	to	_	_	_	_
13-3	1251-1256	their	abstract|abstract[84]	giv|giv[84]	_	_
13-4	1257-1268	application	abstract|abstract[84]	new|giv[84]	_	_
13-5	1269-1274	forms	abstract[84]	giv[84]	_	_
13-6	1275-1276	,	_	_	_	_
13-7	1277-1284	current	abstract[87]	giv[87]	coref	14-1[90_87]
13-8	1285-1295	mainstream	abstract[87]	giv[87]	_	_
13-9	1296-1304	liveness	person|abstract[86]|abstract[87]	giv|giv[86]|giv[87]	coref|coref	14-2[0_86]|17-2
13-10	1305-1314	detection	abstract[86]|abstract[87]	giv[86]|giv[87]	_	_
13-11	1315-1322	methods	abstract[87]	giv[87]	_	_
13-12	1323-1326	are	_	_	_	_
13-13	1327-1334	divided	_	_	_	_
13-14	1335-1339	into	_	_	_	_
13-15	1340-1351	interactive	abstract[88]	new[88]	coref	16-16[106_88]
13-16	1352-1355	and	abstract[88]	new[88]	_	_
13-17	1356-1370	noninteractive	abstract[88]	new[88]	_	_
13-18	1371-1381	categories	abstract[88]	new[88]	_	_
13-19	1382-1383	.	_	_	_	_

#Text=Interactive detection methods use action instructions to interact with users and require users to cooperate to complete certain actions .
14-1	1384-1395	Interactive	abstract[90]	giv[90]	coref	16-3[102_90]
14-2	1396-1405	detection	abstract|abstract[90]	giv|giv[90]	coref	15-13
14-3	1406-1413	methods	abstract[90]	giv[90]	_	_
14-4	1414-1417	use	_	_	_	_
14-5	1418-1424	action	abstract|abstract[92]	new|new[92]	_	_
14-6	1425-1437	instructions	abstract[92]	new[92]	_	_
14-7	1438-1440	to	_	_	_	_
14-8	1441-1449	interact	_	_	_	_
14-9	1450-1454	with	_	_	_	_
14-10	1455-1460	users	person	giv	coref	14-13
14-11	1461-1464	and	_	_	_	_
14-12	1465-1472	require	_	_	_	_
14-13	1473-1478	users	person	giv	_	_
14-14	1479-1481	to	_	_	_	_
14-15	1482-1491	cooperate	_	_	_	_
14-16	1492-1494	to	_	_	_	_
14-17	1495-1503	complete	_	_	_	_
14-18	1504-1511	certain	event[95]	new[95]	_	_
14-19	1512-1519	actions	event[95]	new[95]	_	_
14-20	1520-1521	.	_	_	_	_

#Text=The noninteractive method does not need user interactions and automatically completes the detection task .
15-1	1522-1525	The	abstract[96]	new[96]	coref	21-1[140_96]
15-2	1526-1540	noninteractive	abstract[96]	new[96]	_	_
15-3	1541-1547	method	abstract[96]	new[96]	_	_
15-4	1548-1552	does	_	_	_	_
15-5	1553-1556	not	_	_	_	_
15-6	1557-1561	need	_	_	_	_
15-7	1562-1566	user	person|abstract[98]	giv|new[98]	_	_
15-8	1567-1579	interactions	abstract[98]	new[98]	_	_
15-9	1580-1583	and	_	_	_	_
15-10	1584-1597	automatically	_	_	_	_
15-11	1598-1607	completes	_	_	_	_
15-12	1608-1611	the	abstract[100]	new[100]	_	_
15-13	1612-1621	detection	abstract|abstract[100]	giv|new[100]	coref	17-2[115_0]
15-14	1622-1626	task	abstract[100]	new[100]	_	_
15-15	1627-1628	.	_	_	_	_

#Text=According to the extraction methods of face features , these methods can be divided into two categories : manual feature extraction and automatic feature extraction using a deep learning network .
16-1	1629-1638	According	_	_	_	_
16-2	1639-1641	to	_	_	_	_
16-3	1642-1645	the	abstract[102]	giv[102]	coref	16-10[105_102]
16-4	1646-1656	extraction	abstract|abstract[102]	new|giv[102]	_	_
16-5	1657-1664	methods	abstract[102]	giv[102]	_	_
16-6	1665-1667	of	abstract[102]	giv[102]	_	_
16-7	1668-1672	face	abstract[102]|object|abstract[104]	giv[102]|giv|new[104]	coref|coref	17-18[121_104]|25-26
16-8	1673-1681	features	abstract[102]|abstract[104]	giv[102]|new[104]	_	_
16-9	1682-1683	,	_	_	_	_
16-10	1684-1689	these	abstract[105]	giv[105]	coref	17-1[116_105]
16-11	1690-1697	methods	abstract[105]	giv[105]	_	_
16-12	1698-1701	can	_	_	_	_
16-13	1702-1704	be	_	_	_	_
16-14	1705-1712	divided	_	_	_	_
16-15	1713-1717	into	_	_	_	_
16-16	1718-1721	two	abstract[106]	giv[106]	appos	16-19[108_106]
16-17	1722-1732	categories	abstract[106]	giv[106]	_	_
16-18	1733-1734	:	_	_	_	_
16-19	1735-1741	manual	abstract[108]|abstract[109]	giv[108]|giv[109]	appos|appos	16-19[109_108]|16-23[111_109]
16-20	1742-1749	feature	abstract|abstract[108]|abstract[109]	new|giv[108]|giv[109]	coref	16-24
16-21	1750-1760	extraction	abstract[108]|abstract[109]	giv[108]|giv[109]	_	_
16-22	1761-1764	and	abstract[109]	giv[109]	_	_
16-23	1765-1774	automatic	abstract[109]|abstract[111]	giv[109]|giv[111]	_	_
16-24	1775-1782	feature	abstract[109]|abstract|abstract[111]	giv[109]|giv|giv[111]	_	_
16-25	1783-1793	extraction	abstract[109]|abstract[111]	giv[109]|giv[111]	_	_
16-26	1794-1799	using	abstract[109]|abstract[111]	giv[109]|giv[111]	_	_
16-27	1800-1801	a	abstract[109]|abstract[111]|abstract[113]	giv[109]|giv[111]|new[113]	_	_
16-28	1802-1806	deep	abstract[109]|abstract[111]|abstract[112]|abstract[113]	giv[109]|giv[111]|new[112]|new[113]	coref	31-3[220_112]
16-29	1807-1815	learning	abstract[109]|abstract[111]|abstract[112]|abstract[113]	giv[109]|giv[111]|new[112]|new[113]	_	_
16-30	1816-1823	network	abstract[109]|abstract[111]|abstract[113]	giv[109]|giv[111]|new[113]	_	_
16-31	1824-1825	.	_	_	_	_

#Text=Common liveness detection methods are mainly based on texture , life information , different sensors , and deep features .
17-1	1826-1832	Common	abstract[116]	giv[116]	coref	20-1[135_116]
17-2	1833-1841	liveness	person|abstract[115]|abstract[116]	giv|giv[115]|giv[116]	coref|coref	21-2[0_115]|27-42
17-3	1842-1851	detection	abstract[115]|abstract[116]	giv[115]|giv[116]	_	_
17-4	1852-1859	methods	abstract[116]	giv[116]	_	_
17-5	1860-1863	are	_	_	_	_
17-6	1864-1870	mainly	_	_	_	_
17-7	1871-1876	based	_	_	_	_
17-8	1877-1879	on	_	_	_	_
17-9	1880-1887	texture	abstract	new	coref	21-6
17-10	1888-1889	,	_	_	_	_
17-11	1890-1894	life	abstract|abstract[119]	new|new[119]	coref|coref	24-5|33-6[250_119]
17-12	1895-1906	information	abstract[119]	new[119]	_	_
17-13	1907-1908	,	_	_	_	_
17-14	1909-1918	different	abstract[120]	new[120]	coref	27-5[182_120]
17-15	1919-1926	sensors	abstract[120]	new[120]	_	_
17-16	1927-1928	,	_	_	_	_
17-17	1929-1932	and	_	_	_	_
17-18	1933-1937	deep	abstract[121]	giv[121]	coref	24-5[157_121]
17-19	1938-1946	features	abstract[121]	giv[121]	_	_
17-20	1947-1948	.	_	_	_	_

#Text=Live faces have complex 3D structures , while photo and video attacks are 2D planar structures .
18-1	1949-1953	Live	object[122]	giv[122]	coref	20-11[138_122]
18-2	1954-1959	faces	object[122]	giv[122]	_	_
18-3	1960-1964	have	_	_	_	_
18-4	1965-1972	complex	abstract[123]	new[123]	_	_
18-5	1973-1975	3D	abstract[123]	new[123]	_	_
18-6	1976-1986	structures	abstract[123]	new[123]	_	_
18-7	1987-1988	,	_	_	_	_
18-8	1989-1994	while	_	_	_	_
18-9	1995-2000	photo	object|abstract[126]	new|giv[126]	coref	18-14[127_126]
18-10	2001-2004	and	abstract[126]	giv[126]	_	_
18-11	2005-2010	video	abstract|abstract[126]	new|giv[126]	coref	25-26[174_0]
18-12	2011-2018	attacks	abstract[126]	giv[126]	_	_
18-13	2019-2022	are	_	_	_	_
18-14	2023-2025	2D	abstract[127]	giv[127]	coref	19-7[131_127]
18-15	2026-2032	planar	abstract[127]	giv[127]	_	_
18-16	2033-2043	structures	abstract[127]	giv[127]	_	_
18-17	2044-2045	.	_	_	_	_

#Text=Different light reflections of surfaces from the 3D and 2D structures will exhibit differences in bright and dark areas of facial colors .
19-1	2046-2055	Different	abstract[129]	new[129]	_	_
19-2	2056-2061	light	abstract|abstract[129]	new|new[129]	coref	27-29
19-3	2062-2073	reflections	abstract[129]	new[129]	_	_
19-4	2074-2076	of	abstract[129]	new[129]	_	_
19-5	2077-2085	surfaces	abstract[129]|object	new[129]|new	_	_
19-6	2086-2090	from	abstract[129]	new[129]	_	_
19-7	2091-2094	the	abstract[129]|abstract[131]	new[129]|giv[131]	_	_
19-8	2095-2097	3D	abstract[129]|abstract[131]	new[129]|giv[131]	_	_
19-9	2098-2101	and	abstract[129]|abstract[131]	new[129]|giv[131]	_	_
19-10	2102-2104	2D	abstract[129]|abstract[131]	new[129]|giv[131]	_	_
19-11	2105-2115	structures	abstract[129]|abstract[131]	new[129]|giv[131]	_	_
19-12	2116-2120	will	_	_	_	_
19-13	2121-2128	exhibit	_	_	_	_
19-14	2129-2140	differences	abstract[132]	new[132]	coref	20-5[136_132]
19-15	2141-2143	in	abstract[132]	new[132]	_	_
19-16	2144-2150	bright	abstract[132]|place[133]	new[132]|new[133]	_	_
19-17	2151-2154	and	abstract[132]|place[133]	new[132]|new[133]	_	_
19-18	2155-2159	dark	abstract[132]|place[133]	new[132]|new[133]	_	_
19-19	2160-2165	areas	abstract[132]|place[133]	new[132]|new[133]	_	_
19-20	2166-2168	of	abstract[132]|place[133]	new[132]|new[133]	_	_
19-21	2169-2175	facial	abstract[132]|place[133]|abstract[134]	new[132]|new[133]|new[134]	_	_
19-22	2176-2182	colors	abstract[132]|place[133]|abstract[134]	new[132]|new[133]|new[134]	_	_
19-23	2183-2184	.	_	_	_	_

#Text=Texture-based methods mainly use these differences as clues to classify live and fake faces .
20-1	2185-2198	Texture-based	abstract[135]	giv[135]	coref	29-1[205_135]
20-2	2199-2206	methods	abstract[135]	giv[135]	_	_
20-3	2207-2213	mainly	_	_	_	_
20-4	2214-2217	use	_	_	_	_
20-5	2218-2223	these	abstract[136]	giv[136]	_	_
20-6	2224-2235	differences	abstract[136]	giv[136]	_	_
20-7	2236-2238	as	_	_	_	_
20-8	2239-2244	clues	abstract	new	_	_
20-9	2245-2247	to	_	_	_	_
20-10	2248-2256	classify	_	_	_	_
20-11	2257-2261	live	object[138]	giv[138]	coref	24-29[164_138]
20-12	2262-2265	and	object[138]	giv[138]	_	_
20-13	2266-2270	fake	object[138]	giv[138]	_	_
20-14	2271-2276	faces	object[138]	giv[138]	_	_
20-15	2277-2278	.	_	_	_	_

#Text=The detection method based on texture is implemented using Local Binary Pattern(LBP ) and improved LBP algorithms .
21-1	2279-2282	The	abstract[140]	giv[140]	coref	22-1[146_140]
21-2	2283-2292	detection	abstract|abstract[140]	giv|giv[140]	coref	25-11
21-3	2293-2299	method	abstract[140]	giv[140]	_	_
21-4	2300-2305	based	abstract[140]	giv[140]	_	_
21-5	2306-2308	on	abstract[140]	giv[140]	_	_
21-6	2309-2316	texture	abstract[140]|abstract	giv[140]|giv	_	_
21-7	2317-2319	is	_	_	_	_
21-8	2320-2331	implemented	_	_	_	_
21-9	2332-2337	using	_	_	_	_
21-10	2338-2343	Local	abstract[143]	new[143]	_	_
21-11	2344-2350	Binary	person|abstract[143]	new|new[143]	_	_
21-12	2351-2362	Pattern(LBP	abstract[143]	new[143]	_	_
21-13	2363-2364	)	_	_	_	_
21-14	2365-2368	and	_	_	_	_
21-15	2369-2377	improved	abstract[145]	new[145]	_	_
21-16	2378-2381	LBP	abstract|abstract[145]	new|new[145]	_	_
21-17	2382-2392	algorithms	abstract[145]	new[145]	_	_
21-18	2393-2394	.	_	_	_	_

#Text=This method has a low computational complexity and is easy to implement , but it is greatly influenced by hardware conditions .
22-1	2395-2399	This	abstract[146]	giv[146]	coref	24-1[155_146]
22-2	2400-2406	method	abstract[146]	giv[146]	_	_
22-3	2407-2410	has	_	_	_	_
22-4	2411-2412	a	abstract[147]	new[147]	ana	22-15[0_147]
22-5	2413-2416	low	abstract[147]	new[147]	_	_
22-6	2417-2430	computational	abstract[147]	new[147]	_	_
22-7	2431-2441	complexity	abstract[147]	new[147]	_	_
22-8	2442-2445	and	_	_	_	_
22-9	2446-2448	is	_	_	_	_
22-10	2449-2453	easy	_	_	_	_
22-11	2454-2456	to	_	_	_	_
22-12	2457-2466	implement	_	_	_	_
22-13	2467-2468	,	_	_	_	_
22-14	2469-2472	but	_	_	_	_
22-15	2473-2475	it	abstract	giv	_	_
22-16	2476-2478	is	_	_	_	_
22-17	2479-2486	greatly	_	_	_	_
22-18	2487-2497	influenced	_	_	_	_
22-19	2498-2500	by	_	_	_	_
22-20	2501-2509	hardware	abstract|abstract[150]	new|new[150]	coref|coref	25-2[166_150]|28-17[202_0]
22-21	2510-2520	conditions	abstract[150]	new[150]	_	_
22-22	2521-2522	.	_	_	_	_

#Text=The accuracy of the algorithm decreases when the image quality is low .
23-1	2523-2526	The	abstract[151]	new[151]	coref	25-9[169_151]
23-2	2527-2535	accuracy	abstract[151]	new[151]	_	_
23-3	2536-2538	of	abstract[151]	new[151]	_	_
23-4	2539-2542	the	abstract[151]|abstract[152]	new[151]|new[152]	_	_
23-5	2543-2552	algorithm	abstract[151]|abstract[152]	new[151]|new[152]	_	_
23-6	2553-2562	decreases	event	new	coref|none	32-10[232_0]|23-6[0_232]
23-7	2563-2567	when	_	_	_	_
23-8	2568-2571	the	abstract[154]	new[154]	_	_
23-9	2572-2577	image	abstract|abstract[154]	new|new[154]	coref	27-9
23-10	2578-2585	quality	abstract[154]	new[154]	_	_
23-11	2586-2588	is	_	_	_	_
23-12	2589-2592	low	_	_	_	_
23-13	2593-2594	.	_	_	_	_

#Text=The method based on life features uses vital signs , such as heartbeat , blood flow , blinking , and involuntary micromotion of facial muscles , to classify live and fake faces .
24-1	2595-2598	The	abstract[155]	giv[155]	coref	25-6[167_155]
24-2	2599-2605	method	abstract[155]	giv[155]	_	_
24-3	2606-2611	based	abstract[155]	giv[155]	_	_
24-4	2612-2614	on	abstract[155]	giv[155]	_	_
24-5	2615-2619	life	abstract[155]|abstract|abstract[157]	giv[155]|giv|giv[157]	coref|coref	25-14|25-14[171_157]
24-6	2620-2628	features	abstract[155]|abstract[157]	giv[155]|giv[157]	_	_
24-7	2629-2633	uses	_	_	_	_
24-8	2634-2639	vital	abstract[158]	new[158]	_	_
24-9	2640-2645	signs	abstract[158]	new[158]	_	_
24-10	2646-2647	,	abstract[158]	new[158]	_	_
24-11	2648-2652	such	abstract[158]	new[158]	_	_
24-12	2653-2655	as	abstract[158]	new[158]	_	_
24-13	2656-2665	heartbeat	abstract[158]|event	new[158]|new	_	_
24-14	2666-2667	,	abstract[158]	new[158]	_	_
24-15	2668-2673	blood	abstract[158]|event[160]	new[158]|new[160]	_	_
24-16	2674-2678	flow	abstract[158]|event[160]	new[158]|new[160]	_	_
24-17	2679-2680	,	abstract[158]	new[158]	_	_
24-18	2681-2689	blinking	abstract[158]|event	new[158]|new	_	_
24-19	2690-2691	,	abstract[158]	new[158]	_	_
24-20	2692-2695	and	abstract[158]	new[158]	_	_
24-21	2696-2707	involuntary	abstract[158]|abstract[162]	new[158]|new[162]	_	_
24-22	2708-2719	micromotion	abstract[158]|abstract[162]	new[158]|new[162]	_	_
24-23	2720-2722	of	abstract[158]|abstract[162]	new[158]|new[162]	_	_
24-24	2723-2729	facial	abstract[158]|abstract[162]|object[163]	new[158]|new[162]|new[163]	_	_
24-25	2730-2737	muscles	abstract[158]|abstract[162]|object[163]	new[158]|new[162]|new[163]	_	_
24-26	2738-2739	,	_	_	_	_
24-27	2740-2742	to	_	_	_	_
24-28	2743-2751	classify	_	_	_	_
24-29	2752-2756	live	object[164]	giv[164]	coref	26-9[179_164]
24-30	2757-2760	and	object[164]	giv[164]	_	_
24-31	2761-2765	fake	object[164]	giv[164]	_	_
24-32	2766-2771	faces	object[164]	giv[164]	_	_
24-33	2772-2773	.	_	_	_	_

#Text=Under the constraint conditions , this method has a high detection accuracy if life features can be extracted stably ; however , this method requires face video as the input and needs a large amount of computation .
25-1	2774-2779	Under	_	_	_	_
25-2	2780-2783	the	abstract[166]	giv[166]	_	_
25-3	2784-2794	constraint	abstract|abstract[166]	new|giv[166]	_	_
25-4	2795-2805	conditions	abstract[166]	giv[166]	_	_
25-5	2806-2807	,	_	_	_	_
25-6	2808-2812	this	abstract[167]	giv[167]	coref	25-23[172_167]
25-7	2813-2819	method	abstract[167]	giv[167]	_	_
25-8	2820-2823	has	_	_	_	_
25-9	2824-2825	a	abstract[169]	giv[169]	_	_
25-10	2826-2830	high	abstract[169]	giv[169]	_	_
25-11	2831-2840	detection	abstract|abstract[169]	giv|giv[169]	coref	27-42[197_0]
25-12	2841-2849	accuracy	abstract[169]	giv[169]	_	_
25-13	2850-2852	if	_	_	_	_
25-14	2853-2857	life	abstract|abstract[171]	giv|giv[171]	coref	29-5[206_171]
25-15	2858-2866	features	abstract[171]	giv[171]	_	_
25-16	2867-2870	can	_	_	_	_
25-17	2871-2873	be	_	_	_	_
25-18	2874-2883	extracted	_	_	_	_
25-19	2884-2890	stably	_	_	_	_
25-20	2891-2892	;	_	_	_	_
25-21	2893-2900	however	_	_	_	_
25-22	2901-2902	,	_	_	_	_
25-23	2903-2907	this	abstract[172]	giv[172]	coref	26-14[180_172]
25-24	2908-2914	method	abstract[172]	giv[172]	_	_
25-25	2915-2923	requires	_	_	_	_
25-26	2924-2928	face	object|abstract[174]	giv|giv[174]	coref	27-39
25-27	2929-2934	video	abstract[174]	giv[174]	_	_
25-28	2935-2937	as	_	_	_	_
25-29	2938-2941	the	abstract[175]	new[175]	_	_
25-30	2942-2947	input	abstract[175]	new[175]	_	_
25-31	2948-2951	and	_	_	_	_
25-32	2952-2957	needs	_	_	_	_
25-33	2958-2959	a	abstract[176]	new[176]	_	_
25-34	2960-2965	large	abstract[176]	new[176]	_	_
25-35	2966-2972	amount	abstract[176]	new[176]	_	_
25-36	2973-2975	of	abstract[176]	new[176]	_	_
25-37	2976-2987	computation	abstract[176]|abstract	new[176]|new	_	_
25-38	2988-2989	.	_	_	_	_

#Text=Even more unfortunately , the simulated micromotion of fake faces can also attack this method .
26-1	2990-2994	Even	_	_	_	_
26-2	2995-2999	more	_	_	_	_
26-3	3000-3013	unfortunately	_	_	_	_
26-4	3014-3015	,	_	_	_	_
26-5	3016-3019	the	abstract[178]	new[178]	_	_
26-6	3020-3029	simulated	abstract[178]	new[178]	_	_
26-7	3030-3041	micromotion	abstract[178]	new[178]	_	_
26-8	3042-3044	of	abstract[178]	new[178]	_	_
26-9	3045-3049	fake	abstract[178]|object[179]	new[178]|giv[179]	coref	31-11[222_179]
26-10	3050-3055	faces	abstract[178]|object[179]	new[178]|giv[179]	_	_
26-11	3056-3059	can	_	_	_	_
26-12	3060-3064	also	_	_	_	_
26-13	3065-3071	attack	_	_	_	_
26-14	3072-3076	this	abstract[180]	giv[180]	coref	27-1[181_180]
26-15	3077-3083	method	abstract[180]	giv[180]	_	_
26-16	3084-3085	.	_	_	_	_

#Text=The method based on different sensors adopts different image acquisition systems , such as a multispectral camera , an infrared camera , a deep camera , and a light field camera , to capture corresponding types of human face images for liveness detection .
27-1	3086-3089	The	abstract[181]	giv[181]	coref	28-6[200_181]
27-2	3090-3096	method	abstract[181]	giv[181]	_	_
27-3	3097-3102	based	abstract[181]	giv[181]	_	_
27-4	3103-3105	on	abstract[181]	giv[181]	_	_
27-5	3106-3115	different	abstract[181]|abstract[182]	giv[181]|giv[182]	_	_
27-6	3116-3123	sensors	abstract[181]|abstract[182]	giv[181]|giv[182]	_	_
27-7	3124-3130	adopts	_	_	_	_
27-8	3131-3140	different	object[185]	giv[185]	coref	32-6[231_185]
27-9	3141-3146	image	abstract|abstract[184]|object[185]	giv|new[184]|giv[185]	coref|coref	32-25|32-25[237_184]
27-10	3147-3158	acquisition	abstract[184]|object[185]	new[184]|giv[185]	_	_
27-11	3159-3166	systems	object[185]	giv[185]	_	_
27-12	3167-3168	,	object[185]	giv[185]	_	_
27-13	3169-3173	such	object[185]	giv[185]	_	_
27-14	3174-3176	as	object[185]	giv[185]	_	_
27-15	3177-3178	a	object[185]|object[186]	giv[185]|new[186]	_	_
27-16	3179-3192	multispectral	object[185]|object[186]	giv[185]|new[186]	_	_
27-17	3193-3199	camera	object[185]|object[186]	giv[185]|new[186]	_	_
27-18	3200-3201	,	object[185]	giv[185]	_	_
27-19	3202-3204	an	object[185]|object[188]	giv[185]|new[188]	_	_
27-20	3205-3213	infrared	object[185]|abstract|object[188]	giv[185]|new|new[188]	_	_
27-21	3214-3220	camera	object[185]|object[188]	giv[185]|new[188]	_	_
27-22	3221-3222	,	object[185]	giv[185]	_	_
27-23	3223-3224	a	object[185]|object[189]	giv[185]|new[189]	_	_
27-24	3225-3229	deep	object[185]|object[189]	giv[185]|new[189]	_	_
27-25	3230-3236	camera	object[185]|object[189]	giv[185]|new[189]	_	_
27-26	3237-3238	,	object[185]	giv[185]	_	_
27-27	3239-3242	and	object[185]	giv[185]	_	_
27-28	3243-3244	a	object[185]|object[192]	giv[185]|new[192]	coref	35-5[266_192]
27-29	3245-3250	light	object[185]|abstract|abstract[191]|object[192]	giv[185]|giv|new[191]|new[192]	_	_
27-30	3251-3256	field	object[185]|abstract[191]|object[192]	giv[185]|new[191]|new[192]	_	_
27-31	3257-3263	camera	object[185]|object[192]	giv[185]|new[192]	_	_
27-32	3264-3265	,	object[185]	giv[185]	_	_
27-33	3266-3268	to	object[185]	giv[185]	_	_
27-34	3269-3276	capture	object[185]	giv[185]	_	_
27-35	3277-3290	corresponding	object[185]|abstract[193]	giv[185]|new[193]	_	_
27-36	3291-3296	types	object[185]|abstract[193]	giv[185]|new[193]	_	_
27-37	3297-3299	of	object[185]|abstract[193]	giv[185]|new[193]	_	_
27-38	3300-3305	human	object[185]|abstract[193]|abstract[195]	giv[185]|new[193]|new[195]	coref	35-9[269_195]
27-39	3306-3310	face	object[185]|abstract[193]|object|abstract[195]	giv[185]|new[193]|giv|new[195]	coref	32-6
27-40	3311-3317	images	object[185]|abstract[193]|abstract[195]	giv[185]|new[193]|new[195]	_	_
27-41	3318-3321	for	object[185]	giv[185]	_	_
27-42	3322-3330	liveness	object[185]|person|abstract[197]	giv[185]|giv|giv[197]	coref|coref	31-16|31-15[224_197]
27-43	3331-3340	detection	object[185]|abstract[197]	giv[185]|giv[197]	_	_
27-44	3341-3342	.	_	_	_	_

#Text=The overall recognition accuracy of this method is high , but this method needs to add new hardware and , thus , increases the system cost .
28-1	3343-3346	The	abstract[199]	new[199]	_	_
28-2	3347-3354	overall	abstract[199]	new[199]	_	_
28-3	3355-3366	recognition	abstract|abstract[199]	giv|new[199]	coref	32-6[230_0]
28-4	3367-3375	accuracy	abstract[199]	new[199]	_	_
28-5	3376-3378	of	abstract[199]	new[199]	_	_
28-6	3379-3383	this	abstract[199]|abstract[200]	new[199]|giv[200]	coref	28-12[201_200]
28-7	3384-3390	method	abstract[199]|abstract[200]	new[199]|giv[200]	_	_
28-8	3391-3393	is	_	_	_	_
28-9	3394-3398	high	_	_	_	_
28-10	3399-3400	,	_	_	_	_
28-11	3401-3404	but	_	_	_	_
28-12	3405-3409	this	abstract[201]	giv[201]	_	_
28-13	3410-3416	method	abstract[201]	giv[201]	_	_
28-14	3417-3422	needs	_	_	_	_
28-15	3423-3425	to	_	_	_	_
28-16	3426-3429	add	_	_	_	_
28-17	3430-3433	new	abstract[202]	giv[202]	coref	32-16[0_202]
28-18	3434-3442	hardware	abstract[202]	giv[202]	_	_
28-19	3443-3446	and	_	_	_	_
28-20	3447-3448	,	_	_	_	_
28-21	3449-3453	thus	_	_	_	_
28-22	3454-3455	,	_	_	_	_
28-23	3456-3465	increases	_	_	_	_
28-24	3466-3469	the	abstract[204]	new[204]	_	_
28-25	3470-3476	system	abstract|abstract[204]	new|new[204]	_	_
28-26	3477-3481	cost	abstract[204]	new[204]	_	_
28-27	3482-3483	.	_	_	_	_

#Text=The methods based on deep features involve training of the initial CNN to extract depth features followed by classification .
29-1	3484-3487	The	abstract[205]	giv[205]	coref	30-1[212_205]
29-2	3488-3495	methods	abstract[205]	giv[205]	_	_
29-3	3496-3501	based	abstract[205]	giv[205]	_	_
29-4	3502-3504	on	abstract[205]	giv[205]	_	_
29-5	3505-3509	deep	abstract[205]|abstract[206]	giv[205]|giv[206]	coref	29-15[210_206]
29-6	3510-3518	features	abstract[205]|abstract[206]	giv[205]|giv[206]	_	_
29-7	3519-3526	involve	_	_	_	_
29-8	3527-3535	training	event[207]	new[207]	_	_
29-9	3536-3538	of	event[207]	new[207]	_	_
29-10	3539-3542	the	event[207]|organization[208]	new[207]|new[208]	_	_
29-11	3543-3550	initial	event[207]|organization[208]	new[207]|new[208]	_	_
29-12	3551-3554	CNN	event[207]|organization[208]	new[207]|new[208]	_	_
29-13	3555-3557	to	_	_	_	_
29-14	3558-3565	extract	_	_	_	_
29-15	3566-3571	depth	abstract|abstract[210]	new|giv[210]	coref|coref	30-14[0_210]|33-7
29-16	3572-3580	features	abstract[210]	giv[210]	_	_
29-17	3581-3589	followed	abstract[210]	giv[210]	_	_
29-18	3590-3592	by	abstract[210]	giv[210]	_	_
29-19	3593-3607	classification	abstract[210]|abstract	giv[210]|giv	_	_
29-20	3608-3609	.	_	_	_	_

#Text=These methods use pretrained ResNet-50 , VGG , and other models to extract features and 3D convolution to extract spatiotemporal deep features .
30-1	3610-3615	These	abstract[212]	giv[212]	_	_
30-2	3616-3623	methods	abstract[212]	giv[212]	_	_
30-3	3624-3627	use	_	_	_	_
30-4	3628-3638	pretrained	abstract[213]	new[213]	_	_
30-5	3639-3648	ResNet-50	abstract[213]	new[213]	_	_
30-6	3649-3650	,	_	_	_	_
30-7	3651-3654	VGG	abstract	new	_	_
30-8	3655-3656	,	_	_	_	_
30-9	3657-3660	and	_	_	_	_
30-10	3661-3666	other	abstract[215]	new[215]	_	_
30-11	3667-3673	models	abstract[215]	new[215]	_	_
30-12	3674-3676	to	_	_	_	_
30-13	3677-3684	extract	_	_	_	_
30-14	3685-3693	features	abstract	giv	coref	30-20[219_0]
30-15	3694-3697	and	_	_	_	_
30-16	3698-3700	3D	abstract|abstract[218]	new|new[218]	_	_
30-17	3701-3712	convolution	abstract[218]	new[218]	_	_
30-18	3713-3715	to	abstract[218]	new[218]	_	_
30-19	3716-3723	extract	abstract[218]	new[218]	_	_
30-20	3724-3738	spatiotemporal	abstract[218]|abstract[219]	new[218]|giv[219]	coref	31-7[221_219]
30-21	3739-3743	deep	abstract[218]|abstract[219]	new[218]|giv[219]	_	_
30-22	3744-3752	features	abstract[218]|abstract[219]	new[218]|giv[219]	_	_
30-23	3753-3754	.	_	_	_	_

#Text=Given that deep learning can extract high-level abstract features of human faces autonomously , noninteractive liveness detection using deep learning is a future development trend .
31-1	3755-3760	Given	abstract[227]	giv[227]	coref|coref	31-1[227_224]|33-1[247_227]
31-2	3761-3765	that	abstract[227]	giv[227]	_	_
31-3	3766-3770	deep	abstract[220]|abstract[227]	giv[220]|giv[227]	coref	31-19[225_220]
31-4	3771-3779	learning	abstract[220]|abstract[227]	giv[220]|giv[227]	_	_
31-5	3780-3783	can	abstract[227]	giv[227]	_	_
31-6	3784-3791	extract	abstract[227]	giv[227]	_	_
31-7	3792-3802	high-level	abstract[221]|abstract[227]	giv[221]|giv[227]	_	_
31-8	3803-3811	abstract	abstract[221]|abstract[227]	giv[221]|giv[227]	_	_
31-9	3812-3820	features	abstract[221]|abstract[227]	giv[221]|giv[227]	_	_
31-10	3821-3823	of	abstract[221]|abstract[227]	giv[221]|giv[227]	_	_
31-11	3824-3829	human	abstract[221]|object[222]|abstract[227]	giv[221]|giv[222]|giv[227]	coref	33-4[0_222]
31-12	3830-3835	faces	abstract[221]|object[222]|abstract[227]	giv[221]|giv[222]|giv[227]	_	_
31-13	3836-3848	autonomously	abstract[227]	giv[227]	_	_
31-14	3849-3850	,	abstract[227]	giv[227]	_	_
31-15	3851-3865	noninteractive	abstract[224]|abstract[227]	giv[224]|giv[227]	_	_
31-16	3866-3874	liveness	person|abstract[224]|abstract[227]	giv|giv[224]|giv[227]	coref	33-1
31-17	3875-3884	detection	abstract[224]|abstract[227]	giv[224]|giv[227]	_	_
31-18	3885-3890	using	abstract[224]|abstract[227]	giv[224]|giv[227]	_	_
31-19	3891-3895	deep	abstract[224]|abstract[225]|abstract[227]	giv[224]|giv[225]|giv[227]	_	_
31-20	3896-3904	learning	abstract[224]|abstract[225]|abstract[227]	giv[224]|giv[225]|giv[227]	_	_
31-21	3905-3907	is	abstract[227]	giv[227]	_	_
31-22	3908-3909	a	abstract[227]	giv[227]	_	_
31-23	3910-3916	future	abstract[227]	giv[227]	_	_
31-24	3917-3928	development	abstract|abstract[227]	new|giv[227]	_	_
31-25	3929-3934	trend	abstract[227]	giv[227]	_	_
31-26	3935-3936	.	_	_	_	_

#Text=With the gradual popularization of face recognition systems and the decrease in the price of hardware , it is necessary and worthy by adding image acquisition equipment into some important face authentication systems to improve the security and reliability of them .
32-1	3937-3941	With	_	_	_	_
32-2	3942-3945	the	event[228]	new[228]	_	_
32-3	3946-3953	gradual	event[228]	new[228]	_	_
32-4	3954-3968	popularization	event[228]	new[228]	_	_
32-5	3969-3971	of	event[228]	new[228]	_	_
32-6	3972-3976	face	event[228]|object|abstract[230]|object[231]	new[228]|giv|giv[230]|giv[231]	coref|coref	32-31|32-29[241_231]
32-7	3977-3988	recognition	event[228]|abstract[230]|object[231]	new[228]|giv[230]|giv[231]	_	_
32-8	3989-3996	systems	event[228]|object[231]	new[228]|giv[231]	_	_
32-9	3997-4000	and	_	_	_	_
32-10	4001-4004	the	event[232]	new[232]	_	_
32-11	4005-4013	decrease	event[232]	new[232]	_	_
32-12	4014-4016	in	event[232]	new[232]	_	_
32-13	4017-4020	the	event[232]|abstract[233]	new[232]|new[233]	_	_
32-14	4021-4026	price	event[232]|abstract[233]	new[232]|new[233]	_	_
32-15	4027-4029	of	event[232]|abstract[233]	new[232]|new[233]	_	_
32-16	4030-4038	hardware	event[232]|abstract[233]|abstract	new[232]|new[233]|giv	ana	32-18
32-17	4039-4040	,	_	_	_	_
32-18	4041-4043	it	abstract	giv	_	_
32-19	4044-4046	is	_	_	_	_
32-20	4047-4056	necessary	_	_	_	_
32-21	4057-4060	and	_	_	_	_
32-22	4061-4067	worthy	_	_	_	_
32-23	4068-4070	by	_	_	_	_
32-24	4071-4077	adding	_	_	_	_
32-25	4078-4083	image	abstract|abstract[237]|object[238]	giv|giv[237]|new[238]	_	_
32-26	4084-4095	acquisition	abstract[237]|object[238]	giv[237]|new[238]	_	_
32-27	4096-4105	equipment	object[238]	new[238]	_	_
32-28	4106-4110	into	_	_	_	_
32-29	4111-4115	some	object[241]	giv[241]	_	_
32-30	4116-4125	important	object[241]	giv[241]	_	_
32-31	4126-4130	face	object|abstract[240]|object[241]	giv|new[240]|giv[241]	_	_
32-32	4131-4145	authentication	abstract[240]|object[241]	new[240]|giv[241]	_	_
32-33	4146-4153	systems	object[241]	giv[241]	_	_
32-34	4154-4156	to	_	_	_	_
32-35	4157-4164	improve	_	_	_	_
32-36	4165-4168	the	abstract[242]|abstract[243]	new[242]|new[243]	ana	32-41[0_243]
32-37	4169-4177	security	abstract[242]|abstract[243]	new[242]|new[243]	_	_
32-38	4178-4181	and	abstract[243]	new[243]	_	_
32-39	4182-4193	reliability	abstract[243]|abstract[244]	new[243]|new[244]	_	_
32-40	4194-4196	of	abstract[243]|abstract[244]	new[243]|new[244]	_	_
32-41	4197-4201	them	abstract[243]|abstract[244]|abstract	new[243]|new[244]|giv	_	_
32-42	4202-4203	.	_	_	_	_

#Text=Liveness detection of faces using real depth information is not commonly used in biometrics technology and the literature .
33-1	4204-4212	Liveness	person|abstract[247]	giv|giv[247]	coref|coref	35-17|35-17[271_247]
33-2	4213-4222	detection	abstract[247]	giv[247]	_	_
33-3	4223-4225	of	abstract[247]	giv[247]	_	_
33-4	4226-4231	faces	abstract[247]|object	giv[247]|giv	_	_
33-5	4232-4237	using	abstract[247]	giv[247]	_	_
33-6	4238-4242	real	abstract[247]|abstract[250]	giv[247]|giv[250]	_	_
33-7	4243-4248	depth	abstract[247]|abstract|abstract[250]	giv[247]|giv|giv[250]	coref	34-23
33-8	4249-4260	information	abstract[247]|abstract[250]	giv[247]|giv[250]	_	_
33-9	4261-4263	is	_	_	_	_
33-10	4264-4267	not	_	_	_	_
33-11	4268-4276	commonly	_	_	_	_
33-12	4277-4281	used	_	_	_	_
33-13	4282-4284	in	_	_	_	_
33-14	4285-4295	biometrics	abstract|abstract[252]	new|new[252]	_	_
33-15	4296-4306	technology	abstract[252]	new[252]	_	_
33-16	4307-4310	and	_	_	_	_
33-17	4311-4314	the	abstract[253]	new[253]	_	_
33-18	4315-4325	literature	abstract[253]	new[253]	_	_
33-19	4326-4327	.	_	_	_	_

#Text=All publicly available datasets such as CASIA , NUAA , and PRINT-ATTACK DB are designed for 2D spoofing prevention , and no depth data are included in these datasets .
34-1	4328-4331	All	abstract[254]	new[254]	coref	34-28[263_254]
34-2	4332-4340	publicly	abstract[254]	new[254]	_	_
34-3	4341-4350	available	abstract[254]	new[254]	_	_
34-4	4351-4359	datasets	abstract[254]	new[254]	_	_
34-5	4360-4364	such	abstract[254]	new[254]	_	_
34-6	4365-4367	as	abstract[254]	new[254]	_	_
34-7	4368-4373	CASIA	abstract[254]|abstract	new[254]|new	_	_
34-8	4374-4375	,	abstract[254]	new[254]	_	_
34-9	4376-4380	NUAA	abstract[254]|abstract	new[254]|new	_	_
34-10	4381-4382	,	abstract[254]	new[254]	_	_
34-11	4383-4386	and	abstract[254]	new[254]	_	_
34-12	4387-4399	PRINT-ATTACK	abstract[254]|abstract|abstract[258]	new[254]|new|new[258]	_	_
34-13	4400-4402	DB	abstract[254]|abstract[258]	new[254]|new[258]	_	_
34-14	4403-4406	are	_	_	_	_
34-15	4407-4415	designed	_	_	_	_
34-16	4416-4419	for	_	_	_	_
34-17	4420-4422	2D	abstract[260]	new[260]	_	_
34-18	4423-4431	spoofing	abstract|abstract[260]	new|new[260]	_	_
34-19	4432-4442	prevention	abstract[260]	new[260]	_	_
34-20	4443-4444	,	_	_	_	_
34-21	4445-4448	and	_	_	_	_
34-22	4449-4451	no	abstract[262]	new[262]	_	_
34-23	4452-4457	depth	abstract|abstract[262]	giv|new[262]	_	_
34-24	4458-4462	data	abstract[262]	new[262]	_	_
34-25	4463-4466	are	_	_	_	_
34-26	4467-4475	included	_	_	_	_
34-27	4476-4478	in	_	_	_	_
34-28	4479-4484	these	abstract[263]	giv[263]	_	_
34-29	4485-4493	datasets	abstract[263]	giv[263]	_	_
34-30	4494-4495	.	_	_	_	_

#Text=Therefore , we adopted a Kinect camera acquiring real infrared radiation ( IR ) images for liveness detection .
35-1	4496-4505	Therefore	_	_	_	_
35-2	4506-4507	,	_	_	_	_
35-3	4508-4510	we	person	acc	_	_
35-4	4511-4518	adopted	_	_	_	_
35-5	4519-4520	a	object[266]	giv[266]	_	_
35-6	4521-4527	Kinect	abstract|object[266]	new|giv[266]	_	_
35-7	4528-4534	camera	object[266]	giv[266]	_	_
35-8	4535-4544	acquiring	object[266]	giv[266]	_	_
35-9	4545-4549	real	object[266]|abstract[269]	giv[266]|giv[269]	_	_
35-10	4550-4558	infrared	object[266]|abstract[267]|abstract[269]	giv[266]|new[267]|giv[269]	appos	35-13[0_267]
35-11	4559-4568	radiation	object[266]|abstract[267]|abstract[269]	giv[266]|new[267]|giv[269]	_	_
35-12	4569-4570	(	object[266]|abstract[269]	giv[266]|giv[269]	_	_
35-13	4571-4573	IR	object[266]|abstract|abstract[269]	giv[266]|giv|giv[269]	_	_
35-14	4574-4575	)	object[266]|abstract[269]	giv[266]|giv[269]	_	_
35-15	4576-4582	images	object[266]|abstract[269]	giv[266]|giv[269]	_	_
35-16	4583-4586	for	object[266]	giv[266]	_	_
35-17	4587-4595	liveness	object[266]|person|abstract[271]	giv[266]|giv|giv[271]	_	_
35-18	4596-4605	detection	object[266]|abstract[271]	giv[266]|giv[271]	_	_
35-19	4606-4607	.	_	_	_	_
