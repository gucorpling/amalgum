#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=2. Related Works
1-1	0-2	2.	_	_	_	_
1-2	3-10	Related	abstract[1]	new[1]	coref	2-14[7_1]
1-3	11-16	Works	abstract[1]	new[1]	_	_

#Text=In this section , we put our focus on the relevant introduction of the two mainstream camera-based works , i.e. , appearance-based methods and model-based methods .
2-1	17-19	In	_	_	_	_
2-2	20-24	this	abstract[2]	new[2]	_	_
2-3	25-32	section	abstract[2]	new[2]	_	_
2-4	33-34	,	_	_	_	_
2-5	35-37	we	person	acc	ana	2-7
2-6	38-41	put	_	_	_	_
2-7	42-45	our	person|abstract[5]	giv|new[5]	ana	3-1
2-8	46-51	focus	abstract[5]	new[5]	_	_
2-9	52-54	on	_	_	_	_
2-10	55-58	the	event[6]	new[6]	_	_
2-11	59-67	relevant	event[6]	new[6]	_	_
2-12	68-80	introduction	event[6]	new[6]	_	_
2-13	81-83	of	event[6]	new[6]	_	_
2-14	84-87	the	event[6]|abstract[7]	new[6]|giv[7]	appos	2-20[8_7]
2-15	88-91	two	event[6]|abstract[7]	new[6]|giv[7]	_	_
2-16	92-102	mainstream	event[6]|abstract[7]	new[6]|giv[7]	_	_
2-17	103-115	camera-based	event[6]|abstract[7]	new[6]|giv[7]	_	_
2-18	116-121	works	event[6]|abstract[7]	new[6]|giv[7]	_	_
2-19	122-123	,	_	_	_	_
2-20	124-128	i.e.	abstract[8]|abstract[9]	giv[8]|giv[9]	appos|appos	2-20[9_8]|2-25[10_9]
2-21	129-130	,	abstract[8]|abstract[9]	giv[8]|giv[9]	_	_
2-22	131-147	appearance-based	abstract[8]|abstract[9]	giv[8]|giv[9]	_	_
2-23	148-155	methods	abstract[8]|abstract[9]	giv[8]|giv[9]	_	_
2-24	156-159	and	abstract[9]	giv[9]	_	_
2-25	160-171	model-based	abstract[9]|abstract[10]	giv[9]|giv[10]	coref	3-5[12_10]
2-26	172-179	methods	abstract[9]|abstract[10]	giv[9]|giv[10]	_	_
2-27	180-181	.	_	_	_	_

#Text=We also briefly introduce some multi-model methods .
3-1	182-184	We	person	giv	ana	5-1
3-2	185-189	also	_	_	_	_
3-3	190-197	briefly	_	_	_	_
3-4	198-207	introduce	_	_	_	_
3-5	208-212	some	abstract[12]	giv[12]	coref	5-11[22_12]
3-6	213-224	multi-model	abstract[12]	giv[12]	_	_
3-7	225-232	methods	abstract[12]	giv[12]	_	_
3-8	233-234	.	_	_	_	_

#Text=Dipietro et al. have done elaborate research for all kinds of data gloves and relevant applications .
4-1	235-243	Dipietro	person	new	_	_
4-2	244-246	et	_	_	_	_
4-3	247-250	al.	_	_	_	_
4-4	251-255	have	_	_	_	_
4-5	256-260	done	_	_	_	_
4-6	261-270	elaborate	abstract[14]	new[14]	_	_
4-7	271-279	research	abstract[14]	new[14]	_	_
4-8	280-283	for	_	_	_	_
4-9	284-287	all	abstract[15]	new[15]	_	_
4-10	288-293	kinds	abstract[15]	new[15]	_	_
4-11	294-296	of	abstract[15]	new[15]	_	_
4-12	297-301	data	abstract[15]|abstract|abstract[17]	new[15]|new|new[17]	_	_
4-13	302-308	gloves	abstract[15]|abstract[17]	new[15]|new[17]	_	_
4-14	309-312	and	abstract[15]	new[15]	_	_
4-15	313-321	relevant	abstract[15]|abstract[18]	new[15]|new[18]	_	_
4-16	322-334	applications	abstract[15]|abstract[18]	new[15]|new[18]	_	_
4-17	335-336	.	_	_	_	_

#Text=We refer the readers to for a detailed review of glove-based works .
5-1	337-339	We	person	giv	ana	12-15
5-2	340-345	refer	_	_	_	_
5-3	346-349	the	person[20]	new[20]	coref	12-17[63_20]
5-4	350-357	readers	person[20]	new[20]	_	_
5-5	358-360	to	_	_	_	_
5-6	361-364	for	_	_	_	_
5-7	365-366	a	abstract[21]	new[21]	_	_
5-8	367-375	detailed	abstract[21]	new[21]	_	_
5-9	376-382	review	abstract[21]	new[21]	_	_
5-10	383-385	of	abstract[21]	new[21]	_	_
5-11	386-397	glove-based	abstract[21]|abstract[22]	new[21]|giv[22]	coref	6-2[23_22]
5-12	398-403	works	abstract[21]|abstract[22]	new[21]|giv[22]	_	_
5-13	404-405	.	_	_	_	_

#Text=2.1. Appearance-Based Methods
6-1	406-410	2.1.	_	_	_	_
6-2	411-427	Appearance-Based	abstract[23]	giv[23]	coref	7-1[24_23]
6-3	428-435	Methods	abstract[23]	giv[23]	_	_

#Text=Appearance-based methods train a classifier or a regressor to map image features to hand poses .
7-1	436-452	Appearance-based	abstract[24]	giv[24]	coref	8-11[35_24]
7-2	453-460	methods	abstract[24]	giv[24]	_	_
7-3	461-466	train	_	_	_	_
7-4	467-468	a	abstract[25]	new[25]	_	_
7-5	469-479	classifier	abstract[25]	new[25]	_	_
7-6	480-482	or	_	_	_	_
7-7	483-484	a	abstract[26]	new[26]	_	_
7-8	485-494	regressor	abstract[26]	new[26]	_	_
7-9	495-497	to	_	_	_	_
7-10	498-501	map	_	_	_	_
7-11	502-507	image	object|abstract[28]	new|new[28]	coref	27-15
7-12	508-516	features	abstract[28]	new[28]	_	_
7-13	517-519	to	_	_	_	_
7-14	520-524	hand	object|abstract[30]	new|new[30]	coref	11-7
7-15	525-530	poses	abstract[30]	new[30]	_	_
7-16	531-532	.	_	_	_	_

#Text=Nearest neighbor search and decision trees are widely used in early works .
8-1	533-540	Nearest	person[31]|abstract[32]	new[31]|new[32]	_	_
8-2	541-549	neighbor	person[31]|abstract[32]	new[31]|new[32]	_	_
8-3	550-556	search	abstract[32]	new[32]	_	_
8-4	557-560	and	_	_	_	_
8-5	561-569	decision	event|abstract[34]	new|new[34]	_	_
8-6	570-575	trees	abstract[34]	new[34]	_	_
8-7	576-579	are	_	_	_	_
8-8	580-586	widely	_	_	_	_
8-9	587-591	used	_	_	_	_
8-10	592-594	in	_	_	_	_
8-11	595-600	early	abstract[35]	giv[35]	coref	9-5[40_35]
8-12	601-606	works	abstract[35]	giv[35]	_	_
8-13	607-608	.	_	_	_	_

#Text=In recent years , convolutional neural network ( CNN)-based discriminative methods are state-of-the-art which estimate 3D joint positions directly from depth images .
9-1	609-611	In	_	_	_	_
9-2	612-618	recent	time[36]	new[36]	_	_
9-3	619-624	years	time[36]	new[36]	_	_
9-4	625-626	,	_	_	_	_
9-5	627-640	convolutional	abstract[38]|abstract[40]	new[38]|giv[40]	appos|coref	9-9[0_38]|13-5[65_40]
9-6	641-647	neural	abstract|abstract[38]|abstract[40]	new|new[38]|giv[40]	_	_
9-7	648-655	network	abstract[38]|abstract[40]	new[38]|giv[40]	_	_
9-8	656-657	(	abstract[40]	giv[40]	_	_
9-9	658-668	CNN)-based	abstract|abstract[40]	giv|giv[40]	_	_
9-10	669-683	discriminative	abstract[40]	giv[40]	_	_
9-11	684-691	methods	abstract[40]	giv[40]	_	_
9-12	692-695	are	_	_	_	_
9-13	696-712	state-of-the-art	_	_	_	_
9-14	713-718	which	_	_	_	_
9-15	719-727	estimate	_	_	_	_
9-16	728-730	3D	abstract[41]	new[41]	coref	11-17[54_41]
9-17	731-736	joint	abstract[41]	new[41]	_	_
9-18	737-746	positions	abstract[41]	new[41]	_	_
9-19	747-755	directly	_	_	_	_
9-20	756-760	from	_	_	_	_
9-21	761-766	depth	abstract|abstract[43]	new|new[43]	coref	19-27
9-22	767-773	images	abstract[43]	new[43]	_	_
9-23	774-775	.	_	_	_	_

#Text=Besides , kinematics and geometric constraints are considered to avoid joint estimations violating kinematic constraints .
10-1	776-783	Besides	_	_	_	_
10-2	784-785	,	_	_	_	_
10-3	786-796	kinematics	abstract	new	coref	19-16[88_0]
10-4	797-800	and	_	_	_	_
10-5	801-810	geometric	_	_	_	_
10-6	811-822	constraints	abstract	new	coref	10-14[47_0]
10-7	823-826	are	_	_	_	_
10-8	827-837	considered	_	_	_	_
10-9	838-840	to	_	_	_	_
10-10	841-846	avoid	_	_	_	_
10-11	847-852	joint	abstract[46]	new[46]	_	_
10-12	853-864	estimations	abstract[46]	new[46]	_	_
10-13	865-874	violating	abstract[46]	new[46]	_	_
10-14	875-884	kinematic	abstract[46]|abstract[47]	new[46]|giv[47]	_	_
10-15	885-896	constraints	abstract[46]|abstract[47]	new[46]|giv[47]	_	_
10-16	897-898	.	_	_	_	_

#Text=Malik et al. embedded a novel hand pose and shape layer inside CNN to produce not only 3D joint positions but also hand mesh information .
11-1	899-904	Malik	person	new	_	_
11-2	905-907	et	_	_	_	_
11-3	908-911	al.	_	_	_	_
11-4	912-920	embedded	_	_	_	_
11-5	921-922	a	abstract[52]	new[52]	_	_
11-6	923-928	novel	abstract[52]	new[52]	_	_
11-7	929-933	hand	object|abstract[50]|abstract[52]	giv|new[50]|new[52]	coref|coref	11-23|29-18[0_50]
11-8	934-938	pose	abstract[50]|abstract[52]	new[50]|new[52]	_	_
11-9	939-942	and	abstract[52]	new[52]	_	_
11-10	943-948	shape	abstract|abstract[52]	new|new[52]	_	_
11-11	949-954	layer	abstract[52]	new[52]	_	_
11-12	955-961	inside	_	_	_	_
11-13	962-965	CNN	object	new	_	_
11-14	966-968	to	_	_	_	_
11-15	969-976	produce	_	_	_	_
11-16	977-980	not	_	_	_	_
11-17	981-985	only	abstract[54]|abstract[55]	giv[54]|giv[55]	coref	11-17[55_54]
11-18	986-988	3D	abstract[54]|abstract[55]	giv[54]|giv[55]	_	_
11-19	989-994	joint	abstract[54]|abstract[55]	giv[54]|giv[55]	_	_
11-20	995-1004	positions	abstract[54]|abstract[55]	giv[54]|giv[55]	_	_
11-21	1005-1008	but	abstract[55]	giv[55]	_	_
11-22	1009-1013	also	abstract[55]	giv[55]	_	_
11-23	1014-1018	hand	abstract[55]|object|object[57]|abstract[58]	giv[55]|giv|new[57]|new[58]	coref	14-13
11-24	1019-1023	mesh	abstract[55]|object[57]|abstract[58]	giv[55]|new[57]|new[58]	_	_
11-25	1024-1035	information	abstract[55]|abstract[58]	giv[55]|new[58]	_	_
11-26	1036-1037	.	_	_	_	_

#Text=For a more comprehensive analysis and investigation of the state-of-the-art along-with future challenges , we refer the readers to .
12-1	1038-1041	For	_	_	_	_
12-2	1042-1043	a	abstract[59]	new[59]	coref	15-5[72_59]
12-3	1044-1048	more	abstract[59]	new[59]	_	_
12-4	1049-1062	comprehensive	abstract[59]	new[59]	_	_
12-5	1063-1071	analysis	abstract[59]	new[59]	_	_
12-6	1072-1075	and	_	_	_	_
12-7	1076-1089	investigation	abstract[60]	new[60]	_	_
12-8	1090-1092	of	abstract[60]	new[60]	_	_
12-9	1093-1096	the	abstract[60]	new[60]	_	_
12-10	1097-1113	state-of-the-art	abstract[60]	new[60]	_	_
12-11	1114-1124	along-with	abstract[60]	new[60]	_	_
12-12	1125-1131	future	abstract[60]|abstract[61]	new[60]|new[61]	_	_
12-13	1132-1142	challenges	abstract[60]|abstract[61]	new[60]|new[61]	_	_
12-14	1143-1144	,	_	_	_	_
12-15	1145-1147	we	person	giv	ana	15-1
12-16	1148-1153	refer	_	_	_	_
12-17	1154-1157	the	person[63]	giv[63]	_	_
12-18	1158-1165	readers	person[63]	giv[63]	_	_
12-19	1166-1168	to	_	_	_	_
12-20	1169-1170	.	_	_	_	_

#Text=The biggest limitation of appearance-based methods is the training data .
13-1	1171-1174	The	abstract[64]	new[64]	coref	13-8[67_64]
13-2	1175-1182	biggest	abstract[64]	new[64]	_	_
13-3	1183-1193	limitation	abstract[64]	new[64]	_	_
13-4	1194-1196	of	abstract[64]	new[64]	_	_
13-5	1197-1213	appearance-based	abstract[64]|abstract[65]	new[64]|giv[65]	coref	18-1[81_65]
13-6	1214-1221	methods	abstract[64]|abstract[65]	new[64]|giv[65]	_	_
13-7	1222-1224	is	_	_	_	_
13-8	1225-1228	the	abstract[67]	giv[67]	coref	16-2[75_67]
13-9	1229-1237	training	abstract|abstract[67]	new|giv[67]	coref	29-12
13-10	1238-1242	data	abstract[67]	giv[67]	_	_
13-11	1243-1244	.	_	_	_	_

#Text=Existing benchmarks are not perfect enough to ensure well generalize to unseen hand shapes .
14-1	1245-1253	Existing	abstract[68]	new[68]	_	_
14-2	1254-1264	benchmarks	abstract[68]	new[68]	_	_
14-3	1265-1268	are	_	_	_	_
14-4	1269-1272	not	_	_	_	_
14-5	1273-1280	perfect	_	_	_	_
14-6	1281-1287	enough	_	_	_	_
14-7	1288-1290	to	_	_	_	_
14-8	1291-1297	ensure	_	_	_	_
14-9	1298-1302	well	_	_	_	_
14-10	1303-1313	generalize	_	_	_	_
14-11	1314-1316	to	_	_	_	_
14-12	1317-1323	unseen	abstract[70]	new[70]	_	_
14-13	1324-1328	hand	object|abstract[70]	giv|new[70]	coref	19-7
14-14	1329-1335	shapes	abstract[70]	new[70]	_	_
14-15	1336-1337	.	_	_	_	_

#Text=We refer to for a detailed analysis of the drawbacks of existing data-sets .
15-1	1338-1340	We	person	giv	ana	16-5
15-2	1341-1346	refer	_	_	_	_
15-3	1347-1349	to	_	_	_	_
15-4	1350-1353	for	_	_	_	_
15-5	1354-1355	a	abstract[72]	giv[72]	_	_
15-6	1356-1364	detailed	abstract[72]	giv[72]	_	_
15-7	1365-1373	analysis	abstract[72]	giv[72]	_	_
15-8	1374-1376	of	abstract[72]	giv[72]	_	_
15-9	1377-1380	the	abstract[72]|abstract[73]	giv[72]|new[73]	_	_
15-10	1381-1390	drawbacks	abstract[72]|abstract[73]	giv[72]|new[73]	_	_
15-11	1391-1393	of	abstract[72]|abstract[73]	giv[72]|new[73]	_	_
15-12	1394-1402	existing	abstract[72]|abstract[73]|abstract[74]	giv[72]|new[73]|new[74]	coref	16-16[79_74]
15-13	1403-1412	data-sets	abstract[72]|abstract[73]|abstract[74]	giv[72]|new[73]|new[74]	_	_
15-14	1413-1414	.	_	_	_	_

#Text=Considering this limitation , our system follows the model-based approaches that do not rely on massive data-sets .
16-1	1415-1426	Considering	_	_	_	_
16-2	1427-1431	this	abstract[75]	giv[75]	coref	19-27[93_75]
16-3	1432-1442	limitation	abstract[75]	giv[75]	_	_
16-4	1443-1444	,	_	_	_	_
16-5	1445-1448	our	person|abstract[77]	giv|new[77]	ana|coref	33-2|33-2[169_77]
16-6	1449-1455	system	abstract[77]	new[77]	_	_
16-7	1456-1463	follows	_	_	_	_
16-8	1464-1467	the	abstract[78]	new[78]	_	_
16-9	1468-1479	model-based	abstract[78]	new[78]	_	_
16-10	1480-1490	approaches	abstract[78]	new[78]	_	_
16-11	1491-1495	that	abstract[78]	new[78]	_	_
16-12	1496-1498	do	abstract[78]	new[78]	_	_
16-13	1499-1502	not	abstract[78]	new[78]	_	_
16-14	1503-1507	rely	abstract[78]	new[78]	_	_
16-15	1508-1510	on	abstract[78]	new[78]	_	_
16-16	1511-1518	massive	abstract[78]|abstract[79]	new[78]|giv[79]	coref	32-9[164_79]
16-17	1519-1528	data-sets	abstract[78]|abstract[79]	new[78]|giv[79]	_	_
16-18	1529-1530	.	_	_	_	_

#Text=2.2.
17-1	1531-1535	2.2.	abstract	new	_	_

#Text=Model-Based Methods
18-1	1536-1547	Model-Based	abstract[81]	giv[81]	coref	20-6[97_81]
18-2	1548-1555	Methods	abstract[81]	giv[81]	_	_

#Text=Despite the considerable advance in learning-based hand tracking , systems that employ generative models of explicit hand kinematics and surface geometry and fit these models to depth data using local optimization have produced the most compelling results .
19-1	1556-1563	Despite	_	_	_	_
19-2	1564-1567	the	abstract[82]	new[82]	_	_
19-3	1568-1580	considerable	abstract[82]	new[82]	_	_
19-4	1581-1588	advance	abstract[82]	new[82]	_	_
19-5	1589-1591	in	abstract[82]	new[82]	_	_
19-6	1592-1606	learning-based	abstract[82]|abstract[84]	new[82]|new[84]	coref	32-21[0_84]
19-7	1607-1611	hand	abstract[82]|object|abstract[84]	new[82]|giv|new[84]	coref	19-17
19-8	1612-1620	tracking	abstract[82]|abstract[84]	new[82]|new[84]	_	_
19-9	1621-1622	,	_	_	_	_
19-10	1623-1630	systems	abstract[85]	new[85]	_	_
19-11	1631-1635	that	abstract[85]	new[85]	_	_
19-12	1636-1642	employ	abstract[85]	new[85]	_	_
19-13	1643-1653	generative	abstract[85]|abstract[86]	new[85]|new[86]	coref	19-24[91_86]
19-14	1654-1660	models	abstract[85]|abstract[86]	new[85]|new[86]	_	_
19-15	1661-1663	of	abstract[85]|abstract[86]	new[85]|new[86]	_	_
19-16	1664-1672	explicit	abstract[85]|abstract[86]|abstract[88]	new[85]|new[86]|giv[88]	_	_
19-17	1673-1677	hand	abstract[85]|abstract[86]|object|abstract[88]	new[85]|new[86]|giv|giv[88]	coref	20-18
19-18	1678-1688	kinematics	abstract[85]|abstract[86]|abstract[88]	new[85]|new[86]|giv[88]	_	_
19-19	1689-1692	and	abstract[85]|abstract[86]	new[85]|new[86]	_	_
19-20	1693-1700	surface	abstract[85]|abstract[86]|place|abstract[90]	new[85]|new[86]|new|new[90]	_	_
19-21	1701-1709	geometry	abstract[85]|abstract[86]|abstract[90]	new[85]|new[86]|new[90]	_	_
19-22	1710-1713	and	abstract[85]	new[85]	_	_
19-23	1714-1717	fit	abstract[85]	new[85]	_	_
19-24	1718-1723	these	abstract[85]|abstract[91]	new[85]|giv[91]	coref	37-1[188_91]
19-25	1724-1730	models	abstract[85]|abstract[91]	new[85]|giv[91]	_	_
19-26	1731-1733	to	_	_	_	_
19-27	1734-1739	depth	abstract|abstract[93]	giv|giv[93]	coref	20-35[108_93]
19-28	1740-1744	data	abstract[93]	giv[93]	_	_
19-29	1745-1750	using	abstract[93]	giv[93]	_	_
19-30	1751-1756	local	abstract[93]|abstract[94]	giv[93]|new[94]	_	_
19-31	1757-1769	optimization	abstract[93]|abstract[94]	giv[93]|new[94]	_	_
19-32	1770-1774	have	_	_	_	_
19-33	1775-1783	produced	_	_	_	_
19-34	1784-1787	the	abstract[95]	new[95]	coref	35-15[181_95]
19-35	1788-1792	most	abstract[95]	new[95]	_	_
19-36	1793-1803	compelling	abstract[95]	new[95]	_	_
19-37	1804-1811	results	abstract[95]	new[95]	_	_
19-38	1812-1813	.	_	_	_	_

#Text=The most common problems for model-based methods are a good enough initialization point , an expressive enough hand model and a discriminative object function that minimizes the error between the 3D hand model and the observed data .
20-1	1814-1817	The	abstract[96]	new[96]	coref	20-9[99_96]
20-2	1818-1822	most	abstract[96]	new[96]	_	_
20-3	1823-1829	common	abstract[96]	new[96]	_	_
20-4	1830-1838	problems	abstract[96]	new[96]	_	_
20-5	1839-1842	for	abstract[96]	new[96]	_	_
20-6	1843-1854	model-based	abstract[96]|abstract[97]	new[96]|giv[97]	coref	23-3[115_97]
20-7	1855-1862	methods	abstract[96]|abstract[97]	new[96]|giv[97]	_	_
20-8	1863-1866	are	_	_	_	_
20-9	1867-1868	a	abstract[99]|abstract[100]	giv[99]|giv[100]	coref	20-9[100_99]
20-10	1869-1873	good	abstract[99]|abstract[100]	giv[99]|giv[100]	_	_
20-11	1874-1880	enough	abstract[99]|abstract[100]	giv[99]|giv[100]	_	_
20-12	1881-1895	initialization	abstract|abstract[99]|abstract[100]	new|giv[99]|giv[100]	coref	21-2
20-13	1896-1901	point	abstract[99]|abstract[100]	giv[99]|giv[100]	_	_
20-14	1902-1903	,	abstract[100]	giv[100]	_	_
20-15	1904-1906	an	abstract[100]|abstract[102]	giv[100]|new[102]	coref	20-30[107_102]
20-16	1907-1917	expressive	abstract[100]|abstract[102]	giv[100]|new[102]	_	_
20-17	1918-1924	enough	abstract[100]|abstract[102]	giv[100]|new[102]	_	_
20-18	1925-1929	hand	abstract[100]|object|abstract[102]	giv[100]|giv|new[102]	coref	20-32
20-19	1930-1935	model	abstract[100]|abstract[102]	giv[100]|new[102]	_	_
20-20	1936-1939	and	abstract[100]	giv[100]	_	_
20-21	1940-1941	a	abstract[100]|abstract[104]	giv[100]|new[104]	_	_
20-22	1942-1956	discriminative	abstract[100]|abstract[104]	giv[100]|new[104]	_	_
20-23	1957-1963	object	abstract[100]|abstract|abstract[104]	giv[100]|new|new[104]	_	_
20-24	1964-1972	function	abstract[100]|abstract[104]	giv[100]|new[104]	_	_
20-25	1973-1977	that	abstract[100]|abstract[104]	giv[100]|new[104]	_	_
20-26	1978-1987	minimizes	abstract[100]|abstract[104]	giv[100]|new[104]	_	_
20-27	1988-1991	the	abstract[100]|abstract[104]|abstract[105]	giv[100]|new[104]|new[105]	_	_
20-28	1992-1997	error	abstract[100]|abstract[104]|abstract[105]	giv[100]|new[104]|new[105]	_	_
20-29	1998-2005	between	abstract[100]|abstract[104]|abstract[105]	giv[100]|new[104]|new[105]	_	_
20-30	2006-2009	the	abstract[100]|abstract[104]|abstract[105]|abstract[107]	giv[100]|new[104]|new[105]|giv[107]	coref	31-12[160_107]
20-31	2010-2012	3D	abstract[100]|abstract[104]|abstract[105]|abstract[107]	giv[100]|new[104]|new[105]|giv[107]	_	_
20-32	2013-2017	hand	abstract[100]|abstract[104]|abstract[105]|object|abstract[107]	giv[100]|new[104]|new[105]|giv|giv[107]	coref	26-21
20-33	2018-2023	model	abstract[100]|abstract[104]|abstract[105]|abstract[107]	giv[100]|new[104]|new[105]|giv[107]	_	_
20-34	2024-2027	and	abstract[100]|abstract[104]|abstract[105]	giv[100]|new[104]|new[105]	_	_
20-35	2028-2031	the	abstract[100]|abstract[104]|abstract[105]|abstract[108]	giv[100]|new[104]|new[105]|giv[108]	coref	27-13[134_108]
20-36	2032-2040	observed	abstract[100]|abstract[104]|abstract[105]|abstract[108]	giv[100]|new[104]|new[105]|giv[108]	_	_
20-37	2041-2045	data	abstract[100]|abstract[104]|abstract[105]|abstract[108]	giv[100]|new[104]|new[105]|giv[108]	_	_
20-38	2046-2047	.	_	_	_	_

#Text=2.2.1. Initialization
21-1	2048-2054	2.2.1.	_	_	_	_
21-2	2055-2069	Initialization	abstract	giv	coref	22-1[110_0]

#Text=A good enough Initialization has been proven critical to the robustness , which enables faster converge and better resistant to local optima .
22-1	2070-2071	A	abstract[110]	giv[110]	coref	23-4[0_110]
22-2	2072-2076	good	abstract[110]	giv[110]	_	_
22-3	2077-2083	enough	abstract[110]	giv[110]	_	_
22-4	2084-2098	Initialization	abstract[110]	giv[110]	_	_
22-5	2099-2102	has	_	_	_	_
22-6	2103-2107	been	_	_	_	_
22-7	2108-2114	proven	_	_	_	_
22-8	2115-2123	critical	_	_	_	_
22-9	2124-2126	to	_	_	_	_
22-10	2127-2130	the	abstract[111]	new[111]	_	_
22-11	2131-2141	robustness	abstract[111]	new[111]	_	_
22-12	2142-2143	,	abstract[111]	new[111]	_	_
22-13	2144-2149	which	abstract[111]	new[111]	_	_
22-14	2150-2157	enables	abstract[111]	new[111]	_	_
22-15	2158-2164	faster	abstract[111]|event[112]	new[111]|new[112]	_	_
22-16	2165-2173	converge	abstract[111]|event[112]	new[111]|new[112]	_	_
22-17	2174-2177	and	abstract[111]	new[111]	_	_
22-18	2178-2184	better	abstract[111]	new[111]	_	_
22-19	2185-2194	resistant	abstract[111]	new[111]	_	_
22-20	2195-2197	to	_	_	_	_
22-21	2198-2203	local	abstract[113]	new[113]	_	_
22-22	2204-2210	optima	abstract[113]	new[113]	_	_
22-23	2211-2212	.	_	_	_	_

#Text=There exist many initialization methods .
23-1	2213-2218	There	_	_	_	_
23-2	2219-2224	exist	_	_	_	_
23-3	2225-2229	many	abstract[115]	giv[115]	coref	24-1[116_115]
23-4	2230-2244	initialization	abstract|abstract[115]	giv|giv[115]	coref	26-8
23-5	2245-2252	methods	abstract[115]	giv[115]	_	_
23-6	2253-2254	.	_	_	_	_

#Text=Some works were initialized by the fingertip detection .
24-1	2255-2259	Some	abstract[116]	giv[116]	coref	27-18[135_116]
24-2	2260-2265	works	abstract[116]	giv[116]	_	_
24-3	2266-2270	were	_	_	_	_
24-4	2271-2282	initialized	_	_	_	_
24-5	2283-2285	by	_	_	_	_
24-6	2286-2289	the	abstract[118]	new[118]	_	_
24-7	2290-2299	fingertip	object|abstract[118]	new|new[118]	_	_
24-8	2300-2309	detection	abstract[118]	new[118]	_	_
24-9	2310-2311	.	_	_	_	_

#Text=Besides , Tagliasacchi et al. and Tkach et al. also detected a color wristband as a first alignment .
25-1	2312-2319	Besides	_	_	_	_
25-2	2320-2321	,	_	_	_	_
25-3	2322-2334	Tagliasacchi	person	new	_	_
25-4	2335-2337	et	_	_	_	_
25-5	2338-2341	al.	_	_	_	_
25-6	2342-2345	and	_	_	_	_
25-7	2346-2351	Tkach	person	new	coref	45-11
25-8	2352-2354	et	_	_	_	_
25-9	2355-2358	al.	_	_	_	_
25-10	2359-2363	also	_	_	_	_
25-11	2364-2372	detected	_	_	_	_
25-12	2373-2374	a	object[122]	new[122]	_	_
25-13	2375-2380	color	abstract|object[122]	new|new[122]	_	_
25-14	2381-2390	wristband	object[122]	new[122]	_	_
25-15	2391-2393	as	_	_	_	_
25-16	2394-2395	a	abstract[123]	new[123]	_	_
25-17	2396-2401	first	abstract[123]	new[123]	_	_
25-18	2402-2411	alignment	abstract[123]	new[123]	_	_
25-19	2412-2413	.	_	_	_	_

#Text=The use of simple geometric heuristics for initialization can sometimes be impractical for those gestures which contain occlusions or difficult hand orientations .
26-1	2414-2417	The	event[124]	new[124]	_	_
26-2	2418-2421	use	event[124]	new[124]	_	_
26-3	2422-2424	of	event[124]	new[124]	_	_
26-4	2425-2431	simple	event[124]|abstract[125]	new[124]|new[125]	_	_
26-5	2432-2441	geometric	event[124]|abstract[125]	new[124]|new[125]	_	_
26-6	2442-2452	heuristics	event[124]|abstract[125]	new[124]|new[125]	_	_
26-7	2453-2456	for	event[124]	new[124]	_	_
26-8	2457-2471	initialization	event[124]|abstract	new[124]|giv	coref	30-10
26-9	2472-2475	can	_	_	_	_
26-10	2476-2485	sometimes	_	_	_	_
26-11	2486-2488	be	_	_	_	_
26-12	2489-2500	impractical	_	_	_	_
26-13	2501-2504	for	_	_	_	_
26-14	2505-2510	those	abstract[127]	new[127]	_	_
26-15	2511-2519	gestures	abstract[127]	new[127]	_	_
26-16	2520-2525	which	abstract[127]	new[127]	_	_
26-17	2526-2533	contain	abstract[127]	new[127]	_	_
26-18	2534-2544	occlusions	abstract[127]|abstract	new[127]|new	_	_
26-19	2545-2547	or	abstract[127]	new[127]	_	_
26-20	2548-2557	difficult	abstract[127]|abstract[130]	new[127]|new[130]	_	_
26-21	2558-2562	hand	abstract[127]|object|abstract[130]	new[127]|giv|new[130]	coref	28-7
26-22	2563-2575	orientations	abstract[127]|abstract[130]	new[127]|new[130]	_	_
26-23	2576-2577	.	_	_	_	_

#Text=For this reason , most of the previous studies concentrated on exploiting the given image data with the train-based methods .
27-1	2578-2581	For	_	_	_	_
27-2	2582-2586	this	abstract[131]	new[131]	_	_
27-3	2587-2593	reason	abstract[131]	new[131]	_	_
27-4	2594-2595	,	_	_	_	_
27-5	2596-2600	most	abstract[132]	new[132]	_	_
27-6	2601-2603	of	abstract[132]	new[132]	_	_
27-7	2604-2607	the	abstract[132]	new[132]	_	_
27-8	2608-2616	previous	abstract[132]	new[132]	_	_
27-9	2617-2624	studies	abstract[132]	new[132]	_	_
27-10	2625-2637	concentrated	_	_	_	_
27-11	2638-2640	on	_	_	_	_
27-12	2641-2651	exploiting	_	_	_	_
27-13	2652-2655	the	abstract[134]	giv[134]	coref	46-21[236_134]
27-14	2656-2661	given	abstract[134]	giv[134]	_	_
27-15	2662-2667	image	object|abstract[134]	giv|giv[134]	coref	46-21
27-16	2668-2672	data	abstract[134]	giv[134]	_	_
27-17	2673-2677	with	_	_	_	_
27-18	2678-2681	the	abstract[135]	giv[135]	coref	40-1[190_135]
27-19	2682-2693	train-based	abstract[135]	giv[135]	_	_
27-20	2694-2701	methods	abstract[135]	giv[135]	_	_
27-21	2702-2703	.	_	_	_	_

#Text=Taylor et al. generated candidate ’s hand poses quickly by a retrieval forest .
28-1	2704-2710	Taylor	person	new	coref	29-1
28-2	2711-2713	et	_	_	_	_
28-3	2714-2717	al.	person	new	coref	29-3
28-4	2718-2727	generated	_	_	_	_
28-5	2728-2737	candidate	person[138]	new[138]	_	_
28-6	2738-2740	’s	person[138]	new[138]	_	_
28-7	2741-2745	hand	object	giv	coref	31-9
28-8	2746-2751	poses	_	_	_	_
28-9	2752-2759	quickly	_	_	_	_
28-10	2760-2762	by	_	_	_	_
28-11	2763-2764	a	place[141]	new[141]	coref	29-7[0_141]
28-12	2765-2774	retrieval	event|place[141]	new|new[141]	_	_
28-13	2775-2781	forest	place[141]	new[141]	_	_
28-14	2782-2783	.	_	_	_	_

#Text=Taylor et al. trained a decision forest classifier on a synthetic training set to generate an initial pose estimate .
29-1	2784-2790	Taylor	person	giv	coref	50-1
29-2	2791-2793	et	_	_	_	_
29-3	2794-2797	al.	person	giv	coref	45-13
29-4	2798-2805	trained	_	_	_	_
29-5	2806-2807	a	abstract[146]	new[146]	_	_
29-6	2808-2816	decision	abstract|abstract[146]	new|new[146]	_	_
29-7	2817-2823	forest	place|abstract[146]	giv|new[146]	_	_
29-8	2824-2834	classifier	abstract[146]	new[146]	_	_
29-9	2835-2837	on	_	_	_	_
29-10	2838-2839	a	abstract[148]	new[148]	_	_
29-11	2840-2849	synthetic	abstract[148]	new[148]	_	_
29-12	2850-2858	training	abstract|abstract[148]	giv|new[148]	coref	32-10
29-13	2859-2862	set	abstract[148]	new[148]	_	_
29-14	2863-2865	to	_	_	_	_
29-15	2866-2874	generate	_	_	_	_
29-16	2875-2877	an	abstract[150]	new[150]	_	_
29-17	2878-2885	initial	abstract[150]	new[150]	_	_
29-18	2886-2890	pose	abstract|abstract[150]	giv|new[150]	coref	31-9[159_0]
29-19	2891-2899	estimate	abstract[150]	new[150]	_	_
29-20	2900-2901	.	_	_	_	_

#Text=Sanchez-Riera et al. trained a convolutional neural network for initialization with 243,000 tuples of images .
30-1	2902-2915	Sanchez-Riera	person	new	_	_
30-2	2916-2918	et	_	_	_	_
30-3	2919-2922	al.	_	_	_	_
30-4	2923-2930	trained	_	_	_	_
30-5	2931-2932	a	abstract[152]	new[152]	_	_
30-6	2933-2946	convolutional	abstract[152]	new[152]	_	_
30-7	2947-2953	neural	abstract[152]	new[152]	_	_
30-8	2954-2961	network	abstract[152]	new[152]	_	_
30-9	2962-2965	for	_	_	_	_
30-10	2966-2980	initialization	abstract	giv	coref	32-3
30-11	2981-2985	with	_	_	_	_
30-12	2986-2993	243,000	abstract[154]	new[154]	_	_
30-13	2994-3000	tuples	abstract[154]	new[154]	_	_
30-14	3001-3003	of	abstract[154]	new[154]	_	_
30-15	3004-3010	images	abstract[154]|abstract	new[154]|new	_	_
30-16	3011-3012	.	_	_	_	_

#Text=Sharp et al. inferred a hierarchical distribution over hand pose with a layered discriminative model .
31-1	3013-3018	Sharp	person	new	_	_
31-2	3019-3021	et	_	_	_	_
31-3	3022-3025	al.	_	_	_	_
31-4	3026-3034	inferred	_	_	_	_
31-5	3035-3036	a	abstract[157]	new[157]	_	_
31-6	3037-3049	hierarchical	abstract[157]	new[157]	_	_
31-7	3050-3062	distribution	abstract[157]	new[157]	_	_
31-8	3063-3067	over	abstract[157]	new[157]	_	_
31-9	3068-3072	hand	abstract[157]|object|abstract[159]	new[157]|giv|giv[159]	coref	35-2[175_0]
31-10	3073-3077	pose	abstract[157]|abstract[159]	new[157]|giv[159]	_	_
31-11	3078-3082	with	_	_	_	_
31-12	3083-3084	a	abstract[160]	giv[160]	coref	35-1[176_160]
31-13	3085-3092	layered	abstract[160]	giv[160]	_	_
31-14	3093-3107	discriminative	abstract[160]	giv[160]	_	_
31-15	3108-3113	model	abstract[160]	giv[160]	_	_
31-16	3114-3115	.	_	_	_	_

#Text=However , initialization errors often occur due to imperfect training data-sets , mentioned in Section 2.1 , which may cause tracking failure .
32-1	3116-3123	However	_	_	_	_
32-2	3124-3125	,	_	_	_	_
32-3	3126-3140	initialization	abstract|abstract[162]	giv|new[162]	coref	33-13[171_0]
32-4	3141-3147	errors	abstract[162]	new[162]	_	_
32-5	3148-3153	often	_	_	_	_
32-6	3154-3159	occur	_	_	_	_
32-7	3160-3163	due	_	_	_	_
32-8	3164-3166	to	_	_	_	_
32-9	3167-3176	imperfect	abstract[164]	giv[164]	_	_
32-10	3177-3185	training	abstract|abstract[164]	giv|giv[164]	_	_
32-11	3186-3195	data-sets	abstract[164]	giv[164]	_	_
32-12	3196-3197	,	abstract[164]	giv[164]	_	_
32-13	3198-3207	mentioned	abstract[164]	giv[164]	_	_
32-14	3208-3210	in	abstract[164]	giv[164]	_	_
32-15	3211-3218	Section	abstract[164]|abstract[165]	giv[164]|new[165]	_	_
32-16	3219-3222	2.1	abstract[164]|abstract[165]	giv[164]|new[165]	_	_
32-17	3223-3224	,	abstract[164]	giv[164]	_	_
32-18	3225-3230	which	abstract[164]	giv[164]	_	_
32-19	3231-3234	may	abstract[164]	giv[164]	_	_
32-20	3235-3240	cause	abstract[164]	giv[164]	_	_
32-21	3241-3249	tracking	abstract[164]|abstract|event[167]	giv[164]|giv|new[167]	coref	42-11[204_0]
32-22	3250-3257	failure	abstract[164]|event[167]	giv[164]|new[167]	_	_
32-23	3258-3259	.	_	_	_	_

#Text=In our system , it is more reliable and robust to provide an approximate initialization by a simple data glove .
33-1	3260-3262	In	_	_	_	_
33-2	3263-3266	our	person|abstract[169]	giv|giv[169]	ana|coref	51-14|51-14[263_169]
33-3	3267-3273	system	abstract[169]	giv[169]	_	_
33-4	3274-3275	,	_	_	_	_
33-5	3276-3278	it	abstract	giv	_	_
33-6	3279-3281	is	_	_	_	_
33-7	3282-3286	more	_	_	_	_
33-8	3287-3295	reliable	_	_	_	_
33-9	3296-3299	and	_	_	_	_
33-10	3300-3306	robust	_	_	_	_
33-11	3307-3309	to	_	_	_	_
33-12	3310-3317	provide	_	_	_	_
33-13	3318-3320	an	abstract[171]	giv[171]	_	_
33-14	3321-3332	approximate	abstract[171]	giv[171]	_	_
33-15	3333-3347	initialization	abstract[171]	giv[171]	_	_
33-16	3348-3350	by	_	_	_	_
33-17	3351-3352	a	abstract[173]	new[173]	_	_
33-18	3353-3359	simple	abstract[173]	new[173]	_	_
33-19	3360-3364	data	abstract|abstract[173]	new|new[173]	_	_
33-20	3365-3370	glove	abstract[173]	new[173]	_	_
33-21	3371-3372	.	_	_	_	_

#Text=2.2.2. Hand Model
34-1	3373-3379	2.2.2.	_	_	_	_
34-2	3380-3384	Hand	person[174]	new[174]	_	_
34-3	3385-3390	Model	person[174]	new[174]	_	_

#Text=The human hand model serves as the medium of computation and the presentation of algorithm results .
35-1	3391-3394	The	abstract[176]	giv[176]	coref	36-1[182_176]
35-2	3395-3400	human	object[175]|abstract[176]	giv[175]|giv[176]	coref	37-2[0_175]
35-3	3401-3405	hand	object[175]|abstract[176]	giv[175]|giv[176]	_	_
35-4	3406-3411	model	abstract[176]	giv[176]	_	_
35-5	3412-3418	serves	_	_	_	_
35-6	3419-3421	as	_	_	_	_
35-7	3422-3425	the	abstract[177]	new[177]	_	_
35-8	3426-3432	medium	abstract[177]	new[177]	_	_
35-9	3433-3435	of	abstract[177]	new[177]	_	_
35-10	3436-3447	computation	abstract[177]|abstract	new[177]|new	_	_
35-11	3448-3451	and	_	_	_	_
35-12	3452-3455	the	event[179]	new[179]	_	_
35-13	3456-3468	presentation	event[179]	new[179]	_	_
35-14	3469-3471	of	event[179]	new[179]	_	_
35-15	3472-3481	algorithm	event[179]|abstract|abstract[181]	new[179]|new|giv[181]	_	_
35-16	3482-3489	results	event[179]|abstract[181]	new[179]|giv[181]	_	_
35-17	3490-3491	.	_	_	_	_

#Text=A detailed and accurate generative model tends to deepen the good local minima and widen their basins of convergence .
36-1	3492-3493	A	abstract[182]	giv[182]	coref	41-5[198_182]
36-2	3494-3502	detailed	abstract[182]	giv[182]	_	_
36-3	3503-3506	and	abstract[182]	giv[182]	_	_
36-4	3507-3515	accurate	abstract[182]	giv[182]	_	_
36-5	3516-3526	generative	abstract[182]	giv[182]	_	_
36-6	3527-3532	model	abstract[182]	giv[182]	_	_
36-7	3533-3538	tends	_	_	_	_
36-8	3539-3541	to	_	_	_	_
36-9	3542-3548	deepen	_	_	_	_
36-10	3549-3552	the	abstract[183]	new[183]	ana	36-16[0_183]
36-11	3553-3557	good	abstract[183]	new[183]	_	_
36-12	3558-3563	local	abstract[183]	new[183]	_	_
36-13	3564-3570	minima	abstract[183]	new[183]	_	_
36-14	3571-3574	and	_	_	_	_
36-15	3575-3580	widen	_	_	_	_
36-16	3581-3586	their	abstract|place[185]	giv|new[185]	_	_
36-17	3587-3593	basins	place[185]	new[185]	_	_
36-18	3594-3596	of	place[185]	new[185]	_	_
36-19	3597-3608	convergence	place[185]|abstract	new[185]|new	_	_
36-20	3609-3610	.	_	_	_	_

#Text=Many hand models have been proposed , see
37-1	3611-3615	Many	abstract[188]	giv[188]	coref	48-8[241_188]
37-2	3616-3620	hand	object|abstract[188]	giv|giv[188]	coref	41-6
37-3	3621-3627	models	abstract[188]	giv[188]	_	_
37-4	3628-3632	have	_	_	_	_
37-5	3633-3637	been	_	_	_	_
37-6	3638-3646	proposed	_	_	_	_
37-7	3647-3648	,	_	_	_	_
37-8	3649-3652	see	_	_	_	_

#Text=Figure 1
38-1	3653-3659	Figure	abstract[189]	new[189]	_	_
38-2	3660-3661	1	abstract[189]	new[189]	_	_

#Text=.
39-1	3662-3663	.	_	_	_	_

#Text=Early works used the capsule mode made by two basic geometric primitives : a sphere and a cylinder .
40-1	3664-3669	Early	abstract[190]	giv[190]	_	_
40-2	3670-3675	works	abstract[190]	giv[190]	_	_
40-3	3676-3680	used	_	_	_	_
40-4	3681-3684	the	abstract[192]	new[192]	_	_
40-5	3685-3692	capsule	object|abstract[192]	new|new[192]	_	_
40-6	3693-3697	mode	abstract[192]	new[192]	_	_
40-7	3698-3702	made	abstract[192]	new[192]	_	_
40-8	3703-3705	by	abstract[192]	new[192]	_	_
40-9	3706-3709	two	abstract[192]|abstract[193]	new[192]|new[193]	_	_
40-10	3710-3715	basic	abstract[192]|abstract[193]	new[192]|new[193]	_	_
40-11	3716-3725	geometric	abstract[192]|abstract[193]	new[192]|new[193]	_	_
40-12	3726-3736	primitives	abstract[192]|abstract[193]	new[192]|new[193]	_	_
40-13	3737-3738	:	_	_	_	_
40-14	3739-3740	a	object[194]	new[194]	_	_
40-15	3741-3747	sphere	object[194]	new[194]	_	_
40-16	3748-3751	and	_	_	_	_
40-17	3752-3753	a	object[195]	new[195]	_	_
40-18	3754-3762	cylinder	object[195]	new[195]	_	_
40-19	3763-3764	.	_	_	_	_

#Text=Qian et al. built the hand model using a number of spheres .
41-1	3765-3769	Qian	person	new	_	_
41-2	3770-3772	et	_	_	_	_
41-3	3773-3776	al.	_	_	_	_
41-4	3777-3782	built	_	_	_	_
41-5	3783-3786	the	abstract[198]	giv[198]	coref	43-16[210_198]
41-6	3787-3791	hand	object|abstract[198]	giv|giv[198]	coref	42-11
41-7	3792-3797	model	abstract[198]	giv[198]	_	_
41-8	3798-3803	using	_	_	_	_
41-9	3804-3805	a	object[199]	new[199]	_	_
41-10	3806-3812	number	object[199]	new[199]	_	_
41-11	3813-3815	of	object[199]	new[199]	_	_
41-12	3816-3823	spheres	object[199]	new[199]	_	_
41-13	3824-3825	.	_	_	_	_

#Text=Melax et al. used a union of convex bodies for hand tracking .
42-1	3826-3831	Melax	person	new	_	_
42-2	3832-3834	et	_	_	_	_
42-3	3835-3838	al.	_	_	_	_
42-4	3839-3843	used	_	_	_	_
42-5	3844-3845	a	organization[201]	new[201]	_	_
42-6	3846-3851	union	organization[201]	new[201]	_	_
42-7	3852-3854	of	organization[201]	new[201]	_	_
42-8	3855-3861	convex	organization[201]|object[202]	new[201]|new[202]	_	_
42-9	3862-3868	bodies	organization[201]|object[202]	new[201]|new[202]	_	_
42-10	3869-3872	for	_	_	_	_
42-11	3873-3877	hand	object|abstract[204]	giv|giv[204]	coref|coref	43-9[207_0]|51-11[0_204]
42-12	3878-3886	tracking	abstract[204]	giv[204]	_	_
42-13	3887-3888	.	_	_	_	_

#Text=Sridhar et al. modeled the volumetric extent of the hand as a 3D sum of an-isotropic Gaussian model .
43-1	3889-3896	Sridhar	person	new	_	_
43-2	3897-3899	et	_	_	_	_
43-3	3900-3903	al.	_	_	_	_
43-4	3904-3911	modeled	_	_	_	_
43-5	3912-3915	the	abstract[206]	new[206]	_	_
43-6	3916-3926	volumetric	abstract[206]	new[206]	_	_
43-7	3927-3933	extent	abstract[206]	new[206]	_	_
43-8	3934-3936	of	abstract[206]	new[206]	_	_
43-9	3937-3940	the	abstract[206]|object[207]	new[206]|giv[207]	coref	44-9[0_207]
43-10	3941-3945	hand	abstract[206]|object[207]	new[206]|giv[207]	_	_
43-11	3946-3948	as	_	_	_	_
43-12	3949-3950	a	abstract[208]	new[208]	_	_
43-13	3951-3953	3D	abstract[208]	new[208]	_	_
43-14	3954-3957	sum	abstract[208]	new[208]	_	_
43-15	3958-3960	of	abstract[208]	new[208]	_	_
43-16	3961-3973	an-isotropic	abstract[208]|abstract[210]	new[208]|giv[210]	_	_
43-17	3974-3982	Gaussian	abstract[208]|person|abstract[210]	new[208]|new|giv[210]	_	_
43-18	3983-3988	model	abstract[208]|abstract[210]	new[208]|giv[210]	_	_
43-19	3989-3990	.	_	_	_	_

#Text=These approaches can model a broad spectrum of hand shape variations and enable fast evaluation of distances and a high degree of computational parallelism .
44-1	3991-3996	These	abstract[211]	new[211]	_	_
44-2	3997-4007	approaches	abstract[211]	new[211]	_	_
44-3	4008-4011	can	_	_	_	_
44-4	4012-4017	model	_	_	_	_
44-5	4018-4019	a	abstract[212]	new[212]	_	_
44-6	4020-4025	broad	abstract[212]	new[212]	_	_
44-7	4026-4034	spectrum	abstract[212]	new[212]	_	_
44-8	4035-4037	of	abstract[212]	new[212]	_	_
44-9	4038-4042	hand	abstract[212]|object|abstract[215]	new[212]|giv|new[215]	coref	45-7
44-10	4043-4048	shape	abstract[212]|abstract|abstract[215]	new[212]|new|new[215]	coref	45-7[223_0]
44-11	4049-4059	variations	abstract[212]|abstract[215]	new[212]|new[215]	_	_
44-12	4060-4063	and	_	_	_	_
44-13	4064-4070	enable	_	_	_	_
44-14	4071-4075	fast	abstract[216]|abstract[217]	new[216]|new[217]	ana	45-3[0_217]
44-15	4076-4086	evaluation	abstract[216]|abstract[217]	new[216]|new[217]	_	_
44-16	4087-4089	of	abstract[216]|abstract[217]	new[216]|new[217]	_	_
44-17	4090-4099	distances	abstract[216]|abstract[217]|abstract	new[216]|new[217]|new	_	_
44-18	4100-4103	and	abstract[217]	new[217]	_	_
44-19	4104-4105	a	abstract[217]|abstract[219]	new[217]|new[219]	_	_
44-20	4106-4110	high	abstract[217]|abstract[219]	new[217]|new[219]	_	_
44-21	4111-4117	degree	abstract[217]|abstract[219]	new[217]|new[219]	_	_
44-22	4118-4120	of	abstract[217]|abstract[219]	new[217]|new[219]	_	_
44-23	4121-4134	computational	abstract[217]|abstract[219]|abstract[220]	new[217]|new[219]|new[220]	_	_
44-24	4135-4146	parallelism	abstract[217]|abstract[219]|abstract[220]	new[217]|new[219]|new[220]	_	_
44-25	4147-4148	.	_	_	_	_

#Text=However , they only roughly approximate hand shape even if Tkach et al. proposed the use of sphere-meshes as a novel geometric representation .
45-1	4149-4156	However	_	_	_	_
45-2	4157-4158	,	_	_	_	_
45-3	4159-4163	they	abstract	giv	_	_
45-4	4164-4168	only	_	_	_	_
45-5	4169-4176	roughly	_	_	_	_
45-6	4177-4188	approximate	_	_	_	_
45-7	4189-4193	hand	object|abstract[223]	giv|giv[223]	coref	50-5[251_0]
45-8	4194-4199	shape	abstract[223]	giv[223]	_	_
45-9	4200-4204	even	_	_	_	_
45-10	4205-4207	if	_	_	_	_
45-11	4208-4213	Tkach	person	giv	_	_
45-12	4214-4216	et	_	_	_	_
45-13	4217-4220	al.	person	giv	coref	49-3
45-14	4221-4229	proposed	_	_	_	_
45-15	4230-4233	the	abstract[226]	new[226]	_	_
45-16	4234-4237	use	abstract[226]	new[226]	_	_
45-17	4238-4240	of	abstract[226]	new[226]	_	_
45-18	4241-4254	sphere-meshes	abstract[226]|object	new[226]|new	_	_
45-19	4255-4257	as	abstract[226]	new[226]	_	_
45-20	4258-4259	a	abstract[226]|abstract[228]	new[226]|new[228]	_	_
45-21	4260-4265	novel	abstract[226]|abstract[228]	new[226]|new[228]	_	_
45-22	4266-4275	geometric	abstract[226]|abstract[228]	new[226]|new[228]	_	_
45-23	4276-4290	representation	abstract[226]|abstract[228]	new[226]|new[228]	_	_
45-24	4291-4292	.	_	_	_	_

#Text=An alternative is a triangulated mesh model with linear blend skinning ( LBS ) that is more realistic and fits image data better .
46-1	4293-4295	An	abstract[229]	new[229]	coref	46-4[231_229]
46-2	4296-4307	alternative	abstract[229]	new[229]	_	_
46-3	4308-4310	is	_	_	_	_
46-4	4311-4312	a	abstract[231]	giv[231]	coref	51-17[266_231]
46-5	4313-4325	triangulated	abstract[231]	giv[231]	_	_
46-6	4326-4330	mesh	abstract|abstract[231]	new|giv[231]	coref	51-19[264_0]
46-7	4331-4336	model	abstract[231]	giv[231]	_	_
46-8	4337-4341	with	abstract[231]	giv[231]	_	_
46-9	4342-4348	linear	abstract[231]|abstract[233]	giv[231]|new[233]	appos	46-13[0_233]
46-10	4349-4354	blend	abstract[231]|substance|abstract[233]	giv[231]|new|new[233]	_	_
46-11	4355-4363	skinning	abstract[231]|abstract[233]	giv[231]|new[233]	_	_
46-12	4364-4365	(	_	_	_	_
46-13	4366-4369	LBS	abstract	giv	_	_
46-14	4370-4371	)	_	_	_	_
46-15	4372-4376	that	_	_	_	_
46-16	4377-4379	is	_	_	_	_
46-17	4380-4384	more	_	_	_	_
46-18	4385-4394	realistic	_	_	_	_
46-19	4395-4398	and	_	_	_	_
46-20	4399-4403	fits	_	_	_	_
46-21	4404-4409	image	object|abstract[236]	giv|giv[236]	coref	51-3[259_236]
46-22	4410-4414	data	abstract[236]	giv[236]	_	_
46-23	4415-4421	better	_	_	_	_
46-24	4422-4423	.	_	_	_	_

#Text=But these triangulated meshes cost more computational effort and are hard to deal with the collision .
47-1	4424-4427	But	_	_	_	_
47-2	4428-4433	these	abstract[237]	new[237]	_	_
47-3	4434-4446	triangulated	abstract[237]	new[237]	_	_
47-4	4447-4453	meshes	abstract[237]	new[237]	_	_
47-5	4454-4458	cost	_	_	_	_
47-6	4459-4463	more	abstract[238]	new[238]	_	_
47-7	4464-4477	computational	abstract[238]	new[238]	_	_
47-8	4478-4484	effort	abstract[238]	new[238]	_	_
47-9	4485-4488	and	_	_	_	_
47-10	4489-4492	are	_	_	_	_
47-11	4493-4497	hard	_	_	_	_
47-12	4498-4500	to	_	_	_	_
47-13	4501-4505	deal	_	_	_	_
47-14	4506-4510	with	_	_	_	_
47-15	4511-4514	the	event[239]	new[239]	_	_
47-16	4515-4524	collision	event[239]	new[239]	_	_
47-17	4525-4526	.	_	_	_	_

#Text=There also exist some implicit templates except these explicit models .
48-1	4527-4532	There	_	_	_	_
48-2	4533-4537	also	_	_	_	_
48-3	4538-4543	exist	_	_	_	_
48-4	4544-4548	some	abstract[240]	new[240]	_	_
48-5	4549-4557	implicit	abstract[240]	new[240]	_	_
48-6	4558-4567	templates	abstract[240]	new[240]	_	_
48-7	4568-4574	except	abstract[240]	new[240]	_	_
48-8	4575-4580	these	abstract[240]|abstract[241]	new[240]|giv[241]	_	_
48-9	4581-4589	explicit	abstract[240]|abstract[241]	new[240]|giv[241]	_	_
48-10	4590-4596	models	abstract[240]|abstract[241]	new[240]|giv[241]	_	_
48-11	4597-4598	.	_	_	_	_

#Text=Schmidt et al. voxelized each shape-primitive and computed a signed distance function for the local coordinate frame .
49-1	4599-4606	Schmidt	person	new	_	_
49-2	4607-4609	et	_	_	_	_
49-3	4610-4613	al.	person	giv	coref	50-3
49-4	4614-4623	voxelized	_	_	_	_
49-5	4624-4628	each	abstract[244]	new[244]	_	_
49-6	4629-4644	shape-primitive	abstract[244]	new[244]	_	_
49-7	4645-4648	and	_	_	_	_
49-8	4649-4657	computed	_	_	_	_
49-9	4658-4659	a	abstract[246]	new[246]	coref	50-8[253_246]
49-10	4660-4666	signed	abstract[246]	new[246]	_	_
49-11	4667-4675	distance	abstract|abstract[246]	new|new[246]	coref	50-11
49-12	4676-4684	function	abstract[246]	new[246]	_	_
49-13	4685-4688	for	abstract[246]	new[246]	_	_
49-14	4689-4692	the	abstract[246]|abstract[248]	new[246]|new[248]	_	_
49-15	4693-4698	local	abstract[246]|abstract[248]	new[246]|new[248]	_	_
49-16	4699-4709	coordinate	abstract[246]|abstract|abstract[248]	new[246]|new|new[248]	_	_
49-17	4710-4715	frame	abstract[246]|abstract[248]	new[246]|new[248]	_	_
49-18	4716-4717	.	_	_	_	_

#Text=Taylor et al. constructed the hand as an articulated signed distance function that allows fast calculation of the distance to the hand surface .
50-1	4718-4724	Taylor	person	giv	_	_
50-2	4725-4727	et	_	_	_	_
50-3	4728-4731	al.	person	giv	_	_
50-4	4732-4743	constructed	_	_	_	_
50-5	4744-4747	the	object[251]	giv[251]	coref	50-22[0_251]
50-6	4748-4752	hand	object[251]	giv[251]	_	_
50-7	4753-4755	as	_	_	_	_
50-8	4756-4758	an	abstract[253]	giv[253]	_	_
50-9	4759-4770	articulated	abstract[253]	giv[253]	_	_
50-10	4771-4777	signed	abstract[253]	giv[253]	_	_
50-11	4778-4786	distance	abstract|abstract[253]	giv|giv[253]	coref	50-18[255_0]
50-12	4787-4795	function	abstract[253]	giv[253]	_	_
50-13	4796-4800	that	abstract[253]	giv[253]	_	_
50-14	4801-4807	allows	abstract[253]	giv[253]	_	_
50-15	4808-4812	fast	abstract[253]|abstract[254]	giv[253]|new[254]	_	_
50-16	4813-4824	calculation	abstract[253]|abstract[254]	giv[253]|new[254]	_	_
50-17	4825-4827	of	abstract[253]|abstract[254]	giv[253]|new[254]	_	_
50-18	4828-4831	the	abstract[253]|abstract[254]|abstract[255]	giv[253]|new[254]|giv[255]	_	_
50-19	4832-4840	distance	abstract[253]|abstract[254]|abstract[255]	giv[253]|new[254]|giv[255]	_	_
50-20	4841-4843	to	abstract[253]|abstract[254]|abstract[255]	giv[253]|new[254]|giv[255]	_	_
50-21	4844-4847	the	abstract[253]|abstract[254]|abstract[255]|place[257]	giv[253]|new[254]|giv[255]|new[257]	_	_
50-22	4848-4852	hand	abstract[253]|abstract[254]|abstract[255]|object|place[257]	giv[253]|new[254]|giv[255]|giv|new[257]	coref	51-21
50-23	4853-4860	surface	abstract[253]|abstract[254]|abstract[255]|place[257]	giv[253]|new[254]|giv[255]|new[257]	_	_
50-24	4861-4862	.	_	_	_	_

#Text=To explain the input data better and explicitly visualize the tracking result , our system uses an expressive triangular mesh hand model .
51-1	4863-4865	To	_	_	_	_
51-2	4866-4873	explain	_	_	_	_
51-3	4874-4877	the	abstract[259]	giv[259]	_	_
51-4	4878-4883	input	abstract|abstract[259]	new|giv[259]	_	_
51-5	4884-4888	data	abstract[259]	giv[259]	_	_
51-6	4889-4895	better	_	_	_	_
51-7	4896-4899	and	_	_	_	_
51-8	4900-4910	explicitly	_	_	_	_
51-9	4911-4920	visualize	_	_	_	_
51-10	4921-4924	the	abstract[261]	new[261]	_	_
51-11	4925-4933	tracking	abstract|abstract[261]	giv|new[261]	_	_
51-12	4934-4940	result	abstract[261]	new[261]	_	_
51-13	4941-4942	,	_	_	_	_
51-14	4943-4946	our	person|abstract[263]	giv|giv[263]	_	_
51-15	4947-4953	system	abstract[263]	giv[263]	_	_
51-16	4954-4958	uses	_	_	_	_
51-17	4959-4961	an	abstract[266]	giv[266]	_	_
51-18	4962-4972	expressive	abstract[266]	giv[266]	_	_
51-19	4973-4983	triangular	abstract[264]|abstract[266]	giv[264]|giv[266]	_	_
51-20	4984-4988	mesh	abstract[264]|abstract[266]	giv[264]|giv[266]	_	_
51-21	4989-4993	hand	object|abstract[266]	giv|giv[266]	_	_
51-22	4994-4999	model	abstract[266]	giv[266]	_	_
51-23	5000-5001	.	_	_	_	_
