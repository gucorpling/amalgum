#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=1. Introduction
1-1	0-2	1.	_	_	_	_
1-2	3-15	Introduction	abstract	new	_	_

#Text=Many applications in the real world , such as system identification , regression , and online kernel learning ( OKL ) , require complex nonlinear models .
2-1	16-20	Many	abstract[2]	new[2]	coref	3-13[16_2]
2-2	21-33	applications	abstract[2]	new[2]	_	_
2-3	34-36	in	abstract[2]	new[2]	_	_
2-4	37-40	the	abstract[2]|abstract[3]	new[2]|new[3]	_	_
2-5	41-45	real	abstract[2]|abstract[3]	new[2]|new[3]	_	_
2-6	46-51	world	abstract[2]|abstract[3]	new[2]|new[3]	_	_
2-7	52-53	,	abstract[2]	new[2]	_	_
2-8	54-58	such	abstract[2]	new[2]	_	_
2-9	59-61	as	abstract[2]	new[2]	_	_
2-10	62-68	system	abstract[2]|abstract|abstract[5]	new[2]|new|new[5]	_	_
2-11	69-83	identification	abstract[2]|abstract[5]	new[2]|new[5]	_	_
2-12	84-85	,	abstract[2]	new[2]	_	_
2-13	86-96	regression	abstract[2]|abstract	new[2]|new	_	_
2-14	97-98	,	abstract[2]	new[2]	_	_
2-15	99-102	and	abstract[2]	new[2]	_	_
2-16	103-109	online	abstract[2]|abstract[8]	new[2]|new[8]	appos	2-20[0_8]
2-17	110-116	kernel	abstract[2]|abstract|abstract[8]	new[2]|new|new[8]	coref	3-2
2-18	117-125	learning	abstract[2]|abstract[8]	new[2]|new[8]	_	_
2-19	126-127	(	_	_	_	_
2-20	128-131	OKL	abstract	giv	coref	4-18
2-21	132-133	)	_	_	_	_
2-22	134-135	,	_	_	_	_
2-23	136-143	require	_	_	_	_
2-24	144-151	complex	abstract[10]	new[10]	_	_
2-25	152-161	nonlinear	abstract[10]	new[10]	_	_
2-26	162-168	models	abstract[10]	new[10]	_	_
2-27	169-170	.	_	_	_	_

#Text=The kernel method using a Mercer kernel has attracted interests in tackling these complex nonlinear applications , which transforms nonlinear applications into linear ones in the reproducing kernel Hilbert space ( RKHS ) .
3-1	171-174	The	abstract[12]	new[12]	coref	5-2[33_12]
3-2	175-181	kernel	abstract|abstract[12]	giv|new[12]	coref	3-5[14_0]
3-3	182-188	method	abstract[12]	new[12]	_	_
3-4	189-194	using	abstract[12]	new[12]	_	_
3-5	195-196	a	abstract[12]|abstract[14]	new[12]|giv[14]	coref	3-28[0_14]
3-6	197-203	Mercer	abstract[12]|person|abstract[14]	new[12]|new|giv[14]	_	_
3-7	204-210	kernel	abstract[12]|abstract[14]	new[12]|giv[14]	_	_
3-8	211-214	has	_	_	_	_
3-9	215-224	attracted	_	_	_	_
3-10	225-234	interests	abstract	new	_	_
3-11	235-237	in	_	_	_	_
3-12	238-246	tackling	_	_	_	_
3-13	247-252	these	abstract[16]	giv[16]	coref	3-20[17_16]
3-14	253-260	complex	abstract[16]	giv[16]	_	_
3-15	261-270	nonlinear	abstract[16]	giv[16]	_	_
3-16	271-283	applications	abstract[16]	giv[16]	_	_
3-17	284-285	,	abstract[16]	giv[16]	_	_
3-18	286-291	which	abstract[16]	giv[16]	_	_
3-19	292-302	transforms	abstract[16]|abstract	giv[16]|new	coref|none	14-30[138_0]|3-19[0_138]
3-20	303-312	nonlinear	abstract[16]|abstract[17]	giv[16]|giv[17]	_	_
3-21	313-325	applications	abstract[16]|abstract[17]	giv[16]|giv[17]	_	_
3-22	326-330	into	abstract[16]	giv[16]	_	_
3-23	331-337	linear	abstract[16]|abstract[18]	giv[16]|new[18]	_	_
3-24	338-342	ones	abstract[16]|abstract[18]	giv[16]|new[18]	_	_
3-25	343-345	in	abstract[16]	giv[16]	_	_
3-26	346-349	the	abstract[16]|abstract[21]	giv[16]|new[21]	appos	3-32[0_21]
3-27	350-361	reproducing	abstract[16]|abstract[21]	giv[16]|new[21]	_	_
3-28	362-368	kernel	abstract[16]|abstract|abstract[21]	giv[16]|giv|new[21]	coref	4-6
3-29	369-376	Hilbert	abstract[16]|person|abstract[21]	giv[16]|new|new[21]	_	_
3-30	377-382	space	abstract[16]|abstract[21]	giv[16]|new[21]	_	_
3-31	383-384	(	_	_	_	_
3-32	385-389	RKHS	abstract	giv	coref	4-3
3-33	390-391	)	_	_	_	_
3-34	392-393	.	_	_	_	_

#Text=Developed in RKHS , a kernel adaptive filter ( KAF ) is the most celebrated subfield of OKL algorithms .
4-1	394-403	Developed	abstract[27]	giv[27]	coref	4-1[27_0]
4-2	404-406	in	abstract[27]	giv[27]	_	_
4-3	407-411	RKHS	abstract|abstract[27]	giv|giv[27]	coref	14-20[133_0]
4-4	412-413	,	abstract[27]	giv[27]	_	_
4-5	414-415	a	abstract[25]|abstract[27]	new[25]|giv[27]	appos	4-10[0_25]
4-6	416-422	kernel	abstract|abstract[25]|abstract[27]	giv|new[25]|giv[27]	coref	5-17
4-7	423-431	adaptive	abstract[25]|abstract[27]	new[25]|giv[27]	_	_
4-8	432-438	filter	abstract[25]|abstract[27]	new[25]|giv[27]	_	_
4-9	439-440	(	abstract[27]	giv[27]	_	_
4-10	441-444	KAF	abstract|abstract[27]	giv|giv[27]	_	_
4-11	445-446	)	abstract[27]	giv[27]	_	_
4-12	447-449	is	abstract[27]	giv[27]	_	_
4-13	450-453	the	abstract[27]	giv[27]	_	_
4-14	454-458	most	abstract[27]	giv[27]	_	_
4-15	459-469	celebrated	abstract[27]	giv[27]	_	_
4-16	470-478	subfield	abstract[27]	giv[27]	_	_
4-17	479-481	of	abstract[27]	giv[27]	_	_
4-18	482-485	OKL	abstract[27]|abstract|abstract[29]	giv[27]|giv|new[29]	coref|coref	21-4[212_0]|24-11[247_29]
4-19	486-496	algorithms	abstract[27]|abstract[29]	giv[27]|new[29]	_	_
4-20	497-498	.	_	_	_	_

#Text=Using the simplest stochastic gradient descent ( SGD ) method for learning , KAFs including the kernel least mean square ( KLMS ) algorithm , kernel affine projection algorithm ( KAPA ) , and kernel recursive least squares ( KRLS ) algorithm have been proposed .
5-1	499-504	Using	abstract[34]	new[34]	coref	6-43[0_34]
5-2	505-508	the	abstract[33]|abstract[34]	giv[33]|new[34]	coref	11-3[105_33]
5-3	509-517	simplest	abstract[33]|abstract[34]	giv[33]|new[34]	_	_
5-4	518-528	stochastic	abstract[31]|abstract[33]|abstract[34]	new[31]|giv[33]|new[34]	appos	5-8[0_31]
5-5	529-537	gradient	substance|abstract[31]|abstract[33]|abstract[34]	new|new[31]|giv[33]|new[34]	coref	16-33[163_0]
5-6	538-545	descent	abstract[31]|abstract[33]|abstract[34]	new[31]|giv[33]|new[34]	_	_
5-7	546-547	(	abstract[33]|abstract[34]	giv[33]|new[34]	_	_
5-8	548-551	SGD	abstract|abstract[33]|abstract[34]	giv|giv[33]|new[34]	coref	25-9[258_0]
5-9	552-553	)	abstract[33]|abstract[34]	giv[33]|new[34]	_	_
5-10	554-560	method	abstract[33]|abstract[34]	giv[33]|new[34]	_	_
5-11	561-564	for	abstract[33]|abstract[34]	giv[33]|new[34]	_	_
5-12	565-573	learning	abstract[33]|abstract[34]	giv[33]|new[34]	_	_
5-13	574-575	,	abstract[34]	new[34]	_	_
5-14	576-580	KAFs	abstract[34]	new[34]	_	_
5-15	581-590	including	abstract[34]	new[34]	_	_
5-16	591-594	the	abstract[34]|abstract[40]	new[34]|new[40]	_	_
5-17	595-601	kernel	abstract[34]|abstract|place[38]|abstract[40]	new[34]|giv|new[38]|new[40]	coref|coref	5-26|16-10[153_38]
5-18	602-607	least	abstract[34]|place|place[38]|abstract[40]	new[34]|new|new[38]|new[40]	coref	5-37
5-19	608-612	mean	abstract[34]|abstract|place[38]|abstract[40]	new[34]|new|new[38]|new[40]	coref	16-14[152_0]
5-20	613-619	square	abstract[34]|place[38]|abstract[40]	new[34]|new[38]|new[40]	_	_
5-21	620-621	(	abstract[34]|abstract[40]	new[34]|new[40]	_	_
5-22	622-626	KLMS	abstract[34]|abstract|abstract[40]	new[34]|new|new[40]	coref	31-14
5-23	627-628	)	abstract[34]|abstract[40]	new[34]|new[40]	_	_
5-24	629-638	algorithm	abstract[34]|abstract[40]	new[34]|new[40]	_	_
5-25	639-640	,	abstract[34]	new[34]	_	_
5-26	641-647	kernel	abstract[34]|abstract|abstract[44]	new[34]|giv|new[44]	appos|coref	3-19[0_44]|5-35
5-27	648-654	affine	abstract[34]|abstract|abstract[44]	new[34]|new|new[44]	_	_
5-28	655-665	projection	abstract[34]|abstract|abstract[44]	new[34]|new|new[44]	_	_
5-29	666-675	algorithm	abstract[34]|abstract[44]	new[34]|new[44]	_	_
5-30	676-677	(	_	_	_	_
5-31	678-682	KAPA	abstract	giv	coref	5-35[50_0]
5-32	683-684	)	_	_	_	_
5-33	685-686	,	_	_	_	_
5-34	687-690	and	_	_	_	_
5-35	691-697	kernel	abstract|place[48]|abstract[50]	giv|new[48]|giv[50]	coref|coref	6-6|16-22[160_50]
5-36	698-707	recursive	place[48]|abstract[50]	new[48]|giv[50]	_	_
5-37	708-713	least	place|place[48]|abstract[50]	giv|new[48]|giv[50]	coref	16-14
5-38	714-721	squares	place[48]|abstract[50]	new[48]|giv[50]	_	_
5-39	722-723	(	abstract[50]	giv[50]	_	_
5-40	724-728	KRLS	abstract|abstract[50]	new|giv[50]	coref	31-21
5-41	729-730	)	abstract[50]	giv[50]	_	_
5-42	731-740	algorithm	abstract[50]	giv[50]	_	_
5-43	741-745	have	_	_	_	_
5-44	746-750	been	_	_	_	_
5-45	751-759	proposed	_	_	_	_
5-46	760-761	.	_	_	_	_

#Text=However , allocating a new kernel unit as a radial basis function ( RBF ) center with the coming of new data , the linearly growing structure ( called “ dictionary ” hereafter ) will increase the computational and memory requirements in KAFs .
6-1	762-769	However	_	_	_	_
6-2	770-771	,	_	_	_	_
6-3	772-782	allocating	_	_	_	_
6-4	783-784	a	object[52]	new[52]	_	_
6-5	785-788	new	object[52]	new[52]	_	_
6-6	789-795	kernel	abstract|object[52]	giv|new[52]	coref	10-26
6-7	796-800	unit	object[52]	new[52]	_	_
6-8	801-803	as	_	_	_	_
6-9	804-805	a	place[56]	new[56]	_	_
6-10	806-812	radial	abstract[54]|place[56]	new[54]|new[56]	appos	6-14[0_54]
6-11	813-818	basis	abstract|abstract[54]|place[56]	new|new[54]|new[56]	coref	14-2[124_0]
6-12	819-827	function	abstract[54]|place[56]	new[54]|new[56]	_	_
6-13	828-829	(	place[56]	new[56]	_	_
6-14	830-833	RBF	abstract|place[56]	giv|new[56]	coref	17-2[167_0]
6-15	834-835	)	place[56]	new[56]	_	_
6-16	836-842	center	place[56]	new[56]	_	_
6-17	843-847	with	_	_	_	_
6-18	848-851	the	event[57]	new[57]	_	_
6-19	852-858	coming	event[57]	new[57]	_	_
6-20	859-861	of	event[57]	new[57]	_	_
6-21	862-865	new	event[57]|abstract[58]	new[57]|new[58]	coref	8-5[68_58]
6-22	866-870	data	event[57]|abstract[58]	new[57]|new[58]	_	_
6-23	871-872	,	_	_	_	_
6-24	873-876	the	abstract[59]	new[59]	coref	14-38[140_59]
6-25	877-885	linearly	abstract[59]	new[59]	_	_
6-26	886-893	growing	abstract[59]	new[59]	_	_
6-27	894-903	structure	abstract[59]	new[59]	_	_
6-28	904-905	(	abstract[59]	new[59]	_	_
6-29	906-912	called	abstract[59]	new[59]	_	_
6-30	913-914	“	abstract[59]|abstract[60]	new[59]|new[60]	coref	7-6[64_60]
6-31	915-925	dictionary	abstract[59]|abstract[60]	new[59]|new[60]	_	_
6-32	926-927	”	abstract[59]|abstract[60]	new[59]|new[60]	_	_
6-33	928-937	hereafter	abstract[59]|abstract[60]	new[59]|new[60]	_	_
6-34	938-939	)	abstract[59]	new[59]	_	_
6-35	940-944	will	_	_	_	_
6-36	945-953	increase	_	_	_	_
6-37	954-957	the	abstract[61]	new[61]	_	_
6-38	958-971	computational	abstract[61]	new[61]	_	_
6-39	972-975	and	abstract[61]	new[61]	_	_
6-40	976-982	memory	abstract[61]	new[61]	_	_
6-41	983-995	requirements	abstract[61]	new[61]	_	_
6-42	996-998	in	abstract[61]	new[61]	_	_
6-43	999-1003	KAFs	abstract[61]|abstract	new[61]|giv	coref	15-10
6-44	1004-1005	.	_	_	_	_

#Text=To curb the growth of the dictionary , two categories are chosen for sparsification .
7-1	1006-1008	To	_	_	_	_
7-2	1009-1013	curb	_	_	_	_
7-3	1014-1017	the	abstract[63]	new[63]	_	_
7-4	1018-1024	growth	abstract[63]	new[63]	_	_
7-5	1025-1027	of	abstract[63]	new[63]	_	_
7-6	1028-1031	the	abstract[63]|abstract[64]	new[63]|giv[64]	coref	8-10[0_64]
7-7	1032-1042	dictionary	abstract[63]|abstract[64]	new[63]|giv[64]	_	_
7-8	1043-1044	,	_	_	_	_
7-9	1045-1048	two	abstract[65]	new[65]	_	_
7-10	1049-1059	categories	abstract[65]	new[65]	_	_
7-11	1060-1063	are	_	_	_	_
7-12	1064-1070	chosen	_	_	_	_
7-13	1071-1074	for	_	_	_	_
7-14	1075-1089	sparsification	abstract	new	_	_
7-15	1090-1091	.	_	_	_	_

#Text=The first category accepts only informative data as new dictionary centers by using a threshold , including the surprise criterion ( SC ) , the coherence criterion ( CC ) , and the vector quantization ( VQ ) .
8-1	1092-1095	The	abstract[67]	new[67]	_	_
8-2	1096-1101	first	abstract[67]	new[67]	_	_
8-3	1102-1110	category	abstract[67]	new[67]	_	_
8-4	1111-1118	accepts	_	_	_	_
8-5	1119-1123	only	abstract[68]	giv[68]	coref	12-18[118_68]
8-6	1124-1135	informative	abstract[68]	giv[68]	_	_
8-7	1136-1140	data	abstract[68]	giv[68]	_	_
8-8	1141-1143	as	_	_	_	_
8-9	1144-1147	new	place[70]	new[70]	_	_
8-10	1148-1158	dictionary	abstract|place[70]	giv|new[70]	_	_
8-11	1159-1166	centers	place[70]	new[70]	_	_
8-12	1167-1169	by	_	_	_	_
8-13	1170-1175	using	_	_	_	_
8-14	1176-1177	a	abstract[71]	new[71]	_	_
8-15	1178-1187	threshold	abstract[71]	new[71]	_	_
8-16	1188-1189	,	abstract[71]	new[71]	_	_
8-17	1190-1199	including	abstract[71]	new[71]	_	_
8-18	1200-1203	the	abstract[71]|abstract[73]	new[71]|new[73]	appos	8-22[0_73]
8-19	1204-1212	surprise	abstract[71]|abstract|abstract[73]	new[71]|new|new[73]	_	_
8-20	1213-1222	criterion	abstract[71]|abstract[73]	new[71]|new[73]	_	_
8-21	1223-1224	(	_	_	_	_
8-22	1225-1227	SC	abstract	giv	_	_
8-23	1228-1229	)	_	_	_	_
8-24	1230-1231	,	_	_	_	_
8-25	1232-1235	the	abstract[76]	new[76]	coref	21-15[217_76]
8-26	1236-1245	coherence	abstract|abstract[76]	new|new[76]	_	_
8-27	1246-1255	criterion	abstract[76]	new[76]	_	_
8-28	1256-1257	(	_	_	_	_
8-29	1258-1260	CC	person	new	_	_
8-30	1261-1262	)	_	_	_	_
8-31	1263-1264	,	_	_	_	_
8-32	1265-1268	and	_	_	_	_
8-33	1269-1272	the	abstract[79]	new[79]	appos	8-37[0_79]
8-34	1273-1279	vector	person|abstract[79]	new|new[79]	coref	13-5
8-35	1280-1292	quantization	abstract[79]	new[79]	_	_
8-36	1293-1294	(	_	_	_	_
8-37	1295-1297	VQ	abstract	giv	_	_
8-38	1298-1299	)	_	_	_	_
8-39	1300-1301	.	_	_	_	_

#Text=However , these methods cannot fully address the growing problem and still introduce additional time consumption at each iteration .
9-1	1302-1309	However	_	_	_	_
9-2	1310-1311	,	_	_	_	_
9-3	1312-1317	these	abstract[81]	new[81]	coref	10-1[87_81]
9-4	1318-1325	methods	abstract[81]	new[81]	_	_
9-5	1326-1332	cannot	_	_	_	_
9-6	1333-1338	fully	_	_	_	_
9-7	1339-1346	address	_	_	_	_
9-8	1347-1350	the	abstract[82]	new[82]	coref	10-49[103_82]
9-9	1351-1358	growing	abstract[82]	new[82]	_	_
9-10	1359-1366	problem	abstract[82]	new[82]	_	_
9-11	1367-1370	and	_	_	_	_
9-12	1371-1376	still	_	_	_	_
9-13	1377-1386	introduce	_	_	_	_
9-14	1387-1397	additional	abstract[84]	new[84]	_	_
9-15	1398-1402	time	abstract|abstract[84]	new|new[84]	coref	11-23
9-16	1403-1414	consumption	abstract[84]	new[84]	_	_
9-17	1415-1417	at	_	_	_	_
9-18	1418-1422	each	abstract[85]	new[85]	_	_
9-19	1423-1432	iteration	abstract[85]	new[85]	_	_
9-20	1433-1434	.	_	_	_	_

#Text=The fixed points methods as the second category , including the fixed-budget ( FB ) , the sliding window ( SW ) , and the kernel approximation methods ( e.g. , the Nystrm method and random Fourier features ( RFFs ) method ) , are used to overcome the sublinearly growing problem .
10-1	1435-1438	The	abstract[87]	giv[87]	coref	10-25[95_87]
10-2	1439-1444	fixed	abstract[86]|abstract[87]	new[86]|giv[87]	_	_
10-3	1445-1451	points	abstract[86]|abstract[87]	new[86]|giv[87]	_	_
10-4	1452-1459	methods	abstract[87]	giv[87]	_	_
10-5	1460-1462	as	abstract[87]	giv[87]	_	_
10-6	1463-1466	the	abstract[87]|abstract[88]	giv[87]|new[88]	_	_
10-7	1467-1473	second	abstract[87]|abstract[88]	giv[87]|new[88]	_	_
10-8	1474-1482	category	abstract[87]|abstract[88]	giv[87]|new[88]	_	_
10-9	1483-1484	,	abstract[87]	giv[87]	_	_
10-10	1485-1494	including	abstract[87]	giv[87]	_	_
10-11	1495-1498	the	abstract[87]|abstract[89]	giv[87]|new[89]	appos	10-14[0_89]
10-12	1499-1511	fixed-budget	abstract[87]|abstract[89]	giv[87]|new[89]	_	_
10-13	1512-1513	(	_	_	_	_
10-14	1514-1516	FB	abstract	giv	coref	11-4
10-15	1517-1518	)	_	_	_	_
10-16	1519-1520	,	_	_	_	_
10-17	1521-1524	the	object[91]	new[91]	_	_
10-18	1525-1532	sliding	object[91]	new[91]	_	_
10-19	1533-1539	window	object[91]	new[91]	_	_
10-20	1540-1541	(	_	_	_	_
10-21	1542-1544	SW	abstract	new	coref	11-8
10-22	1545-1546	)	_	_	_	_
10-23	1547-1548	,	_	_	_	_
10-24	1549-1552	and	_	_	_	_
10-25	1553-1556	the	abstract[95]	giv[95]	appos	10-30[97_95]
10-26	1557-1563	kernel	abstract|abstract[94]|abstract[95]	giv|new[94]|giv[95]	coref	14-31[136_0]
10-27	1564-1577	approximation	abstract[94]|abstract[95]	new[94]|giv[95]	_	_
10-28	1578-1585	methods	abstract[95]	giv[95]	_	_
10-29	1586-1587	(	abstract[98]	giv[98]	appos|appos	10-29[98_97]|10-36[102_98]
10-30	1588-1592	e.g.	abstract[97]|abstract[98]	giv[97]|giv[98]	_	_
10-31	1593-1594	,	abstract[97]|abstract[98]	giv[97]|giv[98]	_	_
10-32	1595-1598	the	abstract[97]|abstract[98]	giv[97]|giv[98]	_	_
10-33	1599-1605	Nystrm	abstract|abstract[97]|abstract[98]	new|giv[97]|giv[98]	coref	12-4
10-34	1606-1612	method	abstract[97]|abstract[98]	giv[97]|giv[98]	_	_
10-35	1613-1616	and	abstract[98]	giv[98]	_	_
10-36	1617-1623	random	abstract[98]|abstract[100]|abstract[102]	giv[98]|new[100]|giv[102]	appos|coref	10-40[0_100]|11-3[106_102]
10-37	1624-1631	Fourier	abstract[98]|person|abstract[100]|abstract[102]	giv[98]|new|new[100]|giv[102]	coref	14-8
10-38	1632-1640	features	abstract[98]|abstract[100]|abstract[102]	giv[98]|new[100]|giv[102]	_	_
10-39	1641-1642	(	abstract[98]|abstract[102]	giv[98]|giv[102]	_	_
10-40	1643-1647	RFFs	abstract[98]|abstract|abstract[102]	giv[98]|giv|giv[102]	coref	12-7
10-41	1648-1649	)	abstract[98]|abstract[102]	giv[98]|giv[102]	_	_
10-42	1650-1656	method	abstract[98]|abstract[102]	giv[98]|giv[102]	_	_
10-43	1657-1658	)	abstract[98]|abstract[102]	giv[98]|giv[102]	_	_
10-44	1659-1660	,	_	_	_	_
10-45	1661-1664	are	_	_	_	_
10-46	1665-1669	used	_	_	_	_
10-47	1670-1672	to	_	_	_	_
10-48	1673-1681	overcome	_	_	_	_
10-49	1682-1685	the	abstract[103]	giv[103]	_	_
10-50	1686-1697	sublinearly	abstract[103]	giv[103]	_	_
10-51	1698-1705	growing	abstract[103]	giv[103]	_	_
10-52	1706-1713	problem	abstract[103]	giv[103]	_	_
10-53	1714-1715	.	_	_	_	_

#Text=However , the FB method and the SW method cannot guarantee a good performance in specific environments with a small amount of time .
11-1	1716-1723	However	_	_	_	_
11-2	1724-1725	,	_	_	_	_
11-3	1726-1729	the	abstract[105]|abstract[106]	giv[105]|giv[106]	coref|coref	11-7[108_105]|27-4[272_106]
11-4	1730-1732	FB	abstract|abstract[105]|abstract[106]	giv|giv[105]|giv[106]	_	_
11-5	1733-1739	method	abstract[105]|abstract[106]	giv[105]|giv[106]	_	_
11-6	1740-1743	and	abstract[106]	giv[106]	_	_
11-7	1744-1747	the	abstract[106]|abstract[108]	giv[106]|giv[108]	coref	12-3[114_108]
11-8	1748-1750	SW	abstract[106]|abstract|abstract[108]	giv[106]|giv|giv[108]	_	_
11-9	1751-1757	method	abstract[106]|abstract[108]	giv[106]|giv[108]	_	_
11-10	1758-1764	cannot	_	_	_	_
11-11	1765-1774	guarantee	_	_	_	_
11-12	1775-1776	a	abstract[109]	new[109]	coref	15-14[144_109]
11-13	1777-1781	good	abstract[109]	new[109]	_	_
11-14	1782-1793	performance	abstract[109]	new[109]	_	_
11-15	1794-1796	in	abstract[109]	new[109]	_	_
11-16	1797-1805	specific	abstract[109]|place[110]	new[109]|new[110]	coref	20-42[208_110]
11-17	1806-1818	environments	abstract[109]|place[110]	new[109]|new[110]	_	_
11-18	1819-1823	with	_	_	_	_
11-19	1824-1825	a	abstract[111]	new[111]	_	_
11-20	1826-1831	small	abstract[111]	new[111]	_	_
11-21	1832-1838	amount	abstract[111]	new[111]	_	_
11-22	1839-1841	of	abstract[111]	new[111]	_	_
11-23	1842-1846	time	abstract[111]|abstract	new[111]|giv	_	_
11-24	1847-1848	.	_	_	_	_

#Text=Compared with the Nystrm method , RFFs are drawn from a distribution that is randomly independent from the training data .
12-1	1849-1857	Compared	_	_	_	_
12-2	1858-1862	with	_	_	_	_
12-3	1863-1866	the	abstract[114]	giv[114]	coref	25-5[256_114]
12-4	1867-1873	Nystrm	abstract|abstract[114]	giv|giv[114]	_	_
12-5	1874-1880	method	abstract[114]	giv[114]	_	_
12-6	1881-1882	,	_	_	_	_
12-7	1883-1887	RFFs	abstract	giv	coref	13-8
12-8	1888-1891	are	_	_	_	_
12-9	1892-1897	drawn	_	_	_	_
12-10	1898-1902	from	_	_	_	_
12-11	1903-1904	a	abstract[116]	new[116]	_	_
12-12	1905-1917	distribution	abstract[116]	new[116]	_	_
12-13	1918-1922	that	abstract[116]	new[116]	_	_
12-14	1923-1925	is	abstract[116]	new[116]	_	_
12-15	1926-1934	randomly	abstract[116]	new[116]	_	_
12-16	1935-1946	independent	abstract[116]	new[116]	_	_
12-17	1947-1951	from	abstract[116]	new[116]	_	_
12-18	1952-1955	the	abstract[116]|abstract[118]	new[116]|giv[118]	coref	14-17[130_118]
12-19	1956-1964	training	abstract[116]|abstract|abstract[118]	new[116]|new|giv[118]	coref	18-33
12-20	1965-1969	data	abstract[116]|abstract[118]	new[116]|giv[118]	_	_
12-21	1970-1971	.	_	_	_	_

#Text=Due to a data-independent vector representation , RFFs can provide a good solution to non-stationary circumstances .
13-1	1972-1975	Due	_	_	_	_
13-2	1976-1978	to	_	_	_	_
13-3	1979-1980	a	abstract[120]	new[120]	_	_
13-4	1981-1997	data-independent	abstract[120]	new[120]	_	_
13-5	1998-2004	vector	person|abstract[120]	giv|new[120]	_	_
13-6	2005-2019	representation	abstract[120]	new[120]	_	_
13-7	2020-2021	,	_	_	_	_
13-8	2022-2026	RFFs	abstract	giv	coref	14-5
13-9	2027-2030	can	_	_	_	_
13-10	2031-2038	provide	_	_	_	_
13-11	2039-2040	a	abstract[122]	new[122]	coref	31-10[312_122]
13-12	2041-2045	good	abstract[122]	new[122]	_	_
13-13	2046-2054	solution	abstract[122]	new[122]	_	_
13-14	2055-2057	to	abstract[122]	new[122]	_	_
13-15	2058-2072	non-stationary	abstract[122]|abstract[123]	new[122]|new[123]	_	_
13-16	2073-2086	circumstances	abstract[122]|abstract[123]	new[122]|new[123]	_	_
13-17	2087-2088	.	_	_	_	_

#Text=On the basis of RFFs , random Fourier mapping ( RFM ) is proposed by mapping input data into a finite-dimensional random Fourier features space ( RFFS ) using a randomized feature kernel ’s Fourier transform in a fixed network structure .
14-1	2089-2091	On	_	_	_	_
14-2	2092-2095	the	abstract[124]	giv[124]	_	_
14-3	2096-2101	basis	abstract[124]	giv[124]	_	_
14-4	2102-2104	of	abstract[124]	giv[124]	_	_
14-5	2105-2109	RFFs	abstract[124]|abstract	giv[124]|giv	coref	14-22[132_0]
14-6	2110-2111	,	_	_	_	_
14-7	2112-2118	random	abstract[127]	new[127]	appos	14-11[0_127]
14-8	2119-2126	Fourier	person|abstract[127]	giv|new[127]	coref	14-23
14-9	2127-2134	mapping	abstract[127]	new[127]	_	_
14-10	2135-2136	(	_	_	_	_
14-11	2137-2140	RFM	abstract	giv	coref	15-1[141_0]
14-12	2141-2142	)	_	_	_	_
14-13	2143-2145	is	_	_	_	_
14-14	2146-2154	proposed	_	_	_	_
14-15	2155-2157	by	_	_	_	_
14-16	2158-2165	mapping	_	_	_	_
14-17	2166-2171	input	abstract|abstract[130]	new|giv[130]	coref	18-32[188_130]
14-18	2172-2176	data	abstract[130]	giv[130]	_	_
14-19	2177-2181	into	_	_	_	_
14-20	2182-2183	a	abstract[133]	giv[133]	appos	14-27[0_133]
14-21	2184-2202	finite-dimensional	abstract[133]	giv[133]	_	_
14-22	2203-2209	random	abstract[132]|abstract[133]	giv[132]|giv[133]	coref	16-10[150_132]
14-23	2210-2217	Fourier	person|abstract[132]|abstract[133]	giv|giv[132]|giv[133]	coref	14-35
14-24	2218-2226	features	abstract[132]|abstract[133]	giv[132]|giv[133]	_	_
14-25	2227-2232	space	abstract[133]	giv[133]	_	_
14-26	2233-2234	(	_	_	_	_
14-27	2235-2239	RFFS	abstract	giv	_	_
14-28	2240-2241	)	_	_	_	_
14-29	2242-2247	using	_	_	_	_
14-30	2248-2249	a	abstract[138]	new[138]	_	_
14-31	2250-2260	randomized	abstract[136]|abstract[138]	giv[136]|new[138]	coref	30-5[0_136]
14-32	2261-2268	feature	abstract|abstract[136]|abstract[138]	new|giv[136]|new[138]	_	_
14-33	2269-2275	kernel	abstract[136]|abstract[138]	giv[136]|new[138]	_	_
14-34	2276-2278	’s	abstract[136]|abstract[138]	giv[136]|new[138]	_	_
14-35	2279-2286	Fourier	person|abstract[138]	giv|new[138]	coref	16-11
14-36	2287-2296	transform	abstract[138]	new[138]	_	_
14-37	2297-2299	in	abstract[138]	new[138]	_	_
14-38	2300-2301	a	abstract[138]|abstract[140]	new[138]|giv[140]	_	_
14-39	2302-2307	fixed	abstract[138]|abstract[140]	new[138]|giv[140]	_	_
14-40	2308-2315	network	abstract[138]|abstract|abstract[140]	new[138]|new|giv[140]	_	_
14-41	2316-2325	structure	abstract[138]|abstract[140]	new[138]|giv[140]	_	_
14-42	2326-2327	.	_	_	_	_

#Text=The RFM alleviates the computational and storage burdens of KAFs , and ensures a satisfactory performance under non-stationary conditions .
15-1	2328-2331	The	abstract[141]	giv[141]	coref	16-7[0_141]
15-2	2332-2335	RFM	abstract[141]	giv[141]	_	_
15-3	2336-2346	alleviates	_	_	_	_
15-4	2347-2350	the	abstract[142]	new[142]	_	_
15-5	2351-2364	computational	abstract[142]	new[142]	_	_
15-6	2365-2368	and	abstract[142]	new[142]	_	_
15-7	2369-2376	storage	abstract[142]	new[142]	_	_
15-8	2377-2384	burdens	abstract[142]	new[142]	_	_
15-9	2385-2387	of	abstract[142]	new[142]	_	_
15-10	2388-2392	KAFs	abstract[142]|abstract	new[142]|giv	coref	16-5
15-11	2393-2394	,	_	_	_	_
15-12	2395-2398	and	_	_	_	_
15-13	2399-2406	ensures	_	_	_	_
15-14	2407-2408	a	abstract[144]	giv[144]	coref	18-25[186_144]
15-15	2409-2421	satisfactory	abstract[144]	giv[144]	_	_
15-16	2422-2433	performance	abstract[144]	giv[144]	_	_
15-17	2434-2439	under	abstract[144]	giv[144]	_	_
15-18	2440-2454	non-stationary	abstract[144]|abstract[145]	giv[144]|new[145]	_	_
15-19	2455-2465	conditions	abstract[144]|abstract[145]	giv[144]|new[145]	_	_
15-20	2466-2467	.	_	_	_	_

#Text=The examples for developing KAFs with RFM are the random Fourier features kernel least mean square ( RFFKLMS ) algorithm , random Fourier features maximum correntropy ( RFFMC ) algorithm , and random Fourier features conjugate gradient ( RFFCG ) algorithm .
16-1	2468-2471	The	abstract[146]	new[146]	coref	16-9[155_146]
16-2	2472-2480	examples	abstract[146]	new[146]	_	_
16-3	2481-2484	for	abstract[146]	new[146]	_	_
16-4	2485-2495	developing	abstract[146]	new[146]	_	_
16-5	2496-2500	KAFs	abstract[146]|abstract	new[146]|giv	coref	17-39
16-6	2501-2505	with	abstract[146]	new[146]	_	_
16-7	2506-2509	RFM	abstract[146]|abstract	new[146]|giv	_	_
16-8	2510-2513	are	_	_	_	_
16-9	2514-2517	the	abstract[155]|abstract[156]	giv[155]|giv[156]	coref|ana	16-9[156_155]|17-8[0_156]
16-10	2518-2524	random	abstract[150]|place[153]|abstract[155]|abstract[156]	giv[150]|giv[153]|giv[155]|giv[156]	coref	17-26[0_153]
16-11	2525-2532	Fourier	person|abstract[150]|place[153]|abstract[155]|abstract[156]	giv|giv[150]|giv[153]|giv[155]|giv[156]	coref	16-23
16-12	2533-2541	features	abstract[150]|place[153]|abstract[155]|abstract[156]	giv[150]|giv[153]|giv[155]|giv[156]	_	_
16-13	2542-2548	kernel	place[153]|abstract[155]|abstract[156]	giv[153]|giv[155]|giv[156]	_	_
16-14	2549-2554	least	place|abstract[152]|place[153]|abstract[155]|abstract[156]	giv|giv[152]|giv[153]|giv[155]|giv[156]	coref|coref	17-25[0_152]|17-32
16-15	2555-2559	mean	abstract[152]|place[153]|abstract[155]|abstract[156]	giv[152]|giv[153]|giv[155]|giv[156]	_	_
16-16	2560-2566	square	place[153]|abstract[155]|abstract[156]	giv[153]|giv[155]|giv[156]	_	_
16-17	2567-2568	(	abstract[155]|abstract[156]	giv[155]|giv[156]	_	_
16-18	2569-2576	RFFKLMS	abstract|abstract[155]|abstract[156]	new|giv[155]|giv[156]	_	_
16-19	2577-2578	)	abstract[155]|abstract[156]	giv[155]|giv[156]	_	_
16-20	2579-2588	algorithm	abstract[155]|abstract[156]	giv[155]|giv[156]	_	_
16-21	2589-2590	,	abstract[156]	giv[156]	_	_
16-22	2591-2597	random	abstract[156]|abstract[158]|abstract[160]	giv[156]|new[158]|giv[160]	appos|coref	16-28[0_158]|16-33[165_160]
16-23	2598-2605	Fourier	abstract[156]|person|abstract[158]|abstract[160]	giv[156]|giv|new[158]|giv[160]	coref	16-34
16-24	2606-2614	features	abstract[156]|abstract[158]|abstract[160]	giv[156]|new[158]|giv[160]	_	_
16-25	2615-2622	maximum	abstract[156]|abstract[158]|abstract[160]	giv[156]|new[158]|giv[160]	_	_
16-26	2623-2634	correntropy	abstract[156]|abstract[158]|abstract[160]	giv[156]|new[158]|giv[160]	_	_
16-27	2635-2636	(	abstract[156]|abstract[160]	giv[156]|giv[160]	_	_
16-28	2637-2642	RFFMC	abstract[156]|abstract|abstract[160]	giv[156]|giv|giv[160]	coref	21-17
16-29	2643-2644	)	abstract[156]|abstract[160]	giv[156]|giv[160]	_	_
16-30	2645-2654	algorithm	abstract[156]|abstract[160]	giv[156]|giv[160]	_	_
16-31	2655-2656	,	abstract[156]	giv[156]	_	_
16-32	2657-2660	and	abstract[156]	giv[156]	_	_
16-33	2661-2667	random	abstract[156]|substance[163]|abstract[165]	giv[156]|giv[163]|giv[165]	coref	25-11[0_163]
16-34	2668-2675	Fourier	abstract[156]|person|substance[163]|abstract[165]	giv[156]|giv|giv[163]|giv[165]	_	_
16-35	2676-2684	features	abstract[156]|substance[163]|abstract[165]	giv[156]|giv[163]|giv[165]	_	_
16-36	2685-2694	conjugate	abstract[156]|abstract|substance[163]|abstract[165]	giv[156]|new|giv[163]|giv[165]	coref	27-12
16-37	2695-2703	gradient	abstract[156]|substance[163]|abstract[165]	giv[156]|giv[163]|giv[165]	_	_
16-38	2704-2705	(	abstract[156]|abstract[165]	giv[156]|giv[165]	_	_
16-39	2706-2711	RFFCG	abstract[156]|abstract|abstract[165]	giv[156]|new|giv[165]	_	_
16-40	2712-2713	)	abstract[156]|abstract[165]	giv[156]|giv[165]	_	_
16-41	2714-2723	algorithm	abstract[156]|abstract[165]	giv[156]|giv[165]	_	_
16-42	2724-2725	.	_	_	_	_

#Text=For the loss function , due to their simplicity , smoothness , and mathematical tractability , the second-order statistical measures ( e.g. , minimum mean square error ( MMSE ) and least squares ) are widely utilized in KAFs .
17-1	2726-2729	For	_	_	_	_
17-2	2730-2733	the	abstract[167]	giv[167]	_	_
17-3	2734-2738	loss	abstract|abstract[167]	new|giv[167]	coref	23-18[238_0]
17-4	2739-2747	function	abstract[167]	giv[167]	_	_
17-5	2748-2749	,	_	_	_	_
17-6	2750-2753	due	_	_	_	_
17-7	2754-2756	to	_	_	_	_
17-8	2757-2762	their	abstract|abstract[169]	giv|new[169]	coref	19-17[197_0]
17-9	2763-2773	simplicity	abstract[169]	new[169]	_	_
17-10	2774-2775	,	_	_	_	_
17-11	2776-2786	smoothness	abstract	new	_	_
17-12	2787-2788	,	_	_	_	_
17-13	2789-2792	and	_	_	_	_
17-14	2793-2805	mathematical	abstract[171]	new[171]	_	_
17-15	2806-2818	tractability	abstract[171]	new[171]	_	_
17-16	2819-2820	,	_	_	_	_
17-17	2821-2824	the	abstract[172]	new[172]	appos	17-22[176_172]
17-18	2825-2837	second-order	abstract[172]	new[172]	_	_
17-19	2838-2849	statistical	abstract[172]	new[172]	_	_
17-20	2850-2858	measures	abstract[172]	new[172]	_	_
17-21	2859-2860	(	_	_	_	_
17-22	2861-2865	e.g.	abstract[176]	giv[176]	appos	17-29[0_176]
17-23	2866-2867	,	abstract[176]	giv[176]	_	_
17-24	2868-2875	minimum	abstract|abstract[176]	new|giv[176]	coref	25-18[260_0]
17-25	2876-2880	mean	abstract|abstract[176]	giv|giv[176]	_	_
17-26	2881-2887	square	place|abstract[176]	giv|giv[176]	_	_
17-27	2888-2893	error	abstract[176]	giv[176]	_	_
17-28	2894-2895	(	_	_	_	_
17-29	2896-2900	MMSE	abstract	giv	appos	17-32[179_0]
17-30	2901-2902	)	_	_	_	_
17-31	2903-2906	and	_	_	_	_
17-32	2907-2912	least	place|abstract[179]	giv|giv[179]	coref	18-6[182_179]
17-33	2913-2920	squares	abstract[179]	giv[179]	_	_
17-34	2921-2922	)	_	_	_	_
17-35	2923-2926	are	_	_	_	_
17-36	2927-2933	widely	_	_	_	_
17-37	2934-2942	utilized	_	_	_	_
17-38	2943-2945	in	_	_	_	_
17-39	2946-2950	KAFs	abstract	giv	coref	18-3[181_0]
17-40	2951-2952	.	_	_	_	_

#Text=However , KAFs based on the second-order statistical measures are sensitive to non-Gaussian noises including the sub-Gaussian and super-Gaussian noises , which means that their performance may be seriously degraded if the training data are contaminated by outliers .
18-1	2953-2960	However	_	_	_	_
18-2	2961-2962	,	_	_	_	_
18-3	2963-2967	KAFs	abstract[181]	giv[181]	coref	21-36[223_181]
18-4	2968-2973	based	abstract[181]	giv[181]	_	_
18-5	2974-2976	on	abstract[181]	giv[181]	_	_
18-6	2977-2980	the	abstract[181]|abstract[182]	giv[181]|giv[182]	coref	19-6[191_182]
18-7	2981-2993	second-order	abstract[181]|abstract[182]	giv[181]|giv[182]	_	_
18-8	2994-3005	statistical	abstract[181]|abstract[182]	giv[181]|giv[182]	_	_
18-9	3006-3014	measures	abstract[181]|abstract[182]	giv[181]|giv[182]	_	_
18-10	3015-3018	are	_	_	_	_
18-11	3019-3028	sensitive	_	_	_	_
18-12	3029-3031	to	_	_	_	_
18-13	3032-3044	non-Gaussian	abstract[183]	new[183]	coref	18-16[184_183]
18-14	3045-3051	noises	abstract[183]	new[183]	_	_
18-15	3052-3061	including	abstract[183]	new[183]	_	_
18-16	3062-3065	the	abstract[183]|abstract[184]	new[183]|giv[184]	ana	18-25[0_184]
18-17	3066-3078	sub-Gaussian	abstract[183]|abstract[184]	new[183]|giv[184]	_	_
18-18	3079-3082	and	abstract[183]|abstract[184]	new[183]|giv[184]	_	_
18-19	3083-3097	super-Gaussian	abstract[183]|abstract[184]	new[183]|giv[184]	_	_
18-20	3098-3104	noises	abstract[183]|abstract[184]	new[183]|giv[184]	_	_
18-21	3105-3106	,	abstract[183]|abstract[184]	new[183]|giv[184]	_	_
18-22	3107-3112	which	abstract[183]|abstract[184]	new[183]|giv[184]	_	_
18-23	3113-3118	means	abstract[183]|abstract[184]	new[183]|giv[184]	_	_
18-24	3119-3123	that	abstract[183]|abstract[184]	new[183]|giv[184]	_	_
18-25	3124-3129	their	abstract[183]|abstract[184]|abstract|abstract[186]	new[183]|giv[184]|giv|giv[186]	coref	20-14[201_0]
18-26	3130-3141	performance	abstract[183]|abstract[184]|abstract[186]	new[183]|giv[184]|giv[186]	_	_
18-27	3142-3145	may	abstract[183]|abstract[184]	new[183]|giv[184]	_	_
18-28	3146-3148	be	abstract[183]|abstract[184]	new[183]|giv[184]	_	_
18-29	3149-3158	seriously	abstract[183]|abstract[184]	new[183]|giv[184]	_	_
18-30	3159-3167	degraded	abstract[183]|abstract[184]	new[183]|giv[184]	_	_
18-31	3168-3170	if	_	_	_	_
18-32	3171-3174	the	abstract[188]	giv[188]	_	_
18-33	3175-3183	training	abstract|abstract[188]	giv|giv[188]	coref	22-24
18-34	3184-3188	data	abstract[188]	giv[188]	_	_
18-35	3189-3192	are	_	_	_	_
18-36	3193-3205	contaminated	_	_	_	_
18-37	3206-3208	by	_	_	_	_
18-38	3209-3217	outliers	abstract	new	_	_
18-39	3218-3219	.	_	_	_	_

#Text=To handle this issue , robust statistical measures have therefore gained more attention , among which the lower-order error measure and the higher-lower error measure are two typical examples .
19-1	3220-3222	To	_	_	_	_
19-2	3223-3229	handle	_	_	_	_
19-3	3230-3234	this	abstract[190]	new[190]	_	_
19-4	3235-3240	issue	abstract[190]	new[190]	_	_
19-5	3241-3242	,	_	_	_	_
19-6	3243-3249	robust	abstract[191]	giv[191]	coref	21-3[215_191]
19-7	3250-3261	statistical	abstract[191]	giv[191]	_	_
19-8	3262-3270	measures	abstract[191]	giv[191]	_	_
19-9	3271-3275	have	_	_	_	_
19-10	3276-3285	therefore	_	_	_	_
19-11	3286-3292	gained	_	_	_	_
19-12	3293-3297	more	abstract[192]	new[192]	_	_
19-13	3298-3307	attention	abstract[192]	new[192]	_	_
19-14	3308-3309	,	abstract[192]	new[192]	_	_
19-15	3310-3315	among	abstract[192]	new[192]	_	_
19-16	3316-3321	which	abstract[192]	new[192]	_	_
19-17	3322-3325	the	abstract[192]|abstract[194]|abstract[197]	new[192]|new[194]|giv[197]	_	_
19-18	3326-3337	lower-order	abstract[192]|abstract[194]|abstract[197]	new[192]|new[194]|giv[197]	_	_
19-19	3338-3343	error	abstract[192]|abstract|abstract[194]|abstract[197]	new[192]|new|new[194]|giv[197]	coref	19-24
19-20	3344-3351	measure	abstract[192]|abstract[194]|abstract[197]	new[192]|new[194]|giv[197]	_	_
19-21	3352-3355	and	abstract[192]|abstract[197]	new[192]|giv[197]	_	_
19-22	3356-3359	the	abstract[192]|abstract[196]|abstract[197]	new[192]|new[196]|giv[197]	coref	20-3[199_196]
19-23	3360-3372	higher-lower	abstract[192]|abstract[196]|abstract[197]	new[192]|new[196]|giv[197]	_	_
19-24	3373-3378	error	abstract[192]|abstract|abstract[196]|abstract[197]	new[192]|giv|new[196]|giv[197]	coref	20-5
19-25	3379-3386	measure	abstract[192]|abstract[196]|abstract[197]	new[192]|new[196]|giv[197]	_	_
19-26	3387-3390	are	abstract[192]|abstract[197]	new[192]|giv[197]	_	_
19-27	3391-3394	two	abstract[192]|abstract[197]	new[192]|giv[197]	_	_
19-28	3395-3402	typical	abstract[192]|abstract[197]	new[192]|giv[197]	_	_
19-29	3403-3411	examples	abstract[192]|abstract[197]	new[192]|giv[197]	_	_
19-30	3412-3413	.	_	_	_	_

#Text=However , the higher-order error measure is not suitable for the mixture of Gaussian and super-Gaussian noises ( Laplace , -stable , etc. ) with poor stability and astringency , and the lower-order measure of error is usually more desirable in these noise environments with slow convergence rate .
20-1	3414-3421	However	_	_	_	_
20-2	3422-3423	,	_	_	_	_
20-3	3424-3427	the	abstract[199]	giv[199]	coref	20-32[205_199]
20-4	3428-3440	higher-order	abstract[199]	giv[199]	_	_
20-5	3441-3446	error	abstract|abstract[199]	giv|giv[199]	coref	20-36
20-6	3447-3454	measure	abstract[199]	giv[199]	_	_
20-7	3455-3457	is	_	_	_	_
20-8	3458-3461	not	_	_	_	_
20-9	3462-3470	suitable	_	_	_	_
20-10	3471-3474	for	_	_	_	_
20-11	3475-3478	the	abstract[200]	new[200]	_	_
20-12	3479-3486	mixture	abstract[200]	new[200]	_	_
20-13	3487-3489	of	abstract[200]	new[200]	_	_
20-14	3490-3498	Gaussian	abstract[200]|abstract[201]	new[200]|giv[201]	coref	22-14[228_201]
20-15	3499-3502	and	abstract[200]|abstract[201]	new[200]|giv[201]	_	_
20-16	3503-3517	super-Gaussian	abstract[200]|abstract[201]	new[200]|giv[201]	_	_
20-17	3518-3524	noises	abstract[200]|abstract[201]	new[200]|giv[201]	_	_
20-18	3525-3526	(	_	_	_	_
20-19	3527-3534	Laplace	person	new	_	_
20-20	3535-3536	,	_	_	_	_
20-21	3537-3544	-stable	_	_	_	_
20-22	3545-3546	,	_	_	_	_
20-23	3547-3551	etc.	_	_	_	_
20-24	3552-3553	)	_	_	_	_
20-25	3554-3558	with	_	_	_	_
20-26	3559-3563	poor	abstract[203]	new[203]	_	_
20-27	3564-3573	stability	abstract[203]	new[203]	_	_
20-28	3574-3577	and	_	_	_	_
20-29	3578-3589	astringency	organization	new	_	_
20-30	3590-3591	,	_	_	_	_
20-31	3592-3595	and	_	_	_	_
20-32	3596-3599	the	abstract[205]	giv[205]	coref	23-12[236_205]
20-33	3600-3611	lower-order	abstract[205]	giv[205]	_	_
20-34	3612-3619	measure	abstract[205]	giv[205]	_	_
20-35	3620-3622	of	abstract[205]	giv[205]	_	_
20-36	3623-3628	error	abstract[205]|abstract	giv[205]|giv	coref	21-24
20-37	3629-3631	is	_	_	_	_
20-38	3632-3639	usually	_	_	_	_
20-39	3640-3644	more	_	_	_	_
20-40	3645-3654	desirable	_	_	_	_
20-41	3655-3657	in	_	_	_	_
20-42	3658-3663	these	place[208]	giv[208]	_	_
20-43	3664-3669	noise	abstract|place[208]	new|giv[208]	coref	24-8
20-44	3670-3682	environments	place[208]	giv[208]	_	_
20-45	3683-3687	with	place[208]	giv[208]	_	_
20-46	3688-3692	slow	place[208]|abstract[210]	giv[208]|new[210]	coref	29-10[297_210]
20-47	3693-3704	convergence	place[208]|abstract|abstract[210]	giv[208]|new|new[210]	coref	29-10
20-48	3705-3709	rate	place[208]|abstract[210]	giv[208]|new[210]	_	_
20-49	3710-3711	.	_	_	_	_

#Text=Recently , the information theoretic learning ( ITL ) similarity measures , such as the maximum correntropy criterion ( MCC ) and minimum error entropy criterion ( MEE ) , have been introduced to implement robust KAFs .
21-1	3712-3720	Recently	_	_	_	_
21-2	3721-3722	,	_	_	_	_
21-3	3723-3726	the	abstract[215]	giv[215]	coref	22-1[226_215]
21-4	3727-3738	information	abstract|abstract[212]|abstract[215]	new|giv[212]|giv[215]	appos	21-8[0_212]
21-5	3739-3748	theoretic	abstract[212]|abstract[215]	giv[212]|giv[215]	_	_
21-6	3749-3757	learning	abstract[212]|abstract[215]	giv[212]|giv[215]	_	_
21-7	3758-3759	(	abstract[215]	giv[215]	_	_
21-8	3760-3763	ITL	abstract|abstract[215]	giv|giv[215]	coref	22-2
21-9	3764-3765	)	abstract[215]	giv[215]	_	_
21-10	3766-3776	similarity	abstract|abstract[215]	new|giv[215]	coref	22-3
21-11	3777-3785	measures	abstract[215]	giv[215]	_	_
21-12	3786-3787	,	abstract[215]	giv[215]	_	_
21-13	3788-3792	such	abstract[215]	giv[215]	_	_
21-14	3793-3795	as	abstract[215]	giv[215]	_	_
21-15	3796-3799	the	abstract[215]|abstract[217]	giv[215]|giv[217]	appos	21-20[0_217]
21-16	3800-3807	maximum	abstract[215]|abstract[217]	giv[215]|giv[217]	_	_
21-17	3808-3819	correntropy	abstract[215]|abstract|abstract[217]	giv[215]|giv|giv[217]	_	_
21-18	3820-3829	criterion	abstract[215]|abstract[217]	giv[215]|giv[217]	_	_
21-19	3830-3831	(	_	_	_	_
21-20	3832-3835	MCC	abstract	giv	coref	21-23[221_0]
21-21	3836-3837	)	_	_	_	_
21-22	3838-3841	and	_	_	_	_
21-23	3842-3849	minimum	abstract[220]|abstract[221]	new[220]|giv[221]	appos	21-28[0_221]
21-24	3850-3855	error	abstract|abstract[220]|abstract[221]	giv|new[220]|giv[221]	coref	23-9[234_0]
21-25	3856-3863	entropy	abstract[220]|abstract[221]	new[220]|giv[221]	_	_
21-26	3864-3873	criterion	abstract[221]	giv[221]	_	_
21-27	3874-3875	(	_	_	_	_
21-28	3876-3879	MEE	abstract	giv	coref	24-15[251_0]
21-29	3880-3881	)	_	_	_	_
21-30	3882-3883	,	_	_	_	_
21-31	3884-3888	have	_	_	_	_
21-32	3889-3893	been	_	_	_	_
21-33	3894-3904	introduced	_	_	_	_
21-34	3905-3907	to	_	_	_	_
21-35	3908-3917	implement	_	_	_	_
21-36	3918-3924	robust	abstract[223]	giv[223]	coref	27-32[0_223]
21-37	3925-3929	KAFs	abstract[223]	giv[223]	_	_
21-38	3930-3931	.	_	_	_	_

#Text=The ITL similarity measures have been shown to have a strong robustness against non-Gaussian noises at the expense of increasing computational burden in training processing .
22-1	3932-3935	The	abstract[226]	giv[226]	_	_
22-2	3936-3939	ITL	abstract|abstract[226]	giv|giv[226]	_	_
22-3	3940-3950	similarity	abstract|abstract[226]	giv|giv[226]	_	_
22-4	3951-3959	measures	abstract[226]	giv[226]	_	_
22-5	3960-3964	have	_	_	_	_
22-6	3965-3969	been	_	_	_	_
22-7	3970-3975	shown	_	_	_	_
22-8	3976-3978	to	_	_	_	_
22-9	3979-3983	have	_	_	_	_
22-10	3984-3985	a	abstract[227]	new[227]	_	_
22-11	3986-3992	strong	abstract[227]	new[227]	_	_
22-12	3993-4003	robustness	abstract[227]	new[227]	_	_
22-13	4004-4011	against	abstract[227]	new[227]	_	_
22-14	4012-4024	non-Gaussian	abstract[227]|abstract[228]	new[227]|giv[228]	coref	24-27[252_228]
22-15	4025-4031	noises	abstract[227]|abstract[228]	new[227]|giv[228]	_	_
22-16	4032-4034	at	_	_	_	_
22-17	4035-4038	the	abstract[229]	new[229]	_	_
22-18	4039-4046	expense	abstract[229]	new[229]	_	_
22-19	4047-4049	of	abstract[229]	new[229]	_	_
22-20	4050-4060	increasing	abstract[229]	new[229]	_	_
22-21	4061-4074	computational	abstract[229]|abstract[230]	new[229]|new[230]	_	_
22-22	4075-4081	burden	abstract[229]|abstract[230]	new[229]|new[230]	_	_
22-23	4082-4084	in	abstract[229]|abstract[230]	new[229]|new[230]	_	_
22-24	4085-4093	training	abstract[229]|abstract[230]|abstract|abstract[232]	new[229]|new[230]|giv|new[232]	_	_
22-25	4094-4104	processing	abstract[229]|abstract[230]|abstract[232]	new[229]|new[230]|new[232]	_	_
22-26	4105-4106	.	_	_	_	_

#Text=In addition , minimizing the logarithmic moments of the error , the logarithmic error measure — including the Cauchy loss ( CL ) with low computational complexity — is an appropriate measure of optimality .
23-1	4107-4109	In	_	_	_	_
23-2	4110-4118	addition	_	_	_	_
23-3	4119-4120	,	_	_	_	_
23-4	4121-4131	minimizing	_	_	_	_
23-5	4132-4135	the	abstract[233]	new[233]	_	_
23-6	4136-4147	logarithmic	abstract[233]	new[233]	_	_
23-7	4148-4155	moments	abstract[233]	new[233]	_	_
23-8	4156-4158	of	abstract[233]	new[233]	_	_
23-9	4159-4162	the	abstract[233]|abstract[234]	new[233]|giv[234]	coref	23-14[0_234]
23-10	4163-4168	error	abstract[233]|abstract[234]	new[233]|giv[234]	_	_
23-11	4169-4170	,	_	_	_	_
23-12	4171-4174	the	abstract[236]	giv[236]	coref	23-30[241_236]
23-13	4175-4186	logarithmic	abstract[236]	giv[236]	_	_
23-14	4187-4192	error	abstract|abstract[236]	giv|giv[236]	_	_
23-15	4193-4200	measure	abstract[236]	giv[236]	_	_
23-16	4201-4202	—	abstract[236]	giv[236]	_	_
23-17	4203-4212	including	abstract[236]	giv[236]	_	_
23-18	4213-4216	the	abstract[236]|abstract[238]	giv[236]|giv[238]	appos	23-22[0_238]
23-19	4217-4223	Cauchy	abstract[236]|abstract|abstract[238]	giv[236]|new|giv[238]	coref	24-3
23-20	4224-4228	loss	abstract[236]|abstract[238]	giv[236]|giv[238]	_	_
23-21	4229-4230	(	_	_	_	_
23-22	4231-4233	CL	abstract	giv	coref	24-2[244_0]
23-23	4234-4235	)	_	_	_	_
23-24	4236-4240	with	_	_	_	_
23-25	4241-4244	low	abstract[240]	new[240]	coref	29-13[298_240]
23-26	4245-4258	computational	abstract[240]	new[240]	_	_
23-27	4259-4269	complexity	abstract[240]	new[240]	_	_
23-28	4270-4271	—	_	_	_	_
23-29	4272-4274	is	_	_	_	_
23-30	4275-4277	an	abstract[241]	giv[241]	_	_
23-31	4278-4289	appropriate	abstract[241]	giv[241]	_	_
23-32	4290-4297	measure	abstract[241]	giv[241]	_	_
23-33	4298-4300	of	abstract[241]	giv[241]	_	_
23-34	4301-4311	optimality	abstract[241]|abstract	giv[241]|new	_	_
23-35	4312-4313	.	_	_	_	_

#Text=Using the Cauchy loss to penalize the noise term , some algorithms based on the minimum Cauchy loss ( MCL ) criterion are efficient for combating non-Gaussian noises , especially for heavy-tailed - stable noises .
24-1	4314-4319	Using	_	_	_	_
24-2	4320-4323	the	abstract[244]	giv[244]	coref	24-16[249_244]
24-3	4324-4330	Cauchy	abstract|abstract[244]	giv|giv[244]	coref	24-17
24-4	4331-4335	loss	abstract[244]	giv[244]	_	_
24-5	4336-4338	to	_	_	_	_
24-6	4339-4347	penalize	_	_	_	_
24-7	4348-4351	the	abstract[246]	new[246]	_	_
24-8	4352-4357	noise	abstract|abstract[246]	giv|new[246]	_	_
24-9	4358-4362	term	abstract[246]	new[246]	_	_
24-10	4363-4364	,	_	_	_	_
24-11	4365-4369	some	abstract[247]	giv[247]	coref	25-9[259_247]
24-12	4370-4380	algorithms	abstract[247]	giv[247]	_	_
24-13	4381-4386	based	abstract[247]	giv[247]	_	_
24-14	4387-4389	on	abstract[247]	giv[247]	_	_
24-15	4390-4393	the	abstract[247]|abstract[251]	giv[247]|giv[251]	_	_
24-16	4394-4401	minimum	abstract[247]|abstract[249]|abstract[251]	giv[247]|giv[249]|giv[251]	appos	24-20[0_249]
24-17	4402-4408	Cauchy	abstract[247]|abstract|abstract[249]|abstract[251]	giv[247]|giv|giv[249]|giv[251]	_	_
24-18	4409-4413	loss	abstract[247]|abstract[249]|abstract[251]	giv[247]|giv[249]|giv[251]	_	_
24-19	4414-4415	(	abstract[247]|abstract[251]	giv[247]|giv[251]	_	_
24-20	4416-4419	MCL	abstract[247]|abstract|abstract[251]	giv[247]|giv|giv[251]	coref	25-26
24-21	4420-4421	)	abstract[247]|abstract[251]	giv[247]|giv[251]	_	_
24-22	4422-4431	criterion	abstract[247]|abstract[251]	giv[247]|giv[251]	_	_
24-23	4432-4435	are	_	_	_	_
24-24	4436-4445	efficient	_	_	_	_
24-25	4446-4449	for	_	_	_	_
24-26	4450-4459	combating	_	_	_	_
24-27	4460-4472	non-Gaussian	abstract[252]	giv[252]	coref	24-30[253_252]
24-28	4473-4479	noises	abstract[252]	giv[252]	_	_
24-29	4480-4481	,	_	_	_	_
24-30	4482-4492	especially	abstract[253]	giv[253]	_	_
24-31	4493-4496	for	abstract[253]	giv[253]	_	_
24-32	4497-4509	heavy-tailed	abstract[253]	giv[253]	_	_
24-33	4510-4511	-	abstract[253]	giv[253]	_	_
24-34	4512-4518	stable	abstract[253]	giv[253]	_	_
24-35	4519-4525	noises	abstract[253]	giv[253]	_	_
24-36	4526-4527	.	_	_	_	_

#Text=From the aspect of the optimization method , the stochastic gradient descent ( SGD)-based algorithms cannot find the minimum using the negative gradient in some loss functions .
25-1	4528-4532	From	_	_	_	_
25-2	4533-4536	the	abstract[254]	new[254]	_	_
25-3	4537-4543	aspect	abstract[254]	new[254]	_	_
25-4	4544-4546	of	abstract[254]	new[254]	_	_
25-5	4547-4550	the	abstract[254]|abstract[256]	new[254]|giv[256]	coref	27-4[271_256]
25-6	4551-4563	optimization	abstract[254]|abstract|abstract[256]	new[254]|new|giv[256]	coref	27-29
25-7	4564-4570	method	abstract[254]|abstract[256]	new[254]|giv[256]	_	_
25-8	4571-4572	,	_	_	_	_
25-9	4573-4576	the	abstract[258]|abstract[259]	giv[258]|giv[259]	coref|coref	26-5[265_259]|27-5[0_258]
25-10	4577-4587	stochastic	abstract[258]|abstract[259]	giv[258]|giv[259]	_	_
25-11	4588-4596	gradient	substance|abstract[258]|abstract[259]	giv|giv[258]|giv[259]	coref	25-21[261_0]
25-12	4597-4604	descent	abstract[258]|abstract[259]	giv[258]|giv[259]	_	_
25-13	4605-4606	(	abstract[259]	giv[259]	_	_
25-14	4607-4617	SGD)-based	abstract[259]	giv[259]	_	_
25-15	4618-4628	algorithms	abstract[259]	giv[259]	_	_
25-16	4629-4635	cannot	_	_	_	_
25-17	4636-4640	find	_	_	_	_
25-18	4641-4644	the	abstract[260]	giv[260]	_	_
25-19	4645-4652	minimum	abstract[260]	giv[260]	_	_
25-20	4653-4658	using	_	_	_	_
25-21	4659-4662	the	substance[261]	giv[261]	coref	27-12[275_261]
25-22	4663-4671	negative	substance[261]	giv[261]	_	_
25-23	4672-4680	gradient	substance[261]	giv[261]	_	_
25-24	4681-4683	in	substance[261]	giv[261]	_	_
25-25	4684-4688	some	substance[261]|abstract[263]	giv[261]|new[263]	_	_
25-26	4689-4693	loss	substance[261]|abstract|abstract[263]	giv[261]|giv|new[263]	_	_
25-27	4694-4703	functions	substance[261]|abstract[263]	giv[261]|new[263]	_	_
25-28	4704-4705	.	_	_	_	_

#Text=Toward this end , recursive-based algorithms address these issues at the cost of increasing computational cost .
26-1	4706-4712	Toward	_	_	_	_
26-2	4713-4717	this	abstract[264]	new[264]	_	_
26-3	4718-4721	end	abstract[264]	new[264]	_	_
26-4	4722-4723	,	_	_	_	_
26-5	4724-4739	recursive-based	abstract[265]	giv[265]	coref	28-17[0_265]
26-6	4740-4750	algorithms	abstract[265]	giv[265]	_	_
26-7	4751-4758	address	_	_	_	_
26-8	4759-4764	these	abstract[266]	new[266]	_	_
26-9	4765-4771	issues	abstract[266]	new[266]	_	_
26-10	4772-4774	at	_	_	_	_
26-11	4775-4778	the	abstract[267]	new[267]	coref	26-15[268_267]
26-12	4779-4783	cost	abstract[267]	new[267]	_	_
26-13	4784-4786	of	abstract[267]	new[267]	_	_
26-14	4787-4797	increasing	abstract[267]	new[267]	_	_
26-15	4798-4811	computational	abstract[267]|abstract[268]	new[267]|giv[268]	_	_
26-16	4812-4816	cost	abstract[267]|abstract[268]	new[267]|giv[268]	_	_
26-17	4817-4818	.	_	_	_	_

#Text=In comparison with the SGD method and recursive method , the conjugate gradient ( CG ) method and Newton ’s method as developments of SGD have become alternative optimization methods in KAFs .
27-1	4819-4821	In	_	_	_	_
27-2	4822-4832	comparison	abstract[269]	new[269]	_	_
27-3	4833-4837	with	abstract[269]	new[269]	_	_
27-4	4838-4841	the	abstract[269]|abstract[271]|abstract[272]	new[269]|giv[271]|giv[272]	coref|coref	27-8[273_271]|27-11[278_272]
27-5	4842-4845	SGD	abstract[269]|abstract|abstract[271]|abstract[272]	new[269]|giv|giv[271]|giv[272]	coref	27-25
27-6	4846-4852	method	abstract[269]|abstract[271]|abstract[272]	new[269]|giv[271]|giv[272]	_	_
27-7	4853-4856	and	abstract[269]|abstract[272]	new[269]|giv[272]	_	_
27-8	4857-4866	recursive	abstract[269]|abstract[272]|abstract[273]	new[269]|giv[272]|giv[273]	coref	27-11[277_273]
27-9	4867-4873	method	abstract[269]|abstract[272]|abstract[273]	new[269]|giv[272]|giv[273]	_	_
27-10	4874-4875	,	_	_	_	_
27-11	4876-4879	the	abstract[277]|abstract[278]	giv[277]|giv[278]	coref	27-19[280_277]
27-12	4880-4889	conjugate	abstract|substance[275]|abstract[277]|abstract[278]	giv|giv[275]|giv[277]|giv[278]	coref|coref	30-6|30-5[306_275]
27-13	4890-4898	gradient	substance[275]|abstract[277]|abstract[278]	giv[275]|giv[277]|giv[278]	_	_
27-14	4899-4900	(	abstract[277]|abstract[278]	giv[277]|giv[278]	_	_
27-15	4901-4903	CG	abstract|abstract[277]|abstract[278]	new|giv[277]|giv[278]	coref	29-4
27-16	4904-4905	)	abstract[277]|abstract[278]	giv[277]|giv[278]	_	_
27-17	4906-4912	method	abstract[277]|abstract[278]	giv[277]|giv[278]	_	_
27-18	4913-4916	and	abstract[278]	giv[278]	_	_
27-19	4917-4923	Newton	abstract[278]|person[279]|abstract[280]	giv[278]|new[279]|giv[280]	coref|coref	28-6[287_279]|28-6[288_280]
27-20	4924-4926	’s	abstract[278]|person[279]|abstract[280]	giv[278]|new[279]|giv[280]	_	_
27-21	4927-4933	method	abstract[278]|abstract[280]	giv[278]|giv[280]	_	_
27-22	4934-4936	as	abstract[278]|abstract[280]	giv[278]|giv[280]	_	_
27-23	4937-4949	developments	abstract[278]|abstract[280]|abstract[281]	giv[278]|giv[280]|new[281]	_	_
27-24	4950-4952	of	abstract[278]|abstract[280]|abstract[281]	giv[278]|giv[280]|new[281]	_	_
27-25	4953-4956	SGD	abstract[278]|abstract[280]|abstract[281]|abstract	giv[278]|giv[280]|new[281]|giv	_	_
27-26	4957-4961	have	_	_	_	_
27-27	4962-4968	become	_	_	_	_
27-28	4969-4980	alternative	_	_	_	_
27-29	4981-4993	optimization	abstract	giv	coref	29-37[303_0]
27-30	4994-5001	methods	_	_	_	_
27-31	5002-5004	in	_	_	_	_
27-32	5005-5009	KAFs	abstract	giv	_	_
27-33	5010-5011	.	_	_	_	_

#Text=The inverse of matrix of Newton ’s method increases the computation and causes the divergence of algorithms in some cases .
28-1	5012-5015	The	abstract[285]	new[285]	_	_
28-2	5016-5023	inverse	abstract[285]	new[285]	_	_
28-3	5024-5026	of	abstract[285]	new[285]	_	_
28-4	5027-5033	matrix	abstract[285]|abstract[286]	new[285]|new[286]	_	_
28-5	5034-5036	of	abstract[285]|abstract[286]	new[285]|new[286]	_	_
28-6	5037-5043	Newton	abstract[285]|abstract[286]|person[287]|abstract[288]	new[285]|new[286]|giv[287]|giv[288]	coref	29-3[294_288]
28-7	5044-5046	’s	abstract[285]|abstract[286]|person[287]|abstract[288]	new[285]|new[286]|giv[287]|giv[288]	_	_
28-8	5047-5053	method	abstract[285]|abstract[286]|abstract[288]	new[285]|new[286]|giv[288]	_	_
28-9	5054-5063	increases	_	_	_	_
28-10	5064-5067	the	abstract[289]	new[289]	coref	29-16[299_289]
28-11	5068-5079	computation	abstract[289]	new[289]	_	_
28-12	5080-5083	and	_	_	_	_
28-13	5084-5090	causes	_	_	_	_
28-14	5091-5094	the	abstract[290]	new[290]	_	_
28-15	5095-5105	divergence	abstract[290]	new[290]	_	_
28-16	5106-5108	of	abstract[290]	new[290]	_	_
28-17	5109-5119	algorithms	abstract[290]|abstract	new[290]|giv	_	_
28-18	5120-5122	in	_	_	_	_
28-19	5123-5127	some	abstract[292]	new[292]	_	_
28-20	5128-5133	cases	abstract[292]	new[292]	_	_
28-21	5134-5135	.	_	_	_	_

#Text=However , the CG method gives a trade-off between convergence rate and computational complexity without the inverse computation , and has been successfully applied in various fields , including compressed sensing , neural networks , and large-scale optimization .
29-1	5136-5143	However	_	_	_	_
29-2	5144-5145	,	_	_	_	_
29-3	5146-5149	the	abstract[294]	giv[294]	coref	30-4[308_294]
29-4	5150-5152	CG	abstract|abstract[294]	giv|giv[294]	_	_
29-5	5153-5159	method	abstract[294]	giv[294]	_	_
29-6	5160-5165	gives	_	_	_	_
29-7	5166-5167	a	event[295]	new[295]	_	_
29-8	5168-5177	trade-off	event[295]	new[295]	_	_
29-9	5178-5185	between	event[295]	new[295]	_	_
29-10	5186-5197	convergence	event[295]|abstract|abstract[297]	new[295]|giv|giv[297]	_	_
29-11	5198-5202	rate	event[295]|abstract[297]	new[295]|giv[297]	_	_
29-12	5203-5206	and	event[295]	new[295]	_	_
29-13	5207-5220	computational	event[295]|abstract[298]	new[295]|giv[298]	_	_
29-14	5221-5231	complexity	event[295]|abstract[298]	new[295]|giv[298]	_	_
29-15	5232-5239	without	event[295]|abstract[298]	new[295]|giv[298]	_	_
29-16	5240-5243	the	event[295]|abstract[298]|abstract[299]	new[295]|giv[298]|giv[299]	_	_
29-17	5244-5251	inverse	event[295]|abstract[298]|abstract[299]	new[295]|giv[298]|giv[299]	_	_
29-18	5252-5263	computation	event[295]|abstract[298]|abstract[299]	new[295]|giv[298]|giv[299]	_	_
29-19	5264-5265	,	_	_	_	_
29-20	5266-5269	and	_	_	_	_
29-21	5270-5273	has	_	_	_	_
29-22	5274-5278	been	_	_	_	_
29-23	5279-5291	successfully	_	_	_	_
29-24	5292-5299	applied	_	_	_	_
29-25	5300-5302	in	_	_	_	_
29-26	5303-5310	various	abstract[300]	new[300]	_	_
29-27	5311-5317	fields	abstract[300]	new[300]	_	_
29-28	5318-5319	,	abstract[300]	new[300]	_	_
29-29	5320-5329	including	abstract[300]	new[300]	_	_
29-30	5330-5340	compressed	abstract[300]|abstract[301]	new[300]|new[301]	_	_
29-31	5341-5348	sensing	abstract[300]|abstract[301]	new[300]|new[301]	_	_
29-32	5349-5350	,	abstract[300]	new[300]	_	_
29-33	5351-5357	neural	abstract[300]|abstract[302]	new[300]|new[302]	_	_
29-34	5358-5366	networks	abstract[300]|abstract[302]	new[300]|new[302]	_	_
29-35	5367-5368	,	abstract[300]	new[300]	_	_
29-36	5369-5372	and	abstract[300]	new[300]	_	_
29-37	5373-5384	large-scale	abstract[300]|abstract[303]	new[300]|giv[303]	_	_
29-38	5385-5397	optimization	abstract[300]|abstract[303]	new[300]|giv[303]	_	_
29-39	5398-5399	.	_	_	_	_

#Text=In addition , the kernel conjugate gradient ( KCG ) method is proposed for adaptive filtering .
30-1	5400-5402	In	_	_	_	_
30-2	5403-5411	addition	_	_	_	_
30-3	5412-5413	,	_	_	_	_
30-4	5414-5417	the	abstract[308]	giv[308]	_	_
30-5	5418-5424	kernel	abstract|substance[306]|abstract[308]	giv|giv[306]|giv[308]	_	_
30-6	5425-5434	conjugate	abstract|substance[306]|abstract[308]	giv|giv[306]|giv[308]	_	_
30-7	5435-5443	gradient	substance[306]|abstract[308]	giv[306]|giv[308]	_	_
30-8	5444-5445	(	abstract[308]	giv[308]	_	_
30-9	5446-5449	KCG	abstract|abstract[308]	new|giv[308]	coref	31-1[310_0]
30-10	5450-5451	)	abstract[308]	giv[308]	_	_
30-11	5452-5458	method	abstract[308]	giv[308]	_	_
30-12	5459-5461	is	_	_	_	_
30-13	5462-5470	proposed	_	_	_	_
30-14	5471-5474	for	_	_	_	_
30-15	5475-5483	adaptive	abstract[309]	new[309]	_	_
30-16	5484-5493	filtering	abstract[309]	new[309]	_	_
30-17	5494-5495	.	_	_	_	_

#Text=KCG with low computational and space requirements can produce a better solution than KLMS , and has comparable accuracy to KRLS .
31-1	5496-5499	KCG	abstract[310]	giv[310]	_	_
31-2	5500-5504	with	abstract[310]	giv[310]	_	_
31-3	5505-5508	low	abstract[310]|abstract[311]	giv[310]|new[311]	_	_
31-4	5509-5522	computational	abstract[310]|abstract[311]	giv[310]|new[311]	_	_
31-5	5523-5526	and	abstract[310]|abstract[311]	giv[310]|new[311]	_	_
31-6	5527-5532	space	abstract[310]|abstract[311]	giv[310]|new[311]	_	_
31-7	5533-5545	requirements	abstract[310]|abstract[311]	giv[310]|new[311]	_	_
31-8	5546-5549	can	_	_	_	_
31-9	5550-5557	produce	_	_	_	_
31-10	5558-5559	a	abstract[312]	giv[312]	_	_
31-11	5560-5566	better	abstract[312]	giv[312]	_	_
31-12	5567-5575	solution	abstract[312]	giv[312]	_	_
31-13	5576-5580	than	abstract[312]	giv[312]	_	_
31-14	5581-5585	KLMS	abstract[312]|abstract	giv[312]|giv	_	_
31-15	5586-5587	,	_	_	_	_
31-16	5588-5591	and	_	_	_	_
31-17	5592-5595	has	_	_	_	_
31-18	5596-5606	comparable	abstract[314]	new[314]	_	_
31-19	5607-5615	accuracy	abstract[314]	new[314]	_	_
31-20	5616-5618	to	_	_	_	_
31-21	5619-5623	KRLS	abstract	giv	_	_
31-22	5624-5625	.	_	_	_	_
