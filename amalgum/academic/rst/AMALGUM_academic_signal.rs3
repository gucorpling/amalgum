<rst>
<header>
	<relations>
			<rel name="purpose" type="rst"/>
			<rel name="evidence" type="rst"/>
			<rel name="elaboration" type="rst"/>
			<rel name="circumstance" type="rst"/>
			<rel name="concession" type="rst"/>
			<rel name="condition" type="rst"/>
			<rel name="preparation" type="rst"/>
			<rel name="restatement" type="rst"/>
			<rel name="means" type="rst"/>
			<rel name="attribution" type="rst"/>
			<rel name="contrast" type="multinuc"/>
			<rel name="joint" type="multinuc"/>
			<rel name="sequence" type="multinuc"/>
			<rel name="same_unit" type="multinuc"/>
		</relations>
</header>
<body>
<segment id="1" parent="1001" relname="preparation">3. Impulse Detection Methodology Using Deep Learning</segment>
<segment id="2" parent="1002" relname="preparation">Flexible Boundary Regression</segment>
<segment id="3" parent="1005" relname="span">Since the time lengths of the AE impulse signal</segment>
<segment id="4" parent="3" relname="elaboration">excited by the fuel stream</segment>
<segment id="5" parent="1004" relname="same_unit">are variable ,</segment>
<segment id="6" parent="1006" relname="span">the proposed method must adapt</segment>
<segment id="7" parent="6" relname="purpose">to predict boundaries of different sizes .</segment>
<segment id="8" parent="1008" relname="span">This research introduces the DLFBR impulse detection model ,</segment>
<segment id="9" parent="1010" relname="span">which considers an impulse as an object</segment>
<segment id="10" parent="9" relname="purpose">to be analyzed</segment>
<segment id="11" parent="1009" relname="joint">and recognized .</segment>
<segment id="12" parent="1012" relname="span">This model improves the 1D-CNN</segment>
<segment id="13" parent="12" relname="purpose">to adapt for hit detection in the AE signal .</segment>
<segment id="14" parent="1014" relname="preparation">The research reframes hit detection as a straightforward regression issue ,</segment>
<segment id="15" parent="1014" relname="sequence">directly from the AE signal vector to the boundary box coordinates .</segment>
<segment id="16" parent="1016" relname="same_unit">The proposed method takes an AE signal as the input ,</segment>
<segment id="17" parent="1017" relname="span">feeds it through a neural network structure</segment>
<segment id="18" parent="1019" relname="span">that looks similar to a 1D-CNN</segment>
<segment id="19" parent="18" relname="purpose">to integrate the boundary regression layer ,</segment>
<segment id="20" parent="1018" relname="joint">and receives a vector of box coordinates around the impulse position in the output .</segment>
<segment id="21" parent="1021" relname="span">The basic idea of the detection algorithm includes two steps :</segment>
<segment id="22" parent="1022" relname="span">preprocessing the signal</segment>
<segment id="23" parent="22" relname="purpose">to extract the shape signal and a flexible boundary detector .</segment>
<segment id="24" parent="1024" relname="span">3.1. Preprocessing</segment>
<segment id="25" parent="24" relname="purpose">to Extract the Shape Signal</segment>
<segment id="26" parent="1027" relname="span">The preprocessing step works</segment>
<segment id="27" parent="26" relname="purpose">to extract the global shape of the impulse at the macro-level ,</segment>
<segment id="28" parent="1027" relname="elaboration">corresponding to the length of the sampled signal .</segment>
<segment id="29" parent="1030" relname="span">Normally , the concept of object detection is used in an image processing technique</segment>
<segment id="30" parent="29" relname="elaboration">where the object is smooth , continuous , and mostly homogenous inside the point area of the object .</segment>
<segment id="31" parent="1032" relname="span">With this condition , the convolution neural network considers the boundary of an object to be composed of an edge and blob patterns ,</segment>
<segment id="32" parent="31" relname="elaboration">which have a sudden change between their different colors .</segment>
<segment id="33" parent="1035" relname="span">However , the AE signal</segment>
<segment id="34" parent="33" relname="elaboration">collected from the leak detection testbed always includes environmental noise</segment>
<segment id="35" parent="1034" relname="joint">and contains many small troughs and peaks .</segment>
<segment id="36" parent="1038" relname="span">If these troughs and peaks are smaller than the grid size</segment>
<segment id="37" parent="36" relname="elaboration">generated by the deep learning detector ,</segment>
<segment id="38" parent="1037" relname="span">the object detection algorithm cannot give a satisfying result .</segment>
<segment id="39" parent="1040" relname="span">To mitigate the undesired variations and unexpected instantaneous frequency values</segment>
<segment id="40" parent="39" relname="elaboration">produced by the remaining amount of small noise ,</segment>
<segment id="41" parent="1039" relname="span">the preprocessing step helps obtain the overall shape of the signal with little random noise .</segment>
<segment id="42" parent="1042" relname="preparation">Figure 3</segment>
<segment id="43" parent="1042" relname="joint">presents the preprocessing step of the algorithm .</segment>
<segment id="44" parent="1044" relname="span">In the first step , the AE signal sample is segmented into non-overlapping frames</segment>
<segment id="45" parent="1045" relname="span">and rectified</segment>
<segment id="46" parent="45" relname="purpose">to obtain the positive part .</segment>
<segment id="47" parent="1049" relname="span">Then , in each window , the root means square</segment>
<segment id="48" parent="47" relname="restatement">( RMS )</segment>
<segment id="49" parent="1048" relname="same_unit">is calculated</segment>
<segment id="50" parent="1048" relname="purpose">to form the lower rate RMS signal .</segment>
<segment id="51" parent="1051" relname="span">Next , the lower rate signal is expanded to its original size</segment>
<segment id="52" parent="1052" relname="span">by scaling the time axis</segment>
<segment id="53" parent="52" relname="means">using cubic interpolation and antialiasing .</segment>
<segment id="54" parent="1054" relname="span">The cubic interpolation method performs piecewise cubic Hermite interpolation</segment>
<segment id="55" parent="54" relname="elaboration">based on the values at neighboring grid points .</segment>
<segment id="56" parent="1056" relname="span">It seeks to match only the first-order derivatives at the data points with those in the intervals before and after .</segment>
<segment id="57" parent="1057" relname="span">For a set of data points , , the cubic Hermite interpolant at any point , with , takes the form :</segment>
<segment id="58" parent="57" relname="elaboration">( 1 ) where</segment>
<segment id="59" parent="1060" relname="span">An instance</segment>
<segment id="60" parent="59" relname="elaboration">based on piecewise cubic Hermite interpolation is shape-preserving piecewise cubic ,</segment>
<segment id="61" parent="1061" relname="span">which preserves the shape of the data</segment>
<segment id="62" parent="61" relname="elaboration">since the resulting interpolated function has a continuous derivative .</segment>
<segment id="63" parent="64" relname="concession">Shape-preserving piecewise cubic interpolation has a similar formula to that of piecewise cubic Hermite interpolation ,</segment>
<segment id="64" parent="1063" relname="span">but it differs in the component of the first-order derivatives .</segment>
<segment id="65" parent="1066" relname="span">The output vector value is a weighted average of points</segment>
<segment id="66" parent="65" relname="elaboration">taken from at least the nearest four neighborhoods ;</segment>
<segment id="67" parent="1065" relname="same_unit">this interpolation ensures that the value of the interpolant is located within a range of local points .</segment>
<segment id="68" parent="1046" relname="joint">3.2. Impulse Detection with the Deep Learning Flexible Boundary Regression Detector</segment>
<segment id="69" parent="1069" relname="span">In contrast to general CNNs , the proposed method employs a one-dimensional time-domain signal as the input data</segment>
<segment id="70" parent="69" relname="elaboration">instead of two-dimensional pixels .</segment>
<segment id="71" parent="1071" relname="span">The one-dimensional AE signal is fed into the first convolution layer .</segment>
<segment id="72" parent="1072" relname="span">To detect an object ,</segment>
<segment id="73" parent="1073" relname="joint">the detector takes the feature for that object</segment>
<segment id="74" parent="1073" relname="joint">and assesses it at various locations and scales in the sample signal .</segment>
<segment id="75" parent="1075" relname="span">DLFBR observes the entire signal during the training and testing process</segment>
<segment id="76" parent="75" relname="purpose">to implicitly encode contextual information about the type of object as well as its position .</segment>
<segment id="77" parent="1077" relname="span">The component object detector is only unified into an end-to-end single neural network ,</segment>
<segment id="78" parent="1078" relname="span">which utilizes features from the entire signal</segment>
<segment id="79" parent="78" relname="purpose">to estimate the position for each boundary box .</segment>
<segment id="80" parent="1079" relname="joint">To reason globally about the full sample signal and all of the objects inside the signal ,</segment>
<segment id="81" parent="1080" relname="joint">DLFBR divides the input signal into a grid with a grid size .</segment>
<segment id="82" parent="1083" relname="condition">If the center of an object drops into a cell in the grid ,</segment>
<segment id="83" parent="1083" relname="span">that cell responds</segment>
<segment id="84" parent="83" relname="purpose">to detecting that object .</segment>
<segment id="85" parent="1084" relname="joint">From the generated grid , each grid cell regresses the encircled box and the confidence score for each box .</segment>
<segment id="86" parent="1086" relname="attribution">These confidence scores represent how confident the network is</segment>
<segment id="87" parent="1087" relname="same_unit">that the box contains an object ,</segment>
<segment id="88" parent="89" relname="attribution">as well as how accurate the network thinks</segment>
<segment id="89" parent="1088" relname="span">the predicted box is .</segment>
<segment id="90" parent="1087" relname="elaboration">The confidence is specified as ( 2 )</segment>
<group id="1000" type="span" />
<group id="1001" type="span" parent="1000" relname="span"/>
<group id="1002" type="multinuc" parent="1001" relname="span"/>
<group id="1003" type="span" parent="1002" relname="joint"/>
<group id="1004" type="multinuc" parent="1006" relname="circumstance"/>
<group id="1005" type="span" parent="1004" relname="same_unit"/>
<group id="1006" type="span" parent="1003" relname="span"/>
<group id="1008" type="span" parent="1002" relname="joint"/>
<group id="1009" type="multinuc" parent="8" relname="elaboration"/>
<group id="1010" type="span" parent="1009" relname="joint"/>
<group id="1011" type="multinuc" parent="1002" relname="joint"/>
<group id="1012" type="span" parent="1011" relname="sequence"/>
<group id="1013" type="span" parent="1011" relname="sequence"/>
<group id="1014" type="multinuc" parent="1013" relname="span"/>
<group id="1015" type="multinuc" parent="1014" relname="sequence"/>
<group id="1016" type="multinuc" parent="1015" relname="joint"/>
<group id="1017" type="span" parent="1016" relname="same_unit"/>
<group id="1018" type="multinuc" parent="17" relname="elaboration"/>
<group id="1019" type="span" parent="1018" relname="joint"/>
<group id="1021" type="span" parent="1015" relname="joint"/>
<group id="1022" type="span" parent="21" relname="elaboration"/>
<group id="1024" type="span" parent="1015" relname="joint"/>
<group id="1026" type="span" parent="1015" relname="joint"/>
<group id="1027" type="span" parent="1026" relname="span"/>
<group id="1029" type="span" parent="1015" relname="joint"/>
<group id="1030" type="span" parent="1029" relname="span"/>
<group id="1031" type="multinuc" parent="1030" relname="elaboration"/>
<group id="1032" type="span" parent="1031" relname="contrast"/>
<group id="1033" type="span" parent="1031" relname="contrast"/>
<group id="1034" type="multinuc" parent="1033" relname="span"/>
<group id="1035" type="span" parent="1034" relname="joint"/>
<group id="1036" type="span" parent="1034" relname="evidence"/>
<group id="1037" type="span" parent="1036" relname="span"/>
<group id="1038" type="span" parent="38" relname="condition"/>
<group id="1039" type="span" parent="1037" relname="elaboration"/>
<group id="1040" type="span" parent="41" relname="attribution"/>
<group id="1041" type="span" parent="1015" relname="joint"/>
<group id="1042" type="multinuc" parent="1041" relname="span"/>
<group id="1043" type="multinuc" parent="1042" relname="joint"/>
<group id="1044" type="span" parent="1043" relname="sequence"/>
<group id="1045" type="span" parent="44" relname="elaboration"/>
<group id="1046" type="multinuc" parent="1043" relname="sequence"/>
<group id="1047" type="span" parent="1046" relname="joint"/>
<group id="1048" type="multinuc" parent="1047" relname="span"/>
<group id="1049" type="span" parent="1048" relname="same_unit"/>
<group id="1051" type="span" parent="1046" relname="joint"/>
<group id="1052" type="span" parent="51" relname="means"/>
<group id="1054" type="span" parent="1046" relname="joint"/>
<group id="1056" type="span" parent="1046" relname="joint"/>
<group id="1057" type="span" parent="56" relname="elaboration"/>
<group id="1059" type="span" parent="1046" relname="joint"/>
<group id="1060" type="span" parent="1059" relname="span"/>
<group id="1061" type="span" parent="1060" relname="elaboration"/>
<group id="1063" type="span" parent="1046" relname="joint"/>
<group id="1065" type="multinuc" parent="1046" relname="joint"/>
<group id="1066" type="span" parent="1065" relname="same_unit"/>
<group id="1069" type="span" parent="1046" relname="joint"/>
<group id="1071" type="span" parent="1046" relname="joint"/>
<group id="1072" type="span" parent="71" relname="elaboration"/>
<group id="1073" type="multinuc" parent="72" relname="elaboration"/>
<group id="1075" type="span" parent="1046" relname="joint"/>
<group id="1076" type="span" parent="1046" relname="joint"/>
<group id="1077" type="span" parent="1076" relname="span"/>
<group id="1078" type="span" parent="77" relname="elaboration"/>
<group id="1079" type="multinuc" parent="1077" relname="purpose"/>
<group id="1080" type="multinuc" parent="1079" relname="joint"/>
<group id="1081" type="multinuc" parent="1080" relname="joint"/>
<group id="1082" type="span" parent="1081" relname="joint"/>
<group id="1083" type="span" parent="1082" relname="span"/>
<group id="1084" type="multinuc" parent="1081" relname="joint"/>
<group id="1085" type="span" parent="1084" relname="joint"/>
<group id="1086" type="span" parent="1085" relname="span"/>
<group id="1087" type="multinuc" parent="1086" relname="span"/>
<group id="1088" type="span" parent="1087" relname="same_unit"/>
	</body>
</rst>
