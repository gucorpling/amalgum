<?xml version="1.0" ?>
<text author="Shidan Wang, Donghan  M. Yang, Ruichen Rong, Xiaowei Zhan, Junya Fujimoto, Hongyu Liu, John Minna, Ignacio  Ivan Wistuba, Yang Xie, Guanghua Xiao" dateCollected="2019-11-03" id="autogum_academic_doc476" shortTile="artificial-intelligence" sourceURL="https://www.mdpi.com/2072-6694/11/11/1673/htm" speakerCount="0" speakerList="none" title="Artificial Intelligence in Lung Cancer Pathology Image Analysis" type="academic">
<head>
<s type="frag">
3.	LS	@ord@
Advantages	NNS	Advantages
of	IN	of
Deep	JJ	deep
Learning	NN	learning
Methods	NNS	method
</s>
</head>
<p>
<s type="decl">
To	TO	To
overcome	VB	overcome
the	DT	the
aforementioned	JJ	aforementioned
challenges	NNS	challenge
,	,	,
various	JJ	various
image	NN	image
processing	NN	processing
and	CC	and
machine	NN	machine
learning	VBG	learn
methods	NNS	method
have	VBP	have
been	VBN	be
proposed	VBN	propose
and	CC	and
have	VBP	have
so	RB	so
far	RB	far
achieved	VBN	achieve
great	JJ	great
progress	NN	progress
.	.	.
</s>
<s type="decl">
However	RB	however
,	,	,
it	PRP	it
is	VBZ	be
important	JJ	important
to	TO	to
note	VB	note
the	DT	the
advantages	NNS	advantage
of	IN	of
deep	JJ	deep
learning	NN	learning
methods	NNS	method
over	IN	over
non-deep-learning	JJ	non-deep-learning
methods	NNS	method
(	-LRB-	(
also	RB	also
called	VBN	call
shallow-learning	VBG	shallow-learning
methods	NNS	method
)	-RRB-	)
.	.	.
</s>
</p>
<p>
<s type="decl">
Currently	RB	currently
,	,	,
convolutional	JJ	convolutional
neural	JJ	neural
networks	NNS	network
(	-LRB-	(
CNNs	NNP	CNN
)	-RRB-	)
are	VBP	be
the	DT	the
most	RBS	most
frequently	RB	frequently
used	VBN	use
deep	JJ	deep
learning	NN	learning
model	NN	model
for	IN	for
image	NN	image
data	NNS	datum
classification	NN	classification
,	,	,
including	VBG	include
tumor	NN	tumor
detection	NN	detection
in	IN	in
pathology	NN	pathology
images	NNS	image
of	IN	of
breast	NN	breast
cancer	NN	cancer
,	,	,
renal	NN	renal
cell	NN	cell
carcinoma	NN	carcinoma
,	,	,
prostate	NN	prostate
cancer	NN	cancer
,	,	,
and	CC	and
head	NN	head
and	CC	and
neck	NN	neck
cancer	NN	cancer
.	.	.
</s>
<s type="decl">
Several	JJ	several
forms	NNS	form
of	IN	of
neural	JJ	neural
network	NN	network
have	VBP	have
been	VBN	be
derived	VBN	derive
from	IN	from
CNNs	NNP	CNN
for	IN	for
image	NN	image
segmentation	NN	segmentation
,	,	,
including	VBG	include
fully	RB	fully
convolutional	JJ	convolutional
networks	NNS	network
(	-LRB-	(
FCNs	NN	FCN
)	-RRB-	)
and	CC	and
mask-regional	JJ	mask-regional
convolutional	JJ	convolutional
neural	JJ	neural
networks	NNS	network
(	-LRB-	(
mask-RCNNs	NNS	mask-RCn
)	-RRB-	)
.	.	.
</s>
<s type="decl">
Recurrent	JJ	Recurrent
neural	JJ	neural
networks	NNS	network
(	-LRB-	(
RNNs	NNS	rnn
)	-RRB-	)
,	,	,
which	WDT	which
are	VBP	be
well	RB	well
known	VBN	know
for	IN	for
modeling	VBG	model
dynamic	JJ	dynamic
sequence	NN	sequence
behavior	NN	behavior
such	JJ	such
as	IN	as
speech	NN	speech
recognition	NN	recognition
,	,	,
have	VBP	have
also	RB	also
been	VBN	be
explored	VBN	explore
in	IN	in
multi-label	JJ	multi-label
image	NN	image
classification	NN	classification
and	CC	and
image	NN	image
segmentation	NN	segmentation
.	.	.
</s>
<s type="decl">
In	IN	in
additional	JJ	additional
to	TO	to
the	DT	the
aforementioned	JJ	aforementioned
supervised	VBN	supervise
deep	JJ	deep
learning	NN	learning
models	NNS	model
,	,	,
autoencoder	NN	autoencoder
,	,	,
an	DT	an
unsupervised	JJ	unsupervised
deep	JJ	deep
learning	NN	learning
model	NN	model
,	,	,
has	VBZ	have
shown	VBN	show
ability	NN	ability
in	IN	in
analyzing	VBG	analyze
pathology	NN	pathology
images	NNS	image
through	IN	through
pre-training	NN	pre-training
models	NNS	model
,	,	,
cell	NN	cell
detection	NN	detection
,	,	,
and	CC	and
image	NN	image
feature	NN	feature
extraction	NN	extraction
.	.	.
</s>
<s type="decl">
The	DT	the
taxonomy	NN	taxonomy
of	IN	of
the	DT	the
common	JJ	common
neural	JJ	neural
networks	NNS	network
used	VBN	use
in	IN	in
image	NN	image
analysis	NN	analysis
is	VBZ	be
summarized	VBN	summarize
in	IN	in
</s>
<figure>
<s type="frag">
Figure	NN	Figure
2	CD	2
</s>
</figure>
<s type="frag">
.	.	.
</s>
</p>
<head>
<s type="frag">
3.1	CD	@card@
.	.	.
</s>
<s type="frag">
Inherent	JJ	inherent
Characteristics	NNS	Characterictics
and	CC	and
Advantages	NNS	Advantages
of	IN	of
Convolutional	NNP	convolutional
Neural	NNP	Neural
Networks	NNPS	Networks
(	-LRB-	(
CNNs	NNP	CNN
)	-RRB-	)
</s>
</head>
<p>
<s type="decl">
Inspired	VBN	Inspired
by	IN	by
the	DT	the
working	VBG	work
mechanisms	NNS	mechanism
of	IN	of
the	DT	the
brain	NN	brain
,	,	,
deep	JJ	deep
neural	JJ	neural
networks	NNS	network
,	,	,
also	RB	also
called	VBN	call
“	``	"
deep	JJ	deep
learning	NN	learning
”	''	"
,	,	,
have	VBP	have
one	CD	one
or	CC	or
more	RBR	more
“	``	"
hidden	JJ	hide
”	''	"
layers	NNS	layer
between	IN	between
the	DT	the
input	NN	input
and	CC	and
output	NN	output
layers	NNS	layer
.	.	.
</s>
<s type="decl">
In	IN	in
each	DT	each
layer	NN	lay
,	,	,
there	EX	there
are	VBP	be
many	JJ	many
neurons	NNS	neuron
,	,	,
also	RB	also
called	VBN	call
kernels	NNS	kernel
.	.	.
</s>
<s type="decl">
Each	DT	each
kernel	NN	kernel
(	-LRB-	(
usually	RB	usually
a	DT	a
function	NN	function
in	IN	in
mathematics	NN	mathematics
)	-RRB-	)
takes	VBZ	take
inputs	NNS	input
and	CC	and
computes	VBZ	compute
an	DT	an
output	NN	output
.	.	.
</s>
<s type="decl">
In	IN	in
a	DT	a
CNN	NNP	CNN
model	NN	model
,	,	,
a	DT	a
convolution	NN	convolution
kernel	NN	kernel
computes	VBZ	compute
a	DT	a
feature	NN	feature
at	IN	at
a	DT	a
specific	JJ	specific
location	NN	location
,	,	,
called	VBN	call
a	DT	a
“	``	"
receptive	JJ	receptive
field	NN	field
”	''	"
,	,	,
in	IN	in
the	DT	the
input	NN	input
space	NN	space
.	.	.
</s>
<s type="decl">
The	DT	the
term	NN	term
“	``	"
convolutional	JJ	convolutional
”	''	"
denotes	VBP	denote
the	DT	the
operation	NN	operation
of	IN	of
sliding	VBG	slide
the	DT	the
receptive	JJ	receptive
fields	NNS	field
through	IN	through
the	DT	the
input	NN	input
layer	NN	lay
to	TO	to
generate	VB	generate
the	DT	the
“	``	"
feature	NN	feature
map	NN	map
”	''	"
from	IN	from
the	DT	the
convolution	NN	convolution
layer	NN	lay
as	IN	as
the	DT	the
outputs	NNS	output
.	.	.
</s>
<s type="decl">
In	IN	in
essence	NN	essence
,	,	,
this	DT	this
operation	NN	operation
was	VBD	be
inspired	VBN	inspire
by	IN	by
the	DT	the
functional	JJ	functional
mechanism	NN	mechanism
of	IN	of
the	DT	the
visual	JJ	visual
cortex	NN	cortex
,	,	,
and	CC	and
it	PRP	it
makes	VBZ	make
CNN	NNP	CNN
a	DT	a
great	JJ	great
solution	NN	solution
for	IN	for
many	JJ	many
image	NN	image
analysis	NN	analysis
tasks	NNS	task
.	.	.
</s>
</p>
<p>
<s type="decl">
A	DT	a
deep	JJ	deep
learning	NN	learning
model	NN	model
has	VBZ	have
two	CD	two
important	JJ	important
characteristics	NNS	characteristic
:	:	:
(	-LRB-	(
1	CD	1
)	-RRB-	)
it	PRP	it
allows	VBZ	allow
for	IN	for
the	DT	the
construction	NN	construction
and	CC	and
extraction	NN	extraction
of	IN	of
flexible	JJ	flexible
representational	JJ	representational
features	NNS	feature
from	IN	from
input	NN	input
data	NNS	datum
,	,	,
and	CC	and
(	-LRB-	(
2	CD	2
)	-RRB-	)
it	PRP	it
contains	VBZ	contain
multiple	JJ	multiple
layers	NNS	layer
and	CC	and
many	JJ	many
kernels	NNS	kernel
that	WDT	that
enable	VBP	enable
it	PRP	it
to	TO	to
approximate	JJ	approximate
basically	RB	basically
any	DT	any
complex	JJ	complex
functions	NNS	function
using	VBG	use
the	DT	the
extracted	VBN	extract
features	NNS	feature
.	.	.
</s>
<s type="decl">
In	IN	in
all	DT	all
,	,	,
deep	JJ	deep
neural	JJ	neural
networks	NNS	network
are	VBP	be
capable	JJ	capable
of	IN	of
automatically	RB	automatically
extracting	VBG	extract
features	NNS	feature
and	CC	and
solving	VBG	solve
highly	RB	highly
complex	JJ	complex
prediction	NN	prediction
problems	NNS	problem
.	.	.
</s>
<s type="decl">
In	IN	in
contrast	NN	contrast
,	,	,
traditional	JJ	traditional
machine	NN	machine
learning	NN	learning
methods	NNS	method
have	VBP	have
two	CD	two
major	JJ	major
steps	NNS	step
:	:	:
(	-LRB-	(
1	CD	1
)	-RRB-	)
defining	VBG	define
the	DT	the
features	NNS	feature
,	,	,
and	CC	and
(	-LRB-	(
2	CD	2
)	-RRB-	)
constructing	VBG	construct
models	NNS	model
using	VBG	use
these	DT	these
handcrafted	VBN	handcrafted
features	NNS	feature
.	.	.
</s>
<s type="decl">
Compared	VBN	compared
with	IN	with
traditional	JJ	traditional
methods	NNS	method
,	,	,
deep	JJ	deep
learning	NN	learning
models	NNS	model
have	VBP	have
the	DT	the
following	VBG	follow
advantages	NNS	advantage
:	:	:
</s>
</p>
<p>
<s type="decl">
First	RB	first
,	,	,
deep	JJ	deep
learning	NN	learning
models	NNS	model
greatly	RB	greatly
simplify	VBP	simplify
or	CC	or
remove	VB	remove
the	DT	the
task	NN	task
of	IN	of
manually	RB	manually
defining	VBG	define
features	NNS	feature
.	.	.
</s>
<s type="decl">
Manual	NN	Manual
feature	NN	feature
extraction	NN	extraction
is	VBZ	be
very	RB	very
challenging	VBG	challenge
and	CC	and
time	NN	time
consuming	VBG	consume
,	,	,
especially	RB	especially
in	IN	in
the	DT	the
following	VBG	follow
two	CD	two
scenarios	NNS	scenario
:	:	:
(	-LRB-	(
1	CD	1
)	-RRB-	)
the	DT	the
prediction	NN	prediction
problem	NN	problem
is	VBZ	be
complex	JJ	complex
,	,	,
and/or	NN	and/or
(	-LRB-	(
2	CD	2
)	-RRB-	)
there	EX	there
is	VBZ	be
limited	VBN	limit
prior	IN	prior
knowledge	NN	knowledge
about	IN	about
the	DT	the
relationship	NN	relationship
between	IN	between
input	NN	input
data	NNS	datum
and	CC	and
the	DT	the
outcomes	NNS	outcome
to	TO	to
be	VB	be
predicted	VBN	predict
.	.	.
</s>
<s type="decl">
Both	DT	both
scenarios	NNS	scenario
are	VBP	be
true	JJ	true
of	IN	of
pathology	NN	pathology
image	NN	image
analysis	NN	analysis
,	,	,
as	IN	as
the	DT	the
prediction	NN	prediction
problems	NNS	problem
(	-LRB-	(
such	JJ	such
as	IN	as
using	VBG	use
pathology	JJ	pathology
images	NNS	image
to	TO	to
predict	VB	predict
patient	NN	patient
outcomes	NNS	outcome
or	CC	or
recognizing	VBG	recognize
various	JJ	various
tissue	NN	tissue
structures	NNS	structure
and	CC	and
cells	NNS	cell
from	IN	from
H&E-stained	JJ	H&E-stained
images	NNS	image
)	-RRB-	)
are	VBP	be
very	RB	very
complex	JJ	complex
,	,	,
and	CC	and
despite	IN	despite
the	DT	the
accumulated	VBN	accumulate
knowledge	NN	knowledge
from	IN	from
pathologists	NNS	pathologist
,	,	,
little	JJ	little
is	VBZ	be
known	VBN	know
about	IN	about
which	WDT	which
quantitative	JJ	quantitative
image	NN	image
features	VBZ	feature
predict	VB	predict
the	DT	the
outcomes	NNS	outcome
.	.	.
</s>
<s type="decl">
As	IN	as
a	DT	a
result	NN	result
,	,	,
the	DT	the
advance	NN	advance
of	IN	of
pathology	NN	pathology
image	NN	image
analysis	NN	analysis
had	VBD	have
been	VBN	be
slow	JJ	slow
and	CC	and
limited	VBN	limit
until	IN	until
the	DT	the
recent	JJ	recent
development	NN	development
of	IN	of
deep	JJ	deep
learning	NN	learning
.	.	.
</s>
</p>
<p>
<s type="decl">
Second	RB	second
,	,	,
the	DT	the
computation	NN	computation
of	IN	of
deep	JJ	deep
learning	NN	learning
algorithms	NNS	algorithm
can	MD	can
be	VB	be
highly	RB	highly
parallel	JJ	parallel
.	.	.
</s>
<s type="decl">
As	IN	as
a	DT	a
result	NN	result
,	,	,
deep	JJ	deep
learning	NN	learning
can	MD	can
largely	RB	largely
leverage	VB	leverage
the	DT	the
parallel	JJ	parallel
computing	NN	computing
power	NN	power
from	IN	from
the	DT	the
recent	JJ	recent
developments	NNS	development
in	IN	in
GPU	NNP	GPU
(	-LRB-	(
graphics	NNS	graphic
processing	NN	processing
unit	NN	unit
)	-RRB-	)
hardware	NN	hardware
.	.	.
</s>
<s type="decl">
With	IN	with
GPU-aided	JJ	GPU-aided
computation	NN	computation
,	,	,
processing	VBG	process
(	-LRB-	(
classifying	VBG	classify
or	CC	or
segmenting	VBG	segment
)	-RRB-	)
a	DT	a
1000	CD	@card@
×	SYM	×
1000	CD	@card@
pixels	NNS	pixel
image	NN	image
usually	RB	usually
takes	VBZ	take
less	RBR	less
than	IN	than
one	CD	one
second	JJ	second
for	IN	for
a	DT	a
deep	JJ	deep
learning	NN	learning
model	NN	model
,	,	,
much	RB	much
faster	JJR	faster
than	IN	than
traditional	JJ	traditional
feature	NN	feature
extraction	NN	extraction
steps	NNS	step
and	CC	and
non-deep-learning-based	JJ	non-deep-learning-based
image	NN	image
segmentation	NN	segmentation
methods	NNS	method
.	.	.
</s>
<s type="decl">
Furthermore	RB	furthermore
,	,	,
since	IN	since
deep	JJ	deep
learning	NN	learning
does	VBZ	do
not	RB	not
require	VB	require
handcrafted	VBN	handcrafted
features	NNS	feature
,	,	,
it	PRP	it
can	MD	can
handle	VB	handle
much	RB	much
more	RBR	more
complex	JJ	complex
prediction	NN	prediction
problems	NNS	problem
and	CC	and
is	VBZ	be
able	JJ	able
to	TO	to
recognize	VB	recognize
multiple	JJ	multiple
objects	NNS	object
simultaneously	RB	simultaneously
.	.	.
</s>
<s type="decl">
For	IN	for
example	NN	example
,	,	,
CNNs	NNP	CNN
have	VBP	have
shown	VBN	show
great	JJ	great
power	NN	power
in	IN	in
distinguishing	VBG	distinguishing
as	IN	as
many	JJ	many
as	IN	as
1000	CD	@card@
object	NN	object
categories	NNS	category
.	.	.
</s>
</p>
<p>
<s type="decl">
Other	JJ	other
advantages	NNS	advantage
of	IN	of
deep	JJ	deep
learning	NN	learning
methods	NNS	method
include	VBP	include
the	DT	the
following	VBG	follow
:	:	:
(	-LRB-	(
1	CD	1
)	-RRB-	)
deep	JJ	deep
learning	VBG	learn
models	NNS	model
fully	RB	fully
utilize	VBP	utilize
image	NN	image
data	NNS	datum
,	,	,
as	IN	as
every	DT	every
pixel	NN	pixel
can	MD	can
be	VB	be
utilized	VBN	utilize
in	IN	in
prediction	NN	prediction
model	NN	model
;	:	;
(	-LRB-	(
2	CD	2
)	-RRB-	)
CNN	NNP	CNN
models	NNS	model
are	VBP	be
insensitive	JJ	insensitive
to	TO	to
object	NN	object
position	NN	position
on	IN	on
the	DT	the
image	NN	image
,	,	,
an	DT	an
inherent	JJ	inherent
property	NN	property
of	IN	of
convolution	NN	convolution
operation	NN	operation
;	:	;
and	CC	and
(	-LRB-	(
3	CD	3
)	-RRB-	)
as	IN	as
discussed	VBN	discuss
in	IN	in
the	DT	the
next	JJ	next
section	NN	section
,	,	,
by	IN	by
using	VBG	use
extensive	JJ	extensive
data	NNS	datum
augmentations	NNS	augmentation
in	IN	in
the	DT	the
model	NN	model
training	NN	training
process	NN	process
,	,	,
CNN	NNP	CNN
models	NNS	model
are	VBP	be
robust	JJ	robust
to	TO	to
different	JJ	different
staining	VBG	stain
conditions	NNS	condition
in	IN	in
pathology	NN	pathology
image	NN	image
analysis	NN	analysis
.	.	.
</s>
</p>
</text>
