{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StanfordNLP-CoreNLP-Interface.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-4lzQTC9yxG",
        "colab_type": "text"
      },
      "source": [
        "# StanfordNLP: Python CoreNLP Interface\n",
        "\n",
        "![Latest Version](https://img.shields.io/pypi/v/stanfordnlp.svg?colorB=bc4545)\n",
        "![Python Versions](https://img.shields.io/pypi/pyversions/stanfordnlp.svg?colorB=bc4545)\n",
        "\n",
        "While the StanfordNLP library implements accurate neural network modules for basic functionalities such as part-of-speech tagging and dependency parsing, the [Stanford CoreNLP Java library](https://stanfordnlp.github.io/CoreNLP/) has been developed for years and offers more complementary features such as coreference resolution and relation extraction. To unlock these features, the StanfordNLP library also offers an officially maintained Python interface to the CoreNLP Java library. This interface allows you to get NLP anntotations from CoreNLP by writing native Python code.\n",
        "\n",
        "\n",
        "This tutorial walks you through the installation, setup and basic usage of this Python CoreNLP interface. If you want to learn how to use the neural network components in StanfordNLP, please refer to other tutorials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpKwWeVkASGt",
        "colab_type": "text"
      },
      "source": [
        "## 1. Installation\n",
        "\n",
        "Before the installation starts, please make sure that you have Python 3 and Java installed on your computer. Since Colab already has them installed, we'll skip this procedure in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Az2ECuAfG8",
        "colab_type": "text"
      },
      "source": [
        "### Installing StanfordNLP\n",
        "\n",
        "Installing and importing StanfordNLP are as simple as running the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiFwYAgW4Mss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install stanfordnlp; note that the prefix \"!\" is not needed if you are running in a terminal\n",
        "!pip install stanfordnlp\n",
        "\n",
        "# Import stanfordnlp\n",
        "import stanfordnlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zFvaA8_A32_",
        "colab_type": "text"
      },
      "source": [
        "### Setting up Stanford CoreNLP\n",
        "\n",
        "In order for the interface to work, the Stanford CoreNLP library has to be installed and a `CORENLP_HOME` environment variable has to be pointed to the installation location.\n",
        "\n",
        "**Note**: if you are want to use the interface in a terminal (instead of a Colab notebook), you can properly set the `CORENLP_HOME` environment variable with:\n",
        "\n",
        "```bash\n",
        "export CORENLP_HOME=path_to_corenlp\n",
        "```\n",
        "\n",
        "Here we instead set this variable with the Python `os` library, simply because `export` command is not well-supported in Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3oBy0i-6HWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the Stanford CoreNLP Java library and unzip it to a ./corenlp folder\n",
        "!echo \"Downloading CoreNLP...\"\n",
        "!wget \"http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip\" -O corenlp.zip\n",
        "!unzip corenlp.zip\n",
        "!mv ./stanford-corenlp-full-2018-10-05 ./corenlp\n",
        "\n",
        "# Set the CORENLP_HOME environment variable to point to the installation location\n",
        "import os\n",
        "os.environ[\"CORENLP_HOME\"] = \"./corenlp\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJsuO6D8D05q",
        "colab_type": "text"
      },
      "source": [
        "## 2. Annotating Text with CoreNLP Interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZNHxXHkH1K2",
        "colab_type": "text"
      },
      "source": [
        "### Constructing CoreNLPClient\n",
        "\n",
        "At a high level, the CoreNLP Python interface works by first starting a background Java CoreNLP server process, and then initializing a client instance in Python which can pass the text to the background server process, and accept the returned annotation results.\n",
        "\n",
        "We wrap these functionalities in a `CoreNLPClient` class. Therefore, we need to start by importing this class from StanfordNLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS4OKnqJ8wui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import client module\n",
        "from stanfordnlp.server import CoreNLPClient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP4Dz6PIJHeL",
        "colab_type": "text"
      },
      "source": [
        "After the import is done, we can construct a `CoreNLPClient` instance. The constructor method takes a Python list of annotator names as argument. Here let's explore some basic annotators including tokenization, sentence split, part-of-speech tagging, lemmatization and named entity recognition (NER). \n",
        "\n",
        "Additionally, the client constructor accepts a `memory` argument, which specify how much memory will be allocated to the background Java process. An `endpoint` option can be used to specify a port number used by the communication between the server and the client. The default port is 9000, however, since this port is token in Colab, we'll manually set it to 9001 in the following example.\n",
        "\n",
        "For more options in constructing the clients, please refer to the [CoreNLP Client Options List](https://stanfordnlp.github.io/stanfordnlp/corenlp_client.html#corenlp-client-options)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbOBugvd9JaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001\n",
        "client = CoreNLPClient(annotators=['tokenize','ssplit', 'pos', 'lemma', 'ner'], memory='4G', endpoint='http://localhost:9001')\n",
        "print(client)\n",
        "\n",
        "# Start the background server and wait for some time\n",
        "# Note that in practice this is totally optional, as by default the server will be started when the first annotation is performed\n",
        "client.start()\n",
        "import time; time.sleep(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgTiVjNydmIW",
        "colab_type": "text"
      },
      "source": [
        "Now if you print the background processes, you should be able to find the Java CoreNLP server running."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spZrJ-oFdkdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print background processes and look for java\n",
        "!ps -o pid,cmd | grep java"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxJeJ0D2LoOs",
        "colab_type": "text"
      },
      "source": [
        "### Annotating Text\n",
        "\n",
        "Annotating a piece of text is as simple as passing the text into an `annotate` function of the client object. After the annotation is complete, a `Document`  object will be returned with all annotations.\n",
        "\n",
        "Note that although in general annotations are very fast, the first annotation might take a while to complete in the notebook. Please stay patient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s194RnNg5z95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Annotate some text\n",
        "text = \"Albert Einstein was a German-born theoretical physicist. He developed the theory of relativity.\"\n",
        "document = client.annotate(text)\n",
        "print(type(document))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "semmA3e0TcM1",
        "colab_type": "text"
      },
      "source": [
        "## 3. Accessing Annotations\n",
        "\n",
        "Annotations can be accessed from the returned `Document` object.\n",
        "\n",
        "A `Document` contains a list of `Sentence`s, which contain a list of `Token`s. Here let's first explore the annotations stored in all tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIO4B5d6Rk4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterate over all tokens in all sentences, and print out the word, lemma, pos and ner tags\n",
        "print(\"{:12s}\\t{:12s}\\t{:6s}\\t{}\".format(\"Word\", \"Lemma\", \"POS\", \"NER\"))\n",
        "\n",
        "for i, sent in enumerate(document.sentence):\n",
        "    print(\"[Sentence {}]\".format(i+1))\n",
        "    for t in sent.token:\n",
        "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{}\".format(t.word, t.lemma, t.pos, t.ner))\n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msrJfvu8VV9m",
        "colab_type": "text"
      },
      "source": [
        "Alternatively, you can also browse the NER results by iterating over entity mentions over the sentences. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezEjc9LeV2Xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterate over all detected entity mentions\n",
        "print(\"{:30s}\\t{}\".format(\"Mention\", \"Type\"))\n",
        "\n",
        "for sent in document.sentence:\n",
        "    for m in sent.mentions:\n",
        "        print(\"{:30s}\\t{}\".format(m.entityMentionText, m.entityType))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueGzBZ3hWzkN",
        "colab_type": "text"
      },
      "source": [
        "To print all annotations a sentence, token or mention has, you can simply print the corresponding obejct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_S8o2BHXIed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print annotations of a token\n",
        "print(document.sentence[0].token[0])\n",
        "\n",
        "# Print annotations of a mention\n",
        "print(document.sentence[0].mentions[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPqzMK90X0w3",
        "colab_type": "text"
      },
      "source": [
        "## 4. Shutting Down the CoreNLP Server\n",
        "\n",
        "To shut down the background CoreNLP server process, simply call the `stop` function of the client. Note that once a server is shutdown, you'll have to restart the server with the `start()` function before any annotation is requested."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrJq8lZ3Nw7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shut down the background CoreNLP server\n",
        "client.stop()\n",
        "\n",
        "time.sleep(10)\n",
        "!ps -o pid,cmd | grep java"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23Vwa_ifYfF7",
        "colab_type": "text"
      },
      "source": [
        "### More Information\n",
        "\n",
        "For more information on how to use the `CoreNLPClient`, please go to the [CoreNLPClient documentation page](https://stanfordnlp.github.io/stanfordnlp/corenlp_client.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W435Lwc4YqKb",
        "colab_type": "text"
      },
      "source": [
        "## 5. Other Resources\n",
        "\n",
        "- [StanfordNLP Homepage](https://stanfordnlp.github.io/stanfordnlp/index.html)\n",
        "- [FAQs](https://stanfordnlp.github.io/stanfordnlp/faq.html)\n",
        "- [GitHub Repo](https://github.com/stanfordnlp/stanfordnlp)\n",
        "- [Reporting Issues](https://github.com/stanfordnlp/stanfordnlp/issues)\n",
        "- [System Paper](https://nlp.stanford.edu/pubs/qi2018universal.pdf)\n"
      ]
    }
  ]
}