<text id="autogum_academic_doc365" title="Fault Detection and Diagnosis Using Combined Autoencoder and Long Short-Term Memory Network" shortTile="fault-detection-diagnosis" author="Pangun Park, Piergiuseppe  Di Marco, Hyejeon Shin, Junseong Bang" type="academic" dateCollected="2019-11-03" sourceURL="https://www.mdpi.com/1424-8220/19/21/4612/htm" speakerList="none" speakerCount="0">
<head> 4. Evaluation Setup</head>
<p>
In this section, we describe the benchmark dataset of the practical industrial process and the existing deep neural network approach that we used to compare our proposed method. </p>

<head> 4.1. Tennessee Eastman Challenge Problem</head>
<p>
We evaluate the performance of the proposed method for FDD on Tennessee Eastman Process (TEP). TEP is a widely-used benchmark testbed to investigate the large-scale control and FDD schemes of realistic chemical processes. The simulation data of TEP are highly nonlinear with strong coupling and dynamical behavior. The simulation code and data are available for download in References, respectively. </p>

<p>The main structure of the TEP simulator is described in <figure>Figure 3</figure>. The TEP produces two products <hi rend="italic">G</hi> and <hi rend="italic">H</hi> from four reactants  with additional byproduct <hi rend="italic">F</hi>. The reactions are

</p>

<p>All chemical reactions are irreversible, exothermic and approximately first-order with respect to the reactant concentrations. The reaction rates are a function of temperature through an Arrhenius expression. The reaction to produce <hi rend="italic">G</hi> has a higher activation energy than the one producing <hi rend="italic">H</hi>, thus resulting in more sensitivity to temperature. </p>

<p>To model a practical industrial process, the TEP simulator consists of five major units: reactor, condenser, compressor, separator and stripper. The gaseous reactants are fed into the reactor where liquid products are formed. The product stream of the reactor is cooled through a condenser and fed to a vapor-liquid separator. Non-condensed components are recycled back to the reactor via a compressor. Condensed components are moved to a product stripping column by stripping with feed stream number 4 to eliminate remaining reactants. Products <hi rend="italic">G</hi> and <hi rend="italic">H</hi> are separated in a downstream refining section from the stripper base. The inert and byproducts are purged as vapor from the vapor-liquid separator. In TEP, we monitor a total of 52 variables including 41 measured variables and 11 manipulated variables. </p>

<p>The modern industrial systems interact with multiple subcomponents where each component has several different failure modes. Furthermore, each failure mode typically has long-term dependencies along with short-term ones of time series data. Besides normal data, Table 1 describes 20 different types of faults to evaluate various FDD methods. </p>

<p><figure>Figure 4</figure> shows the raw process variable deviations from their normal states when fault 02 is introduced at  after the simulation started. We also show the normalized variables by the mean and standard deviation of each feature. Although the time-varying features of multivariate data are critical to identify the types of faults, the distinction between various types of faults is a challenging task due to the complex interaction among control processes. In fact, the fault effect is considerably different for various process variables. Furthermore, even if some variables are oscillating due to faults, there is a significant delay to recognize it as shown in <figure>Figure 4</figure>. The combined autoencoder and LSTM network must mine the hidden features of time series data. More detailed information of TEP is described in Reference. </p>

<p>The simulation starts to run in the normal state for . The specific fault out of 20 different types is then injected and it continues to run for . Hence, the total simulation time is  based on the recommendation of the TEP model. Each simulation of the fault repeats 500 times with various initial states and random noise. We set the sampling time as  (20 samples/h) to support the fast fault detection and fault diagnosis. We randomly select 80% time series sample as training sets and the remaining sample as testing sets. We only use the normal state samples without any faults to train the autoencoder for fault detection where anomalous and normal states correspond to positive and negative class, respectively. In addition, 20% of the whole training set is used as the validation set to optimize the decision threshold  for the autoencoder. On the other hand, the time series samples with temporal features are used to train the LSTM-based classifier. In this training set, we remove the first  of the normal state samples in each simulation. Hence, each training set of the LSTM network consists with  of normal data and  of faulty state data. The fraction of the normal state samples prior to faults is used to compensate the detection delay and the possible false positives of the autoencoder. The input sequence of the testing set for LSTM includes  time series data before the first event of the fault detection, captured by the autoencoder. </p>

<head> 4.2. DCNN</head>
<p>
In previous research, a deep convolutional neural network (DCNN)-based approach achieves the best reported results in multivariate time series data from the simulated TEP dataset. We compare the fault diagnosis performance of LSTM and DCNN-based approaches on the TEP dataset. </p>
</text>
