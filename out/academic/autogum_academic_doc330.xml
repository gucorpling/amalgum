<text id="autogum_academic_doc330" title="A New Fusion Approach for Extracting Urban Built-up Areas from Multisource Remotely Sensed Data" shortTile="new-fusion-approach" author="Xiaolong Ma, Chengming Li, Xiaohua Tong, Sicong Liu" type="academic" dateCollected="2019-11-03" sourceURL="https://www.mdpi.com/2072-4292/11/21/2516/htm" speakerList="none" speakerCount="0">
<head> 1. Introduction</head>
<p>
Urban built-up areas are generally defined as the urban administrative region where the majority of the area has been developed, and the municipal public facilities are widely available. These areas tend to have a higher population density and more social-environmental problems than their surroundings. One of the main advantages of remote sensing technology is that information about the extents and elements of the built-up areas can be identified and extracted for urban planning and resource management, risk assessment, and disaster warning. Methods for extracting and analyzing the traditional optical remote sensing image data for urban built-up areas from QuickBird, Landsat, Systeme Probatoire dâ€™ Observation de la Terre (SPOT), and Moderate Resolution Imaging Spectroradiometer (MODIS) are emerging continuously. It is worth stressing that the Defense Meteorological Satellite Program-Operational Linescan System (DMSP-OLS) nighttime light data can effectively detect city lights and extract information about cities, and the related theories and technologies have driven great achievements in many fields, such as the extraction of urban scope, the monitoring of urban expansion changes, and the prediction of socioeconomic factors, such as gross national product, power consumption, and carbon emissions. </p>

<p>High-resolution optical remote sensing images and other high-quality land cover data products are important data sources for the extraction of urban information. Li et al. proposed an approach to detect built-up areas by using unsupervised learning technology, which was based on remote sensing images with high resolution. Chen et al. developed a field-based method to automatically detect built-up areas from high-resolution satellite images. However, most of the available data have a limited temporal coverage, which limits its usefulness for dynamic spatial or temporal analysis. Problems arise when the same object exhibits different spectra and different objects exhibit the same spectrum. If results are interpreted accurately, an analysis usually requires complex computations or limited accuracy, leading to time consumption and instability. Additionally, most high-resolution data and the associated extraction methods are mainly limited by their temporal coverage or spatial characteristics. Moreover, labor-intensive and time-consuming disadvantages will become increasingly obvious when considering a large number of scenarios. Undoubtedly, these are the manifestation of the limited usefulness of large-scale studies, especially those predicated on urban remote sensing, such as urban dynamic analysis and geographical condition monitoring. </p>

<p>Recent advances related to the data fusion of nighttime light data and other daylight images aim to enable feature complementation and information enhancement and are potentially useful for compensating for the disadvantages of the abovementioned single data sources in extracting urban information. Bhatti proposed a novel method to extract built-up areas by integrating temperature data, normalized difference vegetation index (NDVI), and the modified normalized difference water index (MNDWI), which improved the overall accuracy of the extraction. Lin et al. proposed a maximum-entropy method for extracting urban areas from data collected in 2000, 2005 and 2010 by combining MODIS surface reflectance, MODIS NDVI, and DMSP-OLS data based on the maximum-entropy model (MAXENT). Zhou et al. developed a cluster-based method to estimate the optimal thresholds and map urban extent from the DMSP-OLS NTL data based on the cluster size and overall nighttime light magnitude, which can be used to map urban areas at different levels. Although these methods can reduce the issues of over- and underestimation, the deficiencies of nighttime light data resolution, such as the overlapping of adjacent pixels, geolocation error, and the limited temporal coverage of the data products, can still be considered unavoidable influencing factors. Shi et al. proposed an improved Neighborhood Focal Statistic (NFS) method based on nighttime light data, NDVI data, and water vector data in accordance with the approximation of the characterization trend of each urban area in the nighttime light data and digital elevation model (DEM). The improved NFS method primarily identifies central and marginal urban areas using maximum and minimum NFS calculations based on the DMSP-OLS data while eliminating vegetation features and water bodies with multisource geographic data integration to optimally extract the urban areas. However, the abovementioned research mainly achieved data fusion at a single level or only discussed data integration from the perspective of GIS (i.e., an overlay analysis). Huang et al. proposed a novel ensemble support vector machine (SVM) method, which combined multisource data (including remote sensing and socioeconomic data). The core concept of his method is an adaptive thresholding technique, which can be used to identify the diverse urban characteristics for mapping urban areas, especially for prefecture-level cities. Substantial achievements have been obtained by the abovementioned fusion methods, especially for urban information extraction from high resolution images, nighttime light data, and various other products. The following challenges may still be encountered: (1) Since urban elements are characterized from different remote sensing data, the features dependent on the relevant sample selection and training parameters or indices have not been comprehensively considered; (2) The issue of differences in the resolution among multisource data has not been addressed properly. Specifically, the adverse influences of the extraction result accuracy may still occur regardless of the adopted fusion method. </p>
</text>
