To some extent this might be explained by the differences in word segmentation between the two dictionaries applied in this research : many expressions ( e. g. , oro wa , ’ from ’ or pet turasi , ’ to go upstream ’ ) written as two separate segments by Kirikae ( both in the lexicon part of the Ainu shin-yōshū jiten , as well as in his modernized transcriptions of the yukar stories , which we use as the gold standard data ) , are transcribed as a single unit ( orowa , petturasi ) by Bugaeva et al. Once these forms are added to the lexicon , the word segmentation algorithm , which prefers long tokens over shorter ones , stops applying segmentation to the tokens orowa and petturasi ( and that causes recall to drop ) .
1,2 person
9,14 abstract|12,14 abstract|15,18 abstract|20,22 abstract|23,25 abstract|32,35 abstract|36,38 abstract|51,52 person|55,63 abstract|59,63 abstract|68,69 person|68,75 abstract|72,75 abstract|73,75 abstract|77,78 person|80,84 abstract|89,92 abstract|95,96 abstract|98,99 person|98,101 person|100,101 person|102,104 abstract|107,109 abstract|110,113 abstract|110,114 abstract|120,122 object|125,126 abstract|127,132 abstract|127,132 object|131,132 abstract|134,135 abstract|136,137 abstract

Relatively low values of recall for normalization in JK samples , observed across all combinations of dictionaries and input text versions , can be explained by a high occurrence of forms transcribed according to non-standard rules modified by Bugaeva et al. in the modernized version of the dictionary , but not included in the list of universal transcription change rules applied in this research , such as ‘ ra’→‘r ’ ( e. g. , arapa → arpa ) , ‘ ri’→‘r ’ ( e. g. , pirika → pirka ) , ‘ ru’→‘r ’ ( e. g. , kuru → kur ) , ‘ ro’→‘r ’ ( e. g. , koro → kor ) or ‘ ei’→‘e ’ ( e. g. , reihei → rehe ) .
1,2 person
1,11 abstract|9,11 abstract|9,11 object|19,22 abstract|27,32 abstract|31,32 abstract|35,37 abstract|39,40 person|41,42 person|43,49 abstract|47,49 object|57,61 abstract|59,60 abstract|59,61 abstract|63,65 abstract|68,71 abstract|99,100 person|104,107 abstract|111,112 person|113,114 person|117,118 abstract

The only two types of tokenization errors made in the JK samples ( O/M ) when the combined dictionary was used , but not with the JK dictionary , were both of this type — the expressions transcribed by Bugaeva et al. as somo ki ( ’ do not ’ ) and te ta ( ’ here ’ ) are listed as somoki and teta in the Ainu shin-yōshū jiten .
1,2 person
1,8 abstract|6,8 abstract|10,13 abstract|14,15 abstract|17,20 object|26,29 object|31,35 abstract|33,35 abstract|36,38 abstract|40,41 person|42,43 person|47,55 abstract|53,55 abstract|65,66 abstract|67,71 abstract

It shows a weak point of the presented segmentation algorithm : while adding new forms to the lexicon improves its versatility ( ability to process texts from different domains ) , it also increases the number of possible mistakes the tokenizer can make with texts for which the original lexicon had been ( nearly ) optimal .
1,2 person
1,2 abstract|3,11 abstract|7,11 abstract|14,16 abstract|17,19 abstract|20,21 abstract|20,21 object|20,22 abstract|26,30 abstract|28,30 abstract|32,33 abstract|35,42 abstract|45,46 abstract|48,51 abstract

This is due to the fact that these rules are so far only observed in the dictionary of Jinbō and Kanazawa and more importantly , initial tests performed during the development of the algorithm showed that including them in the algorithm can cause errors when processing yukars and other texts .
1,2 person
1,2 abstract|1,2 event|5,7 abstract|8,10 abstract|19,20 person|21,22 person|26,28 abstract|30,35 abstract|33,35 abstract|38,39 abstract|40,42 abstract|44,45 abstract|47,48 abstract|49,51 abstract|49,51 object

The combined dictionary performed better than the other two dictionaries on test data unrelated to the training data ( Shib . and Muk . ) , and also achieved the best overall results ( F-score ) .
1,2 person
1,4 object|7,11 object|12,14 abstract|16,19 abstract|20,21 person|23,24 person|30,34 abstract|35,36 abstract

This means that the original word segmentation , even if it causes some errors ( as with the word tuyka — see Section 6.2 ) , still supports tokenization rather than hindering it .
1,2 person
1,2 abstract|1,2 event|4,8 abstract|11,12 abstract|13,15 abstract|18,20 abstract|20,21 abstract|23,25 abstract|29,30 abstract|33,34 abstract

Scores achieved by the tokenizer on texts with original word boundaries retained ( Y9 – 13 ( O/M ) and JK samples ( O/M ) ) were higher than with spaces removed .
1,2 person
4,12 abstract|9,12 abstract|14,15 abstract|24,25 object

Transcription normalization based on Kirikae ’s lexicon achieved the highest scores for the Y9 – 13 dataset , which is not surprising , since the dictionary is based on yukar epics .
1,2 person
1,3 abstract|1,8 abstract|5,7 person|5,8 abstract|9,12 abstract|13,15 abstract|13,17 abstract|13,18 abstract|25,27 object|30,31 abstract|30,32 abstract

Similarly to transcription normalization , the tokenization algorithm also performed the best for yukar stories ( Y9 – 13 ) when coupled with the Ainu shin-yōshū jiten ( KK ) .
1,2 person
3,5 abstract|6,9 abstract|14,15 abstract|14,16 abstract|17,18 abstract|24,28 abstract

In the case of JK samples , however , performance with the combined dictionary ( JK+KK ) was as good as with the JK dictionary only .
1,2 person
2,7 abstract|5,7 abstract|5,7 object|12,15 object|12,17 abstract|16,17 abstract|23,26 abstract

Table 13 shows a fragment from Y9 – 13 ( M-SR ) before and after segmentation .
1,2 person
1,3 object|4,10 abstract|7,8 abstract

In all test configurations the results for texts with original word segmentation retained were slightly better .
1,2 person
2,5 abstract|5,13 abstract|10,13 abstract

On the other hand , overall recall was higher with the KK dictionary .
1,2 person
6,8 abstract|11,14 abstract|11,14 object

Analogically , for JK samples , the JK dictionary was the best .
1,2 person
4,6 abstract|7,10 object

The results of tokenization experiments are shown in Table 12 .
1,2 person
1,6 abstract|4,6 abstract|9,11 abstract

Furthermore , the combined dictionary achieved the best overall results .
1,2 person
3,6 organization|7,11 abstract

Table 11 shows the results of transcription normalization experiments .
1,2 person
1,3 object|4,10 abstract|7,10 abstract

This phenomenon occurs in the opposite direction as well :
1,2 person
1,3 abstract|5,8 abstract

Results and Discussion
1,2 person
1,2 abstract|3,4 abstract

8.1 .
1,2 person
1,2 abstract

Transcription Normalization
1,2 person
1,3 abstract

8.2 .
1,2 person
1,2 abstract

8 .
1,2 person


Tokenization
1,2 person
1,2 abstract
