Most relevant work has been done using the “ WEKA Spreadsheet to ARFF ” service to convert the NSL-KDD data set format from files with the csv extension to ARFF extension format ( including “ training data set ( KDDTrain+ ) ” and “ test data set ( KDDTest+ ) ” ( https://github.com/jmnwong/NSL-KDD-Dataset ) is the reference URL .
1,2 person
1,4 abstract|18,23 abstract|24,29 object|26,29 abstract|30,33 abstract|44,48 abstract|53,54 place|56,59 abstract|56,59 object

To represent the data record with a low-dimensional vector , only pieces of eigenvector ( named as the principal direction ) are needed , corresponding to pieces of the largest eigenvalue ( ) , and the variance of the projection of the input data in the principal direction is greater than the variance in any other direction .
1,2 person
3,6 abstract|3,6 object|7,10 object|12,15 object|18,21 abstract|36,45 abstract|36,49 abstract|39,45 abstract|42,45 abstract|46,49 abstract|52,58 abstract|55,58 abstract

In this study , a comparison has been made between the correct rate of APT network attack detection using the NSL-KDD data sets and PCA dimensionality reduction technology and four machine learning classification algorithms : SVM , naive Bayes , decision tree , and the multi-layer perceptron neural network ( MLP ) .
1,2 person
2,4 abstract|5,7 abstract|5,7 event|15,16 abstract|15,19 abstract|20,24 abstract|25,29 abstract|30,35 abstract|31,35 abstract|36,37 abstract|41,43 abstract|45,50 abstract

The purpose of PCA is to maximize internal information and increase calculation speed after dimension reduction , and to evaluate the importance of the direction by the size of the data variance in the projection direction .
1,2 person
1,5 abstract|4,5 object|8,10 abstract|12,14 abstract|15,17 abstract|21,26 abstract|24,26 abstract|27,37 abstract|30,33 abstract|30,37 abstract|34,37 abstract

Therefore , while facing current popular APT attacks hidden behind communication behavior , and even in the communication content , it is possible to obtain key information by using network packet analysis technology .
1,2 person
5,9 abstract|7,8 abstract|7,9 abstract|11,13 abstract|17,20 abstract|26,28 abstract|30,34 abstract

The analysis of APT network attack packets is not new technology , but it has become an essential part of network administrators and information security and is used to analyze regular activities .
1,2 person
1,8 abstract|4,8 abstract|4,8 object|10,12 abstract|14,15 abstract|17,23 abstract|17,26 abstract|21,22 place|21,23 person|24,26 abstract|31,33 abstract

These were SVM , naive Bayes , decision tree , and MLP and they were used to train and test the data and compare and analyze the results .
1,2 person
1,2 abstract|1,2 object|3,4 abstract|8,10 abstract|8,13 abstract|14,15 abstract|21,23 abstract|27,29 abstract

Hence parameter is the approximate precision of the pieces of the largest eigenvector , so the following relationship ( 4 ) is obtained ( 4 )
1,2 person
4,14 abstract|8,14 abstract|11,14 abstract|16,19 abstract|20,21 abstract|25,26 abstract

PCA does this transformation by finding a feature vector , and projecting the dimension data onto that feature vector to minimize the overall projection error .
1,2 person
1,2 object|3,5 abstract|3,5 event|13,16 abstract|17,20 abstract|17,20 object|22,26 abstract

Finally , the pre-processed training and test data sets were grouped and tested , and experiments with the four classification algorithms were carried out .
1,2 person
3,10 abstract|3,10 object|18,22 abstract|19,22 abstract

Assuming , and , the random dimension with the mean ( ) inputs the data recording its definition as ( 1 ) ( 1 )
1,2 person
5,11 abstract|14,16 abstract|17,18 abstract|17,19 abstract|21,22 abstract

Side recording of network packets from a target host can provide information about events that enables even more information to be obtained through analysis .
1,2 person
1,6 abstract|1,10 abstract|4,6 object|7,10 place|12,15 abstract|14,15 event|17,20 abstract|24,25 abstract

PCA is a statistical technique that transforms a set of possible correlation variables to a set of linearly uncorrelated variables by orthogonal transformation .
1,2 person
1,2 object|3,6 abstract|8,14 abstract|11,14 abstract|15,21 abstract|18,21 abstract|22,24 abstract

There were four categories of anomalous attack DoS , Probe , R2L , and U2R and the definitions are shown in Table 1 .
1,2 person
6,8 abstract|6,16 abstract|17,19 abstract

PCA can preserve around 0.9 variance of the original data set and significantly reduce the number of features as well as the dimensions .
1,2 person
1,2 object|4,11 quantity|4,12 quantity|8,12 abstract|18,19 abstract|22,24 abstract

The original high-dimensional data set is projected onto a smaller subspace while preserving most of the information contained in the original data set .
1,2 person
1,6 abstract|9,12 object|16,18 abstract|16,24 abstract|20,24 object

In the current network milieu , where information security incidents are frequent , this investigation has become regular and essential .
1,2 person
2,6 place|8,10 abstract|14,16 abstract

In the past , it usually applied to the analysis of network behavior or debugging of the network environment .
1,2 person
5,6 abstract|9,14 abstract|12,13 place|12,14 abstract|15,20 abstract|17,20 abstract|17,20 place

A set of related features in high-dimensional data is converted to a smaller subset and named as principal component .
1,2 person
1,6 abstract|1,9 abstract|7,9 abstract|12,15 abstract|18,20 abstract

Because the data has different ranges , preprocessing needed to be done to round up all the features .
1,2 person
2,4 object|5,7 abstract|16,19 abstract

Each record had data with 41 different feature attributes presenting the content of the network packets .
1,2 person
1,3 abstract|1,3 object|4,10 abstract|6,10 abstract|8,10 abstract|11,17 abstract|14,17 abstract|14,17 object

The PCA algorithm was then used to reduce the size of the classified data set .
1,2 person
1,4 abstract|9,16 abstract|9,16 quantity|12,16 abstract|12,16 object

In Equation ( 3 ) , is the eigenvalue and is the corresponding eigenvector .
1,2 person
2,3 abstract|8,10 abstract|12,15 abstract

The definition f the covariance matrix of is ( 2 ) : ( 2 )
1,2 person
1,8 abstract|4,8 abstract

High-dimensional data can be transformed to low-order dimension data ( ) .
1,2 person
1,3 abstract|7,10 abstract|7,12 abstract

PCA solves the eigenvalues problem of Covariance matrix ( 3 )
1,2 person
1,2 object|3,9 abstract|3,11 abstract|3,12 abstract

Two type classifiers were used , normal , and anomaly .
1,2 person
1,4 abstract|7,8 abstract|10,11 abstract

The transformed set of variables is the principal component .
1,2 person
1,6 abstract|7,10 abstract

Method of Signal Dimension
1,2 person
1,5 abstract|3,5 abstract

Materials and Experimental Setup
1,2 person
1,2 object|1,5 abstract

2.1 .
1,2 person
1,2 abstract

2.2 .
1,2 person
1,2 abstract

2 .
1,2 person


Methods
1,2 person
1,2 abstract
