As the complexity level of spatial analysis is increased , the number of MapReduce steps is also increased , resulting in augmented difficulties for the developers to write iterative code to define the increasingly more complicated MapReduce steps .
1,2 person
6,8 abstract|11,16 abstract|14,16 abstract|22,24 abstract|25,27 person|29,31 abstract|33,39 abstract|33,39 object|37,38 object

This has led to a number of geospatial systems ( e. g. , SpatialHadoop and GeoSpark ) being developed , mostly by injecting spatial data types or functions inside existing big data systems .
1,2 person
1,2 abstract|5,10 abstract|8,10 abstract|24,27 abstract|28,29 abstract|30,34 abstract|30,34 object

The challenges for geospatial big data , however , lie in confronting not only how to store and analyze the data , but also how to transform the data while achieving good performance .
1,2 person
1,7 abstract|4,7 abstract|20,22 abstract|28,30 abstract|28,30 object|32,34 abstract

To resolve this issue , in our previous work , we found a way to represent spatial analysis as a sequence of one or more units of spatial or non-spatial operators .
1,2 person
3,5 abstract|7,8 person|7,10 abstract|11,12 person|13,15 abstract|17,19 abstract|20,32 abstract|23,32 abstract|28,32 abstract

Spatial analysis usually requires handling more than one MapReduce step , where the output of the data from a previous MapReduce step becomes the input to the next MapReduce step .
1,2 person
1,3 abstract|6,11 abstract|13,23 abstract|16,23 abstract|19,23 abstract|21,22 object|24,31 abstract|27,31 abstract|29,30 object

Hadoop , especially , has proven to be a mature big data platform and so several geospatial big data systems have been constructed by inserting spatial data awareness into Hadoop .
1,2 person
9,14 abstract|16,21 abstract|17,21 abstract|26,29 abstract|30,31 object

Among these , the most well-known aspect of geospatial data is spatial relationship , describing the relationship of some objects in a specific location to other objects in neighboring locations .
1,2 person
4,11 abstract|9,11 abstract|12,14 abstract|16,25 abstract|16,31 abstract|22,25 place|29,31 place

For example , we found that it took about 13 hours and 30 minutes to load 821 GB of digital tachograph ( DTG ) data using the traditional ETL method .
1,2 person
4,5 person|7,8 abstract|9,12 time|13,15 time|17,19 quantity|17,22 quantity|20,22 object|20,26 abstract|27,31 abstract

A large percentage of these sensor big data is geospatial data , describing information about physical things in relation to geographic space that can be represented in a coordinate system .
1,2 person
1,9 abstract|5,9 abstract|6,7 object|10,12 abstract|14,23 abstract|16,23 object|21,23 abstract|28,31 abstract

During this conversion process , our system controls the number of MapReduce steps in such a way as to achieve better performance by decreasing the overhead of mapping and reducing .
1,2 person
2,4 event|2,5 abstract|2,5 event|6,7 person|6,8 abstract|9,14 abstract|12,13 object|12,14 abstract|21,23 abstract|25,29 abstract|25,31 abstract

In recent years , numerous types of sensors have been connected to the Internet of Things ( IoT ) and have produced huge volumes of data with high velocity .
1,2 person
2,4 time|5,9 object|8,9 object|28,30 abstract

To deal with the considerable quantity of big data in the ETL process , there have been several attempts in recent years to utilize a parallelized data processing concept .
1,2 person
4,10 quantity|8,10 abstract|8,14 abstract|11,14 abstract|18,20 event|21,23 time|25,29 abstract|25,30 abstract

This allows developers of geospatial big data applications to create spatial applications by simply combining built-in spatial or non-spatial operators , without having any detailed knowledge of MapReduce .
1,2 person
1,2 abstract|3,8 person|3,9 person|5,9 abstract|5,9 object|11,13 abstract|16,21 abstract|19,21 abstract|24,29 abstract|28,29 object

That is , it takes a lot of time to prepare the data required for geospatial analysis , thereby delaying obtaining the results of spatial analysis results .
1,2 person
4,5 abstract|6,10 time|12,18 abstract|16,18 abstract|22,28 abstract|25,27 abstract|25,28 abstract

In the ETL process , data are extracted from data sources , then transformed , involving normalization and cleansing , and loaded into the target data base .
1,2 person
2,5 abstract|3,5 abstract|6,7 abstract|10,12 abstract|24,28 object

Once the sequence of operators has been incorporated , it is automatically transformed to the map and reduces jobs in our Hadoop-based geospatial big data system .
1,2 person
2,6 abstract|10,11 abstract|15,17 abstract|15,17 object|19,20 abstract|21,22 person|21,27 abstract|21,27 object

Systems designed for big data have existed for years ( e. g. , Hadoop and Spark ) ; however , they are uninformed about spatial properties .
1,2 person
1,2 abstract|4,6 abstract|9,10 time|25,27 abstract

With the advance of IoT technologies , more diverse data have now become available , thereby greatly increasing the amount of geospatial big data .
1,2 person
5,7 abstract|8,11 abstract|19,25 abstract|22,25 abstract

These coordinate data differ from normal string or integer data , requiring the data pre-processing process to include a lot of floating-point arithmetic computations .
1,2 person
1,4 abstract|6,11 abstract|13,17 abstract|19,25 abstract|22,25 abstract

Typically , to generate a MapReduce job for a required operation in Hadoop , developers need to program a map and reduce functions .
1,2 person
5,8 object|13,14 place|15,16 person|19,21 object|23,24 abstract

Given the general properties of big data , the unique characteristics of geospatial data create an innovative challenge in data preparation .
1,2 person
2,8 abstract|6,8 abstract|9,15 abstract|13,15 abstract|16,19 abstract|20,22 abstract

The conventional ETL system is typically operated on a single machine that cannot effectively handle huge volumes of big data .
1,2 person
1,5 abstract|9,12 object|16,21 abstract|16,21 object|19,21 abstract

The calculation of spatial relationship is mostly included in spatial analysis and has been generally regarded as a sophisticated problem .
1,2 person
1,6 abstract|4,6 abstract|10,12 abstract|18,21 abstract

However , the time required to transform massive amounts of geospatial data into the Hadoop platform has gradually increased .
1,2 person
3,5 time|8,13 abstract|8,13 object|14,17 abstract

To deal with the challenges in processing and analyzing geospatial big data , several systems have emerged .
1,2 person
4,13 abstract|10,13 abstract|14,16 abstract

It is important to analyze this geospatial big data as soon as possible to extract useful insights .
1,2 person
1,2 event|6,10 abstract|16,18 abstract

However , it is still not easy for big data software developers to create geospatial applications .
1,2 person
3,4 abstract|9,13 person|9,17 abstract|15,17 abstract|15,17 object

Currently , a large amount of geospatial data is continuously provided from many spatial sensors .
1,2 person
3,9 abstract|7,9 abstract|13,16 object

Examples include transformation in geometry , converting coordination reference systems , and evaluating spatial relationships .
1,2 person
1,2 abstract|3,6 abstract|5,6 abstract|8,11 abstract|14,16 abstract

Moreover , processing temporal elements also complicates the handling of geospatial data .
1,2 person
4,6 abstract|8,13 abstract|11,13 abstract

Geospatial data typically include position data .
1,2 person
1,3 abstract|1,3 object|5,6 abstract|5,7 abstract

1 .
1,2 person


Introduction
1,2 person
1,2 abstract
