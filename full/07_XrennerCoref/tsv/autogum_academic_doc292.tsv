#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=3 .
1-1	0-1	3	quantity	new	_	_
1-2	2-3	.	_	_	_	_

#Text=Impulse Detection Methodology
2-1	4-11	Impulse	person|abstract[4]	new|new[4]	_	_
2-2	12-21	Detection	abstract|abstract[4]	new|new[4]	coref	5-7
2-3	22-33	Methodology	abstract[4]	new[4]	_	_

#Text=Using Deep Learning Flexible Boundary Regression
3-1	34-39	Using	_	_	_	_
3-2	40-44	Deep	abstract[6]	new[6]	coref	7-9[0_6]
3-3	45-53	Learning	abstract[6]	new[6]	_	_
3-4	54-62	Flexible	abstract[6]	new[6]	_	_
3-5	63-71	Boundary	abstract|abstract[6]	new|new[6]	coref	7-20
3-6	72-82	Regression	abstract[6]	new[6]	_	_

#Text=Since the time lengths of the AE impulse signal excited by the fuel stream are variable , the proposed method must adapt to predict boundaries of different sizes .
4-1	83-88	Since	_	_	_	_
4-2	89-92	the	quantity[8]	new[8]	_	_
4-3	93-97	time	time|quantity[8]	new|new[8]	coref	22-16
4-4	98-105	lengths	quantity[8]	new[8]	_	_
4-5	106-108	of	quantity[8]	new[8]	_	_
4-6	109-112	the	quantity[8]|abstract[11]	new[8]|new[11]	coref	6-12[27_11]
4-7	113-115	AE	quantity[8]|abstract|abstract[11]	new[8]|new|new[11]	coref	6-13
4-8	116-123	impulse	quantity[8]|abstract|abstract[11]	new[8]|new|new[11]	coref	5-6
4-9	124-130	signal	quantity[8]|abstract[11]	new[8]|new[11]	_	_
4-10	131-138	excited	_	_	_	_
4-11	139-141	by	_	_	_	_
4-12	142-145	the	abstract[13]	new[13]	_	_
4-13	146-150	fuel	substance|abstract[13]	new|new[13]	_	_
4-14	151-157	stream	abstract[13]	new[13]	_	_
4-15	158-161	are	_	_	_	_
4-16	162-170	variable	_	_	_	_
4-17	171-172	,	_	_	_	_
4-18	173-176	the	abstract[14]	new[14]	coref	8-1[37_14]
4-19	177-185	proposed	abstract[14]	new[14]	_	_
4-20	186-192	method	abstract[14]	new[14]	_	_
4-21	193-197	must	_	_	_	_
4-22	198-203	adapt	_	_	_	_
4-23	204-206	to	_	_	_	_
4-24	207-214	predict	_	_	_	_
4-25	215-225	boundaries	place[15]	new[15]	_	_
4-26	226-228	of	place[15]	new[15]	_	_
4-27	229-238	different	place[15]|abstract[16]	new[15]|new[16]	_	_
4-28	239-244	sizes	place[15]|abstract[16]	new[15]|new[16]	_	_
4-29	245-246	.	_	_	_	_

#Text=This research introduces the DLFBR impulse detection model , which considers an impulse as an object to be analyzed and recognized .
5-1	247-251	This	abstract[17]	new[17]	coref	7-1[28_17]
5-2	252-260	research	abstract[17]	new[17]	_	_
5-3	261-271	introduces	_	_	_	_
5-4	272-275	the	abstract[21]	new[21]	coref	6-1[23_21]
5-5	276-281	DLFBR	object|abstract[21]	new|new[21]	coref	34-1
5-6	282-289	impulse	abstract|abstract[21]	giv|new[21]	coref	5-12[22_0]
5-7	290-299	detection	abstract|abstract[21]	giv|new[21]	coref	6-9[25_0]
5-8	300-305	model	abstract[21]	new[21]	_	_
5-9	306-307	,	_	_	_	_
5-10	308-313	which	_	_	_	_
5-11	314-323	considers	_	_	_	_
5-12	324-326	an	abstract[22]	giv[22]	coref	8-41[0_22]
5-13	327-334	impulse	abstract[22]	giv[22]	_	_
5-14	335-337	as	abstract[22]	giv[22]	_	_
5-15	338-340	an	abstract[22]	giv[22]	_	_
5-16	341-347	object	abstract[22]	giv[22]	_	_
5-17	348-350	to	_	_	_	_
5-18	351-353	be	_	_	_	_
5-19	354-362	analyzed	_	_	_	_
5-20	363-366	and	_	_	_	_
5-21	367-377	recognized	_	_	_	_
5-22	378-379	.	_	_	_	_

#Text=This model improves the 1D-CNN to adapt for hit detection in the AE signal .
6-1	380-384	This	abstract[23]	giv[23]	_	_
6-2	385-390	model	abstract[23]	giv[23]	_	_
6-3	391-399	improves	_	_	_	_
6-4	400-403	the	object[24]	new[24]	coref	8-23[43_24]
6-5	404-410	1D-CNN	object[24]	new[24]	_	_
6-6	411-413	to	_	_	_	_
6-7	414-419	adapt	_	_	_	_
6-8	420-423	for	_	_	_	_
6-9	424-427	hit	abstract[25]	giv[25]	coref	7-4[29_25]
6-10	428-437	detection	abstract[25]	giv[25]	_	_
6-11	438-440	in	abstract[25]	giv[25]	_	_
6-12	441-444	the	abstract[25]|abstract[27]	giv[25]|giv[27]	coref	7-16[0_27]
6-13	445-447	AE	abstract[25]|abstract|abstract[27]	giv[25]|giv|giv[27]	coref	7-15
6-14	448-454	signal	abstract[25]|abstract[27]	giv[25]|giv[27]	_	_
6-15	455-456	.	_	_	_	_

#Text=The research reframes hit detection as a straightforward regression issue , directly from the AE signal vector to the boundary box coordinates .
7-1	457-460	The	abstract[28]	giv[28]	_	_
7-2	461-469	research	abstract[28]	giv[28]	_	_
7-3	470-478	reframes	_	_	_	_
7-4	479-482	hit	abstract[29]	giv[29]	coref	9-6[0_29]
7-5	483-492	detection	abstract[29]	giv[29]	_	_
7-6	493-495	as	abstract[29]	giv[29]	_	_
7-7	496-497	a	abstract[29]	giv[29]	_	_
7-8	498-513	straightforward	abstract[29]	giv[29]	_	_
7-9	514-524	regression	abstract[29]|abstract	giv[29]|giv	coref	8-29
7-10	525-530	issue	abstract[29]	giv[29]	_	_
7-11	531-532	,	_	_	_	_
7-12	533-541	directly	abstract[33]	new[33]	coref	8-34[47_33]
7-13	542-546	from	abstract[33]	new[33]	_	_
7-14	547-550	the	abstract[33]	new[33]	_	_
7-15	551-553	AE	abstract|abstract[33]	giv|new[33]	coref	8-6
7-16	554-560	signal	abstract|abstract[33]	giv|new[33]	coref	8-5[39_0]
7-17	561-567	vector	abstract[33]	new[33]	_	_
7-18	568-570	to	abstract[33]	new[33]	_	_
7-19	571-574	the	abstract[33]|abstract[36]	new[33]|new[36]	coref	8-37[49_36]
7-20	575-583	boundary	abstract[33]|abstract|abstract[36]	new[33]|giv|new[36]	coref	8-28
7-21	584-587	box	abstract[33]|abstract|abstract[36]	new[33]|new|new[36]	coref	8-37
7-22	588-599	coordinates	abstract[33]|abstract[36]	new[33]|new[36]	_	_
7-23	600-601	.	_	_	_	_

#Text=The proposed method takes an AE signal as the input , feeds it through a neural network structure that looks similar to a 1D-CNN to integrate the boundary regression layer , and receives a vector of box coordinates around the impulse position in the output .
8-1	602-605	The	abstract[37]	giv[37]	coref	23-1[150_37]
8-2	606-614	proposed	abstract[37]	giv[37]	_	_
8-3	615-621	method	abstract[37]	giv[37]	_	_
8-4	622-627	takes	_	_	_	_
8-5	628-630	an	abstract[39]	giv[39]	ana	8-13[0_39]
8-6	631-633	AE	abstract|abstract[39]	giv|giv[39]	coref	15-4
8-7	634-640	signal	abstract[39]	giv[39]	_	_
8-8	641-643	as	_	_	_	_
8-9	644-647	the	_	_	_	_
8-10	648-653	input	_	_	_	_
8-11	654-655	,	_	_	_	_
8-12	656-661	feeds	_	_	_	_
8-13	662-664	it	abstract	giv	coref	9-13[57_0]
8-14	665-672	through	_	_	_	_
8-15	673-674	a	abstract[42]	new[42]	_	_
8-16	675-681	neural	abstract[42]	new[42]	_	_
8-17	682-689	network	abstract|abstract[42]	new|new[42]	coref	14-5[83_0]
8-18	690-699	structure	abstract[42]	new[42]	_	_
8-19	700-704	that	_	_	_	_
8-20	705-710	looks	_	_	_	_
8-21	711-718	similar	_	_	_	_
8-22	719-721	to	_	_	_	_
8-23	722-723	a	object[43]	giv[43]	_	_
8-24	724-730	1D-CNN	object[43]	giv[43]	_	_
8-25	731-733	to	_	_	_	_
8-26	734-743	integrate	_	_	_	_
8-27	744-747	the	abstract[46]	new[46]	_	_
8-28	748-756	boundary	abstract|abstract[46]	giv|new[46]	coref	9-23
8-29	757-767	regression	abstract|abstract[46]	giv|new[46]	_	_
8-30	768-773	layer	abstract[46]	new[46]	_	_
8-31	774-775	,	_	_	_	_
8-32	776-779	and	_	_	_	_
8-33	780-788	receives	_	_	_	_
8-34	789-790	a	abstract[47]	giv[47]	coref	28-3[0_47]
8-35	791-797	vector	abstract[47]	giv[47]	_	_
8-36	798-800	of	abstract[47]	giv[47]	_	_
8-37	801-804	box	abstract[47]|abstract|abstract[49]	giv[47]|giv|giv[49]	_	_
8-38	805-816	coordinates	abstract[47]|abstract[49]	giv[47]|giv[49]	_	_
8-39	817-823	around	abstract[47]|abstract[49]	giv[47]|giv[49]	_	_
8-40	824-827	the	abstract[47]|abstract[49]|abstract[51]	giv[47]|giv[49]|new[51]	_	_
8-41	828-835	impulse	abstract[47]|abstract[49]|abstract|abstract[51]	giv[47]|giv[49]|giv|new[51]	coref	12-11[67_0]
8-42	836-844	position	abstract[47]|abstract[49]|abstract[51]	giv[47]|giv[49]|new[51]	_	_
8-43	845-847	in	abstract[47]|abstract[49]|abstract[51]	giv[47]|giv[49]|new[51]	_	_
8-44	848-851	the	abstract[47]|abstract[49]|abstract[51]|abstract[52]	giv[47]|giv[49]|new[51]|new[52]	coref	28-2[0_52]
8-45	852-858	output	abstract[47]|abstract[49]|abstract[51]|abstract[52]	giv[47]|giv[49]|new[51]|new[52]	_	_
8-46	859-860	.	_	_	_	_

#Text=The basic idea of the detection algorithm includes two steps : preprocessing the signal to extract the shape signal and a flexible boundary detector .
9-1	861-864	The	abstract[53]	new[53]	_	_
9-2	865-870	basic	abstract[53]	new[53]	_	_
9-3	871-875	idea	abstract[53]	new[53]	_	_
9-4	876-878	of	abstract[53]	new[53]	_	_
9-5	879-882	the	abstract[53]|abstract[55]	new[53]|new[55]	coref	16-19[110_55]
9-6	883-892	detection	abstract[53]|abstract|abstract[55]	new[53]|giv|new[55]	coref	13-6[73_0]
9-7	893-902	algorithm	abstract[53]|abstract[55]	new[53]|new[55]	_	_
9-8	903-911	includes	_	_	_	_
9-9	912-915	two	abstract[56]	new[56]	_	_
9-10	916-921	steps	abstract[56]	new[56]	_	_
9-11	922-923	:	_	_	_	_
9-12	924-937	preprocessing	_	_	_	_
9-13	938-941	the	abstract[57]	giv[57]	coref	9-17[59_57]
9-14	942-948	signal	abstract[57]	giv[57]	_	_
9-15	949-951	to	_	_	_	_
9-16	952-959	extract	_	_	_	_
9-17	960-963	the	abstract[59]	giv[59]	coref	11-4[63_59]
9-18	964-969	shape	abstract|abstract[59]	new|giv[59]	coref	12-7[66_0]
9-19	970-976	signal	abstract[59]	giv[59]	_	_
9-20	977-980	and	_	_	_	_
9-21	981-982	a	object[61]	new[61]	coref	16-14[107_61]
9-22	983-991	flexible	object[61]	new[61]	_	_
9-23	992-1000	boundary	abstract|object[61]	giv|new[61]	coref	14-10[84_0]
9-24	1001-1009	detector	object[61]	new[61]	_	_
9-25	1010-1011	.	_	_	_	_

#Text=3.1 .
10-1	1012-1015	3.1	abstract	new	_	_
10-2	1016-1017	.	_	_	_	_

#Text=Preprocessing to Extract the Shape Signal
11-1	1018-1031	Preprocessing	_	_	_	_
11-2	1032-1034	to	_	_	_	_
11-3	1035-1042	Extract	_	_	_	_
11-4	1043-1046	the	object[63]	giv[63]	coref	12-22[70_63]
11-5	1047-1052	Shape	object[63]	giv[63]	_	_
11-6	1053-1059	Signal	object[63]	giv[63]	_	_

#Text=The preprocessing step works to extract the global shape of the impulse at the macro-level , corresponding to the length of the sampled signal .
12-1	1060-1063	The	object[65]	new[65]	coref	13-16[77_65]
12-2	1064-1077	preprocessing	abstract|object[65]	new|new[65]	coref	17-21
12-3	1078-1082	step	object[65]	new[65]	_	_
12-4	1083-1088	works	_	_	_	_
12-5	1089-1091	to	_	_	_	_
12-6	1092-1099	extract	_	_	_	_
12-7	1100-1103	the	abstract[66]	giv[66]	_	_
12-8	1104-1110	global	abstract[66]	giv[66]	_	_
12-9	1111-1116	shape	abstract[66]	giv[66]	_	_
12-10	1117-1119	of	abstract[66]	giv[66]	_	_
12-11	1120-1123	the	abstract[66]|abstract[67]	giv[66]|giv[67]	_	_
12-12	1124-1131	impulse	abstract[66]|abstract[67]	giv[66]|giv[67]	_	_
12-13	1132-1134	at	abstract[66]|abstract[67]	giv[66]|giv[67]	_	_
12-14	1135-1138	the	abstract[66]|abstract[67]|abstract[68]	giv[66]|giv[67]|new[68]	_	_
12-15	1139-1150	macro-level	abstract[66]|abstract[67]|abstract[68]	giv[66]|giv[67]|new[68]	_	_
12-16	1151-1152	,	_	_	_	_
12-17	1153-1166	corresponding	_	_	_	_
12-18	1167-1169	to	_	_	_	_
12-19	1170-1173	the	abstract[69]	new[69]	_	_
12-20	1174-1180	length	abstract[69]	new[69]	_	_
12-21	1181-1183	of	abstract[69]	new[69]	_	_
12-22	1184-1187	the	abstract[69]|abstract[70]	new[69]|giv[70]	coref	15-3[93_70]
12-23	1188-1195	sampled	abstract[69]|abstract[70]	new[69]|giv[70]	_	_
12-24	1196-1202	signal	abstract[69]|abstract[70]	new[69]|giv[70]	_	_
12-25	1203-1204	.	_	_	_	_

#Text=Normally , the concept of object detection is used in an image processing technique where the object is smooth , continuous , and mostly homogenous inside the point area of the object .
13-1	1205-1213	Normally	_	_	_	_
13-2	1214-1215	,	_	_	_	_
13-3	1216-1219	the	abstract[71]	new[71]	_	_
13-4	1220-1227	concept	abstract[71]	new[71]	_	_
13-5	1228-1230	of	abstract[71]	new[71]	_	_
13-6	1231-1237	object	abstract[71]|abstract|abstract[73]	new[71]|new|giv[73]	coref|coref	15-10[0_73]|15-10[0_73]
13-7	1238-1247	detection	abstract[71]|abstract[73]	new[71]|giv[73]	_	_
13-8	1248-1250	is	_	_	_	_
13-9	1251-1255	used	_	_	_	_
13-10	1256-1258	in	_	_	_	_
13-11	1259-1261	an	abstract[76]	new[76]	_	_
13-12	1262-1267	image	abstract|abstract[76]	new|new[76]	_	_
13-13	1268-1278	processing	abstract|abstract[76]	new|new[76]	_	_
13-14	1279-1288	technique	abstract[76]	new[76]	_	_
13-15	1289-1294	where	_	_	_	_
13-16	1295-1298	the	object[77]	giv[77]	coref	13-31[80_77]
13-17	1299-1305	object	object[77]	giv[77]	_	_
13-18	1306-1308	is	_	_	_	_
13-19	1309-1315	smooth	_	_	_	_
13-20	1316-1317	,	_	_	_	_
13-21	1318-1328	continuous	_	_	_	_
13-22	1329-1330	,	_	_	_	_
13-23	1331-1334	and	_	_	_	_
13-24	1335-1341	mostly	_	_	_	_
13-25	1342-1352	homogenous	_	_	_	_
13-26	1353-1359	inside	_	_	_	_
13-27	1360-1363	the	place[79]	new[79]	_	_
13-28	1364-1369	point	place|place[79]	new|new[79]	coref	25-14[168_0]
13-29	1370-1374	area	place[79]	new[79]	_	_
13-30	1375-1377	of	place[79]	new[79]	_	_
13-31	1378-1381	the	place[79]|object[80]	new[79]|giv[80]	coref	14-13[85_80]
13-32	1382-1388	object	place[79]|object[80]	new[79]|giv[80]	_	_
13-33	1389-1390	.	_	_	_	_

#Text=With this condition , the convolution neural network considers the boundary of an object to be composed of an edge and blob patterns , which have a sudden change between their different colors .
14-1	1391-1395	With	_	_	_	_
14-2	1396-1400	this	abstract[81]	new[81]	_	_
14-3	1401-1410	condition	abstract[81]	new[81]	_	_
14-4	1411-1412	,	_	_	_	_
14-5	1413-1416	the	abstract[83]	giv[83]	_	_
14-6	1417-1428	convolution	abstract|abstract[83]	new|giv[83]	coref	32-10
14-7	1429-1435	neural	abstract[83]	giv[83]	_	_
14-8	1436-1443	network	abstract[83]	giv[83]	_	_
14-9	1444-1453	considers	_	_	_	_
14-10	1454-1457	the	abstract[84]	giv[84]	coref	30-7[205_84]
14-11	1458-1466	boundary	abstract[84]	giv[84]	_	_
14-12	1467-1469	of	abstract[84]	giv[84]	_	_
14-13	1470-1472	an	abstract[84]|object[85]	giv[84]|giv[85]	coref	16-20[0_85]
14-14	1473-1479	object	abstract[84]|object[85]	giv[84]|giv[85]	_	_
14-15	1480-1482	to	_	_	_	_
14-16	1483-1485	be	_	_	_	_
14-17	1486-1494	composed	_	_	_	_
14-18	1495-1497	of	_	_	_	_
14-19	1498-1500	an	object[86]	new[86]	_	_
14-20	1501-1505	edge	object[86]	new[86]	_	_
14-21	1506-1509	and	_	_	_	_
14-22	1510-1514	blob	object|abstract[88]	new|new[88]	ana|ana	14-31[0_88]|14-31[0_88]
14-23	1515-1523	patterns	abstract[88]	new[88]	_	_
14-24	1524-1525	,	_	_	_	_
14-25	1526-1531	which	_	_	_	_
14-26	1532-1536	have	_	_	_	_
14-27	1537-1538	a	abstract[89]	new[89]	_	_
14-28	1539-1545	sudden	abstract[89]	new[89]	_	_
14-29	1546-1552	change	abstract[89]	new[89]	_	_
14-30	1553-1560	between	abstract[89]	new[89]	_	_
14-31	1561-1566	their	abstract[89]|abstract|abstract[91]	new[89]|giv|new[91]	_	_
14-32	1567-1576	different	abstract[89]|abstract[91]	new[89]|new[91]	_	_
14-33	1577-1583	colors	abstract[89]|abstract[91]	new[89]|new[91]	_	_
14-34	1584-1585	.	_	_	_	_

#Text=However , the AE signal collected from the leak detection testbed always includes environmental noise and contains many small troughs and peaks .
15-1	1586-1593	However	_	_	_	_
15-2	1594-1595	,	_	_	_	_
15-3	1596-1599	the	abstract[93]	giv[93]	coref	17-29[120_93]
15-4	1600-1602	AE	abstract|abstract[93]	giv|giv[93]	coref	20-7
15-5	1603-1609	signal	abstract[93]	giv[93]	_	_
15-6	1610-1619	collected	_	_	_	_
15-7	1620-1624	from	_	_	_	_
15-8	1625-1628	the	abstract[96]	new[96]	_	_
15-9	1629-1633	leak	abstract|abstract[96]	new|new[96]	_	_
15-10	1634-1643	detection	abstract|abstract[96]	giv|new[96]	coref	16-21
15-11	1644-1651	testbed	abstract[96]	new[96]	_	_
15-12	1652-1658	always	_	_	_	_
15-13	1659-1667	includes	_	_	_	_
15-14	1668-1681	environmental	abstract[97]	new[97]	coref	17-17[116_97]
15-15	1682-1687	noise	abstract[97]	new[97]	_	_
15-16	1688-1691	and	_	_	_	_
15-17	1692-1700	contains	_	_	_	_
15-18	1701-1705	many	place[98]|abstract[99]	new[98]|new[99]	coref|coref|coref|coref	16-2[101_98]|16-2[102_99]|16-2[101_98]|16-2[102_99]
15-19	1706-1711	small	place[98]|abstract[99]	new[98]|new[99]	_	_
15-20	1712-1719	troughs	place[98]|abstract[99]	new[98]|new[99]	_	_
15-21	1720-1723	and	abstract[99]	new[99]	_	_
15-22	1724-1729	peaks	abstract[99]|abstract	new[99]|new	coref	16-5
15-23	1730-1731	.	_	_	_	_

#Text=If these troughs and peaks are smaller than the grid size generated by the deep learning detector , the object detection algorithm cannot give a satisfying result .
16-1	1732-1734	If	_	_	_	_
16-2	1735-1740	these	place[101]|abstract[102]	giv[101]|giv[102]	_	_
16-3	1741-1748	troughs	place[101]|abstract[102]	giv[101]|giv[102]	_	_
16-4	1749-1752	and	abstract[102]	giv[102]	_	_
16-5	1753-1758	peaks	abstract[102]|abstract	giv[102]|giv	_	_
16-6	1759-1762	are	_	_	_	_
16-7	1763-1770	smaller	_	_	_	_
16-8	1771-1775	than	_	_	_	_
16-9	1776-1779	the	quantity[105]	new[105]	coref	22-10[142_105]
16-10	1780-1784	grid	abstract|quantity[105]	new|new[105]	coref	23-16
16-11	1785-1789	size	quantity[105]	new[105]	_	_
16-12	1790-1799	generated	_	_	_	_
16-13	1800-1802	by	_	_	_	_
16-14	1803-1806	the	object[107]	giv[107]	coref	30-4[207_107]
16-15	1807-1811	deep	object[107]	giv[107]	_	_
16-16	1812-1820	learning	abstract|object[107]	new|giv[107]	_	_
16-17	1821-1829	detector	object[107]	giv[107]	_	_
16-18	1830-1831	,	_	_	_	_
16-19	1832-1835	the	abstract[110]	giv[110]	coref	19-6[125_110]
16-20	1836-1842	object	object|abstract[110]	giv|giv[110]	coref	17-20[118_0]
16-21	1843-1852	detection	abstract|abstract[110]	giv|giv[110]	coref	30-1[203_0]
16-22	1853-1862	algorithm	abstract[110]	giv[110]	_	_
16-23	1863-1869	cannot	_	_	_	_
16-24	1870-1874	give	_	_	_	_
16-25	1875-1876	a	abstract[111]	new[111]	_	_
16-26	1877-1887	satisfying	abstract[111]	new[111]	_	_
16-27	1888-1894	result	abstract[111]	new[111]	_	_
16-28	1895-1896	.	_	_	_	_

#Text=To mitigate the undesired variations and unexpected instantaneous frequency values produced by the remaining amount of small noise , the preprocessing step helps obtain the overall shape of the signal with little random noise .
17-1	1897-1899	To	_	_	_	_
17-2	1900-1908	mitigate	_	_	_	_
17-3	1909-1912	the	abstract[112]	new[112]	_	_
17-4	1913-1922	undesired	abstract[112]	new[112]	_	_
17-5	1923-1933	variations	abstract[112]	new[112]	_	_
17-6	1934-1937	and	_	_	_	_
17-7	1938-1948	unexpected	abstract[114]	new[114]	coref	23-12[154_114]
17-8	1949-1962	instantaneous	abstract[114]	new[114]	_	_
17-9	1963-1972	frequency	abstract|abstract[114]	new|new[114]	_	_
17-10	1973-1979	values	abstract[114]	new[114]	_	_
17-11	1980-1988	produced	_	_	_	_
17-12	1989-1991	by	_	_	_	_
17-13	1992-1995	the	quantity[115]	new[115]	_	_
17-14	1996-2005	remaining	quantity[115]	new[115]	_	_
17-15	2006-2012	amount	quantity[115]	new[115]	_	_
17-16	2013-2015	of	quantity[115]	new[115]	_	_
17-17	2016-2021	small	quantity[115]|abstract[116]	new[115]|giv[116]	coref	17-32[121_116]
17-18	2022-2027	noise	quantity[115]|abstract[116]	new[115]|giv[116]	_	_
17-19	2028-2029	,	_	_	_	_
17-20	2030-2033	the	object[118]	giv[118]	coref	19-2[124_118]
17-21	2034-2047	preprocessing	abstract|object[118]	giv|giv[118]	coref	19-3
17-22	2048-2052	step	object[118]	giv[118]	_	_
17-23	2053-2058	helps	_	_	_	_
17-24	2059-2065	obtain	_	_	_	_
17-25	2066-2069	the	abstract[119]	new[119]	_	_
17-26	2070-2077	overall	abstract[119]	new[119]	_	_
17-27	2078-2083	shape	abstract[119]	new[119]	_	_
17-28	2084-2086	of	abstract[119]	new[119]	_	_
17-29	2087-2090	the	abstract[119]|abstract[120]	new[119]|giv[120]	coref	20-8[0_120]
17-30	2091-2097	signal	abstract[119]|abstract[120]	new[119]|giv[120]	_	_
17-31	2098-2102	with	abstract[119]|abstract[120]	new[119]|giv[120]	_	_
17-32	2103-2109	little	abstract[119]|abstract[120]|abstract[121]	new[119]|giv[120]|giv[121]	_	_
17-33	2110-2116	random	abstract[119]|abstract[120]|abstract[121]	new[119]|giv[120]|giv[121]	_	_
17-34	2117-2122	noise	abstract[119]|abstract[120]|abstract[121]	new[119]|giv[120]|giv[121]	_	_
17-35	2123-2124	.	_	_	_	_

#Text=Figure 3
18-1	2125-2131	Figure	abstract[122]	new[122]	_	_
18-2	2132-2133	3	abstract[122]	new[122]	_	_

#Text=presents the preprocessing step of the algorithm .
19-1	2134-2142	presents	_	_	_	_
19-2	2143-2146	the	object[124]	giv[124]	coref	20-2[126_124]
19-3	2147-2160	preprocessing	abstract|object[124]	giv|giv[124]	_	_
19-4	2161-2165	step	object[124]	giv[124]	_	_
19-5	2166-2168	of	object[124]	giv[124]	_	_
19-6	2169-2172	the	object[124]|abstract[125]	giv[124]|giv[125]	_	_
19-7	2173-2182	algorithm	object[124]|abstract[125]	giv[124]|giv[125]	_	_
19-8	2183-2184	.	_	_	_	_

#Text=In the first step , the AE signal sample is segmented into non-overlapping frames and rectified to obtain the positive part .
20-1	2185-2187	In	_	_	_	_
20-2	2188-2191	the	object[126]	giv[126]	coref	33-3[218_126]
20-3	2192-2197	first	object[126]	giv[126]	_	_
20-4	2198-2202	step	object[126]	giv[126]	_	_
20-5	2203-2204	,	_	_	_	_
20-6	2205-2208	the	object[129]	new[129]	coref	33-24[0_129]
20-7	2209-2211	AE	substance|object[129]	giv|new[129]	coref	32-3
20-8	2212-2218	signal	abstract|object[129]	giv|new[129]	coref	21-18[138_0]
20-9	2219-2225	sample	object[129]	new[129]	_	_
20-10	2226-2228	is	_	_	_	_
20-11	2229-2238	segmented	_	_	_	_
20-12	2239-2243	into	_	_	_	_
20-13	2244-2259	non-overlapping	abstract[130]	new[130]	_	_
20-14	2260-2266	frames	abstract[130]	new[130]	_	_
20-15	2267-2270	and	_	_	_	_
20-16	2271-2280	rectified	_	_	_	_
20-17	2281-2283	to	_	_	_	_
20-18	2284-2290	obtain	_	_	_	_
20-19	2291-2294	the	abstract[131]	new[131]	_	_
20-20	2295-2303	positive	abstract[131]	new[131]	_	_
20-21	2304-2308	part	abstract[131]	new[131]	_	_
20-22	2309-2310	.	_	_	_	_

#Text=Then , in each window , the root means square ( RMS ) is calculated to form the lower rate RMS signal .
21-1	2311-2315	Then	_	_	_	_
21-2	2316-2317	,	_	_	_	_
21-3	2318-2320	in	_	_	_	_
21-4	2321-2325	each	object[132]	new[132]	ana	22-10[0_132]
21-5	2326-2332	window	object[132]	new[132]	_	_
21-6	2333-2334	,	_	_	_	_
21-7	2335-2338	the	object[133]	new[133]	_	_
21-8	2339-2343	root	object[133]	new[133]	_	_
21-9	2344-2349	means	_	_	_	_
21-10	2350-2356	square	place	new	_	_
21-11	2357-2358	(	_	_	_	_
21-12	2359-2362	RMS	abstract	new	coref	21-21
21-13	2363-2364	)	_	_	_	_
21-14	2365-2367	is	_	_	_	_
21-15	2368-2378	calculated	_	_	_	_
21-16	2379-2381	to	_	_	_	_
21-17	2382-2386	form	abstract	new	coref|none	25-20[169_0]|21-17[0_169]
21-18	2387-2390	the	abstract[138]	giv[138]	coref	22-3[140_138]
21-19	2391-2396	lower	abstract[138]	giv[138]	_	_
21-20	2397-2401	rate	abstract|abstract[138]	new|giv[138]	coref	22-5
21-21	2402-2405	RMS	abstract|abstract[138]	giv|giv[138]	_	_
21-22	2406-2412	signal	abstract[138]	giv[138]	_	_
21-23	2413-2414	.	_	_	_	_

#Text=Next , the lower rate signal is expanded to its original size by scaling the time axis using cubic interpolation and antialiasing .
22-1	2415-2419	Next	_	_	_	_
22-2	2420-2421	,	_	_	_	_
22-3	2422-2425	the	abstract[140]	giv[140]	coref	31-11[211_140]
22-4	2426-2431	lower	abstract[140]	giv[140]	_	_
22-5	2432-2436	rate	abstract|abstract[140]	giv|giv[140]	_	_
22-6	2437-2443	signal	abstract[140]	giv[140]	_	_
22-7	2444-2446	is	_	_	_	_
22-8	2447-2455	expanded	_	_	_	_
22-9	2456-2458	to	_	_	_	_
22-10	2459-2462	its	object|quantity[142]	giv|giv[142]	coref|coref	36-27[254_142]|36-27[254_142]
22-11	2463-2471	original	quantity[142]	giv[142]	_	_
22-12	2472-2476	size	quantity[142]	giv[142]	_	_
22-13	2477-2479	by	_	_	_	_
22-14	2480-2487	scaling	_	_	_	_
22-15	2488-2491	the	abstract[144]	new[144]	_	_
22-16	2492-2496	time	time|abstract[144]	giv|new[144]	_	_
22-17	2497-2501	axis	abstract[144]	new[144]	_	_
22-18	2502-2507	using	_	_	_	_
22-19	2508-2513	cubic	abstract|abstract[146]	new|new[146]	coref|coref|coref|coref	23-2|23-3[0_146]|23-2|23-3[0_146]
22-20	2514-2527	interpolation	abstract[146]	new[146]	_	_
22-21	2528-2531	and	_	_	_	_
22-22	2532-2544	antialiasing	abstract	new	_	_
22-23	2545-2546	.	_	_	_	_

#Text=The cubic interpolation method performs piecewise cubic Hermite interpolation based on the values at neighboring grid points .
23-1	2547-2550	The	abstract[150]	giv[150]	coref	31-7[210_150]
23-2	2551-2556	cubic	abstract|abstract[150]	giv|giv[150]	coref	23-7
23-3	2557-2570	interpolation	abstract|abstract[150]	giv|giv[150]	coref	23-6[153_0]
23-4	2571-2577	method	abstract[150]	giv[150]	_	_
23-5	2578-2586	performs	_	_	_	_
23-6	2587-2596	piecewise	abstract[153]	giv[153]	ana	24-1[0_153]
23-7	2597-2602	cubic	abstract|abstract[153]	giv|giv[153]	coref	25-10
23-8	2603-2610	Hermite	person|abstract[153]	new|giv[153]	coref	25-11
23-9	2611-2624	interpolation	abstract[153]	giv[153]	_	_
23-10	2625-2630	based	_	_	_	_
23-11	2631-2633	on	_	_	_	_
23-12	2634-2637	the	abstract[154]	giv[154]	_	_
23-13	2638-2644	values	abstract[154]	giv[154]	_	_
23-14	2645-2647	at	abstract[154]	giv[154]	_	_
23-15	2648-2659	neighboring	abstract[154]|abstract[156]	giv[154]|new[156]	coref	24-10[160_156]
23-16	2660-2664	grid	abstract[154]|abstract|abstract[156]	giv[154]|giv|new[156]	coref	36-24[253_0]
23-17	2665-2671	points	abstract[154]|abstract[156]	giv[154]|new[156]	_	_
23-18	2672-2673	.	_	_	_	_

#Text=It seeks to match only the first-order derivatives at the data points with those in the intervals before and after .
24-1	2674-2676	It	abstract	giv	ana	24-14[161_0]
24-2	2677-2682	seeks	_	_	_	_
24-3	2683-2685	to	_	_	_	_
24-4	2686-2691	match	_	_	_	_
24-5	2692-2696	only	abstract[158]	new[158]	coref	27-24[190_158]
24-6	2697-2700	the	abstract[158]	new[158]	_	_
24-7	2701-2712	first-order	abstract[158]	new[158]	_	_
24-8	2713-2724	derivatives	abstract[158]	new[158]	_	_
24-9	2725-2727	at	abstract[158]	new[158]	_	_
24-10	2728-2731	the	abstract[158]|abstract[160]	new[158]|giv[160]	coref	25-2[164_160]
24-11	2732-2736	data	abstract[158]|abstract|abstract[160]	new[158]|new|giv[160]	coref	25-5
24-12	2737-2743	points	abstract[158]|abstract[160]	new[158]|giv[160]	_	_
24-13	2744-2748	with	_	_	_	_
24-14	2749-2754	those	abstract[161]	giv[161]	coref	26-7[174_161]
24-15	2755-2757	in	abstract[161]	giv[161]	_	_
24-16	2758-2761	the	abstract[161]|time[162]	giv[161]|new[162]	_	_
24-17	2762-2771	intervals	abstract[161]|time[162]	giv[161]|new[162]	_	_
24-18	2772-2778	before	abstract[161]	giv[161]	_	_
24-19	2779-2782	and	abstract[161]	giv[161]	_	_
24-20	2783-2788	after	abstract[161]	giv[161]	_	_
24-21	2789-2790	.	_	_	_	_

#Text=For a set of data points , , the cubic Hermite interpolant at any point , with , takes the form : ( 1 ) where
25-1	2791-2794	For	_	_	_	_
25-2	2795-2796	a	abstract[164]	giv[164]	coref	28-10[0_164]
25-3	2797-2800	set	abstract[164]	giv[164]	_	_
25-4	2801-2803	of	abstract[164]	giv[164]	_	_
25-5	2804-2808	data	abstract|abstract[164]	giv|giv[164]	coref	26-19[177_0]
25-6	2809-2815	points	abstract[164]	giv[164]	_	_
25-7	2816-2817	,	_	_	_	_
25-8	2818-2819	,	_	_	_	_
25-9	2820-2823	the	abstract[167]	new[167]	coref	28-27[199_167]
25-10	2824-2829	cubic	abstract|abstract[167]	giv|new[167]	coref	26-5[172_0]
25-11	2830-2837	Hermite	person|abstract[167]	giv|new[167]	coref	26-7
25-12	2838-2849	interpolant	abstract[167]	new[167]	_	_
25-13	2850-2852	at	abstract[167]	new[167]	_	_
25-14	2853-2856	any	abstract[167]|place[168]	new[167]|giv[168]	_	_
25-15	2857-2862	point	abstract[167]|place[168]	new[167]|giv[168]	_	_
25-16	2863-2864	,	_	_	_	_
25-17	2865-2869	with	_	_	_	_
25-18	2870-2871	,	_	_	_	_
25-19	2872-2877	takes	_	_	_	_
25-20	2878-2881	the	abstract[169]	new[169]	_	_
25-21	2882-2886	form	abstract[169]	new[169]	_	_
25-22	2887-2888	:	_	_	_	_
25-23	2889-2890	(	_	_	_	_
25-24	2891-2892	1	_	_	_	_
25-25	2893-2894	)	_	_	_	_
25-26	2895-2900	where	_	_	_	_

#Text=An instance based on piecewise cubic Hermite interpolation is shape-preserving piecewise cubic , which preserves the shape of the data since the resulting interpolated function has a continuous derivative .
26-1	2901-2903	An	abstract[170]	new[170]	_	_
26-2	2904-2912	instance	abstract[170]	new[170]	_	_
26-3	2913-2918	based	_	_	_	_
26-4	2919-2921	on	_	_	_	_
26-5	2922-2931	piecewise	abstract|abstract[172]	new|giv[172]	coref|coref|coref|coref	26-11[175_172]|27-2|26-11[175_172]|27-2
26-6	2932-2937	cubic	abstract[172]	giv[172]	_	_
26-7	2938-2945	Hermite	person|abstract[174]	giv|giv[174]	coref|coref|coref|coref	27-1[182_174]|27-14|27-1[182_174]|27-14
26-8	2946-2959	interpolation	abstract[174]	giv[174]	_	_
26-9	2960-2962	is	_	_	_	_
26-10	2963-2979	shape-preserving	_	_	_	_
26-11	2980-2989	piecewise	abstract[175]	giv[175]	coref	27-2[181_175]
26-12	2990-2995	cubic	abstract[175]	giv[175]	_	_
26-13	2996-2997	,	_	_	_	_
26-14	2998-3003	which	_	_	_	_
26-15	3004-3013	preserves	_	_	_	_
26-16	3014-3017	the	abstract[176]	new[176]	_	_
26-17	3018-3023	shape	abstract[176]	new[176]	_	_
26-18	3024-3026	of	abstract[176]	new[176]	_	_
26-19	3027-3030	the	abstract[176]|abstract[177]	new[176]|giv[177]	_	_
26-20	3031-3035	data	abstract[176]|abstract[177]	new[176]|giv[177]	_	_
26-21	3036-3041	since	_	_	_	_
26-22	3042-3045	the	abstract[178]	new[178]	_	_
26-23	3046-3055	resulting	abstract[178]	new[178]	_	_
26-24	3056-3068	interpolated	abstract[178]	new[178]	_	_
26-25	3069-3077	function	abstract[178]	new[178]	_	_
26-26	3078-3081	has	_	_	_	_
26-27	3082-3083	a	abstract[179]	new[179]	_	_
26-28	3084-3094	continuous	abstract[179]	new[179]	_	_
26-29	3095-3105	derivative	abstract[179]	new[179]	_	_
26-30	3106-3107	.	_	_	_	_

#Text=Shape-preserving piecewise cubic interpolation has a similar formula to that of piecewise cubic Hermite interpolation , but it differs in the component of the first-order derivatives .
27-1	3108-3124	Shape-preserving	abstract[182]	giv[182]	coref	27-12[187_182]
27-2	3125-3134	piecewise	abstract|abstract[181]|abstract[182]	giv|giv[181]|giv[182]	coref|coref|coref|coref	27-12|27-12[185_181]|27-12|27-12[185_181]
27-3	3135-3140	cubic	abstract[181]|abstract[182]	giv[181]|giv[182]	_	_
27-4	3141-3154	interpolation	abstract[182]	giv[182]	_	_
27-5	3155-3158	has	_	_	_	_
27-6	3159-3160	a	abstract[183]	new[183]	_	_
27-7	3161-3168	similar	abstract[183]	new[183]	_	_
27-8	3169-3176	formula	abstract[183]	new[183]	_	_
27-9	3177-3179	to	_	_	_	_
27-10	3180-3184	that	_	_	_	_
27-11	3185-3187	of	_	_	_	_
27-12	3188-3197	piecewise	abstract|abstract[185]|abstract[187]	giv|giv[185]|giv[187]	ana|ana|ana	27-18[0_187]|27-18[0_187]|27-18[0_187]
27-13	3198-3203	cubic	abstract[185]|abstract[187]	giv[185]|giv[187]	_	_
27-14	3204-3211	Hermite	person|abstract[187]	giv|giv[187]	_	_
27-15	3212-3225	interpolation	abstract[187]	giv[187]	_	_
27-16	3226-3227	,	_	_	_	_
27-17	3228-3231	but	_	_	_	_
27-18	3232-3234	it	abstract	giv	coref	28-20[197_0]
27-19	3235-3242	differs	_	_	_	_
27-20	3243-3245	in	_	_	_	_
27-21	3246-3249	the	abstract[189]	new[189]	coref	35-2[0_189]
27-22	3250-3259	component	abstract[189]	new[189]	_	_
27-23	3260-3262	of	abstract[189]	new[189]	_	_
27-24	3263-3266	the	abstract[189]|abstract[190]	new[189]|giv[190]	_	_
27-25	3267-3278	first-order	abstract[189]|abstract[190]	new[189]|giv[190]	_	_
27-26	3279-3290	derivatives	abstract[189]|abstract[190]	new[189]|giv[190]	_	_
27-27	3291-3292	.	_	_	_	_

#Text=The output vector value is a weighted average of points taken from at least the nearest four neighborhoods ; this interpolation ensures that the value of the interpolant is located within a range of local points .
28-1	3293-3296	The	abstract[193]	new[193]	coref	28-6[194_193]
28-2	3297-3303	output	abstract|abstract[193]	giv|new[193]	_	_
28-3	3304-3310	vector	abstract|abstract[193]	giv|new[193]	_	_
28-4	3311-3316	value	abstract[193]	new[193]	_	_
28-5	3317-3319	is	_	_	_	_
28-6	3320-3321	a	abstract[194]	giv[194]	coref	28-24[198_194]
28-7	3322-3330	weighted	abstract[194]	giv[194]	_	_
28-8	3331-3338	average	abstract[194]	giv[194]	_	_
28-9	3339-3341	of	abstract[194]	giv[194]	_	_
28-10	3342-3348	points	abstract[194]|abstract	giv[194]|giv	coref	28-35[200_0]
28-11	3349-3354	taken	_	_	_	_
28-12	3355-3359	from	_	_	_	_
28-13	3360-3362	at	place[196]	new[196]	_	_
28-14	3363-3368	least	place[196]	new[196]	_	_
28-15	3369-3372	the	place[196]	new[196]	_	_
28-16	3373-3380	nearest	place[196]	new[196]	_	_
28-17	3381-3385	four	place[196]	new[196]	_	_
28-18	3386-3399	neighborhoods	place[196]	new[196]	_	_
28-19	3400-3401	;	_	_	_	_
28-20	3402-3406	this	abstract[197]	giv[197]	_	_
28-21	3407-3420	interpolation	abstract[197]	giv[197]	_	_
28-22	3421-3428	ensures	_	_	_	_
28-23	3429-3433	that	_	_	_	_
28-24	3434-3437	the	abstract[198]	giv[198]	_	_
28-25	3438-3443	value	abstract[198]	giv[198]	_	_
28-26	3444-3446	of	abstract[198]	giv[198]	_	_
28-27	3447-3450	the	abstract[198]|abstract[199]	giv[198]|giv[199]	_	_
28-28	3451-3462	interpolant	abstract[198]|abstract[199]	giv[198]|giv[199]	_	_
28-29	3463-3465	is	_	_	_	_
28-30	3466-3473	located	_	_	_	_
28-31	3474-3480	within	_	_	_	_
28-32	3481-3482	a	_	_	_	_
28-33	3483-3488	range	_	_	_	_
28-34	3489-3491	of	_	_	_	_
28-35	3492-3497	local	abstract[200]	giv[200]	_	_
28-36	3498-3504	points	abstract[200]	giv[200]	_	_
28-37	3505-3506	.	_	_	_	_

#Text=3.2 .
29-1	3507-3510	3.2	abstract	new	_	_
29-2	3511-3512	.	_	_	_	_

#Text=Impulse Detection with the Deep Learning Flexible Boundary Regression Detector
30-1	3513-3520	Impulse	person|abstract[203]	new|giv[203]	_	_
30-2	3521-3530	Detection	abstract[203]	giv[203]	_	_
30-3	3531-3535	with	abstract[203]	giv[203]	_	_
30-4	3536-3539	the	abstract[203]|object[207]	giv[203]|giv[207]	coref	33-6[219_207]
30-5	3540-3544	Deep	abstract[203]|object[207]	giv[203]|giv[207]	_	_
30-6	3545-3553	Learning	abstract[203]|person|object[207]	giv[203]|new|giv[207]	_	_
30-7	3554-3562	Flexible	abstract[203]|abstract[205]|object[207]	giv[203]|giv[205]|giv[207]	_	_
30-8	3563-3571	Boundary	abstract[203]|abstract[205]|object[207]	giv[203]|giv[205]|giv[207]	_	_
30-9	3572-3582	Regression	abstract[203]|abstract|object[207]	giv[203]|new|giv[207]	_	_
30-10	3583-3591	Detector	abstract[203]|object[207]	giv[203]|giv[207]	_	_

#Text=In contrast to general CNNs , the proposed method employs a one-dimensional time-domain signal as the input data instead of two-dimensional pixels .
31-1	3592-3594	In	_	_	_	_
31-2	3595-3603	contrast	abstract[208]	new[208]	_	_
31-3	3604-3606	to	abstract[208]	new[208]	_	_
31-4	3607-3614	general	abstract[208]|object[209]	new[208]|new[209]	_	_
31-5	3615-3619	CNNs	abstract[208]|object[209]	new[208]|new[209]	_	_
31-6	3620-3621	,	_	_	_	_
31-7	3622-3625	the	abstract[210]	giv[210]	_	_
31-8	3626-3634	proposed	abstract[210]	giv[210]	_	_
31-9	3635-3641	method	abstract[210]	giv[210]	_	_
31-10	3642-3649	employs	_	_	_	_
31-11	3650-3651	a	abstract[211]	giv[211]	coref	32-1[215_211]
31-12	3652-3667	one-dimensional	abstract[211]	giv[211]	_	_
31-13	3668-3679	time-domain	abstract[211]	giv[211]	_	_
31-14	3680-3686	signal	abstract[211]	giv[211]	_	_
31-15	3687-3689	as	_	_	_	_
31-16	3690-3693	the	_	_	_	_
31-17	3694-3699	input	abstract	new	coref	36-21
31-18	3700-3704	data	_	_	_	_
31-19	3705-3712	instead	abstract[213]	new[213]	_	_
31-20	3713-3715	of	abstract[213]	new[213]	_	_
31-21	3716-3731	two-dimensional	abstract[213]	new[213]	_	_
31-22	3732-3738	pixels	abstract[213]	new[213]	_	_
31-23	3739-3740	.	_	_	_	_

#Text=The one-dimensional AE signal is fed into the first convolution layer .
32-1	3741-3744	The	abstract[215]	giv[215]	coref	33-23[226_215]
32-2	3745-3760	one-dimensional	abstract[215]	giv[215]	_	_
32-3	3761-3763	AE	abstract|abstract[215]	giv|giv[215]	_	_
32-4	3764-3770	signal	abstract[215]	giv[215]	_	_
32-5	3771-3773	is	_	_	_	_
32-6	3774-3777	fed	_	_	_	_
32-7	3778-3782	into	_	_	_	_
32-8	3783-3786	the	object[217]	new[217]	_	_
32-9	3787-3792	first	object[217]	new[217]	_	_
32-10	3793-3804	convolution	substance|object[217]	giv|new[217]	_	_
32-11	3805-3810	layer	object[217]	new[217]	_	_
32-12	3811-3812	.	_	_	_	_

#Text=To detect an object , the detector takes the feature for that object and assesses it at various locations and scales in the sample signal .
33-1	3813-3815	To	_	_	_	_
33-2	3816-3822	detect	_	_	_	_
33-3	3823-3825	an	object[218]	giv[218]	coref	33-12[221_218]
33-4	3826-3832	object	object[218]	giv[218]	_	_
33-5	3833-3834	,	_	_	_	_
33-6	3835-3838	the	object[219]	giv[219]	coref	35-1[239_219]
33-7	3839-3847	detector	object[219]	giv[219]	_	_
33-8	3848-3853	takes	_	_	_	_
33-9	3854-3857	the	abstract[220]	new[220]	ana	33-16[0_220]
33-10	3858-3865	feature	abstract[220]	new[220]	_	_
33-11	3866-3869	for	abstract[220]	new[220]	_	_
33-12	3870-3874	that	abstract[220]|object[221]	new[220]|giv[221]	coref	34-21[0_221]
33-13	3875-3881	object	abstract[220]|object[221]	new[220]|giv[221]	_	_
33-14	3882-3885	and	_	_	_	_
33-15	3886-3894	assesses	_	_	_	_
33-16	3895-3897	it	abstract	giv	_	_
33-17	3898-3900	at	_	_	_	_
33-18	3901-3908	various	place[223]	new[223]	_	_
33-19	3909-3918	locations	place[223]	new[223]	_	_
33-20	3919-3922	and	_	_	_	_
33-21	3923-3929	scales	abstract[224]	new[224]	_	_
33-22	3930-3932	in	abstract[224]	new[224]	_	_
33-23	3933-3936	the	abstract[224]|abstract[226]	new[224]|giv[226]	coref	34-3[228_226]
33-24	3937-3943	sample	abstract[224]|object|abstract[226]	new[224]|giv|giv[226]	coref	36-7
33-25	3944-3950	signal	abstract[224]|abstract[226]	new[224]|giv[226]	_	_
33-26	3951-3952	.	_	_	_	_

#Text=DLFBR observes the entire signal during the training and testing process to implicitly encode contextual information about the type of object as well as its position .
34-1	3953-3958	DLFBR	object	giv	coref	36-18
34-2	3959-3967	observes	_	_	_	_
34-3	3968-3971	the	abstract[228]	giv[228]	coref	35-19[242_228]
34-4	3972-3978	entire	abstract[228]	giv[228]	_	_
34-5	3979-3985	signal	abstract[228]	giv[228]	_	_
34-6	3986-3992	during	abstract[228]	giv[228]	_	_
34-7	3993-3996	the	abstract[228]|abstract[229]	giv[228]|new[229]	_	_
34-8	3997-4005	training	abstract[228]|abstract[229]	giv[228]|new[229]	_	_
34-9	4006-4009	and	abstract[228]	giv[228]	_	_
34-10	4010-4017	testing	abstract[228]|abstract|abstract[231]	giv[228]|new|new[231]	_	_
34-11	4018-4025	process	abstract[228]|abstract[231]	giv[228]|new[231]	_	_
34-12	4026-4028	to	_	_	_	_
34-13	4029-4039	implicitly	_	_	_	_
34-14	4040-4046	encode	_	_	_	_
34-15	4047-4057	contextual	abstract[232]	new[232]	_	_
34-16	4058-4069	information	abstract[232]	new[232]	_	_
34-17	4070-4075	about	abstract[232]	new[232]	_	_
34-18	4076-4079	the	abstract[232]|abstract[233]	new[232]|new[233]	_	_
34-19	4080-4084	type	abstract[232]|abstract[233]	new[232]|new[233]	_	_
34-20	4085-4087	of	abstract[232]|abstract[233]	new[232]|new[233]	_	_
34-21	4088-4094	object	abstract[232]|abstract[233]|object	new[232]|new[233]|giv	ana	34-25
34-22	4095-4097	as	abstract[232]	new[232]	_	_
34-23	4098-4102	well	abstract[232]	new[232]	_	_
34-24	4103-4105	as	abstract[232]	new[232]	_	_
34-25	4106-4109	its	abstract[232]|object|abstract[236]	new[232]|giv|new[236]	coref|coref|coref|coref	35-3|35-24[243_236]|35-3|35-24[243_236]
34-26	4110-4118	position	abstract[232]|abstract[236]	new[232]|new[236]	_	_
34-27	4119-4120	.	_	_	_	_

#Text=The component object detector is only unified into an end-to-end single neural network , which utilizes features from the entire signal to estimate the position for each boundary box .
35-1	4121-4124	The	object[239]	giv[239]	_	_
35-2	4125-4134	component	abstract|object[239]	giv|giv[239]	_	_
35-3	4135-4141	object	object|object[239]	giv|giv[239]	coref	37-5[256_0]
35-4	4142-4150	detector	object[239]	giv[239]	_	_
35-5	4151-4153	is	_	_	_	_
35-6	4154-4158	only	_	_	_	_
35-7	4159-4166	unified	_	_	_	_
35-8	4167-4171	into	_	_	_	_
35-9	4172-4174	an	place[240]	new[240]	coref	39-7[270_240]
35-10	4175-4185	end-to-end	place[240]	new[240]	_	_
35-11	4186-4192	single	place[240]	new[240]	_	_
35-12	4193-4199	neural	place[240]	new[240]	_	_
35-13	4200-4207	network	place[240]	new[240]	_	_
35-14	4208-4209	,	_	_	_	_
35-15	4210-4215	which	_	_	_	_
35-16	4216-4224	utilizes	_	_	_	_
35-17	4225-4233	features	abstract	new	_	_
35-18	4234-4238	from	_	_	_	_
35-19	4239-4242	the	abstract[242]	giv[242]	coref	36-5[247_242]
35-20	4243-4249	entire	abstract[242]	giv[242]	_	_
35-21	4250-4256	signal	abstract[242]	giv[242]	_	_
35-22	4257-4259	to	_	_	_	_
35-23	4260-4268	estimate	_	_	_	_
35-24	4269-4272	the	abstract[243]	giv[243]	_	_
35-25	4273-4281	position	abstract[243]	giv[243]	_	_
35-26	4282-4285	for	abstract[243]	giv[243]	_	_
35-27	4286-4290	each	abstract[243]|object[245]	giv[243]|new[245]	coref	36-10[248_245]
35-28	4291-4299	boundary	abstract[243]|place|object[245]	giv[243]|new|new[245]	_	_
35-29	4300-4303	box	abstract[243]|object[245]	giv[243]|new[245]	_	_
35-30	4304-4305	.	_	_	_	_

#Text=To reason globally about the full sample signal and all of the objects inside the signal , DLFBR divides the input signal into a grid with a grid size .
36-1	4306-4308	To	_	_	_	_
36-2	4309-4315	reason	_	_	_	_
36-3	4316-4324	globally	_	_	_	_
36-4	4325-4330	about	_	_	_	_
36-5	4331-4334	the	abstract[247]	giv[247]	coref	36-15[249_247]
36-6	4335-4339	full	abstract[247]	giv[247]	_	_
36-7	4340-4346	sample	object|abstract[247]	giv|giv[247]	_	_
36-8	4347-4353	signal	abstract[247]	giv[247]	_	_
36-9	4354-4357	and	_	_	_	_
36-10	4358-4361	all	object[248]	giv[248]	coref	38-10[264_248]
36-11	4362-4364	of	object[248]	giv[248]	_	_
36-12	4365-4368	the	object[248]	giv[248]	_	_
36-13	4369-4376	objects	object[248]	giv[248]	_	_
36-14	4377-4383	inside	object[248]	giv[248]	_	_
36-15	4384-4387	the	object[248]|abstract[249]	giv[248]|giv[249]	coref	36-20[252_249]
36-16	4388-4394	signal	object[248]|abstract[249]	giv[248]|giv[249]	_	_
36-17	4395-4396	,	_	_	_	_
36-18	4397-4402	DLFBR	organization	giv	_	_
36-19	4403-4410	divides	_	_	_	_
36-20	4411-4414	the	abstract[252]	giv[252]	_	_
36-21	4415-4420	input	abstract|abstract[252]	giv|giv[252]	_	_
36-22	4421-4427	signal	abstract[252]	giv[252]	_	_
36-23	4428-4432	into	_	_	_	_
36-24	4433-4434	a	abstract[253]	giv[253]	coref	37-12[258_253]
36-25	4435-4439	grid	abstract[253]	giv[253]	_	_
36-26	4440-4444	with	abstract[253]	giv[253]	_	_
36-27	4445-4446	a	abstract[253]|quantity[254]	giv[253]|giv[254]	_	_
36-28	4447-4451	grid	abstract[253]|quantity[254]	giv[253]|giv[254]	_	_
36-29	4452-4456	size	abstract[253]|quantity[254]	giv[253]|giv[254]	_	_
36-30	4457-4458	.	_	_	_	_

#Text=If the center of an object drops into a cell in the grid , that cell responds to detecting that object .
37-1	4459-4461	If	_	_	_	_
37-2	4462-4465	the	person[255]	new[255]	_	_
37-3	4466-4472	center	person[255]	new[255]	_	_
37-4	4473-4475	of	person[255]	new[255]	_	_
37-5	4476-4478	an	person[255]|object[256]	new[255]|giv[256]	coref	37-20[260_256]
37-6	4479-4485	object	person[255]|object[256]	new[255]|giv[256]	_	_
37-7	4486-4491	drops	_	_	_	_
37-8	4492-4496	into	_	_	_	_
37-9	4497-4498	a	object[257]	new[257]	coref	37-15[259_257]
37-10	4499-4503	cell	object[257]	new[257]	_	_
37-11	4504-4506	in	_	_	_	_
37-12	4507-4510	the	abstract[258]	giv[258]	coref	38-2[261_258]
37-13	4511-4515	grid	abstract[258]	giv[258]	_	_
37-14	4516-4517	,	_	_	_	_
37-15	4518-4522	that	object[259]	giv[259]	coref	38-6[263_259]
37-16	4523-4527	cell	object[259]	giv[259]	_	_
37-17	4528-4536	responds	_	_	_	_
37-18	4537-4539	to	_	_	_	_
37-19	4540-4549	detecting	_	_	_	_
37-20	4550-4554	that	object[260]	giv[260]	coref	39-14[272_260]
37-21	4555-4561	object	object[260]	giv[260]	_	_
37-22	4562-4563	.	_	_	_	_

#Text=From the generated grid , each grid cell regresses the encircled box and the confidence score for each box .
38-1	4564-4568	From	_	_	_	_
38-2	4569-4572	the	abstract[261]	giv[261]	coref	38-7[0_261]
38-3	4573-4582	generated	abstract[261]	giv[261]	_	_
38-4	4583-4587	grid	abstract[261]	giv[261]	_	_
38-5	4588-4589	,	_	_	_	_
38-6	4590-4594	each	object[263]	giv[263]	_	_
38-7	4595-4599	grid	abstract|object[263]	giv|giv[263]	_	_
38-8	4600-4604	cell	object[263]	giv[263]	_	_
38-9	4605-4614	regresses	_	_	_	_
38-10	4615-4618	the	object[264]	giv[264]	coref	38-18[267_264]
38-11	4619-4628	encircled	object[264]	giv[264]	_	_
38-12	4629-4632	box	object[264]	giv[264]	_	_
38-13	4633-4636	and	_	_	_	_
38-14	4637-4640	the	abstract[266]	new[266]	_	_
38-15	4641-4651	confidence	abstract|abstract[266]	new|new[266]	coref	39-2
38-16	4652-4657	score	abstract[266]	new[266]	_	_
38-17	4658-4661	for	abstract[266]	new[266]	_	_
38-18	4662-4666	each	abstract[266]|object[267]	new[266]|giv[267]	coref	39-11[271_267]
38-19	4667-4670	box	abstract[266]|object[267]	new[266]|giv[267]	_	_
38-20	4671-4672	.	_	_	_	_

#Text=These confidence scores represent how confident the network is that the box contains an object , as well as how accurate the network thinks the predicted box is .
39-1	4673-4678	These	abstract[269]	new[269]	_	_
39-2	4679-4689	confidence	abstract|abstract[269]	giv|new[269]	coref	40-1[275_0]
39-3	4690-4696	scores	abstract[269]	new[269]	_	_
39-4	4697-4706	represent	_	_	_	_
39-5	4707-4710	how	_	_	_	_
39-6	4711-4720	confident	_	_	_	_
39-7	4721-4724	the	place[270]	giv[270]	coref	39-22[273_270]
39-8	4725-4732	network	place[270]	giv[270]	_	_
39-9	4733-4735	is	_	_	_	_
39-10	4736-4740	that	_	_	_	_
39-11	4741-4744	the	object[271]	giv[271]	coref	39-25[274_271]
39-12	4745-4748	box	object[271]	giv[271]	_	_
39-13	4749-4757	contains	_	_	_	_
39-14	4758-4760	an	object[272]	giv[272]	_	_
39-15	4761-4767	object	object[272]	giv[272]	_	_
39-16	4768-4769	,	_	_	_	_
39-17	4770-4772	as	_	_	_	_
39-18	4773-4777	well	_	_	_	_
39-19	4778-4780	as	_	_	_	_
39-20	4781-4784	how	_	_	_	_
39-21	4785-4793	accurate	_	_	_	_
39-22	4794-4797	the	place[273]	giv[273]	_	_
39-23	4798-4805	network	place[273]	giv[273]	_	_
39-24	4806-4812	thinks	_	_	_	_
39-25	4813-4816	the	object[274]	giv[274]	_	_
39-26	4817-4826	predicted	object[274]	giv[274]	_	_
39-27	4827-4830	box	object[274]	giv[274]	_	_
39-28	4831-4833	is	_	_	_	_
39-29	4834-4835	.	_	_	_	_

#Text=The confidence is specified as ( 2 )
40-1	4836-4839	The	abstract[275]	giv[275]	_	_
40-2	4840-4850	confidence	abstract[275]	giv[275]	_	_
40-3	4851-4853	is	_	_	_	_
40-4	4854-4863	specified	_	_	_	_
40-5	4864-4866	as	_	_	_	_
40-6	4867-4868	(	_	_	_	_
40-7	4869-4870	2	_	_	_	_
40-8	4871-4872	)	_	_	_	_
