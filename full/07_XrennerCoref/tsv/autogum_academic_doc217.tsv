#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=2 .
1-1	0-1	2	quantity	new	_	_
1-2	2-3	.	_	_	_	_

#Text=Related Works
2-1	4-11	Related	object[2]	new[2]	coref	3-14[8_2]
2-2	12-17	Works	object[2]	new[2]	_	_

#Text=In this section , we put our focus on the relevant introduction of the two mainstream camera-based works , i. e. , appearance-based methods and model-based methods .
3-1	18-20	In	_	_	_	_
3-2	21-25	this	abstract[3]	new[3]	_	_
3-3	26-33	section	abstract[3]	new[3]	_	_
3-4	34-35	,	_	_	_	_
3-5	36-38	we	person	acc	ana	3-7
3-6	39-42	put	_	_	_	_
3-7	43-46	our	person|abstract[6]	giv|new[6]	ana|ana	4-1|4-1
3-8	47-52	focus	abstract[6]	new[6]	_	_
3-9	53-55	on	_	_	_	_
3-10	56-59	the	abstract[7]	new[7]	_	_
3-11	60-68	relevant	abstract[7]	new[7]	_	_
3-12	69-81	introduction	abstract[7]	new[7]	_	_
3-13	82-84	of	abstract[7]	new[7]	_	_
3-14	85-88	the	abstract[7]|object[8]	new[7]|giv[8]	coref	5-11[22_8]
3-15	89-92	two	abstract[7]|object[8]	new[7]|giv[8]	_	_
3-16	93-103	mainstream	abstract[7]|object[8]	new[7]|giv[8]	_	_
3-17	104-116	camera-based	abstract[7]|object[8]	new[7]|giv[8]	_	_
3-18	117-122	works	abstract[7]|object[8]	new[7]|giv[8]	_	_
3-19	123-124	,	abstract[7]	new[7]	_	_
3-20	125-127	i.	abstract[7]	new[7]	_	_
3-21	128-130	e.	abstract[7]	new[7]	_	_
3-22	131-132	,	abstract[7]	new[7]	_	_
3-23	133-149	appearance-based	abstract[7]|abstract[9]	new[7]|new[9]	_	_
3-24	150-157	methods	abstract[7]|abstract[9]	new[7]|new[9]	_	_
3-25	158-161	and	abstract[7]	new[7]	_	_
3-26	162-173	model-based	abstract[7]|abstract[10]	new[7]|new[10]	coref	4-5[12_10]
3-27	174-181	methods	abstract[7]|abstract[10]	new[7]|new[10]	_	_
3-28	182-183	.	_	_	_	_

#Text=We also briefly introduce some multi-model methods . Dipietro et al. have done elaborate research for all kinds of data gloves and relevant applications .
4-1	184-186	We	person	giv	ana	5-1
4-2	187-191	also	_	_	_	_
4-3	192-199	briefly	_	_	_	_
4-4	200-209	introduce	_	_	_	_
4-5	210-214	some	abstract[12]	giv[12]	coref	7-1[24_12]
4-6	215-226	multi-model	abstract[12]	giv[12]	_	_
4-7	227-234	methods	abstract[12]	giv[12]	_	_
4-8	235-236	.	_	_	_	_
4-9	237-245	Dipietro	person	new	_	_
4-10	246-248	et	_	_	_	_
4-11	249-252	al.	_	_	_	_
4-12	253-257	have	_	_	_	_
4-13	258-262	done	_	_	_	_
4-14	263-272	elaborate	abstract[14]	new[14]	_	_
4-15	273-281	research	abstract[14]	new[14]	_	_
4-16	282-285	for	_	_	_	_
4-17	286-289	all	abstract[15]	new[15]	_	_
4-18	290-295	kinds	abstract[15]	new[15]	_	_
4-19	296-298	of	abstract[15]	new[15]	_	_
4-20	299-303	data	abstract[15]|abstract|object[17]	new[15]|new|new[17]	_	_
4-21	304-310	gloves	abstract[15]|object[17]	new[15]|new[17]	_	_
4-22	311-314	and	abstract[15]	new[15]	_	_
4-23	315-323	relevant	abstract[15]|abstract[18]	new[15]|new[18]	_	_
4-24	324-336	applications	abstract[15]|abstract[18]	new[15]|new[18]	_	_
4-25	337-338	.	_	_	_	_

#Text=We refer the readers to for a detailed review of glove-based works .
5-1	339-341	We	person	giv	ana	12-15
5-2	342-347	refer	_	_	_	_
5-3	348-351	the	person[20]	new[20]	coref	12-17[61_20]
5-4	352-359	readers	person[20]	new[20]	_	_
5-5	360-362	to	_	_	_	_
5-6	363-366	for	_	_	_	_
5-7	367-368	a	abstract[21]	new[21]	_	_
5-8	369-377	detailed	abstract[21]	new[21]	_	_
5-9	378-384	review	abstract[21]	new[21]	_	_
5-10	385-387	of	abstract[21]	new[21]	_	_
5-11	388-399	glove-based	abstract[21]|object[22]	new[21]|giv[22]	coref	9-11[35_22]
5-12	400-405	works	abstract[21]|object[22]	new[21]|giv[22]	_	_
5-13	406-407	.	_	_	_	_

#Text=2.1 .
6-1	408-411	2.1	abstract	new	_	_
6-2	412-413	.	_	_	_	_

#Text=Appearance-Based Methods
7-1	414-430	Appearance-Based	abstract[24]	giv[24]	coref	8-1[25_24]
7-2	431-438	Methods	abstract[24]	giv[24]	_	_

#Text=Appearance-based methods train a classifier or a regressor to map image features to hand poses .
8-1	439-455	Appearance-based	abstract[25]	giv[25]	coref	10-9[38_25]
8-2	456-463	methods	abstract[25]	giv[25]	_	_
8-3	464-469	train	_	_	_	_
8-4	470-471	a	abstract[26]	new[26]	coref	28-42[139_26]
8-5	472-482	classifier	abstract[26]	new[26]	_	_
8-6	483-485	or	_	_	_	_
8-7	486-487	a	abstract[27]	new[27]	_	_
8-8	488-497	regressor	abstract[27]	new[27]	_	_
8-9	498-500	to	abstract[27]	new[27]	_	_
8-10	501-504	map	abstract[27]	new[27]	_	_
8-11	505-510	image	object	new	coref	28-15
8-12	511-519	features	_	_	_	_
8-13	520-522	to	_	_	_	_
8-14	523-527	hand	object|abstract[30]	new|new[30]	coref|coref	11-23|11-23
8-15	528-533	poses	abstract[30]	new[30]	_	_
8-16	534-535	.	_	_	_	_

#Text=Nearest neighbor search and decision trees are widely used in early works .
9-1	536-543	Nearest	abstract[32]	new[32]	_	_
9-2	544-552	neighbor	person|abstract[32]	new|new[32]	_	_
9-3	553-559	search	abstract[32]	new[32]	_	_
9-4	560-563	and	_	_	_	_
9-5	564-572	decision	abstract|object[34]	new|new[34]	coref|coref	28-40[138_0]|28-40[138_0]
9-6	573-578	trees	object[34]	new[34]	_	_
9-7	579-582	are	_	_	_	_
9-8	583-589	widely	_	_	_	_
9-9	590-594	used	_	_	_	_
9-10	595-597	in	_	_	_	_
9-11	598-603	early	object[35]	giv[35]	coref	25-1[114_35]
9-12	604-609	works	object[35]	giv[35]	_	_
9-13	610-611	.	_	_	_	_

#Text=In recent years , convolutional neural network ( CNN)-based discriminative methods are state-of-the-art which estimate 3D joint positions directly from depth images .
10-1	612-614	In	_	_	_	_
10-2	615-621	recent	time[36]	new[36]	_	_
10-3	622-627	years	time[36]	new[36]	_	_
10-4	628-629	,	_	_	_	_
10-5	630-643	convolutional	abstract[37]	new[37]	coref	28-60[145_37]
10-6	644-650	neural	abstract[37]	new[37]	_	_
10-7	651-658	network	abstract[37]	new[37]	_	_
10-8	659-660	(	_	_	_	_
10-9	661-671	CNN)-based	abstract[38]	giv[38]	coref	13-5[63_38]
10-10	672-686	discriminative	abstract[38]	giv[38]	_	_
10-11	687-694	methods	abstract[38]	giv[38]	_	_
10-12	695-698	are	_	_	_	_
10-13	699-715	state-of-the-art	_	_	_	_
10-14	716-721	which	_	_	_	_
10-15	722-730	estimate	_	_	_	_
10-16	731-733	3D	person|abstract[40]	new|new[40]	coref|coref|coref|coref	11-33[53_40]|20-31|11-33[53_40]|20-31
10-17	734-739	joint	abstract[40]	new[40]	_	_
10-18	740-749	positions	abstract[40]	new[40]	_	_
10-19	750-758	directly	object[42]	new[42]	coref	28-70[0_42]
10-20	759-763	from	object[42]	new[42]	_	_
10-21	764-769	depth	abstract|object[42]	new|new[42]	_	_
10-22	770-776	images	object[42]	new[42]	_	_
10-23	777-778	.	_	_	_	_

#Text=Besides , kinematics and geometric constraints are considered to avoid joint estimations violating kinematic constraints . Malik et al. embedded a novel hand pose and shape layer inside CNN to produce not only 3D joint positions but also hand mesh information .
11-1	779-786	Besides	_	_	_	_
11-2	787-788	,	_	_	_	_
11-3	789-799	kinematics	abstract|abstract[44]	new|new[44]	coref|coref|coref|coref	19-16[86_0]|19-16[87_44]|19-16[86_0]|19-16[87_44]
11-4	800-803	and	abstract[44]	new[44]	_	_
11-5	804-813	geometric	abstract[44]|abstract[45]	new[44]|new[45]	coref	11-14[47_45]
11-6	814-825	constraints	abstract[44]|abstract[45]	new[44]|new[45]	_	_
11-7	826-829	are	_	_	_	_
11-8	830-840	considered	_	_	_	_
11-9	841-843	to	_	_	_	_
11-10	844-849	avoid	_	_	_	_
11-11	850-855	joint	abstract[46]	new[46]	_	_
11-12	856-867	estimations	abstract[46]	new[46]	_	_
11-13	868-877	violating	_	_	_	_
11-14	878-887	kinematic	abstract[47]	giv[47]	_	_
11-15	888-899	constraints	abstract[47]	giv[47]	_	_
11-16	900-901	.	_	_	_	_
11-17	902-907	Malik	person	new	_	_
11-18	908-910	et	_	_	_	_
11-19	911-914	al.	_	_	_	_
11-20	915-923	embedded	_	_	_	_
11-21	924-925	a	abstract[50]	new[50]	coref	28-53[0_50]
11-22	926-931	novel	abstract[50]	new[50]	_	_
11-23	932-936	hand	object|abstract[50]	giv|new[50]	coref	11-39
11-24	937-941	pose	abstract[50]	new[50]	_	_
11-25	942-945	and	_	_	_	_
11-26	946-951	shape	_	_	_	_
11-27	952-957	layer	abstract	new	_	_
11-28	958-964	inside	_	_	_	_
11-29	965-968	CNN	object	new	_	_
11-30	969-971	to	_	_	_	_
11-31	972-979	produce	_	_	_	_
11-32	980-983	not	_	_	_	_
11-33	984-988	only	abstract[53]	giv[53]	_	_
11-34	989-991	3D	abstract[53]	giv[53]	_	_
11-35	992-997	joint	abstract[53]	giv[53]	_	_
11-36	998-1007	positions	abstract[53]	giv[53]	_	_
11-37	1008-1011	but	abstract[53]	giv[53]	_	_
11-38	1012-1016	also	abstract[53]	giv[53]	_	_
11-39	1017-1021	hand	abstract[53]|object|abstract[56]	giv[53]|giv|new[56]	coref|coref	14-13|14-13
11-40	1022-1026	mesh	abstract[53]|abstract|abstract[56]	giv[53]|new|new[56]	_	_
11-41	1027-1038	information	abstract[53]|abstract[56]	giv[53]|new[56]	_	_
11-42	1039-1040	.	_	_	_	_

#Text=For a more comprehensive analysis and investigation of the state-of-the-art along-with future challenges , we refer the readers to .
12-1	1041-1044	For	_	_	_	_
12-2	1045-1046	a	abstract[57]	new[57]	coref	15-5[70_57]
12-3	1047-1051	more	abstract[57]	new[57]	_	_
12-4	1052-1065	comprehensive	abstract[57]	new[57]	_	_
12-5	1066-1074	analysis	abstract[57]	new[57]	_	_
12-6	1075-1078	and	_	_	_	_
12-7	1079-1092	investigation	abstract[58]	new[58]	_	_
12-8	1093-1095	of	abstract[58]	new[58]	_	_
12-9	1096-1099	the	abstract[58]|abstract[59]	new[58]|new[59]	_	_
12-10	1100-1116	state-of-the-art	abstract[58]|abstract[59]	new[58]|new[59]	_	_
12-11	1117-1127	along-with	abstract[58]|abstract[59]	new[58]|new[59]	_	_
12-12	1128-1134	future	abstract[58]|abstract[59]	new[58]|new[59]	_	_
12-13	1135-1145	challenges	abstract[58]|abstract[59]	new[58]|new[59]	_	_
12-14	1146-1147	,	_	_	_	_
12-15	1148-1150	we	person	giv	ana	15-1
12-16	1151-1156	refer	_	_	_	_
12-17	1157-1160	the	person[61]	giv[61]	_	_
12-18	1161-1168	readers	person[61]	giv[61]	_	_
12-19	1169-1171	to	_	_	_	_
12-20	1172-1173	.	_	_	_	_

#Text=The biggest limitation of appearance-based methods is the training data .
13-1	1174-1177	The	abstract[62]	new[62]	coref	13-8[65_62]
13-2	1178-1185	biggest	abstract[62]	new[62]	_	_
13-3	1186-1196	limitation	abstract[62]	new[62]	_	_
13-4	1197-1199	of	abstract[62]	new[62]	_	_
13-5	1200-1216	appearance-based	abstract[62]|abstract[63]	new[62]|giv[63]	coref	18-1[79_63]
13-6	1217-1224	methods	abstract[62]|abstract[63]	new[62]|giv[63]	_	_
13-7	1225-1227	is	_	_	_	_
13-8	1228-1231	the	abstract[65]	giv[65]	coref	16-2[73_65]
13-9	1232-1240	training	abstract|abstract[65]	new|giv[65]	coref	28-47
13-10	1241-1245	data	abstract[65]	giv[65]	_	_
13-11	1246-1247	.	_	_	_	_

#Text=Existing benchmarks are not perfect enough to ensure well generalize to unseen hand shapes .
14-1	1248-1256	Existing	_	_	_	_
14-2	1257-1267	benchmarks	abstract	new	_	_
14-3	1268-1271	are	_	_	_	_
14-4	1272-1275	not	_	_	_	_
14-5	1276-1283	perfect	_	_	_	_
14-6	1284-1290	enough	_	_	_	_
14-7	1291-1293	to	_	_	_	_
14-8	1294-1300	ensure	_	_	_	_
14-9	1301-1305	well	_	_	_	_
14-10	1306-1316	generalize	_	_	_	_
14-11	1317-1319	to	_	_	_	_
14-12	1320-1326	unseen	abstract[68]	new[68]	_	_
14-13	1327-1331	hand	object|abstract[68]	giv|new[68]	coref	19-7
14-14	1332-1338	shapes	abstract[68]	new[68]	_	_
14-15	1339-1340	.	_	_	_	_

#Text=We refer to for a detailed analysis of the drawbacks of existing data-sets .
15-1	1341-1343	We	person	giv	ana	16-5
15-2	1344-1349	refer	_	_	_	_
15-3	1350-1352	to	_	_	_	_
15-4	1353-1356	for	_	_	_	_
15-5	1357-1358	a	abstract[70]	giv[70]	_	_
15-6	1359-1367	detailed	abstract[70]	giv[70]	_	_
15-7	1368-1376	analysis	abstract[70]	giv[70]	_	_
15-8	1377-1379	of	abstract[70]	giv[70]	_	_
15-9	1380-1383	the	abstract[70]|abstract[71]	giv[70]|new[71]	_	_
15-10	1384-1393	drawbacks	abstract[70]|abstract[71]	giv[70]|new[71]	_	_
15-11	1394-1396	of	abstract[70]|abstract[71]	giv[70]|new[71]	_	_
15-12	1397-1405	existing	abstract[70]|abstract[71]|abstract[72]	giv[70]|new[71]|new[72]	coref	16-16[77_72]
15-13	1406-1415	data-sets	abstract[70]|abstract[71]|abstract[72]	giv[70]|new[71]|new[72]	_	_
15-14	1416-1417	.	_	_	_	_

#Text=Considering this limitation , our system follows the model-based approaches that do not rely on massive data-sets .
16-1	1418-1429	Considering	_	_	_	_
16-2	1430-1434	this	abstract[73]	giv[73]	coref	19-28[0_73]
16-3	1435-1445	limitation	abstract[73]	giv[73]	_	_
16-4	1446-1447	,	_	_	_	_
16-5	1448-1451	our	person|abstract[75]	giv|new[75]	ana|coref|ana|coref	30-2|30-2[161_75]|30-2|30-2[161_75]
16-6	1452-1458	system	abstract[75]	new[75]	_	_
16-7	1459-1466	follows	_	_	_	_
16-8	1467-1470	the	abstract[76]	new[76]	_	_
16-9	1471-1482	model-based	abstract[76]	new[76]	_	_
16-10	1483-1493	approaches	abstract[76]	new[76]	_	_
16-11	1494-1498	that	_	_	_	_
16-12	1499-1501	do	_	_	_	_
16-13	1502-1505	not	_	_	_	_
16-14	1506-1510	rely	_	_	_	_
16-15	1511-1513	on	_	_	_	_
16-16	1514-1521	massive	abstract[77]	giv[77]	coref	29-9[157_77]
16-17	1522-1531	data-sets	abstract[77]	giv[77]	_	_
16-18	1532-1533	.	_	_	_	_

#Text=2.2 .
17-1	1534-1537	2.2	abstract	new	_	_
17-2	1538-1539	.	_	_	_	_

#Text=Model-Based Methods
18-1	1540-1551	Model-Based	abstract[79]	giv[79]	coref	20-6[95_79]
18-2	1552-1559	Methods	abstract[79]	giv[79]	_	_

#Text=Despite the considerable advance in learning-based hand tracking , systems that employ generative models of explicit hand kinematics and surface geometry and fit these models to depth data using local optimization have produced the most compelling results .
19-1	1560-1567	Despite	_	_	_	_
19-2	1568-1571	the	abstract[80]	new[80]	_	_
19-3	1572-1584	considerable	abstract[80]	new[80]	_	_
19-4	1585-1592	advance	abstract[80]	new[80]	_	_
19-5	1593-1595	in	abstract[80]	new[80]	_	_
19-6	1596-1610	learning-based	abstract[80]|event[82]	new[80]|new[82]	_	_
19-7	1611-1615	hand	abstract[80]|object|event[82]	new[80]|giv|new[82]	coref	19-17
19-8	1616-1624	tracking	abstract[80]|event[82]	new[80]|new[82]	_	_
19-9	1625-1626	,	_	_	_	_
19-10	1627-1634	systems	abstract	new	_	_
19-11	1635-1639	that	_	_	_	_
19-12	1640-1646	employ	_	_	_	_
19-13	1647-1657	generative	abstract[84]	new[84]	coref	19-24[90_84]
19-14	1658-1664	models	abstract[84]	new[84]	_	_
19-15	1665-1667	of	abstract[84]	new[84]	_	_
19-16	1668-1676	explicit	abstract[84]|abstract[86]|abstract[87]	new[84]|giv[86]|giv[87]	_	_
19-17	1677-1681	hand	abstract[84]|object|abstract[86]|abstract[87]	new[84]|giv|giv[86]|giv[87]	coref	20-18
19-18	1682-1692	kinematics	abstract[84]|abstract[86]|abstract[87]	new[84]|giv[86]|giv[87]	_	_
19-19	1693-1696	and	abstract[84]|abstract[87]	new[84]|giv[87]	_	_
19-20	1697-1704	surface	abstract[84]|abstract[87]|place|abstract[89]	new[84]|giv[87]|new|new[89]	_	_
19-21	1705-1713	geometry	abstract[84]|abstract[87]|abstract[89]	new[84]|giv[87]|new[89]	_	_
19-22	1714-1717	and	_	_	_	_
19-23	1718-1721	fit	_	_	_	_
19-24	1722-1727	these	abstract[90]	giv[90]	coref	35-1[182_90]
19-25	1728-1734	models	abstract[90]	giv[90]	_	_
19-26	1735-1737	to	_	_	_	_
19-27	1738-1743	depth	_	_	_	_
19-28	1744-1748	data	abstract	giv	coref	20-35[106_0]
19-29	1749-1754	using	_	_	_	_
19-30	1755-1760	local	abstract[92]	new[92]	_	_
19-31	1761-1773	optimization	abstract[92]	new[92]	_	_
19-32	1774-1778	have	_	_	_	_
19-33	1779-1787	produced	_	_	_	_
19-34	1788-1791	the	abstract[93]	new[93]	coref	33-15[175_93]
19-35	1792-1796	most	abstract[93]	new[93]	_	_
19-36	1797-1807	compelling	abstract[93]	new[93]	_	_
19-37	1808-1815	results	abstract[93]	new[93]	_	_
19-38	1816-1817	.	_	_	_	_

#Text=The most common problems for model-based methods are a good enough initialization point , an expressive enough hand model and a discriminative object function that minimizes the error between the 3D hand model and the observed data .
20-1	1818-1821	The	abstract[94]	new[94]	coref	20-9[97_94]
20-2	1822-1826	most	abstract[94]	new[94]	_	_
20-3	1827-1833	common	abstract[94]	new[94]	_	_
20-4	1834-1842	problems	abstract[94]	new[94]	_	_
20-5	1843-1846	for	abstract[94]	new[94]	_	_
20-6	1847-1858	model-based	abstract[94]|abstract[95]	new[94]|giv[95]	coref	24-3[113_95]
20-7	1859-1866	methods	abstract[94]|abstract[95]	new[94]|giv[95]	_	_
20-8	1867-1870	are	_	_	_	_
20-9	1871-1872	a	abstract[97]	giv[97]	_	_
20-10	1873-1877	good	abstract[97]	giv[97]	_	_
20-11	1878-1884	enough	abstract[97]	giv[97]	_	_
20-12	1885-1899	initialization	abstract|abstract[97]	new|giv[97]	coref	22-1
20-13	1900-1905	point	abstract[97]	giv[97]	_	_
20-14	1906-1907	,	abstract[97]	giv[97]	_	_
20-15	1908-1910	an	abstract[97]|abstract[99]	giv[97]|new[99]	coref	20-30[105_99]
20-16	1911-1921	expressive	abstract[97]|abstract[99]	giv[97]|new[99]	_	_
20-17	1922-1928	enough	abstract[97]|abstract[99]	giv[97]|new[99]	_	_
20-18	1929-1933	hand	abstract[97]|object|abstract[99]	giv[97]|giv|new[99]	coref	20-32
20-19	1934-1939	model	abstract[97]|abstract[99]	giv[97]|new[99]	_	_
20-20	1940-1943	and	abstract[97]	giv[97]	_	_
20-21	1944-1945	a	abstract[97]|abstract[101]	giv[97]|new[101]	_	_
20-22	1946-1960	discriminative	abstract[97]|abstract[101]	giv[97]|new[101]	_	_
20-23	1961-1967	object	abstract[97]|object|abstract[101]	giv[97]|new|new[101]	_	_
20-24	1968-1976	function	abstract[97]|abstract[101]	giv[97]|new[101]	_	_
20-25	1977-1981	that	_	_	_	_
20-26	1982-1991	minimizes	_	_	_	_
20-27	1992-1995	the	abstract[102]	new[102]	_	_
20-28	1996-2001	error	abstract[102]	new[102]	_	_
20-29	2002-2009	between	abstract[102]	new[102]	_	_
20-30	2010-2013	the	abstract[102]|abstract[105]	new[102]|giv[105]	coref	28-83[153_105]
20-31	2014-2016	3D	abstract[102]|object|abstract[105]	new[102]|giv|giv[105]	coref	38-58
20-32	2017-2021	hand	abstract[102]|object|abstract[105]	new[102]|giv|giv[105]	coref	27-21
20-33	2022-2027	model	abstract[102]|abstract[105]	new[102]|giv[105]	_	_
20-34	2028-2031	and	abstract[102]	new[102]	_	_
20-35	2032-2035	the	abstract[102]|abstract[106]	new[102]|giv[106]	coref	28-13[131_106]
20-36	2036-2044	observed	abstract[102]|abstract[106]	new[102]|giv[106]	_	_
20-37	2045-2049	data	abstract[102]|abstract[106]	new[102]|giv[106]	_	_
20-38	2050-2051	.	_	_	_	_

#Text=2.2.1 .
21-1	2052-2057	2.2.1	abstract	new	_	_
21-2	2058-2059	.	_	_	_	_

#Text=Initialization
22-1	2060-2074	Initialization	abstract	giv	coref	23-1[109_0]

#Text=A good enough Initialization has been proven critical to the robustness , which enables faster converge and better resistant to local optima .
23-1	2075-2076	A	abstract[109]	giv[109]	coref	24-4[0_109]
23-2	2077-2081	good	abstract[109]	giv[109]	_	_
23-3	2082-2088	enough	abstract[109]	giv[109]	_	_
23-4	2089-2103	Initialization	abstract[109]	giv[109]	_	_
23-5	2104-2107	has	_	_	_	_
23-6	2108-2112	been	_	_	_	_
23-7	2113-2119	proven	_	_	_	_
23-8	2120-2128	critical	_	_	_	_
23-9	2129-2131	to	_	_	_	_
23-10	2132-2135	the	abstract[110]	new[110]	_	_
23-11	2136-2146	robustness	abstract[110]	new[110]	_	_
23-12	2147-2148	,	_	_	_	_
23-13	2149-2154	which	_	_	_	_
23-14	2155-2162	enables	_	_	_	_
23-15	2163-2169	faster	_	_	_	_
23-16	2170-2178	converge	_	_	_	_
23-17	2179-2182	and	_	_	_	_
23-18	2183-2189	better	_	_	_	_
23-19	2190-2199	resistant	_	_	_	_
23-20	2200-2202	to	_	_	_	_
23-21	2203-2208	local	abstract[111]	new[111]	_	_
23-22	2209-2215	optima	abstract[111]	new[111]	_	_
23-23	2216-2217	.	_	_	_	_

#Text=There exist many initialization methods .
24-1	2218-2223	There	_	_	_	_
24-2	2224-2229	exist	_	_	_	_
24-3	2230-2234	many	abstract[113]	giv[113]	coref	28-18[132_113]
24-4	2235-2249	initialization	abstract|abstract[113]	giv|giv[113]	coref	27-8
24-5	2250-2257	methods	abstract[113]	giv[113]	_	_
24-6	2258-2259	.	_	_	_	_

#Text=Some works were initialized by the fingertip detection .
25-1	2260-2264	Some	object[114]	giv[114]	coref	38-1[184_114]
25-2	2265-2270	works	object[114]	giv[114]	_	_
25-3	2271-2275	were	_	_	_	_
25-4	2276-2287	initialized	_	_	_	_
25-5	2288-2290	by	_	_	_	_
25-6	2291-2294	the	abstract[116]	new[116]	_	_
25-7	2295-2304	fingertip	abstract|abstract[116]	new|new[116]	_	_
25-8	2305-2314	detection	abstract[116]	new[116]	_	_
25-9	2315-2316	.	_	_	_	_

#Text=Besides , Tagliasacchi et al. and Tkach et al. also detected a color wristband as a first alignment .
26-1	2317-2324	Besides	_	_	_	_
26-2	2325-2326	,	_	_	_	_
26-3	2327-2339	Tagliasacchi	person	new	_	_
26-4	2340-2342	et	_	_	_	_
26-5	2343-2346	al.	_	_	_	_
26-6	2347-2350	and	_	_	_	_
26-7	2351-2356	Tkach	person	new	coref	40-11
26-8	2357-2359	et	_	_	_	_
26-9	2360-2363	al.	_	_	_	_
26-10	2364-2368	also	_	_	_	_
26-11	2369-2377	detected	_	_	_	_
26-12	2378-2379	a	object[120]	new[120]	_	_
26-13	2380-2385	color	abstract|object[120]	new|new[120]	_	_
26-14	2386-2395	wristband	object[120]	new[120]	_	_
26-15	2396-2398	as	_	_	_	_
26-16	2399-2400	a	_	_	_	_
26-17	2401-2406	first	_	_	_	_
26-18	2407-2416	alignment	_	_	_	_
26-19	2417-2418	.	_	_	_	_

#Text=The use of simple geometric heuristics for initialization can sometimes be impractical for those gestures which contain occlusions or difficult hand orientations .
27-1	2419-2422	The	abstract[121]	new[121]	_	_
27-2	2423-2426	use	abstract[121]	new[121]	_	_
27-3	2427-2429	of	abstract[121]	new[121]	_	_
27-4	2430-2436	simple	abstract[121]|abstract[122]	new[121]|new[122]	_	_
27-5	2437-2446	geometric	abstract[121]|abstract[122]	new[121]|new[122]	_	_
27-6	2447-2457	heuristics	abstract[121]|abstract[122]	new[121]|new[122]	_	_
27-7	2458-2461	for	abstract[121]|abstract[122]	new[121]|new[122]	_	_
27-8	2462-2476	initialization	abstract[121]|abstract[122]|abstract	new[121]|new[122]|giv	coref	28-65[146_0]
27-9	2477-2480	can	_	_	_	_
27-10	2481-2490	sometimes	_	_	_	_
27-11	2491-2493	be	_	_	_	_
27-12	2494-2505	impractical	_	_	_	_
27-13	2506-2509	for	_	_	_	_
27-14	2510-2515	those	abstract[124]	new[124]	_	_
27-15	2516-2524	gestures	abstract[124]	new[124]	_	_
27-16	2525-2530	which	_	_	_	_
27-17	2531-2538	contain	_	_	_	_
27-18	2539-2549	occlusions	abstract	new	_	_
27-19	2550-2552	or	_	_	_	_
27-20	2553-2562	difficult	abstract[127]	new[127]	_	_
27-21	2563-2567	hand	object|abstract[127]	giv|new[127]	coref	28-26[135_0]
27-22	2568-2580	orientations	abstract[127]	new[127]	_	_
27-23	2581-2582	.	_	_	_	_

#Text=For this reason , most of the previous studies concentrated on exploiting the given image data with the train-based methods . Taylor et al. generated candidate ’s hand poses quickly by a retrieval forest . Taylor et al. trained a decision forest classifier on a synthetic training set to generate an initial pose estimate . Sanchez-Riera et al. trained a convolutional neural network for initialization with 243,000 tuples of images . Sharp et al. inferred a hierarchical distribution over hand pose with a layered discriminative model .
28-1	2583-2586	For	_	_	_	_
28-2	2587-2591	this	abstract[128]	new[128]	_	_
28-3	2592-2598	reason	abstract[128]	new[128]	_	_
28-4	2599-2600	,	_	_	_	_
28-5	2601-2605	most	abstract[129]	new[129]	_	_
28-6	2606-2608	of	abstract[129]	new[129]	_	_
28-7	2609-2612	the	abstract[129]	new[129]	_	_
28-8	2613-2621	previous	abstract[129]	new[129]	_	_
28-9	2622-2629	studies	abstract[129]	new[129]	_	_
28-10	2630-2642	concentrated	_	_	_	_
28-11	2643-2645	on	_	_	_	_
28-12	2646-2656	exploiting	_	_	_	_
28-13	2657-2660	the	abstract[131]	giv[131]	coref	30-19[0_131]
28-14	2661-2666	given	abstract[131]	giv[131]	_	_
28-15	2667-2672	image	abstract|abstract[131]	giv|giv[131]	coref	41-21
28-16	2673-2677	data	abstract[131]	giv[131]	_	_
28-17	2678-2682	with	abstract[131]	giv[131]	_	_
28-18	2683-2686	the	abstract[131]|abstract[132]	giv[131]|giv[132]	_	_
28-19	2687-2698	train-based	abstract[131]|abstract[132]	giv[131]|giv[132]	_	_
28-20	2699-2706	methods	abstract[131]|abstract[132]	giv[131]|giv[132]	_	_
28-21	2707-2708	.	_	_	_	_
28-22	2709-2715	Taylor	person	new	coref	28-36
28-23	2716-2718	et	_	_	_	_
28-24	2719-2722	al.	_	_	_	_
28-25	2723-2732	generated	_	_	_	_
28-26	2733-2742	candidate	person[134]|object[135]	new[134]|giv[135]	coref|coref	28-80[0_135]|28-80[0_135]
28-27	2743-2745	’s	person[134]|object[135]	new[134]|giv[135]	_	_
28-28	2746-2750	hand	object[135]	giv[135]	_	_
28-29	2751-2756	poses	_	_	_	_
28-30	2757-2764	quickly	_	_	_	_
28-31	2765-2767	by	_	_	_	_
28-32	2768-2769	a	object[136]	new[136]	_	_
28-33	2770-2779	retrieval	object[136]	new[136]	_	_
28-34	2780-2786	forest	object[136]	new[136]	_	_
28-35	2787-2788	.	_	_	_	_
28-36	2789-2795	Taylor	person	giv	coref	44-16
28-37	2796-2798	et	_	_	_	_
28-38	2799-2802	al.	_	_	_	_
28-39	2803-2810	trained	_	_	_	_
28-40	2811-2812	a	abstract[138]	giv[138]	_	_
28-41	2813-2821	decision	abstract[138]	giv[138]	_	_
28-42	2822-2828	forest	abstract[139]	giv[139]	_	_
28-43	2829-2839	classifier	abstract[139]	giv[139]	_	_
28-44	2840-2842	on	abstract[139]	giv[139]	_	_
28-45	2843-2844	a	abstract[139]|abstract[141]	giv[139]|new[141]	_	_
28-46	2845-2854	synthetic	abstract[139]|abstract[141]	giv[139]|new[141]	_	_
28-47	2855-2863	training	abstract[139]|abstract|abstract[141]	giv[139]|giv|new[141]	coref	29-10
28-48	2864-2867	set	abstract[139]|abstract[141]	giv[139]|new[141]	_	_
28-49	2868-2870	to	_	_	_	_
28-50	2871-2879	generate	_	_	_	_
28-51	2880-2882	an	abstract[143]	new[143]	_	_
28-52	2883-2890	initial	abstract[143]	new[143]	_	_
28-53	2891-2895	pose	abstract|abstract[143]	giv|new[143]	coref	28-80[152_0]
28-54	2896-2904	estimate	abstract[143]	new[143]	_	_
28-55	2905-2906	.	_	_	_	_
28-56	2907-2920	Sanchez-Riera	person	new	_	_
28-57	2921-2923	et	_	_	_	_
28-58	2924-2927	al.	_	_	_	_
28-59	2928-2935	trained	_	_	_	_
28-60	2936-2937	a	abstract[145]	giv[145]	_	_
28-61	2938-2951	convolutional	abstract[145]	giv[145]	_	_
28-62	2952-2958	neural	abstract[145]	giv[145]	_	_
28-63	2959-2966	network	abstract[145]	giv[145]	_	_
28-64	2967-2970	for	abstract[145]	giv[145]	_	_
28-65	2971-2985	initialization	abstract[145]|abstract[146]	giv[145]|giv[146]	coref	29-3[0_146]
28-66	2986-2990	with	abstract[145]|abstract[146]	giv[145]|giv[146]	_	_
28-67	2991-2998	243,000	abstract[145]|abstract[146]|quantity[147]	giv[145]|giv[146]|new[147]	_	_
28-68	2999-3005	tuples	abstract[145]|abstract[146]|quantity[147]	giv[145]|giv[146]|new[147]	_	_
28-69	3006-3008	of	abstract[145]|abstract[146]|quantity[147]	giv[145]|giv[146]|new[147]	_	_
28-70	3009-3015	images	abstract[145]|abstract[146]|quantity[147]|object	giv[145]|giv[146]|new[147]|giv	_	_
28-71	3016-3017	.	_	_	_	_
28-72	3018-3023	Sharp	person	new	_	_
28-73	3024-3026	et	_	_	_	_
28-74	3027-3030	al.	_	_	_	_
28-75	3031-3039	inferred	_	_	_	_
28-76	3040-3041	a	abstract[150]	new[150]	_	_
28-77	3042-3054	hierarchical	abstract[150]	new[150]	_	_
28-78	3055-3067	distribution	abstract[150]	new[150]	_	_
28-79	3068-3072	over	abstract[150]	new[150]	_	_
28-80	3073-3077	hand	abstract[150]|object|abstract[152]	new[150]|giv|giv[152]	coref|coref	33-3|33-3
28-81	3078-3082	pose	abstract[150]|abstract[152]	new[150]|giv[152]	_	_
28-82	3083-3087	with	abstract[150]|abstract[152]	new[150]|giv[152]	_	_
28-83	3088-3089	a	abstract[150]|abstract[152]|abstract[153]	new[150]|giv[152]|giv[153]	coref	33-1[170_153]
28-84	3090-3097	layered	abstract[150]|abstract[152]|abstract[153]	new[150]|giv[152]|giv[153]	_	_
28-85	3098-3112	discriminative	abstract[150]|abstract[152]|abstract[153]	new[150]|giv[152]|giv[153]	_	_
28-86	3113-3118	model	abstract[150]|abstract[152]|abstract[153]	new[150]|giv[152]|giv[153]	_	_
28-87	3119-3120	.	_	_	_	_

#Text=However , initialization errors often occur due to imperfect training data-sets , mentioned in Section 2.1 , which may cause tracking failure .
29-1	3121-3128	However	_	_	_	_
29-2	3129-3130	,	_	_	_	_
29-3	3131-3145	initialization	abstract|abstract[155]	giv|new[155]	coref|coref	30-13[164_0]|30-13[164_0]
29-4	3146-3152	errors	abstract[155]	new[155]	_	_
29-5	3153-3158	often	_	_	_	_
29-6	3159-3164	occur	_	_	_	_
29-7	3165-3168	due	_	_	_	_
29-8	3169-3171	to	_	_	_	_
29-9	3172-3181	imperfect	abstract[157]	giv[157]	_	_
29-10	3182-3190	training	abstract|abstract[157]	giv|giv[157]	_	_
29-11	3191-3200	data-sets	abstract[157]	giv[157]	_	_
29-12	3201-3202	,	_	_	_	_
29-13	3203-3212	mentioned	_	_	_	_
29-14	3213-3215	in	_	_	_	_
29-15	3216-3223	Section	abstract[158]	new[158]	_	_
29-16	3224-3227	2.1	abstract[158]	new[158]	_	_
29-17	3228-3229	,	_	_	_	_
29-18	3230-3235	which	_	_	_	_
29-19	3236-3239	may	_	_	_	_
29-20	3240-3245	cause	_	_	_	_
29-21	3246-3254	tracking	abstract[159]	new[159]	ana	30-5[0_159]
29-22	3255-3262	failure	abstract[159]	new[159]	_	_
29-23	3263-3264	.	_	_	_	_

#Text=In our system , it is more reliable and robust to provide an approximate initialization by a simple data glove .
30-1	3265-3267	In	_	_	_	_
30-2	3268-3271	our	person|abstract[161]	giv|giv[161]	ana|coref|ana|coref	45-14|45-14[249_161]|45-14|45-14[249_161]
30-3	3272-3278	system	abstract[161]	giv[161]	_	_
30-4	3279-3280	,	_	_	_	_
30-5	3281-3283	it	abstract	giv	_	_
30-6	3284-3286	is	_	_	_	_
30-7	3287-3291	more	_	_	_	_
30-8	3292-3300	reliable	_	_	_	_
30-9	3301-3304	and	_	_	_	_
30-10	3305-3311	robust	_	_	_	_
30-11	3312-3314	to	abstract[163]	new[163]	_	_
30-12	3315-3322	provide	abstract[163]	new[163]	_	_
30-13	3323-3325	an	abstract[163]|abstract[164]	new[163]|giv[164]	_	_
30-14	3326-3337	approximate	abstract[163]|abstract[164]	new[163]|giv[164]	_	_
30-15	3338-3352	initialization	abstract[163]|abstract[164]	new[163]|giv[164]	_	_
30-16	3353-3355	by	_	_	_	_
30-17	3356-3357	a	object[166]	new[166]	_	_
30-18	3358-3364	simple	object[166]	new[166]	_	_
30-19	3365-3369	data	abstract|object[166]	giv|new[166]	coref	41-21[227_0]
30-20	3370-3375	glove	object[166]	new[166]	_	_
30-21	3376-3377	.	_	_	_	_

#Text=2.2.2 .
31-1	3378-3383	2.2.2	abstract	new	_	_
31-2	3384-3385	.	_	_	_	_

#Text=Hand Model
32-1	3386-3390	Hand	abstract[168]	new[168]	_	_
32-2	3391-3396	Model	abstract[168]	new[168]	_	_

#Text=The human hand model serves as the medium of computation and the presentation of algorithm results .
33-1	3397-3400	The	abstract[170]	giv[170]	coref	34-1[176_170]
33-2	3401-3406	human	abstract[170]	giv[170]	_	_
33-3	3407-3411	hand	object|abstract[170]	giv|giv[170]	coref	35-2
33-4	3412-3417	model	abstract[170]	giv[170]	_	_
33-5	3418-3424	serves	_	_	_	_
33-6	3425-3427	as	_	_	_	_
33-7	3428-3431	the	_	_	_	_
33-8	3432-3438	medium	_	_	_	_
33-9	3439-3441	of	_	_	_	_
33-10	3442-3453	computation	abstract|abstract[172]	new|new[172]	ana|ana	34-16[0_172]|34-16[0_172]
33-11	3454-3457	and	abstract[172]	new[172]	_	_
33-12	3458-3461	the	abstract[172]|abstract[173]	new[172]|new[173]	_	_
33-13	3462-3474	presentation	abstract[172]|abstract[173]	new[172]|new[173]	_	_
33-14	3475-3477	of	abstract[172]|abstract[173]	new[172]|new[173]	_	_
33-15	3478-3487	algorithm	abstract[172]|abstract[173]|abstract|abstract[175]	new[172]|new[173]|new|giv[175]	_	_
33-16	3488-3495	results	abstract[172]|abstract[173]|abstract[175]	new[172]|new[173]|giv[175]	_	_
33-17	3496-3497	.	_	_	_	_

#Text=A detailed and accurate generative model tends to deepen the good local minima and widen their basins of convergence .
34-1	3498-3499	A	abstract[176]	giv[176]	coref	38-24[192_176]
34-2	3500-3508	detailed	abstract[176]	giv[176]	_	_
34-3	3509-3512	and	abstract[176]	giv[176]	_	_
34-4	3513-3521	accurate	abstract[176]	giv[176]	_	_
34-5	3522-3532	generative	abstract[176]	giv[176]	_	_
34-6	3533-3538	model	abstract[176]	giv[176]	_	_
34-7	3539-3544	tends	_	_	_	_
34-8	3545-3547	to	_	_	_	_
34-9	3548-3554	deepen	_	_	_	_
34-10	3555-3558	the	abstract[177]	new[177]	_	_
34-11	3559-3563	good	abstract[177]	new[177]	_	_
34-12	3564-3569	local	abstract[177]	new[177]	_	_
34-13	3570-3576	minima	abstract[177]	new[177]	_	_
34-14	3577-3580	and	_	_	_	_
34-15	3581-3586	widen	_	_	_	_
34-16	3587-3592	their	abstract|abstract[179]	giv|new[179]	_	_
34-17	3593-3599	basins	abstract[179]	new[179]	_	_
34-18	3600-3602	of	abstract[179]	new[179]	_	_
34-19	3603-3614	convergence	abstract[179]|abstract	new[179]|new	_	_
34-20	3615-3616	.	_	_	_	_

#Text=Many hand models have been proposed , see
35-1	3617-3621	Many	abstract[182]	giv[182]	coref	43-8[232_182]
35-2	3622-3626	hand	object|abstract[182]	giv|giv[182]	coref	38-25
35-3	3627-3633	models	abstract[182]	giv[182]	_	_
35-4	3634-3638	have	_	_	_	_
35-5	3639-3643	been	_	_	_	_
35-6	3644-3652	proposed	_	_	_	_
35-7	3653-3654	,	_	_	_	_
35-8	3655-3658	see	_	_	_	_

#Text=Figure 1
36-1	3659-3665	Figure	object[183]	new[183]	_	_
36-2	3666-3667	1	object[183]	new[183]	_	_

#Text=.
37-1	3668-3669	.	_	_	_	_

#Text=Early works used the capsule mode made by two basic geometric primitives : a sphere and a cylinder . Qian et al. built the hand model using a number of spheres . Melax et al. used a union of convex bodies for hand tracking . Sridhar et al. modeled the volumetric extent of the hand as a 3D sum of an-isotropic Gaussian model .
38-1	3670-3675	Early	object[184]	giv[184]	_	_
38-2	3676-3681	works	object[184]	giv[184]	_	_
38-3	3682-3686	used	_	_	_	_
38-4	3687-3690	the	abstract[186]	new[186]	_	_
38-5	3691-3698	capsule	object|abstract[186]	new|new[186]	_	_
38-6	3699-3703	mode	abstract[186]	new[186]	_	_
38-7	3704-3708	made	_	_	_	_
38-8	3709-3711	by	_	_	_	_
38-9	3712-3715	two	abstract[187]	new[187]	_	_
38-10	3716-3721	basic	abstract[187]	new[187]	_	_
38-11	3722-3731	geometric	abstract[187]	new[187]	_	_
38-12	3732-3742	primitives	abstract[187]	new[187]	_	_
38-13	3743-3744	:	_	_	_	_
38-14	3745-3746	a	object[188]	new[188]	_	_
38-15	3747-3753	sphere	object[188]	new[188]	_	_
38-16	3754-3757	and	_	_	_	_
38-17	3758-3759	a	object[189]	new[189]	_	_
38-18	3760-3768	cylinder	object[189]	new[189]	_	_
38-19	3769-3770	.	_	_	_	_
38-20	3771-3775	Qian	person	new	_	_
38-21	3776-3778	et	_	_	_	_
38-22	3779-3782	al.	_	_	_	_
38-23	3783-3788	built	_	_	_	_
38-24	3789-3792	the	abstract[192]	giv[192]	coref	38-61[203_192]
38-25	3793-3797	hand	object|abstract[192]	giv|giv[192]	coref	38-43
38-26	3798-3803	model	abstract[192]	giv[192]	_	_
38-27	3804-3809	using	_	_	_	_
38-28	3810-3811	a	object[193]	new[193]	_	_
38-29	3812-3818	number	object[193]	new[193]	_	_
38-30	3819-3821	of	object[193]	new[193]	_	_
38-31	3822-3829	spheres	object[193]	new[193]	_	_
38-32	3830-3831	.	_	_	_	_
38-33	3832-3837	Melax	person	new	_	_
38-34	3838-3840	et	_	_	_	_
38-35	3841-3844	al.	_	_	_	_
38-36	3845-3849	used	_	_	_	_
38-37	3850-3851	a	organization[195]	new[195]	_	_
38-38	3852-3857	union	organization[195]	new[195]	_	_
38-39	3858-3860	of	organization[195]	new[195]	_	_
38-40	3861-3867	convex	organization[195]|object[196]	new[195]|new[196]	_	_
38-41	3868-3874	bodies	organization[195]|object[196]	new[195]|new[196]	_	_
38-42	3875-3878	for	organization[195]|object[196]	new[195]|new[196]	_	_
38-43	3879-3883	hand	organization[195]|object[196]|object	new[195]|new[196]|giv	coref	38-54[200_0]
38-44	3884-3892	tracking	_	_	_	_
38-45	3893-3894	.	_	_	_	_
38-46	3895-3902	Sridhar	person	new	_	_
38-47	3903-3905	et	_	_	_	_
38-48	3906-3909	al.	_	_	_	_
38-49	3910-3917	modeled	_	_	_	_
38-50	3918-3921	the	abstract[199]	new[199]	_	_
38-51	3922-3932	volumetric	abstract[199]	new[199]	_	_
38-52	3933-3939	extent	abstract[199]	new[199]	_	_
38-53	3940-3942	of	abstract[199]	new[199]	_	_
38-54	3943-3946	the	abstract[199]|object[200]	new[199]|giv[200]	coref	39-9[0_200]
38-55	3947-3951	hand	abstract[199]|object[200]	new[199]|giv[200]	_	_
38-56	3952-3954	as	_	_	_	_
38-57	3955-3956	a	_	_	_	_
38-58	3957-3959	3D	abstract	giv	_	_
38-59	3960-3963	sum	_	_	_	_
38-60	3964-3966	of	_	_	_	_
38-61	3967-3979	an-isotropic	abstract[203]	giv[203]	_	_
38-62	3980-3988	Gaussian	person|abstract[203]	new|giv[203]	_	_
38-63	3989-3994	model	abstract[203]	giv[203]	_	_
38-64	3995-3996	.	_	_	_	_

#Text=These approaches can model a broad spectrum of hand shape variations and enable fast evaluation of distances and a high degree of computational parallelism .
39-1	3997-4002	These	abstract[204]	new[204]	_	_
39-2	4003-4013	approaches	abstract[204]	new[204]	_	_
39-3	4014-4017	can	_	_	_	_
39-4	4018-4023	model	_	_	_	_
39-5	4024-4025	a	abstract[205]	new[205]	_	_
39-6	4026-4031	broad	abstract[205]	new[205]	_	_
39-7	4032-4040	spectrum	abstract[205]	new[205]	_	_
39-8	4041-4043	of	abstract[205]	new[205]	_	_
39-9	4044-4048	hand	abstract[205]|object|abstract[208]	new[205]|giv|new[208]	coref|coref	40-7|40-7
39-10	4049-4054	shape	abstract[205]|abstract|abstract[208]	new[205]|new|new[208]	coref	40-4[216_0]
39-11	4055-4065	variations	abstract[205]|abstract[208]	new[205]|new[208]	_	_
39-12	4066-4069	and	_	_	_	_
39-13	4070-4076	enable	_	_	_	_
39-14	4077-4081	fast	abstract[209]|abstract[210]	new[209]|new[210]	ana|ana	40-3[0_210]|40-3[0_210]
39-15	4082-4092	evaluation	abstract[209]|abstract[210]	new[209]|new[210]	_	_
39-16	4093-4095	of	abstract[209]|abstract[210]	new[209]|new[210]	_	_
39-17	4096-4105	distances	abstract[209]|abstract[210]|abstract	new[209]|new[210]|new	_	_
39-18	4106-4109	and	abstract[210]	new[210]	_	_
39-19	4110-4111	a	abstract[210]|abstract[212]	new[210]|new[212]	_	_
39-20	4112-4116	high	abstract[210]|abstract[212]	new[210]|new[212]	_	_
39-21	4117-4123	degree	abstract[210]|abstract[212]	new[210]|new[212]	_	_
39-22	4124-4126	of	abstract[210]|abstract[212]	new[210]|new[212]	_	_
39-23	4127-4140	computational	abstract[210]|abstract[212]|abstract[213]	new[210]|new[212]|new[213]	_	_
39-24	4141-4152	parallelism	abstract[210]|abstract[212]|abstract[213]	new[210]|new[212]|new[213]	_	_
39-25	4153-4154	.	_	_	_	_

#Text=However , they only roughly approximate hand shape even if Tkach et al. proposed the use of sphere-meshes as a novel geometric representation .
40-1	4155-4162	However	_	_	_	_
40-2	4163-4164	,	_	_	_	_
40-3	4165-4169	they	abstract	giv	_	_
40-4	4170-4174	only	abstract[216]	giv[216]	_	_
40-5	4175-4182	roughly	abstract[216]	giv[216]	_	_
40-6	4183-4194	approximate	abstract[216]	giv[216]	_	_
40-7	4195-4199	hand	object|abstract[216]	giv|giv[216]	coref	44-20[239_0]
40-8	4200-4205	shape	abstract[216]	giv[216]	_	_
40-9	4206-4210	even	_	_	_	_
40-10	4211-4213	if	_	_	_	_
40-11	4214-4219	Tkach	person	giv	_	_
40-12	4220-4222	et	_	_	_	_
40-13	4223-4226	al.	_	_	_	_
40-14	4227-4235	proposed	_	_	_	_
40-15	4236-4239	the	abstract[218]	new[218]	_	_
40-16	4240-4243	use	abstract[218]	new[218]	_	_
40-17	4244-4246	of	abstract[218]	new[218]	_	_
40-18	4247-4260	sphere-meshes	abstract[218]|object	new[218]|new	_	_
40-19	4261-4263	as	_	_	_	_
40-20	4264-4265	a	_	_	_	_
40-21	4266-4271	novel	_	_	_	_
40-22	4272-4281	geometric	_	_	_	_
40-23	4282-4296	representation	_	_	_	_
40-24	4297-4298	.	_	_	_	_

#Text=An alternative is a triangulated mesh model with linear blend skinning ( LBS ) that is more realistic and fits image data better .
41-1	4299-4301	An	abstract[220]	new[220]	coref	41-4[222_220]
41-2	4302-4313	alternative	abstract[220]	new[220]	_	_
41-3	4314-4316	is	_	_	_	_
41-4	4317-4318	a	abstract[222]	giv[222]	coref	45-17[252_222]
41-5	4319-4331	triangulated	abstract[222]	giv[222]	_	_
41-6	4332-4336	mesh	object|abstract[222]	new|giv[222]	coref	45-20
41-7	4337-4342	model	abstract[222]	giv[222]	_	_
41-8	4343-4347	with	abstract[222]	giv[222]	_	_
41-9	4348-4354	linear	abstract[222]|object[224]	giv[222]|new[224]	_	_
41-10	4355-4360	blend	abstract[222]|substance|object[224]	giv[222]|new|new[224]	_	_
41-11	4361-4369	skinning	abstract[222]|object[224]	giv[222]|new[224]	_	_
41-12	4370-4371	(	_	_	_	_
41-13	4372-4375	LBS	abstract	new	_	_
41-14	4376-4377	)	_	_	_	_
41-15	4378-4382	that	_	_	_	_
41-16	4383-4385	is	_	_	_	_
41-17	4386-4390	more	_	_	_	_
41-18	4391-4400	realistic	_	_	_	_
41-19	4401-4404	and	_	_	_	_
41-20	4405-4409	fits	_	_	_	_
41-21	4410-4415	image	object|abstract[227]	giv|giv[227]	coref|coref	45-3[246_227]|45-3[246_227]
41-22	4416-4420	data	abstract[227]	giv[227]	_	_
41-23	4421-4427	better	_	_	_	_
41-24	4428-4429	.	_	_	_	_

#Text=But these triangulated meshes cost more computational effort and are hard to deal with the collision .
42-1	4430-4433	But	_	_	_	_
42-2	4434-4439	these	object[228]	new[228]	_	_
42-3	4440-4452	triangulated	object[228]	new[228]	_	_
42-4	4453-4459	meshes	object[228]	new[228]	_	_
42-5	4460-4464	cost	_	_	_	_
42-6	4465-4469	more	abstract[229]	new[229]	_	_
42-7	4470-4483	computational	abstract[229]	new[229]	_	_
42-8	4484-4490	effort	abstract[229]	new[229]	_	_
42-9	4491-4494	and	_	_	_	_
42-10	4495-4498	are	_	_	_	_
42-11	4499-4503	hard	_	_	_	_
42-12	4504-4506	to	_	_	_	_
42-13	4507-4511	deal	_	_	_	_
42-14	4512-4516	with	_	_	_	_
42-15	4517-4520	the	event[230]	new[230]	_	_
42-16	4521-4530	collision	event[230]	new[230]	_	_
42-17	4531-4532	.	_	_	_	_

#Text=There also exist some implicit templates except these explicit models . Schmidt et al.
43-1	4533-4538	There	_	_	_	_
43-2	4539-4543	also	_	_	_	_
43-3	4544-4549	exist	_	_	_	_
43-4	4550-4554	some	abstract[231]	new[231]	_	_
43-5	4555-4563	implicit	abstract[231]	new[231]	_	_
43-6	4564-4573	templates	abstract[231]	new[231]	_	_
43-7	4574-4580	except	abstract[231]	new[231]	_	_
43-8	4581-4586	these	abstract[231]|abstract[232]	new[231]|giv[232]	_	_
43-9	4587-4595	explicit	abstract[231]|abstract[232]	new[231]|giv[232]	_	_
43-10	4596-4602	models	abstract[231]|abstract[232]	new[231]|giv[232]	_	_
43-11	4603-4604	.	_	_	_	_
43-12	4605-4612	Schmidt	person	new	_	_
43-13	4613-4615	et	_	_	_	_
43-14	4616-4619	al.	_	_	_	_

#Text=voxelized each shape-primitive and computed a signed distance function for the local coordinate frame . Taylor et al. constructed the hand as an articulated signed distance function that allows fast calculation of the distance to the hand surface .
44-1	4620-4629	voxelized	_	_	_	_
44-2	4630-4634	each	_	_	_	_
44-3	4635-4650	shape-primitive	_	_	_	_
44-4	4651-4654	and	_	_	_	_
44-5	4655-4663	computed	_	_	_	_
44-6	4664-4665	a	abstract[235]	new[235]	_	_
44-7	4666-4672	signed	abstract[235]	new[235]	_	_
44-8	4673-4681	distance	abstract|abstract[235]	new|new[235]	coref	44-26
44-9	4682-4690	function	abstract[235]	new[235]	_	_
44-10	4691-4694	for	abstract[235]	new[235]	_	_
44-11	4695-4698	the	abstract[235]|abstract[237]	new[235]|new[237]	_	_
44-12	4699-4704	local	abstract[235]|abstract[237]	new[235]|new[237]	_	_
44-13	4705-4715	coordinate	abstract[235]|abstract|abstract[237]	new[235]|new|new[237]	_	_
44-14	4716-4721	frame	abstract[235]|abstract[237]	new[235]|new[237]	_	_
44-15	4722-4723	.	_	_	_	_
44-16	4724-4730	Taylor	person	giv	_	_
44-17	4731-4733	et	_	_	_	_
44-18	4734-4737	al.	_	_	_	_
44-19	4738-4749	constructed	_	_	_	_
44-20	4750-4753	the	object[239]	giv[239]	coref	44-37[0_239]
44-21	4754-4758	hand	object[239]	giv[239]	_	_
44-22	4759-4761	as	_	_	_	_
44-23	4762-4764	an	_	_	_	_
44-24	4765-4776	articulated	_	_	_	_
44-25	4777-4783	signed	_	_	_	_
44-26	4784-4792	distance	abstract	giv	coref	44-33[242_0]
44-27	4793-4801	function	_	_	_	_
44-28	4802-4806	that	_	_	_	_
44-29	4807-4813	allows	_	_	_	_
44-30	4814-4818	fast	abstract[241]	new[241]	_	_
44-31	4819-4830	calculation	abstract[241]	new[241]	_	_
44-32	4831-4833	of	abstract[241]	new[241]	_	_
44-33	4834-4837	the	abstract[241]|abstract[242]	new[241]|giv[242]	_	_
44-34	4838-4846	distance	abstract[241]|abstract[242]	new[241]|giv[242]	_	_
44-35	4847-4849	to	abstract[241]|abstract[242]	new[241]|giv[242]	_	_
44-36	4850-4853	the	abstract[241]|abstract[242]|object[244]	new[241]|giv[242]|new[244]	_	_
44-37	4854-4858	hand	abstract[241]|abstract[242]|object|object[244]	new[241]|giv[242]|giv|new[244]	coref	45-21
44-38	4859-4866	surface	abstract[241]|abstract[242]|object[244]	new[241]|giv[242]|new[244]	_	_
44-39	4867-4868	.	_	_	_	_

#Text=To explain the input data better and explicitly visualize the tracking result , our system uses an expressive triangular mesh hand model .
45-1	4869-4871	To	_	_	_	_
45-2	4872-4879	explain	_	_	_	_
45-3	4880-4883	the	abstract[246]	giv[246]	_	_
45-4	4884-4889	input	abstract|abstract[246]	new|giv[246]	_	_
45-5	4890-4894	data	abstract[246]	giv[246]	_	_
45-6	4895-4901	better	_	_	_	_
45-7	4902-4905	and	_	_	_	_
45-8	4906-4916	explicitly	_	_	_	_
45-9	4917-4926	visualize	_	_	_	_
45-10	4927-4930	the	abstract[247]	new[247]	_	_
45-11	4931-4939	tracking	abstract[247]	new[247]	_	_
45-12	4940-4946	result	abstract[247]	new[247]	_	_
45-13	4947-4948	,	_	_	_	_
45-14	4949-4952	our	person|abstract[249]	giv|giv[249]	_	_
45-15	4953-4959	system	abstract[249]	giv[249]	_	_
45-16	4960-4964	uses	_	_	_	_
45-17	4965-4967	an	abstract[252]	giv[252]	_	_
45-18	4968-4978	expressive	abstract[252]	giv[252]	_	_
45-19	4979-4989	triangular	abstract[252]	giv[252]	_	_
45-20	4990-4994	mesh	object|abstract[252]	giv|giv[252]	_	_
45-21	4995-4999	hand	object|abstract[252]	giv|giv[252]	_	_
45-22	5000-5005	model	abstract[252]	giv[252]	_	_
45-23	5006-5007	.	_	_	_	_
