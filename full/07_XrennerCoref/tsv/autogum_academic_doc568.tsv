#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=1 .
1-1	0-1	1	quantity	new	_	_
1-2	2-3	.	_	_	_	_

#Text=Introduction
2-1	4-16	Introduction	abstract	new	_	_

#Text=Many applications in the real world , such as system identification , regression , and online kernel learning ( OKL ) , require complex nonlinear models .
3-1	17-21	Many	abstract[3]	new[3]	coref	4-13[17_3]
3-2	22-34	applications	abstract[3]	new[3]	_	_
3-3	35-37	in	abstract[3]	new[3]	_	_
3-4	38-41	the	abstract[3]|abstract[4]	new[3]|new[4]	_	_
3-5	42-46	real	abstract[3]|abstract[4]	new[3]|new[4]	_	_
3-6	47-52	world	abstract[3]|abstract[4]	new[3]|new[4]	_	_
3-7	53-54	,	abstract[3]	new[3]	_	_
3-8	55-59	such	abstract[3]	new[3]	_	_
3-9	60-62	as	abstract[3]	new[3]	_	_
3-10	63-69	system	abstract[3]|abstract|abstract[6]	new[3]|new|new[6]	_	_
3-11	70-84	identification	abstract[3]|abstract[6]	new[3]|new[6]	_	_
3-12	85-86	,	abstract[3]	new[3]	_	_
3-13	87-97	regression	abstract[3]|abstract	new[3]|new	_	_
3-14	98-99	,	abstract[3]	new[3]	_	_
3-15	100-103	and	abstract[3]	new[3]	_	_
3-16	104-110	online	abstract[3]|abstract[9]	new[3]|new[9]	appos	3-20[0_9]
3-17	111-117	kernel	abstract[3]|object|abstract[9]	new[3]|new|new[9]	coref	4-2
3-18	118-126	learning	abstract[3]|abstract[9]	new[3]|new[9]	_	_
3-19	127-128	(	_	_	_	_
3-20	129-132	OKL	abstract	giv	coref	5-18
3-21	133-134	)	_	_	_	_
3-22	135-136	,	_	_	_	_
3-23	137-144	require	_	_	_	_
3-24	145-152	complex	abstract[11]	new[11]	_	_
3-25	153-162	nonlinear	abstract[11]	new[11]	_	_
3-26	163-169	models	abstract[11]	new[11]	_	_
3-27	170-171	.	_	_	_	_

#Text=The kernel method using a Mercer kernel has attracted interests in tackling these complex nonlinear applications , which transforms nonlinear applications into linear ones in the reproducing kernel Hilbert space ( RKHS ) .
4-1	172-175	The	abstract[13]	new[13]	coref	6-10[0_13]
4-2	176-182	kernel	object|abstract[13]	giv|new[13]	coref	4-5[15_0]
4-3	183-189	method	abstract[13]	new[13]	_	_
4-4	190-195	using	_	_	_	_
4-5	196-197	a	object[15]	giv[15]	coref	4-28[0_15]
4-6	198-204	Mercer	person|object[15]	new|giv[15]	_	_
4-7	205-211	kernel	object[15]	giv[15]	_	_
4-8	212-215	has	_	_	_	_
4-9	216-225	attracted	_	_	_	_
4-10	226-235	interests	abstract	new	_	_
4-11	236-238	in	_	_	_	_
4-12	239-247	tackling	_	_	_	_
4-13	248-253	these	abstract[17]	giv[17]	coref	4-20[18_17]
4-14	254-261	complex	abstract[17]	giv[17]	_	_
4-15	262-271	nonlinear	abstract[17]	giv[17]	_	_
4-16	272-284	applications	abstract[17]	giv[17]	_	_
4-17	285-286	,	_	_	_	_
4-18	287-292	which	_	_	_	_
4-19	293-303	transforms	abstract	new	coref|none	15-30[133_0]|4-19[0_133]
4-20	304-313	nonlinear	abstract[18]	giv[18]	_	_
4-21	314-326	applications	abstract[18]	giv[18]	_	_
4-22	327-331	into	_	_	_	_
4-23	332-338	linear	abstract[19]	new[19]	_	_
4-24	339-343	ones	abstract[19]	new[19]	_	_
4-25	344-346	in	abstract[19]	new[19]	_	_
4-26	347-350	the	abstract[19]|abstract[22]	new[19]|new[22]	coref	15-20[128_22]
4-27	351-362	reproducing	abstract[19]|abstract[22]	new[19]|new[22]	_	_
4-28	363-369	kernel	abstract[19]|object|abstract[22]	new[19]|giv|new[22]	coref	5-6
4-29	370-377	Hilbert	abstract[19]|person|abstract[22]	new[19]|new|new[22]	_	_
4-30	378-383	space	abstract[19]|abstract[22]	new[19]|new[22]	_	_
4-31	384-385	(	_	_	_	_
4-32	386-390	RKHS	object	new	coref	5-3
4-33	391-392	)	_	_	_	_
4-34	393-394	.	_	_	_	_

#Text=Developed in RKHS , a kernel adaptive filter ( KAF ) is the most celebrated subfield of OKL algorithms .
5-1	395-404	Developed	_	_	_	_
5-2	405-407	in	_	_	_	_
5-3	408-412	RKHS	abstract	giv	_	_
5-4	413-414	,	_	_	_	_
5-5	415-416	a	abstract[26]	new[26]	appos	5-10[0_26]
5-6	417-423	kernel	person|abstract[26]	giv|new[26]	coref	6-17
5-7	424-432	adaptive	abstract[26]	new[26]	_	_
5-8	433-439	filter	abstract[26]	new[26]	_	_
5-9	440-441	(	_	_	_	_
5-10	442-445	KAF	abstract	giv	coref	5-13[28_0]
5-11	446-447	)	_	_	_	_
5-12	448-450	is	_	_	_	_
5-13	451-454	the	abstract[28]	giv[28]	_	_
5-14	455-459	most	abstract[28]	giv[28]	_	_
5-15	460-470	celebrated	abstract[28]	giv[28]	_	_
5-16	471-479	subfield	abstract[28]	giv[28]	_	_
5-17	480-482	of	abstract[28]	giv[28]	_	_
5-18	483-486	OKL	abstract[28]|abstract|abstract[30]	giv[28]|giv|new[30]	coref|coref|coref|coref	6-12|25-11[236_30]|6-12|25-11[236_30]
5-19	487-497	algorithms	abstract[28]|abstract[30]	giv[28]|new[30]	_	_
5-20	498-499	.	_	_	_	_

#Text=Using the simplest stochastic gradient descent ( SGD ) method for learning , KAFs including the kernel least mean square ( KLMS ) algorithm , kernel affine projection algorithm ( KAPA ) , and kernel recursive least squares ( KRLS ) algorithm have been proposed .
6-1	500-505	Using	_	_	_	_
6-2	506-509	the	abstract[32]	new[32]	appos	6-8[0_32]
6-3	510-518	simplest	abstract[32]	new[32]	_	_
6-4	519-529	stochastic	abstract[32]	new[32]	_	_
6-5	530-538	gradient	abstract|abstract[32]	new|new[32]	coref	17-36[153_0]
6-6	539-546	descent	abstract[32]	new[32]	_	_
6-7	547-548	(	_	_	_	_
6-8	549-552	SGD	abstract	giv	coref	26-9[247_0]
6-9	553-554	)	_	_	_	_
6-10	555-561	method	abstract	giv	appos	6-14
6-11	562-565	for	_	_	_	_
6-12	566-574	learning	abstract	giv	coref	22-5[201_0]
6-13	575-576	,	_	_	_	_
6-14	577-581	KAFs	abstract	giv	coref	7-43
6-15	582-591	including	_	_	_	_
6-16	592-595	the	place[38]|abstract[40]	new[38]|new[40]	appos|appos	6-22[0_38]|6-22[0_38]
6-17	596-602	kernel	person|place[38]|abstract[40]	giv|new[38]|new[40]	coref	6-26
6-18	603-608	least	place[38]|abstract[40]	new[38]|new[40]	_	_
6-19	609-613	mean	place[38]|abstract[40]	new[38]|new[40]	_	_
6-20	614-620	square	place[38]|abstract[40]	new[38]|new[40]	_	_
6-21	621-622	(	abstract[40]	new[40]	_	_
6-22	623-627	KLMS	place|abstract[40]	giv|new[40]	coref	18-27
6-23	628-629	)	abstract[40]	new[40]	_	_
6-24	630-639	algorithm	abstract[40]	new[40]	_	_
6-25	640-641	,	_	_	_	_
6-26	642-648	kernel	object|abstract[43]	giv|new[43]	coref|coref|coref|coref	6-35|6-42[0_43]|6-35|6-42[0_43]
6-27	649-655	affine	abstract[43]	new[43]	_	_
6-28	656-666	projection	object|abstract[43]	new|new[43]	_	_
6-29	667-676	algorithm	abstract[43]	new[43]	_	_
6-30	677-678	(	_	_	_	_
6-31	679-683	KAPA	abstract	new	_	_
6-32	684-685	)	_	_	_	_
6-33	686-687	,	_	_	_	_
6-34	688-691	and	_	_	_	_
6-35	692-698	kernel	object|abstract[46]	giv|new[46]	appos|coref|appos|coref	6-40|7-6|6-40|7-6
6-36	699-708	recursive	abstract[46]	new[46]	_	_
6-37	709-714	least	abstract[46]	new[46]	_	_
6-38	715-722	squares	abstract[46]	new[46]	_	_
6-39	723-724	(	_	_	_	_
6-40	725-729	KRLS	abstract	giv	coref	18-33[166_0]
6-41	730-731	)	_	_	_	_
6-42	732-741	algorithm	abstract	giv	coref	17-27[151_0]
6-43	742-746	have	_	_	_	_
6-44	747-751	been	_	_	_	_
6-45	752-760	proposed	_	_	_	_
6-46	761-762	.	_	_	_	_

#Text=However , allocating a new kernel unit as a radial basis function ( RBF ) center with the coming of new data , the linearly growing structure ( called “ dictionary ” hereafter ) will increase the computational and memory requirements in KAFs .
7-1	763-770	However	_	_	_	_
7-2	771-772	,	_	_	_	_
7-3	773-783	allocating	_	_	_	_
7-4	784-785	a	object[50]	new[50]	_	_
7-5	786-789	new	object[50]	new[50]	_	_
7-6	790-796	kernel	person|object[50]	giv|new[50]	coref	11-26
7-7	797-801	unit	object[50]	new[50]	_	_
7-8	802-804	as	_	_	_	_
7-9	805-806	a	_	_	_	_
7-10	807-813	radial	_	_	_	_
7-11	814-819	basis	abstract	new	coref	15-2[119_0]
7-12	820-828	function	_	_	_	_
7-13	829-830	(	_	_	_	_
7-14	831-834	RBF	abstract	new	_	_
7-15	835-836	)	_	_	_	_
7-16	837-843	center	person[53]	new[53]	_	_
7-17	844-848	with	person[53]	new[53]	_	_
7-18	849-852	the	person[53]|abstract[54]	new[53]|new[54]	_	_
7-19	853-859	coming	person[53]|abstract[54]	new[53]|new[54]	_	_
7-20	860-862	of	person[53]|abstract[54]	new[53]|new[54]	_	_
7-21	863-866	new	person[53]|abstract[54]|abstract[55]	new[53]|new[54]|new[55]	coref	9-5[65_55]
7-22	867-871	data	person[53]|abstract[54]|abstract[55]	new[53]|new[54]|new[55]	_	_
7-23	872-873	,	_	_	_	_
7-24	874-877	the	abstract[56]	new[56]	coref	15-38[135_56]
7-25	878-886	linearly	abstract[56]	new[56]	_	_
7-26	887-894	growing	abstract[56]	new[56]	_	_
7-27	895-904	structure	abstract[56]	new[56]	_	_
7-28	905-906	(	_	_	_	_
7-29	907-913	called	_	_	_	_
7-30	914-915	“	object[57]	new[57]	coref	8-6[61_57]
7-31	916-926	dictionary	object[57]	new[57]	_	_
7-32	927-928	”	object[57]	new[57]	_	_
7-33	929-938	hereafter	object[57]	new[57]	_	_
7-34	939-940	)	_	_	_	_
7-35	941-945	will	_	_	_	_
7-36	946-954	increase	_	_	_	_
7-37	955-958	the	abstract[58]	new[58]	_	_
7-38	959-972	computational	abstract[58]	new[58]	_	_
7-39	973-976	and	abstract[58]	new[58]	_	_
7-40	977-983	memory	abstract[58]	new[58]	_	_
7-41	984-996	requirements	abstract[58]	new[58]	_	_
7-42	997-999	in	abstract[58]	new[58]	_	_
7-43	1000-1004	KAFs	abstract[58]|abstract	new[58]|giv	coref	11-33[93_0]
7-44	1005-1006	.	_	_	_	_

#Text=To curb the growth of the dictionary , two categories are chosen for sparsification .
8-1	1007-1009	To	_	_	_	_
8-2	1010-1014	curb	_	_	_	_
8-3	1015-1018	the	abstract[60]	new[60]	_	_
8-4	1019-1025	growth	abstract[60]	new[60]	_	_
8-5	1026-1028	of	abstract[60]	new[60]	_	_
8-6	1029-1032	the	abstract[60]|object[61]	new[60]|giv[61]	coref	9-10[0_61]
8-7	1033-1043	dictionary	abstract[60]|object[61]	new[60]|giv[61]	_	_
8-8	1044-1045	,	_	_	_	_
8-9	1046-1049	two	abstract[62]	new[62]	_	_
8-10	1050-1060	categories	abstract[62]	new[62]	_	_
8-11	1061-1064	are	_	_	_	_
8-12	1065-1071	chosen	_	_	_	_
8-13	1072-1075	for	_	_	_	_
8-14	1076-1090	sparsification	abstract	new	_	_
8-15	1091-1092	.	_	_	_	_

#Text=The first category accepts only informative data as new dictionary centers by using a threshold , including the surprise criterion ( SC ) , the coherence criterion ( CC ) , and the vector quantization ( VQ ) .
9-1	1093-1096	The	abstract[64]	new[64]	_	_
9-2	1097-1102	first	abstract[64]	new[64]	_	_
9-3	1103-1111	category	abstract[64]	new[64]	_	_
9-4	1112-1119	accepts	_	_	_	_
9-5	1120-1124	only	abstract[65]	giv[65]	coref	13-18[113_65]
9-6	1125-1136	informative	abstract[65]	giv[65]	_	_
9-7	1137-1141	data	abstract[65]	giv[65]	_	_
9-8	1142-1144	as	abstract[65]	giv[65]	_	_
9-9	1145-1148	new	abstract[65]	giv[65]	_	_
9-10	1149-1159	dictionary	abstract[65]|object	giv[65]|giv	_	_
9-11	1160-1167	centers	abstract[65]	giv[65]	_	_
9-12	1168-1170	by	_	_	_	_
9-13	1171-1176	using	_	_	_	_
9-14	1177-1178	a	abstract[67]	new[67]	_	_
9-15	1179-1188	threshold	abstract[67]	new[67]	_	_
9-16	1189-1190	,	abstract[67]	new[67]	_	_
9-17	1191-1200	including	abstract[67]	new[67]	_	_
9-18	1201-1204	the	abstract[67]|abstract[69]	new[67]|new[69]	appos	9-22[0_69]
9-19	1205-1213	surprise	abstract[67]|abstract|abstract[69]	new[67]|new|new[69]	_	_
9-20	1214-1223	criterion	abstract[67]|abstract[69]	new[67]|new[69]	_	_
9-21	1224-1225	(	_	_	_	_
9-22	1226-1228	SC	abstract	giv	_	_
9-23	1229-1230	)	_	_	_	_
9-24	1231-1232	,	_	_	_	_
9-25	1233-1236	the	abstract[72]	new[72]	coref	22-15[206_72]
9-26	1237-1246	coherence	quantity|abstract[72]	new|new[72]	_	_
9-27	1247-1256	criterion	abstract[72]	new[72]	_	_
9-28	1257-1258	(	_	_	_	_
9-29	1259-1261	CC	abstract	new	_	_
9-30	1262-1263	)	_	_	_	_
9-31	1264-1265	,	_	_	_	_
9-32	1266-1269	and	_	_	_	_
9-33	1270-1273	the	abstract[75]	new[75]	appos	9-37[0_75]
9-34	1274-1280	vector	person|abstract[75]	new|new[75]	coref	14-5
9-35	1281-1293	quantization	abstract[75]	new[75]	_	_
9-36	1294-1295	(	_	_	_	_
9-37	1296-1298	VQ	abstract	giv	_	_
9-38	1299-1300	)	_	_	_	_
9-39	1301-1302	.	_	_	_	_

#Text=However , these methods cannot fully address the growing problem and still introduce additional time consumption at each iteration .
10-1	1303-1310	However	_	_	_	_
10-2	1311-1312	,	_	_	_	_
10-3	1313-1318	these	abstract[77]	new[77]	coref	11-1[83_77]
10-4	1319-1326	methods	abstract[77]	new[77]	_	_
10-5	1327-1333	cannot	_	_	_	_
10-6	1334-1339	fully	_	_	_	_
10-7	1340-1347	address	_	_	_	_
10-8	1348-1351	the	abstract[78]	new[78]	coref	11-50[98_78]
10-9	1352-1359	growing	abstract[78]	new[78]	_	_
10-10	1360-1367	problem	abstract[78]	new[78]	_	_
10-11	1368-1371	and	_	_	_	_
10-12	1372-1377	still	_	_	_	_
10-13	1378-1387	introduce	_	_	_	_
10-14	1388-1398	additional	abstract[80]	new[80]	_	_
10-15	1399-1403	time	abstract|abstract[80]	new|new[80]	_	_
10-16	1404-1415	consumption	abstract[80]	new[80]	_	_
10-17	1416-1418	at	_	_	_	_
10-18	1419-1423	each	abstract[81]	new[81]	_	_
10-19	1424-1433	iteration	abstract[81]	new[81]	_	_
10-20	1434-1435	.	_	_	_	_

#Text=The fixed points methods as the second category , including the fixed-budget ( FB ) , the sliding window ( SW ) , and the kernel approximation methods ( e. g. , the Nystrm method and random Fourier features ( RFFs ) method ) , are used to overcome the sublinearly growing problem .
11-1	1436-1439	The	abstract[83]	giv[83]	coref	11-25[90_83]
11-2	1440-1445	fixed	abstract[83]	giv[83]	_	_
11-3	1446-1452	points	abstract|abstract[83]	new|giv[83]	_	_
11-4	1453-1460	methods	abstract[83]	giv[83]	_	_
11-5	1461-1463	as	abstract[83]	giv[83]	_	_
11-6	1464-1467	the	abstract[83]	giv[83]	_	_
11-7	1468-1474	second	abstract[83]	giv[83]	_	_
11-8	1475-1483	category	abstract[83]	giv[83]	_	_
11-9	1484-1485	,	abstract[83]	giv[83]	_	_
11-10	1486-1495	including	abstract[83]	giv[83]	_	_
11-11	1496-1499	the	abstract[83]	giv[83]	_	_
11-12	1500-1512	fixed-budget	abstract[83]	giv[83]	_	_
11-13	1513-1514	(	_	_	_	_
11-14	1515-1517	FB	abstract	new	coref	12-4
11-15	1518-1519	)	_	_	_	_
11-16	1520-1521	,	_	_	_	_
11-17	1522-1525	the	abstract[86]	new[86]	appos	11-21[0_86]
11-18	1526-1533	sliding	object|abstract[86]	new|new[86]	_	_
11-19	1534-1540	window	abstract[86]	new[86]	_	_
11-20	1541-1542	(	_	_	_	_
11-21	1543-1545	SW	abstract	giv	coref	12-8
11-22	1546-1547	)	_	_	_	_
11-23	1548-1549	,	_	_	_	_
11-24	1550-1553	and	_	_	_	_
11-25	1554-1557	the	abstract[90]	giv[90]	coref	28-28[271_90]
11-26	1558-1564	kernel	object|abstract[90]	giv|giv[90]	coref	15-31[131_0]
11-27	1565-1578	approximation	abstract|abstract[90]	new|giv[90]	_	_
11-28	1579-1586	methods	abstract[90]	giv[90]	_	_
11-29	1587-1588	(	_	_	_	_
11-30	1589-1591	e.	event[91]	new[91]	_	_
11-31	1592-1594	g.	event[91]	new[91]	_	_
11-32	1595-1596	,	_	_	_	_
11-33	1597-1600	the	abstract[93]|abstract[94]	giv[93]|new[94]	coref|coref|coref|coref	11-40[97_93]|12-3[101_94]|11-40[97_93]|12-3[101_94]
11-34	1601-1607	Nystrm	place|abstract[93]|abstract[94]	new|giv[93]|new[94]	coref	13-4
11-35	1608-1614	method	abstract[93]|abstract[94]	giv[93]|new[94]	_	_
11-36	1615-1618	and	abstract[94]	new[94]	_	_
11-37	1619-1625	random	abstract[94]|person[95]	new[94]|new[95]	coref	15-8[0_95]
11-38	1626-1633	Fourier	abstract[94]|person[95]	new[94]|new[95]	_	_
11-39	1634-1642	features	_	_	_	_
11-40	1643-1644	(	abstract[97]	giv[97]	coref	12-3[100_97]
11-41	1645-1649	RFFs	abstract|abstract[97]	new|giv[97]	coref	13-7
11-42	1650-1651	)	abstract[97]	giv[97]	_	_
11-43	1652-1658	method	abstract[97]	giv[97]	_	_
11-44	1659-1660	)	_	_	_	_
11-45	1661-1662	,	_	_	_	_
11-46	1663-1666	are	_	_	_	_
11-47	1667-1671	used	_	_	_	_
11-48	1672-1674	to	_	_	_	_
11-49	1675-1683	overcome	_	_	_	_
11-50	1684-1687	the	abstract[98]	giv[98]	_	_
11-51	1688-1699	sublinearly	abstract[98]	giv[98]	_	_
11-52	1700-1707	growing	abstract[98]	giv[98]	_	_
11-53	1708-1715	problem	abstract[98]	giv[98]	_	_
11-54	1716-1717	.	_	_	_	_

#Text=However , the FB method and the SW method cannot guarantee a good performance in specific environments with a small amount of time .
12-1	1718-1725	However	_	_	_	_
12-2	1726-1727	,	_	_	_	_
12-3	1728-1731	the	abstract[100]|abstract[101]	giv[100]|giv[101]	coref|coref|coref|coref	12-7[103_100]|28-4[261_101]|12-7[103_100]|28-4[261_101]
12-4	1732-1734	FB	abstract|abstract[100]|abstract[101]	giv|giv[100]|giv[101]	_	_
12-5	1735-1741	method	abstract[100]|abstract[101]	giv[100]|giv[101]	_	_
12-6	1742-1745	and	abstract[101]	giv[101]	_	_
12-7	1746-1749	the	abstract[101]|abstract[103]	giv[101]|giv[103]	coref	13-3[109_103]
12-8	1750-1752	SW	abstract[101]|place|abstract[103]	giv[101]|giv|giv[103]	_	_
12-9	1753-1759	method	abstract[101]|abstract[103]	giv[101]|giv[103]	_	_
12-10	1760-1766	cannot	_	_	_	_
12-11	1767-1776	guarantee	_	_	_	_
12-12	1777-1778	a	abstract[104]	new[104]	coref	16-14[139_104]
12-13	1779-1783	good	abstract[104]	new[104]	_	_
12-14	1784-1795	performance	abstract[104]	new[104]	_	_
12-15	1796-1798	in	abstract[104]	new[104]	_	_
12-16	1799-1807	specific	abstract[104]|place[105]	new[104]|new[105]	coref	21-42[197_105]
12-17	1808-1820	environments	abstract[104]|place[105]	new[104]|new[105]	_	_
12-18	1821-1825	with	abstract[104]|place[105]	new[104]|new[105]	_	_
12-19	1826-1827	a	abstract[104]|place[105]|abstract[106]	new[104]|new[105]|new[106]	_	_
12-20	1828-1833	small	abstract[104]|place[105]|abstract[106]	new[104]|new[105]|new[106]	_	_
12-21	1834-1840	amount	abstract[104]|place[105]|abstract[106]	new[104]|new[105]|new[106]	_	_
12-22	1841-1843	of	abstract[104]|place[105]|abstract[106]	new[104]|new[105]|new[106]	_	_
12-23	1844-1848	time	abstract[104]|place[105]|abstract[106]|time	new[104]|new[105]|new[106]|new	_	_
12-24	1849-1850	.	_	_	_	_

#Text=Compared with the Nystrm method , RFFs are drawn from a distribution that is randomly independent from the training data .
13-1	1851-1859	Compared	_	_	_	_
13-2	1860-1864	with	_	_	_	_
13-3	1865-1868	the	abstract[109]	giv[109]	coref	16-10[0_109]
13-4	1869-1875	Nystrm	place|abstract[109]	giv|giv[109]	_	_
13-5	1876-1882	method	abstract[109]	giv[109]	_	_
13-6	1883-1884	,	_	_	_	_
13-7	1885-1889	RFFs	abstract	giv	coref	14-8
13-8	1890-1893	are	_	_	_	_
13-9	1894-1899	drawn	_	_	_	_
13-10	1900-1904	from	_	_	_	_
13-11	1905-1906	a	abstract[111]	new[111]	_	_
13-12	1907-1919	distribution	abstract[111]	new[111]	_	_
13-13	1920-1924	that	_	_	_	_
13-14	1925-1927	is	_	_	_	_
13-15	1928-1936	randomly	_	_	_	_
13-16	1937-1948	independent	_	_	_	_
13-17	1949-1953	from	_	_	_	_
13-18	1954-1957	the	abstract[113]	giv[113]	coref	15-17[125_113]
13-19	1958-1966	training	abstract|abstract[113]	new|giv[113]	coref	19-33
13-20	1967-1971	data	abstract[113]	giv[113]	_	_
13-21	1972-1973	.	_	_	_	_

#Text=Due to a data-independent vector representation , RFFs can provide a good solution to non-stationary circumstances .
14-1	1974-1977	Due	_	_	_	_
14-2	1978-1980	to	_	_	_	_
14-3	1981-1982	a	abstract[115]	new[115]	_	_
14-4	1983-1999	data-independent	abstract[115]	new[115]	_	_
14-5	2000-2006	vector	person|abstract[115]	giv|new[115]	_	_
14-6	2007-2021	representation	abstract[115]	new[115]	_	_
14-7	2022-2023	,	_	_	_	_
14-8	2024-2028	RFFs	object	giv	coref	15-5
14-9	2029-2032	can	_	_	_	_
14-10	2033-2040	provide	_	_	_	_
14-11	2041-2042	a	abstract[117]	new[117]	coref	32-10[300_117]
14-12	2043-2047	good	abstract[117]	new[117]	_	_
14-13	2048-2056	solution	abstract[117]	new[117]	_	_
14-14	2057-2059	to	abstract[117]	new[117]	_	_
14-15	2060-2074	non-stationary	abstract[117]|abstract[118]	new[117]|new[118]	_	_
14-16	2075-2088	circumstances	abstract[117]|abstract[118]	new[117]|new[118]	_	_
14-17	2089-2090	.	_	_	_	_

#Text=On the basis of RFFs , random Fourier mapping ( RFM ) is proposed by mapping input data into a finite-dimensional random Fourier features space ( RFFS ) using a randomized feature kernel ’s Fourier transform in a fixed network structure .
15-1	2091-2093	On	_	_	_	_
15-2	2094-2097	the	abstract[119]	giv[119]	_	_
15-3	2098-2103	basis	abstract[119]	giv[119]	_	_
15-4	2104-2106	of	abstract[119]	giv[119]	_	_
15-5	2107-2111	RFFs	abstract[119]|abstract	giv[119]|giv	_	_
15-6	2112-2113	,	_	_	_	_
15-7	2114-2120	random	abstract[122]	new[122]	appos	15-11[0_122]
15-8	2121-2128	Fourier	person|abstract[122]	giv|new[122]	coref	15-23
15-9	2129-2136	mapping	abstract[122]	new[122]	_	_
15-10	2137-2138	(	_	_	_	_
15-11	2139-2142	RFM	abstract	giv	coref	16-1[136_0]
15-12	2143-2144	)	_	_	_	_
15-13	2145-2147	is	_	_	_	_
15-14	2148-2156	proposed	_	_	_	_
15-15	2157-2159	by	_	_	_	_
15-16	2160-2167	mapping	_	_	_	_
15-17	2168-2173	input	abstract|abstract[125]	new|giv[125]	coref|coref	19-32[177_125]|19-32[177_125]
15-18	2174-2178	data	abstract[125]	giv[125]	_	_
15-19	2179-2183	into	_	_	_	_
15-20	2184-2185	a	abstract[128]	giv[128]	appos	15-27[0_128]
15-21	2186-2204	finite-dimensional	abstract[128]	giv[128]	_	_
15-22	2205-2211	random	abstract[128]	giv[128]	_	_
15-23	2212-2219	Fourier	person|abstract[128]	giv|giv[128]	coref	15-35
15-24	2220-2228	features	abstract|abstract[128]	new|giv[128]	_	_
15-25	2229-2234	space	abstract[128]	giv[128]	_	_
15-26	2235-2236	(	_	_	_	_
15-27	2237-2241	RFFS	abstract	giv	_	_
15-28	2242-2243	)	_	_	_	_
15-29	2244-2249	using	_	_	_	_
15-30	2250-2251	a	abstract[133]	new[133]	_	_
15-31	2252-2262	randomized	object[131]|abstract[133]	giv[131]|new[133]	coref	17-13[0_131]
15-32	2263-2270	feature	abstract|object[131]|abstract[133]	new|giv[131]|new[133]	_	_
15-33	2271-2277	kernel	object[131]|abstract[133]	giv[131]|new[133]	_	_
15-34	2278-2280	’s	object[131]|abstract[133]	giv[131]|new[133]	_	_
15-35	2281-2288	Fourier	person|abstract[133]	giv|new[133]	coref	17-11
15-36	2289-2298	transform	abstract[133]	new[133]	_	_
15-37	2299-2301	in	abstract[133]	new[133]	_	_
15-38	2302-2303	a	abstract[133]|abstract[135]	new[133]|giv[135]	_	_
15-39	2304-2309	fixed	abstract[133]|abstract[135]	new[133]|giv[135]	_	_
15-40	2310-2317	network	abstract[133]|place|abstract[135]	new[133]|new|giv[135]	_	_
15-41	2318-2327	structure	abstract[133]|abstract[135]	new[133]|giv[135]	_	_
15-42	2328-2329	.	_	_	_	_

#Text=The RFM alleviates the computational and storage burdens of KAFs , and ensures a satisfactory performance under non-stationary conditions .
16-1	2330-2333	The	abstract[136]	giv[136]	coref	17-7[0_136]
16-2	2334-2337	RFM	abstract[136]	giv[136]	_	_
16-3	2338-2348	alleviates	_	_	_	_
16-4	2349-2352	the	abstract[137]	new[137]	_	_
16-5	2353-2366	computational	abstract[137]	new[137]	_	_
16-6	2367-2370	and	abstract[137]	new[137]	_	_
16-7	2371-2378	storage	abstract[137]	new[137]	_	_
16-8	2379-2386	burdens	abstract[137]	new[137]	_	_
16-9	2387-2389	of	abstract[137]	new[137]	_	_
16-10	2390-2394	KAFs	abstract[137]|abstract	new[137]|giv	coref	17-5
16-11	2395-2396	,	_	_	_	_
16-12	2397-2400	and	_	_	_	_
16-13	2401-2408	ensures	_	_	_	_
16-14	2409-2410	a	abstract[139]	giv[139]	coref	19-25[175_139]
16-15	2411-2423	satisfactory	abstract[139]	giv[139]	_	_
16-16	2424-2435	performance	abstract[139]	giv[139]	_	_
16-17	2436-2441	under	abstract[139]	giv[139]	_	_
16-18	2442-2456	non-stationary	abstract[139]|abstract[140]	giv[139]|new[140]	_	_
16-19	2457-2467	conditions	abstract[139]|abstract[140]	giv[139]|new[140]	_	_
16-20	2468-2469	.	_	_	_	_

#Text=The examples for developing KAFs with RFM are the random Fourier features kernel least mean square ( RFFKLMS ) algorithm , random Fourier features maximum correntropy ( RFFMC ) algorithm , and random Fourier features conjugate gradient ( RFFCG ) algorithm .
17-1	2470-2473	The	abstract[141]	new[141]	coref	17-9[145_141]
17-2	2474-2482	examples	abstract[141]	new[141]	_	_
17-3	2483-2486	for	_	_	_	_
17-4	2487-2497	developing	_	_	_	_
17-5	2498-2502	KAFs	abstract	giv	coref	18-40
17-6	2503-2507	with	_	_	_	_
17-7	2508-2511	RFM	abstract	giv	_	_
17-8	2512-2515	are	_	_	_	_
17-9	2516-2519	the	abstract[145]	giv[145]	ana	18-8[0_145]
17-10	2520-2526	random	abstract[145]	giv[145]	_	_
17-11	2527-2534	Fourier	person|abstract[145]	giv|giv[145]	coref	17-22[148_0]
17-12	2535-2543	features	abstract[145]	giv[145]	_	_
17-13	2544-2550	kernel	person	giv	coref	31-5
17-14	2551-2556	least	_	_	_	_
17-15	2557-2561	mean	_	_	_	_
17-16	2562-2568	square	_	_	_	_
17-17	2569-2570	(	_	_	_	_
17-18	2571-2578	RFFKLMS	abstract	new	_	_
17-19	2579-2580	)	_	_	_	_
17-20	2581-2590	algorithm	_	_	_	_
17-21	2591-2592	,	_	_	_	_
17-22	2593-2599	random	person[148]	giv[148]	coref	17-33[152_148]
17-23	2600-2607	Fourier	person[148]	giv[148]	_	_
17-24	2608-2616	features	_	_	_	_
17-25	2617-2624	maximum	abstract[149]	new[149]	coref	22-17[0_149]
17-26	2625-2636	correntropy	abstract[149]	new[149]	_	_
17-27	2637-2638	(	abstract[149]|abstract[151]	new[149]|giv[151]	coref	17-41[0_151]
17-28	2639-2644	RFFMC	abstract[149]|abstract|abstract[151]	new[149]|new|giv[151]	_	_
17-29	2645-2646	)	abstract[149]|abstract[151]	new[149]|giv[151]	_	_
17-30	2647-2656	algorithm	abstract[149]|abstract[151]	new[149]|giv[151]	_	_
17-31	2657-2658	,	_	_	_	_
17-32	2659-2662	and	_	_	_	_
17-33	2663-2669	random	person[152]	giv[152]	_	_
17-34	2670-2677	Fourier	person[152]	giv[152]	_	_
17-35	2678-2686	features	_	_	_	_
17-36	2687-2696	conjugate	abstract[153]	giv[153]	appos	17-39[0_153]
17-37	2697-2705	gradient	abstract[153]	giv[153]	_	_
17-38	2706-2707	(	_	_	_	_
17-39	2708-2713	RFFCG	abstract	giv	coref	26-11
17-40	2714-2715	)	_	_	_	_
17-41	2716-2725	algorithm	abstract	giv	_	_
17-42	2726-2727	.	_	_	_	_

#Text=For the loss function , due to their simplicity , smoothness , and mathematical tractability , the second-order statistical measures ( e. g. , minimum mean square error ( MMSE ) and least squares ) are widely utilized in KAFs .
18-1	2728-2731	For	_	_	_	_
18-2	2732-2735	the	abstract[157]	new[157]	_	_
18-3	2736-2740	loss	abstract|abstract[157]	new|new[157]	coref	24-18[227_0]
18-4	2741-2749	function	abstract[157]	new[157]	_	_
18-5	2750-2751	,	_	_	_	_
18-6	2752-2755	due	_	_	_	_
18-7	2756-2758	to	_	_	_	_
18-8	2759-2764	their	abstract|abstract[159]	giv|new[159]	_	_
18-9	2765-2775	simplicity	abstract[159]	new[159]	_	_
18-10	2776-2777	,	_	_	_	_
18-11	2778-2788	smoothness	abstract	new	_	_
18-12	2789-2790	,	_	_	_	_
18-13	2791-2794	and	_	_	_	_
18-14	2795-2807	mathematical	abstract[161]	new[161]	_	_
18-15	2808-2820	tractability	abstract[161]	new[161]	_	_
18-16	2821-2822	,	_	_	_	_
18-17	2823-2826	the	abstract[162]	new[162]	coref	19-6[169_162]
18-18	2827-2839	second-order	abstract[162]	new[162]	_	_
18-19	2840-2851	statistical	abstract[162]	new[162]	_	_
18-20	2852-2860	measures	abstract[162]	new[162]	_	_
18-21	2861-2862	(	_	_	_	_
18-22	2863-2865	e.	_	_	_	_
18-23	2866-2868	g.	_	_	_	_
18-24	2869-2870	,	_	_	_	_
18-25	2871-2878	minimum	abstract[164]	new[164]	appos	18-30[0_164]
18-26	2879-2883	mean	abstract[164]	new[164]	_	_
18-27	2884-2890	square	place|abstract[164]	giv|new[164]	coref	32-14
18-28	2891-2896	error	abstract[164]	new[164]	_	_
18-29	2897-2898	(	_	_	_	_
18-30	2899-2903	MMSE	abstract	giv	coref	20-17[182_0]
18-31	2904-2905	)	_	_	_	_
18-32	2906-2909	and	_	_	_	_
18-33	2910-2915	least	abstract[166]	giv[166]	coref	32-21[0_166]
18-34	2916-2923	squares	abstract[166]	giv[166]	_	_
18-35	2924-2925	)	_	_	_	_
18-36	2926-2929	are	_	_	_	_
18-37	2930-2936	widely	_	_	_	_
18-38	2937-2945	utilized	_	_	_	_
18-39	2946-2948	in	_	_	_	_
18-40	2949-2953	KAFs	abstract	giv	coref	19-3
18-41	2954-2955	.	_	_	_	_

#Text=However , KAFs based on the second-order statistical measures are sensitive to non-Gaussian noises including the sub-Gaussian and super-Gaussian noises , which means that their performance may be seriously degraded if the training data are contaminated by outliers .
19-1	2956-2963	However	_	_	_	_
19-2	2964-2965	,	_	_	_	_
19-3	2966-2970	KAFs	abstract	giv	coref	22-36[212_0]
19-4	2971-2976	based	_	_	_	_
19-5	2977-2979	on	_	_	_	_
19-6	2980-2983	the	abstract[169]	giv[169]	coref	20-6[180_169]
19-7	2984-2996	second-order	abstract[169]	giv[169]	_	_
19-8	2997-3008	statistical	abstract[169]	giv[169]	_	_
19-9	3009-3017	measures	abstract[169]	giv[169]	_	_
19-10	3018-3021	are	_	_	_	_
19-11	3022-3031	sensitive	_	_	_	_
19-12	3032-3034	to	_	_	_	_
19-13	3035-3047	non-Gaussian	abstract[170]	new[170]	_	_
19-14	3048-3054	noises	abstract[170]	new[170]	_	_
19-15	3055-3064	including	abstract[170]	new[170]	_	_
19-16	3065-3068	the	abstract[170]|abstract[171]	new[170]|new[171]	_	_
19-17	3069-3081	sub-Gaussian	abstract[170]|abstract[171]	new[170]|new[171]	_	_
19-18	3082-3085	and	abstract[170]	new[170]	_	_
19-19	3086-3100	super-Gaussian	abstract[170]|animal|abstract[173]	new[170]|new|new[173]	ana|ana	19-25[0_173]|19-25[0_173]
19-20	3101-3107	noises	abstract[170]|abstract[173]	new[170]|new[173]	_	_
19-21	3108-3109	,	_	_	_	_
19-22	3110-3115	which	_	_	_	_
19-23	3116-3121	means	_	_	_	_
19-24	3122-3126	that	_	_	_	_
19-25	3127-3132	their	abstract|abstract[175]	giv|giv[175]	coref|coref	21-16[190_0]|21-16[190_0]
19-26	3133-3144	performance	abstract[175]	giv[175]	_	_
19-27	3145-3148	may	_	_	_	_
19-28	3149-3151	be	_	_	_	_
19-29	3152-3161	seriously	_	_	_	_
19-30	3162-3170	degraded	_	_	_	_
19-31	3171-3173	if	_	_	_	_
19-32	3174-3177	the	abstract[177]	giv[177]	_	_
19-33	3178-3186	training	abstract|abstract[177]	giv|giv[177]	coref	23-24
19-34	3187-3191	data	abstract[177]	giv[177]	_	_
19-35	3192-3195	are	_	_	_	_
19-36	3196-3208	contaminated	_	_	_	_
19-37	3209-3211	by	_	_	_	_
19-38	3212-3220	outliers	abstract	new	_	_
19-39	3221-3222	.	_	_	_	_

#Text=To handle this issue , robust statistical measures have therefore gained more attention , among which the lower-order error measure and the higher-lower error measure are two typical examples .
20-1	3223-3225	To	_	_	_	_
20-2	3226-3232	handle	_	_	_	_
20-3	3233-3237	this	abstract[179]	new[179]	_	_
20-4	3238-3243	issue	abstract[179]	new[179]	_	_
20-5	3244-3245	,	_	_	_	_
20-6	3246-3252	robust	abstract[180]	giv[180]	coref	22-5[204_180]
20-7	3253-3264	statistical	abstract[180]	giv[180]	_	_
20-8	3265-3273	measures	abstract[180]	giv[180]	_	_
20-9	3274-3278	have	_	_	_	_
20-10	3279-3288	therefore	_	_	_	_
20-11	3289-3295	gained	_	_	_	_
20-12	3296-3300	more	abstract[181]	new[181]	_	_
20-13	3301-3310	attention	abstract[181]	new[181]	_	_
20-14	3311-3312	,	_	_	_	_
20-15	3313-3318	among	_	_	_	_
20-16	3319-3324	which	_	_	_	_
20-17	3325-3328	the	abstract[182]	giv[182]	coref	20-24[0_182]
20-18	3329-3340	lower-order	abstract[182]	giv[182]	_	_
20-19	3341-3346	error	abstract[182]	giv[182]	_	_
20-20	3347-3354	measure	abstract	new	coref|none	20-22[184_0]|20-20[0_230]
20-21	3355-3358	and	_	_	_	_
20-22	3359-3362	the	abstract[184]	new[184]	coref	20-27[185_184]
20-23	3363-3375	higher-lower	abstract[184]	new[184]	_	_
20-24	3376-3381	error	abstract|abstract[184]	giv|new[184]	coref	21-5
20-25	3382-3389	measure	abstract[184]	new[184]	_	_
20-26	3390-3393	are	_	_	_	_
20-27	3394-3397	two	abstract[185]	giv[185]	coref	21-3[187_185]
20-28	3398-3405	typical	abstract[185]	giv[185]	_	_
20-29	3406-3414	examples	abstract[185]	giv[185]	_	_
20-30	3415-3416	.	_	_	_	_

#Text=However , the higher-order error measure is not suitable for the mixture of Gaussian and super-Gaussian noises ( Laplace , -stable , etc. ) with poor stability and astringency , and the lower-order measure of error is usually more desirable in these noise environments with slow convergence rate .
21-1	3417-3424	However	_	_	_	_
21-2	3425-3426	,	_	_	_	_
21-3	3427-3430	the	abstract[187]	giv[187]	coref	21-32[194_187]
21-4	3431-3443	higher-order	abstract[187]	giv[187]	_	_
21-5	3444-3449	error	abstract|abstract[187]	giv|giv[187]	coref	21-36
21-6	3450-3457	measure	abstract[187]	giv[187]	_	_
21-7	3458-3460	is	_	_	_	_
21-8	3461-3464	not	_	_	_	_
21-9	3465-3473	suitable	_	_	_	_
21-10	3474-3477	for	_	_	_	_
21-11	3478-3481	the	abstract[188]	new[188]	_	_
21-12	3482-3489	mixture	abstract[188]	new[188]	_	_
21-13	3490-3492	of	abstract[188]	new[188]	_	_
21-14	3493-3501	Gaussian	abstract[188]|person	new[188]|new	_	_
21-15	3502-3505	and	_	_	_	_
21-16	3506-3520	super-Gaussian	abstract[190]	giv[190]	coref	23-14[217_190]
21-17	3521-3527	noises	abstract[190]	giv[190]	_	_
21-18	3528-3529	(	abstract[190]	giv[190]	_	_
21-19	3530-3537	Laplace	abstract[190]|person	giv[190]|new	_	_
21-20	3538-3539	,	abstract[190]	giv[190]	_	_
21-21	3540-3547	-stable	abstract[190]	giv[190]	_	_
21-22	3548-3549	,	abstract[190]	giv[190]	_	_
21-23	3550-3554	etc.	abstract[190]	giv[190]	_	_
21-24	3555-3556	)	abstract[190]	giv[190]	_	_
21-25	3557-3561	with	abstract[190]	giv[190]	_	_
21-26	3562-3566	poor	abstract[190]|abstract[192]	giv[190]|new[192]	_	_
21-27	3567-3576	stability	abstract[190]|abstract[192]	giv[190]|new[192]	_	_
21-28	3577-3580	and	abstract[190]	giv[190]	_	_
21-29	3581-3592	astringency	abstract[190]|abstract	giv[190]|new	_	_
21-30	3593-3594	,	_	_	_	_
21-31	3595-3598	and	_	_	_	_
21-32	3599-3602	the	abstract[194]	giv[194]	coref	24-12[225_194]
21-33	3603-3614	lower-order	abstract[194]	giv[194]	_	_
21-34	3615-3622	measure	abstract[194]	giv[194]	_	_
21-35	3623-3625	of	abstract[194]	giv[194]	_	_
21-36	3626-3631	error	abstract[194]|abstract	giv[194]|giv	coref	22-24
21-37	3632-3634	is	_	_	_	_
21-38	3635-3642	usually	_	_	_	_
21-39	3643-3647	more	_	_	_	_
21-40	3648-3657	desirable	_	_	_	_
21-41	3658-3660	in	_	_	_	_
21-42	3661-3666	these	place[197]	giv[197]	_	_
21-43	3667-3672	noise	abstract|place[197]	new|giv[197]	coref	25-8
21-44	3673-3685	environments	place[197]	giv[197]	_	_
21-45	3686-3690	with	place[197]	giv[197]	_	_
21-46	3691-3695	slow	place[197]|abstract[199]	giv[197]|new[199]	coref	30-10[285_199]
21-47	3696-3707	convergence	place[197]|abstract|abstract[199]	giv[197]|new|new[199]	coref	30-10
21-48	3708-3712	rate	place[197]|abstract[199]	giv[197]|new[199]	_	_
21-49	3713-3714	.	_	_	_	_

#Text=Recently , the information theoretic learning ( ITL ) similarity measures , such as the maximum correntropy criterion ( MCC ) and minimum error entropy criterion ( MEE ) , have been introduced to implement robust KAFs .
22-1	3715-3723	Recently	_	_	_	_
22-2	3724-3725	,	_	_	_	_
22-3	3726-3729	the	abstract[200]	new[200]	_	_
22-4	3730-3741	information	abstract[200]	new[200]	_	_
22-5	3742-3751	theoretic	abstract[200]|abstract[201]|abstract[204]	new[200]|giv[201]|giv[204]	appos|coref|appos|coref	22-8[0_201]|23-1[215_204]|22-8[0_201]|23-1[215_204]
22-6	3752-3760	learning	abstract[200]|abstract[201]|abstract[204]	new[200]|giv[201]|giv[204]	_	_
22-7	3761-3762	(	abstract[200]|abstract[204]	new[200]|giv[204]	_	_
22-8	3763-3766	ITL	abstract[200]|abstract|abstract[204]	new[200]|giv|giv[204]	coref	23-2
22-9	3767-3768	)	abstract[200]|abstract[204]	new[200]|giv[204]	_	_
22-10	3769-3779	similarity	abstract[200]|abstract|abstract[204]	new[200]|new|giv[204]	coref	23-3
22-11	3780-3788	measures	abstract[200]|abstract[204]	new[200]|giv[204]	_	_
22-12	3789-3790	,	abstract[200]|abstract[204]	new[200]|giv[204]	_	_
22-13	3791-3795	such	abstract[200]|abstract[204]	new[200]|giv[204]	_	_
22-14	3796-3798	as	abstract[200]|abstract[204]	new[200]|giv[204]	_	_
22-15	3799-3802	the	abstract[200]|abstract[204]|abstract[206]	new[200]|giv[204]|giv[206]	coref	22-23[210_206]
22-16	3803-3810	maximum	abstract[200]|abstract[204]|abstract[206]	new[200]|giv[204]|giv[206]	_	_
22-17	3811-3822	correntropy	abstract[200]|abstract[204]|abstract|abstract[206]	new[200]|giv[204]|giv|giv[206]	_	_
22-18	3823-3832	criterion	abstract[200]|abstract[204]|abstract[206]	new[200]|giv[204]|giv[206]	_	_
22-19	3833-3834	(	_	_	_	_
22-20	3835-3838	MCC	object	new	_	_
22-21	3839-3840	)	_	_	_	_
22-22	3841-3844	and	_	_	_	_
22-23	3845-3852	minimum	abstract[210]	giv[210]	coref	25-22[0_210]
22-24	3853-3858	error	abstract|abstract[210]	giv|giv[210]	coref	24-9[223_0]
22-25	3859-3866	entropy	quantity|abstract[210]	new|giv[210]	_	_
22-26	3867-3876	criterion	abstract[210]	giv[210]	_	_
22-27	3877-3878	(	_	_	_	_
22-28	3879-3882	MEE	object	new	_	_
22-29	3883-3884	)	_	_	_	_
22-30	3885-3886	,	_	_	_	_
22-31	3887-3891	have	_	_	_	_
22-32	3892-3896	been	_	_	_	_
22-33	3897-3907	introduced	_	_	_	_
22-34	3908-3910	to	_	_	_	_
22-35	3911-3920	implement	_	_	_	_
22-36	3921-3927	robust	abstract[212]	giv[212]	coref	26-5[245_212]
22-37	3928-3932	KAFs	abstract[212]	giv[212]	_	_
22-38	3933-3934	.	_	_	_	_

#Text=The ITL similarity measures have been shown to have a strong robustness against non-Gaussian noises at the expense of increasing computational burden in training processing .
23-1	3935-3938	The	abstract[215]	giv[215]	_	_
23-2	3939-3942	ITL	abstract|abstract[215]	giv|giv[215]	_	_
23-3	3943-3953	similarity	abstract|abstract[215]	giv|giv[215]	_	_
23-4	3954-3962	measures	abstract[215]	giv[215]	_	_
23-5	3963-3967	have	_	_	_	_
23-6	3968-3972	been	_	_	_	_
23-7	3973-3978	shown	_	_	_	_
23-8	3979-3981	to	_	_	_	_
23-9	3982-3986	have	_	_	_	_
23-10	3987-3988	a	abstract[216]	new[216]	_	_
23-11	3989-3995	strong	abstract[216]	new[216]	_	_
23-12	3996-4006	robustness	abstract[216]	new[216]	_	_
23-13	4007-4014	against	abstract[216]	new[216]	_	_
23-14	4015-4027	non-Gaussian	abstract[216]|abstract[217]	new[216]|giv[217]	coref	25-27[241_217]
23-15	4028-4034	noises	abstract[216]|abstract[217]	new[216]|giv[217]	_	_
23-16	4035-4037	at	abstract[216]|abstract[217]	new[216]|giv[217]	_	_
23-17	4038-4041	the	abstract[216]|abstract[217]|abstract[218]	new[216]|giv[217]|new[218]	_	_
23-18	4042-4049	expense	abstract[216]|abstract[217]|abstract[218]	new[216]|giv[217]|new[218]	_	_
23-19	4050-4052	of	_	_	_	_
23-20	4053-4063	increasing	_	_	_	_
23-21	4064-4077	computational	abstract[219]	new[219]	_	_
23-22	4078-4084	burden	abstract[219]	new[219]	_	_
23-23	4085-4087	in	abstract[219]	new[219]	_	_
23-24	4088-4096	training	abstract[219]|abstract|abstract[221]	new[219]|giv|new[221]	_	_
23-25	4097-4107	processing	abstract[219]|abstract[221]	new[219]|new[221]	_	_
23-26	4108-4109	.	_	_	_	_

#Text=In addition , minimizing the logarithmic moments of the error , the logarithmic error measure — including the Cauchy loss ( CL ) with low computational complexity — is an appropriate measure of optimality .
24-1	4110-4112	In	_	_	_	_
24-2	4113-4121	addition	_	_	_	_
24-3	4122-4123	,	_	_	_	_
24-4	4124-4134	minimizing	_	_	_	_
24-5	4135-4138	the	abstract[222]	new[222]	_	_
24-6	4139-4150	logarithmic	abstract[222]	new[222]	_	_
24-7	4151-4158	moments	abstract[222]	new[222]	_	_
24-8	4159-4161	of	abstract[222]	new[222]	_	_
24-9	4162-4165	the	abstract[222]|abstract[223]	new[222]|giv[223]	coref	24-14[0_223]
24-10	4166-4171	error	abstract[222]|abstract[223]	new[222]|giv[223]	_	_
24-11	4172-4173	,	_	_	_	_
24-12	4174-4177	the	abstract[225]	giv[225]	coref	24-30[230_225]
24-13	4178-4189	logarithmic	abstract[225]	giv[225]	_	_
24-14	4190-4195	error	abstract|abstract[225]	giv|giv[225]	_	_
24-15	4196-4203	measure	abstract[225]	giv[225]	_	_
24-16	4204-4205	—	abstract[225]	giv[225]	_	_
24-17	4206-4215	including	abstract[225]	giv[225]	_	_
24-18	4216-4219	the	abstract[225]|abstract[227]	giv[225]|giv[227]	appos	24-22[0_227]
24-19	4220-4226	Cauchy	abstract[225]|person|abstract[227]	giv[225]|new|giv[227]	coref	25-3
24-20	4227-4231	loss	abstract[225]|abstract[227]	giv[225]|giv[227]	_	_
24-21	4232-4233	(	_	_	_	_
24-22	4234-4236	CL	abstract	giv	coref	25-2[233_0]
24-23	4237-4238	)	_	_	_	_
24-24	4239-4243	with	_	_	_	_
24-25	4244-4247	low	abstract[229]	new[229]	coref	30-13[286_229]
24-26	4248-4261	computational	abstract[229]	new[229]	_	_
24-27	4262-4272	complexity	abstract[229]	new[229]	_	_
24-28	4273-4274	—	_	_	_	_
24-29	4275-4277	is	_	_	_	_
24-30	4278-4280	an	abstract[230]	giv[230]	_	_
24-31	4281-4292	appropriate	abstract[230]	giv[230]	_	_
24-32	4293-4300	measure	abstract[230]	giv[230]	_	_
24-33	4301-4303	of	abstract[230]	giv[230]	_	_
24-34	4304-4314	optimality	abstract[230]|abstract	giv[230]|new	_	_
24-35	4315-4316	.	_	_	_	_

#Text=Using the Cauchy loss to penalize the noise term , some algorithms based on the minimum Cauchy loss ( MCL ) criterion are efficient for combating non-Gaussian noises , especially for heavy-tailed - stable noises .
25-1	4317-4322	Using	_	_	_	_
25-2	4323-4326	the	abstract[233]	giv[233]	coref	25-15[238_233]
25-3	4327-4333	Cauchy	person|abstract[233]	giv|giv[233]	coref	25-17
25-4	4334-4338	loss	abstract[233]	giv[233]	_	_
25-5	4339-4341	to	_	_	_	_
25-6	4342-4350	penalize	_	_	_	_
25-7	4351-4354	the	abstract[235]	new[235]	_	_
25-8	4355-4360	noise	abstract|abstract[235]	giv|new[235]	_	_
25-9	4361-4365	term	abstract[235]	new[235]	_	_
25-10	4366-4367	,	_	_	_	_
25-11	4368-4372	some	abstract[236]	giv[236]	coref	26-14[248_236]
25-12	4373-4383	algorithms	abstract[236]	giv[236]	_	_
25-13	4384-4389	based	_	_	_	_
25-14	4390-4392	on	_	_	_	_
25-15	4393-4396	the	abstract[238]	giv[238]	coref	26-26[0_238]
25-16	4397-4404	minimum	abstract[238]	giv[238]	_	_
25-17	4405-4411	Cauchy	person|abstract[238]	giv|giv[238]	_	_
25-18	4412-4416	loss	abstract[238]	giv[238]	_	_
25-19	4417-4418	(	_	_	_	_
25-20	4419-4422	MCL	object	new	_	_
25-21	4423-4424	)	_	_	_	_
25-22	4425-4434	criterion	abstract	giv	_	_
25-23	4435-4438	are	_	_	_	_
25-24	4439-4448	efficient	_	_	_	_
25-25	4449-4452	for	_	_	_	_
25-26	4453-4462	combating	_	_	_	_
25-27	4463-4475	non-Gaussian	abstract[241]	giv[241]	coref	25-30[242_241]
25-28	4476-4482	noises	abstract[241]	giv[241]	_	_
25-29	4483-4484	,	_	_	_	_
25-30	4485-4495	especially	abstract[242]	giv[242]	_	_
25-31	4496-4499	for	abstract[242]	giv[242]	_	_
25-32	4500-4512	heavy-tailed	abstract[242]	giv[242]	_	_
25-33	4513-4514	-	abstract[242]	giv[242]	_	_
25-34	4515-4521	stable	abstract[242]	giv[242]	_	_
25-35	4522-4528	noises	abstract[242]	giv[242]	_	_
25-36	4529-4530	.	_	_	_	_

#Text=From the aspect of the optimization method , the stochastic gradient descent ( SGD)-based algorithms cannot find the minimum using the negative gradient in some loss functions .
26-1	4531-4535	From	_	_	_	_
26-2	4536-4539	the	abstract[243]	new[243]	_	_
26-3	4540-4546	aspect	abstract[243]	new[243]	_	_
26-4	4547-4549	of	abstract[243]	new[243]	_	_
26-5	4550-4553	the	abstract[243]|abstract[245]	new[243]|giv[245]	coref	28-4[260_245]
26-6	4554-4566	optimization	abstract[243]|abstract|abstract[245]	new[243]|new|giv[245]	coref	28-29
26-7	4567-4573	method	abstract[243]|abstract[245]	new[243]|giv[245]	_	_
26-8	4574-4575	,	_	_	_	_
26-9	4576-4579	the	abstract[247]	giv[247]	coref	28-5[0_247]
26-10	4580-4590	stochastic	abstract[247]	giv[247]	_	_
26-11	4591-4599	gradient	abstract|abstract[247]	giv|giv[247]	coref	26-21[250_0]
26-12	4600-4607	descent	abstract[247]	giv[247]	_	_
26-13	4608-4609	(	_	_	_	_
26-14	4610-4620	SGD)-based	abstract[248]	giv[248]	coref	27-5[254_248]
26-15	4621-4631	algorithms	abstract[248]	giv[248]	_	_
26-16	4632-4638	cannot	_	_	_	_
26-17	4639-4643	find	_	_	_	_
26-18	4644-4647	the	abstract[249]	new[249]	_	_
26-19	4648-4655	minimum	abstract[249]	new[249]	_	_
26-20	4656-4661	using	_	_	_	_
26-21	4662-4665	the	abstract[250]	giv[250]	coref	28-11[263_250]
26-22	4666-4674	negative	abstract[250]	giv[250]	_	_
26-23	4675-4683	gradient	abstract[250]	giv[250]	_	_
26-24	4684-4686	in	abstract[250]	giv[250]	_	_
26-25	4687-4691	some	abstract[250]|abstract[252]	giv[250]|new[252]	_	_
26-26	4692-4696	loss	abstract[250]|abstract|abstract[252]	giv[250]|giv|new[252]	_	_
26-27	4697-4706	functions	abstract[250]|abstract[252]	giv[250]|new[252]	_	_
26-28	4707-4708	.	_	_	_	_

#Text=Toward this end , recursive-based algorithms address these issues at the cost of increasing computational cost .
27-1	4709-4715	Toward	_	_	_	_
27-2	4716-4720	this	abstract[253]	new[253]	_	_
27-3	4721-4724	end	abstract[253]	new[253]	_	_
27-4	4725-4726	,	_	_	_	_
27-5	4727-4742	recursive-based	abstract[254]	giv[254]	coref	29-17[0_254]
27-6	4743-4753	algorithms	abstract[254]	giv[254]	_	_
27-7	4754-4761	address	_	_	_	_
27-8	4762-4767	these	abstract[255]	new[255]	_	_
27-9	4768-4774	issues	abstract[255]	new[255]	_	_
27-10	4775-4777	at	_	_	_	_
27-11	4778-4781	the	abstract[256]	new[256]	coref	27-15[257_256]
27-12	4782-4786	cost	abstract[256]	new[256]	_	_
27-13	4787-4789	of	_	_	_	_
27-14	4790-4800	increasing	_	_	_	_
27-15	4801-4814	computational	abstract[257]	giv[257]	_	_
27-16	4815-4819	cost	abstract[257]	giv[257]	_	_
27-17	4820-4821	.	_	_	_	_

#Text=In comparison with the SGD method and recursive method , the conjugate gradient ( CG ) method and Newton ’s method as developments of SGD have become alternative optimization methods in KAFs .
28-1	4822-4824	In	_	_	_	_
28-2	4825-4835	comparison	abstract[258]	new[258]	_	_
28-3	4836-4840	with	abstract[258]	new[258]	_	_
28-4	4841-4844	the	abstract[258]|abstract[260]|abstract[261]	new[258]|giv[260]|giv[261]	coref|coref|coref|coref	28-8[262_260]|28-11[266_261]|28-8[262_260]|28-11[266_261]
28-5	4845-4848	SGD	abstract[258]|abstract|abstract[260]|abstract[261]	new[258]|giv|giv[260]|giv[261]	coref	28-25
28-6	4849-4855	method	abstract[258]|abstract[260]|abstract[261]	new[258]|giv[260]|giv[261]	_	_
28-7	4856-4859	and	abstract[258]|abstract[261]	new[258]|giv[261]	_	_
28-8	4860-4869	recursive	abstract[258]|abstract[261]|abstract[262]	new[258]|giv[261]|giv[262]	coref	28-11[265_262]
28-9	4870-4876	method	abstract[258]|abstract[261]|abstract[262]	new[258]|giv[261]|giv[262]	_	_
28-10	4877-4878	,	_	_	_	_
28-11	4879-4882	the	abstract[263]|abstract[265]|abstract[266]	giv[263]|giv[265]|giv[266]	appos|coref|appos|coref|appos|coref	28-15[0_263]|28-19[268_265]|28-15[0_263]|28-19[268_265]|28-15[0_263]|28-19[268_265]
28-12	4883-4892	conjugate	abstract[263]|abstract[265]|abstract[266]	giv[263]|giv[265]|giv[266]	_	_
28-13	4893-4901	gradient	abstract[263]|abstract[265]|abstract[266]	giv[263]|giv[265]|giv[266]	_	_
28-14	4902-4903	(	abstract[265]|abstract[266]	giv[265]|giv[266]	_	_
28-15	4904-4906	CG	abstract|abstract[265]|abstract[266]	giv|giv[265]|giv[266]	coref	30-4
28-16	4907-4908	)	abstract[265]|abstract[266]	giv[265]|giv[266]	_	_
28-17	4909-4915	method	abstract[265]|abstract[266]	giv[265]|giv[266]	_	_
28-18	4916-4919	and	abstract[266]	giv[266]	_	_
28-19	4920-4926	Newton	abstract[266]|person[267]|abstract[268]	giv[266]|new[267]|giv[268]	coref|coref|coref|coref	28-32[0_268]|29-6[275_267]|28-32[0_268]|29-6[275_267]
28-20	4927-4929	’s	abstract[266]|person[267]|abstract[268]	giv[266]|new[267]|giv[268]	_	_
28-21	4930-4936	method	abstract[266]|abstract[268]	giv[266]|giv[268]	_	_
28-22	4937-4939	as	abstract[266]|abstract[268]	giv[266]|giv[268]	_	_
28-23	4940-4952	developments	abstract[266]|abstract[268]	giv[266]|giv[268]	_	_
28-24	4953-4955	of	abstract[266]|abstract[268]	giv[266]|giv[268]	_	_
28-25	4956-4959	SGD	abstract[266]|abstract[268]|abstract	giv[266]|giv[268]|giv	_	_
28-26	4960-4964	have	_	_	_	_
28-27	4965-4971	become	_	_	_	_
28-28	4972-4983	alternative	abstract[271]	giv[271]	_	_
28-29	4984-4996	optimization	abstract|abstract[271]	giv|giv[271]	coref	30-37[291_0]
28-30	4997-5004	methods	abstract[271]	giv[271]	_	_
28-31	5005-5007	in	abstract[271]	giv[271]	_	_
28-32	5008-5012	KAFs	abstract[271]|abstract	giv[271]|giv	coref	29-6[276_0]
28-33	5013-5014	.	_	_	_	_

#Text=The inverse of matrix of Newton ’s method increases the computation and causes the divergence of algorithms in some cases .
29-1	5015-5018	The	abstract[273]	new[273]	_	_
29-2	5019-5026	inverse	abstract[273]	new[273]	_	_
29-3	5027-5029	of	abstract[273]	new[273]	_	_
29-4	5030-5036	matrix	abstract[273]|abstract[274]	new[273]|new[274]	_	_
29-5	5037-5039	of	abstract[273]|abstract[274]	new[273]|new[274]	_	_
29-6	5040-5046	Newton	abstract[273]|abstract[274]|person[275]|abstract[276]	new[273]|new[274]|giv[275]|giv[276]	coref|coref	30-3[282_276]|30-3[282_276]
29-7	5047-5049	’s	abstract[273]|abstract[274]|person[275]|abstract[276]	new[273]|new[274]|giv[275]|giv[276]	_	_
29-8	5050-5056	method	abstract[273]|abstract[274]|abstract[276]	new[273]|new[274]|giv[276]	_	_
29-9	5057-5066	increases	_	_	_	_
29-10	5067-5070	the	abstract[277]	new[277]	coref	30-16[287_277]
29-11	5071-5082	computation	abstract[277]	new[277]	_	_
29-12	5083-5086	and	_	_	_	_
29-13	5087-5093	causes	_	_	_	_
29-14	5094-5097	the	abstract[278]	new[278]	_	_
29-15	5098-5108	divergence	abstract[278]	new[278]	_	_
29-16	5109-5111	of	abstract[278]	new[278]	_	_
29-17	5112-5122	algorithms	abstract[278]|abstract	new[278]|giv	_	_
29-18	5123-5125	in	_	_	_	_
29-19	5126-5130	some	abstract[280]	new[280]	_	_
29-20	5131-5136	cases	abstract[280]	new[280]	_	_
29-21	5137-5138	.	_	_	_	_

#Text=However , the CG method gives a trade-off between convergence rate and computational complexity without the inverse computation , and has been successfully applied in various fields , including compressed sensing , neural networks , and large-scale optimization .
30-1	5139-5146	However	_	_	_	_
30-2	5147-5148	,	_	_	_	_
30-3	5149-5152	the	abstract[282]	giv[282]	coref	31-11[0_282]
30-4	5153-5155	CG	abstract|abstract[282]	giv|giv[282]	coref	31-4[294_0]
30-5	5156-5162	method	abstract[282]	giv[282]	_	_
30-6	5163-5168	gives	_	_	_	_
30-7	5169-5170	a	abstract[283]	new[283]	_	_
30-8	5171-5180	trade-off	abstract[283]	new[283]	_	_
30-9	5181-5188	between	abstract[283]	new[283]	_	_
30-10	5189-5200	convergence	abstract[283]|abstract|abstract[285]	new[283]|giv|giv[285]	_	_
30-11	5201-5205	rate	abstract[283]|abstract[285]	new[283]|giv[285]	_	_
30-12	5206-5209	and	abstract[283]	new[283]	_	_
30-13	5210-5223	computational	abstract[283]|abstract[286]	new[283]|giv[286]	_	_
30-14	5224-5234	complexity	abstract[283]|abstract[286]	new[283]|giv[286]	_	_
30-15	5235-5242	without	abstract[283]|abstract[286]	new[283]|giv[286]	_	_
30-16	5243-5246	the	abstract[283]|abstract[286]|abstract[287]	new[283]|giv[286]|giv[287]	_	_
30-17	5247-5254	inverse	abstract[283]|abstract[286]|abstract[287]	new[283]|giv[286]|giv[287]	_	_
30-18	5255-5266	computation	abstract[283]|abstract[286]|abstract[287]	new[283]|giv[286]|giv[287]	_	_
30-19	5267-5268	,	_	_	_	_
30-20	5269-5272	and	_	_	_	_
30-21	5273-5276	has	_	_	_	_
30-22	5277-5281	been	_	_	_	_
30-23	5282-5294	successfully	_	_	_	_
30-24	5295-5302	applied	_	_	_	_
30-25	5303-5305	in	_	_	_	_
30-26	5306-5313	various	abstract[288]	new[288]	_	_
30-27	5314-5320	fields	abstract[288]	new[288]	_	_
30-28	5321-5322	,	abstract[288]	new[288]	_	_
30-29	5323-5332	including	abstract[288]	new[288]	_	_
30-30	5333-5343	compressed	abstract[288]|abstract[289]	new[288]|new[289]	_	_
30-31	5344-5351	sensing	abstract[288]|abstract[289]	new[288]|new[289]	_	_
30-32	5352-5353	,	abstract[288]	new[288]	_	_
30-33	5354-5360	neural	abstract[288]|abstract[290]	new[288]|new[290]	_	_
30-34	5361-5369	networks	abstract[288]|abstract[290]	new[288]|new[290]	_	_
30-35	5370-5371	,	abstract[288]	new[288]	_	_
30-36	5372-5375	and	abstract[288]	new[288]	_	_
30-37	5376-5387	large-scale	abstract[288]|abstract[291]	new[288]|giv[291]	_	_
30-38	5388-5400	optimization	abstract[288]|abstract[291]	new[288]|giv[291]	_	_
30-39	5401-5402	.	_	_	_	_

#Text=In addition , the kernel conjugate gradient ( KCG ) method is proposed for adaptive filtering .
31-1	5403-5405	In	_	_	_	_
31-2	5406-5414	addition	_	_	_	_
31-3	5415-5416	,	_	_	_	_
31-4	5417-5420	the	abstract[294]	giv[294]	appos	31-9[0_294]
31-5	5421-5427	kernel	person|abstract[294]	giv|giv[294]	_	_
31-6	5428-5437	conjugate	abstract|abstract[294]	new|giv[294]	_	_
31-7	5438-5446	gradient	abstract[294]	giv[294]	_	_
31-8	5447-5448	(	_	_	_	_
31-9	5449-5452	KCG	abstract	giv	coref	32-1[298_0]
31-10	5453-5454	)	_	_	_	_
31-11	5455-5461	method	abstract	giv	_	_
31-12	5462-5464	is	_	_	_	_
31-13	5465-5473	proposed	_	_	_	_
31-14	5474-5477	for	_	_	_	_
31-15	5478-5486	adaptive	abstract[297]	new[297]	_	_
31-16	5487-5496	filtering	abstract[297]	new[297]	_	_
31-17	5497-5498	.	_	_	_	_

#Text=KCG with low computational and space requirements can produce a better solution than KLMS , and has comparable accuracy to KRLS .
32-1	5499-5502	KCG	abstract[298]	giv[298]	_	_
32-2	5503-5507	with	abstract[298]	giv[298]	_	_
32-3	5508-5511	low	abstract[298]|abstract[299]	giv[298]|new[299]	_	_
32-4	5512-5525	computational	abstract[298]|abstract[299]	giv[298]|new[299]	_	_
32-5	5526-5529	and	abstract[298]|abstract[299]	giv[298]|new[299]	_	_
32-6	5530-5535	space	abstract[298]|abstract[299]	giv[298]|new[299]	_	_
32-7	5536-5548	requirements	abstract[298]|abstract[299]	giv[298]|new[299]	_	_
32-8	5549-5552	can	_	_	_	_
32-9	5553-5560	produce	_	_	_	_
32-10	5561-5562	a	abstract[300]	giv[300]	_	_
32-11	5563-5569	better	abstract[300]	giv[300]	_	_
32-12	5570-5578	solution	abstract[300]	giv[300]	_	_
32-13	5579-5583	than	abstract[300]	giv[300]	_	_
32-14	5584-5588	KLMS	abstract[300]|abstract	giv[300]|giv	_	_
32-15	5589-5590	,	_	_	_	_
32-16	5591-5594	and	_	_	_	_
32-17	5595-5598	has	_	_	_	_
32-18	5599-5609	comparable	abstract[302]	new[302]	_	_
32-19	5610-5618	accuracy	abstract[302]	new[302]	_	_
32-20	5619-5621	to	_	_	_	_
32-21	5622-5626	KRLS	abstract	giv	_	_
32-22	5627-5628	.	_	_	_	_
