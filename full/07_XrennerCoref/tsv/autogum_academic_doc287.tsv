#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Referent|entity|infstat
#T_RL=webanno.custom.Coref|type|BT_webanno.custom.Referent


#Text=1 .
1-1	0-1	1	quantity	new	_	_
1-2	2-3	.	_	_	_	_

#Text=Introduction
2-1	4-16	Introduction	abstract	new	_	_

#Text=Significant technological progress in image processing algorithms and ability to improve perception of the world surrounding us using modern deep learning methods has led to invention and enablement of various applications that were previously much harder to implement , e. g. , face recognition , objects detection and segmentation or image resolution enhancement .
3-1	17-28	Significant	abstract[3]	new[3]	coref	5-9[34_3]
3-2	29-42	technological	abstract[3]	new[3]	_	_
3-3	43-51	progress	abstract[3]	new[3]	_	_
3-4	52-54	in	abstract[3]	new[3]	_	_
3-5	55-60	image	abstract[3]|object	new[3]|new	coref	3-51
3-6	61-71	processing	abstract[3]|abstract|abstract[6]	new[3]|new|new[6]	coref|coref	23-26[157_6]|23-26[157_6]
3-7	72-82	algorithms	abstract[3]|abstract[6]	new[3]|new[6]	_	_
3-8	83-86	and	abstract[3]	new[3]	_	_
3-9	87-94	ability	abstract[3]|abstract	new[3]|new	_	_
3-10	95-97	to	_	_	_	_
3-11	98-105	improve	_	_	_	_
3-12	106-116	perception	abstract[8]	new[8]	_	_
3-13	117-119	of	abstract[8]	new[8]	_	_
3-14	120-123	the	abstract[8]|place[9]	new[8]|new[9]	_	_
3-15	124-129	world	abstract[8]|place[9]	new[8]|new[9]	_	_
3-16	130-141	surrounding	_	_	_	_
3-17	142-144	us	person	acc	_	_
3-18	145-150	using	_	_	_	_
3-19	151-157	modern	abstract[12]	new[12]	coref	12-5[91_12]
3-20	158-162	deep	abstract[12]	new[12]	_	_
3-21	163-171	learning	abstract|abstract[12]	new|new[12]	_	_
3-22	172-179	methods	abstract[12]	new[12]	_	_
3-23	180-183	has	_	_	_	_
3-24	184-187	led	_	_	_	_
3-25	188-190	to	_	_	_	_
3-26	191-200	invention	event	new	_	_
3-27	201-204	and	_	_	_	_
3-28	205-215	enablement	event[14]	new[14]	_	_
3-29	216-218	of	event[14]	new[14]	_	_
3-30	219-226	various	event[14]|abstract[15]	new[14]|new[15]	coref	4-10[27_15]
3-31	227-239	applications	event[14]|abstract[15]	new[14]|new[15]	_	_
3-32	240-244	that	_	_	_	_
3-33	245-249	were	_	_	_	_
3-34	250-260	previously	_	_	_	_
3-35	261-265	much	_	_	_	_
3-36	266-272	harder	_	_	_	_
3-37	273-275	to	_	_	_	_
3-38	276-285	implement	_	_	_	_
3-39	286-287	,	_	_	_	_
3-40	288-290	e.	_	_	_	_
3-41	291-293	g.	_	_	_	_
3-42	294-295	,	_	_	_	_
3-43	296-300	face	object|abstract[17]	new|new[17]	coref|coref	23-9[151_0]|23-9[151_0]
3-44	301-312	recognition	abstract[17]	new[17]	_	_
3-45	313-314	,	_	_	_	_
3-46	315-322	objects	object|abstract[19]	new|new[19]	coref|coref	21-10[134_19]|21-10[134_19]
3-47	323-332	detection	abstract[19]	new[19]	_	_
3-48	333-336	and	_	_	_	_
3-49	337-349	segmentation	abstract	new	_	_
3-50	350-352	or	_	_	_	_
3-51	353-358	image	object|abstract[23]	giv|new[23]	_	_
3-52	359-369	resolution	abstract|abstract[23]	new|new[23]	coref	20-3[128_0]
3-53	370-381	enhancement	abstract[23]	new[23]	_	_
3-54	382-383	.	_	_	_	_

#Text=Another factor that steers the direction of advances in new applications is the increased capabilities of many electronic digital devices .
4-1	384-391	Another	abstract[24]	new[24]	coref	4-13[28_24]
4-2	392-398	factor	abstract[24]	new[24]	_	_
4-3	399-403	that	_	_	_	_
4-4	404-410	steers	_	_	_	_
4-5	411-414	the	abstract[25]	new[25]	_	_
4-6	415-424	direction	abstract[25]	new[25]	_	_
4-7	425-427	of	abstract[25]	new[25]	_	_
4-8	428-436	advances	abstract[25]|abstract[26]	new[25]|new[26]	_	_
4-9	437-439	in	abstract[25]|abstract[26]	new[25]|new[26]	_	_
4-10	440-443	new	abstract[25]|abstract[26]|abstract[27]	new[25]|new[26]|giv[27]	coref	6-7[41_27]
4-11	444-456	applications	abstract[25]|abstract[26]|abstract[27]	new[25]|new[26]|giv[27]	_	_
4-12	457-459	is	_	_	_	_
4-13	460-463	the	abstract[28]	giv[28]	_	_
4-14	464-473	increased	abstract[28]	giv[28]	_	_
4-15	474-486	capabilities	abstract[28]	giv[28]	_	_
4-16	487-489	of	abstract[28]	giv[28]	_	_
4-17	490-494	many	abstract[28]|object[29]	giv[28]|new[29]	coref	5-24[38_29]
4-18	495-505	electronic	abstract[28]|object[29]	giv[28]|new[29]	_	_
4-19	506-513	digital	abstract[28]|object[29]	giv[28]|new[29]	_	_
4-20	514-521	devices	abstract[28]|object[29]	giv[28]|new[29]	_	_
4-21	522-523	.	_	_	_	_

#Text=Medical diagnostics and reasoning systems also benefited from this progress , allowing for real-time vital signs analysis and tracking using standard cameras or wearable devices .
5-1	524-531	Medical	abstract[30]|abstract[31]	new[30]|new[31]	coref|coref|coref|coref	6-11[42_30]|6-11[43_31]|6-11[42_30]|6-11[43_31]
5-2	532-543	diagnostics	abstract[30]|abstract[31]	new[30]|new[31]	_	_
5-3	544-547	and	abstract[31]	new[31]	_	_
5-4	548-557	reasoning	abstract[31]|abstract|abstract[33]	new[31]|new|new[33]	_	_
5-5	558-565	systems	abstract[31]|abstract[33]	new[31]|new[33]	_	_
5-6	566-570	also	_	_	_	_
5-7	571-580	benefited	_	_	_	_
5-8	581-585	from	_	_	_	_
5-9	586-590	this	abstract[34]	giv[34]	_	_
5-10	591-599	progress	abstract[34]	giv[34]	_	_
5-11	600-601	,	_	_	_	_
5-12	602-610	allowing	_	_	_	_
5-13	611-614	for	_	_	_	_
5-14	615-624	real-time	abstract[36]	new[36]	coref	6-41[55_36]
5-15	625-630	vital	abstract[36]	new[36]	_	_
5-16	631-636	signs	abstract|abstract[36]	new|new[36]	_	_
5-17	637-645	analysis	abstract[36]	new[36]	_	_
5-18	646-649	and	_	_	_	_
5-19	650-658	tracking	_	_	_	_
5-20	659-664	using	_	_	_	_
5-21	665-673	standard	object[37]	new[37]	coref	7-4[58_37]
5-22	674-681	cameras	object[37]	new[37]	_	_
5-23	682-684	or	_	_	_	_
5-24	685-693	wearable	object[38]	giv[38]	_	_
5-25	694-701	devices	object[38]	giv[38]	_	_
5-26	702-703	.	_	_	_	_

#Text=The remote measurement of RR has many potential applications in medical diagnostics and screenings like monitoring of newborns or small children in incubators or hospital beds , monitoring of the severe acute respiratory syndrome ( SARS ) , support in emotion analysis , etc.
6-1	704-707	The	abstract[39]	new[39]	_	_
6-2	708-714	remote	abstract[39]	new[39]	_	_
6-3	715-726	measurement	abstract[39]	new[39]	_	_
6-4	727-729	of	abstract[39]	new[39]	_	_
6-5	730-732	RR	abstract[39]|abstract	new[39]|new	_	_
6-6	733-736	has	_	_	_	_
6-7	737-741	many	abstract[41]	giv[41]	_	_
6-8	742-751	potential	abstract[41]	giv[41]	_	_
6-9	752-764	applications	abstract[41]	giv[41]	_	_
6-10	765-767	in	abstract[41]	giv[41]	_	_
6-11	768-775	medical	abstract[41]|abstract[42]|abstract[43]	giv[41]|giv[42]|giv[43]	_	_
6-12	776-787	diagnostics	abstract[41]|abstract[42]|abstract[43]	giv[41]|giv[42]|giv[43]	_	_
6-13	788-791	and	abstract[41]|abstract[43]	giv[41]|giv[43]	_	_
6-14	792-802	screenings	abstract[41]|abstract[43]|event	giv[41]|giv[43]|new	_	_
6-15	803-807	like	abstract[41]	giv[41]	_	_
6-16	808-818	monitoring	abstract[41]|event[45]	giv[41]|new[45]	_	_
6-17	819-821	of	abstract[41]|event[45]	giv[41]|new[45]	_	_
6-18	822-830	newborns	abstract[41]|event[45]|person	giv[41]|new[45]|new	_	_
6-19	831-833	or	abstract[41]|event[45]	giv[41]|new[45]	_	_
6-20	834-839	small	abstract[41]|event[45]|person[47]	giv[41]|new[45]|new[47]	_	_
6-21	840-848	children	abstract[41]|event[45]|person[47]	giv[41]|new[45]|new[47]	_	_
6-22	849-851	in	abstract[41]|event[45]|person[47]	giv[41]|new[45]|new[47]	_	_
6-23	852-862	incubators	abstract[41]|event[45]|person[47]|object	giv[41]|new[45]|new[47]|new	_	_
6-24	863-865	or	abstract[41]|event[45]|person[47]	giv[41]|new[45]|new[47]	_	_
6-25	866-874	hospital	abstract[41]|event[45]|person[47]|place|place[50]	giv[41]|new[45]|new[47]|new|new[50]	_	_
6-26	875-879	beds	abstract[41]|event[45]|person[47]|place[50]	giv[41]|new[45]|new[47]|new[50]	_	_
6-27	880-881	,	_	_	_	_
6-28	882-892	monitoring	_	_	_	_
6-29	893-895	of	_	_	_	_
6-30	896-899	the	abstract[51]	new[51]	appos	6-36[0_51]
6-31	900-906	severe	abstract[51]	new[51]	_	_
6-32	907-912	acute	abstract[51]	new[51]	_	_
6-33	913-924	respiratory	abstract[51]	new[51]	_	_
6-34	925-933	syndrome	abstract[51]	new[51]	_	_
6-35	934-935	(	_	_	_	_
6-36	936-940	SARS	abstract	giv	appos	6-39[53_0]
6-37	941-942	)	_	_	_	_
6-38	943-944	,	_	_	_	_
6-39	945-952	support	abstract[53]	giv[53]	_	_
6-40	953-955	in	abstract[53]	giv[53]	_	_
6-41	956-963	emotion	abstract[53]|abstract|abstract[55]	giv[53]|new|giv[55]	_	_
6-42	964-972	analysis	abstract[53]|abstract[55]	giv[53]|giv[55]	_	_
6-43	973-974	,	_	_	_	_
6-44	975-979	etc.	_	_	_	_

#Text=The use of thermal cameras was proposed to analyze facial images and estimate RR based on a nasal heat flow and described in and other papers .
7-1	980-983	The	abstract[56]	new[56]	_	_
7-2	984-987	use	abstract[56]	new[56]	_	_
7-3	988-990	of	abstract[56]	new[56]	_	_
7-4	991-998	thermal	abstract[56]|animal|object[58]	new[56]|new|giv[58]	coref|coref|coref|coref	9-14|17-5[110_58]|9-14|17-5[110_58]
7-5	999-1006	cameras	abstract[56]|object[58]	new[56]|giv[58]	_	_
7-6	1007-1010	was	_	_	_	_
7-7	1011-1019	proposed	_	_	_	_
7-8	1020-1022	to	_	_	_	_
7-9	1023-1030	analyze	_	_	_	_
7-10	1031-1037	facial	object[59]	new[59]	coref	21-4[0_59]
7-11	1038-1044	images	object[59]	new[59]	_	_
7-12	1045-1048	and	_	_	_	_
7-13	1049-1057	estimate	_	_	_	_
7-14	1058-1060	RR	person	new	coref	8-5
7-15	1061-1066	based	_	_	_	_
7-16	1067-1069	on	_	_	_	_
7-17	1070-1071	a	abstract[62]	new[62]	_	_
7-18	1072-1077	nasal	abstract[62]	new[62]	_	_
7-19	1078-1082	heat	abstract|abstract[62]	new|new[62]	_	_
7-20	1083-1087	flow	abstract[62]	new[62]	_	_
7-21	1088-1091	and	_	_	_	_
7-22	1092-1101	described	_	_	_	_
7-23	1102-1104	in	_	_	_	_
7-24	1105-1108	and	_	_	_	_
7-25	1109-1114	other	object[63]	new[63]	_	_
7-26	1115-1121	papers	object[63]	new[63]	_	_
7-27	1122-1123	.	_	_	_	_

#Text=The typical estimation of RR requires a multi step procedure .
8-1	1124-1127	The	abstract[64]	new[64]	_	_
8-2	1128-1135	typical	abstract[64]	new[64]	_	_
8-3	1136-1146	estimation	abstract[64]	new[64]	_	_
8-4	1147-1149	of	abstract[64]	new[64]	_	_
8-5	1150-1152	RR	abstract[64]|abstract	new[64]|giv	_	_
8-6	1153-1161	requires	_	_	_	_
8-7	1162-1163	a	abstract[67]	new[67]	_	_
8-8	1164-1169	multi	abstract[67]	new[67]	_	_
8-9	1170-1174	step	event|abstract[67]	new|new[67]	coref	13-2[93_0]
8-10	1175-1184	procedure	abstract[67]	new[67]	_	_
8-11	1185-1186	.	_	_	_	_

#Text=First , a Region Of Interest ( ROI ) is detected for each thermal frame representing the source of thermal changes ( due to respiration ) in the area of nostrils or a mouth .
9-1	1187-1192	First	_	_	_	_
9-2	1193-1194	,	_	_	_	_
9-3	1195-1196	a	abstract[68]	new[68]	appos	9-8[0_68]
9-4	1197-1203	Region	abstract[68]	new[68]	_	_
9-5	1204-1206	Of	abstract[68]	new[68]	_	_
9-6	1207-1215	Interest	abstract[68]	new[68]	_	_
9-7	1216-1217	(	_	_	_	_
9-8	1218-1221	ROI	abstract	giv	coref	10-1[78_0]
9-9	1222-1223	)	_	_	_	_
9-10	1224-1226	is	_	_	_	_
9-11	1227-1235	detected	_	_	_	_
9-12	1236-1239	for	_	_	_	_
9-13	1240-1244	each	abstract[71]	new[71]	coref	10-14[79_71]
9-14	1245-1252	thermal	time|abstract[71]	giv|new[71]	coref	17-9
9-15	1253-1258	frame	abstract[71]	new[71]	_	_
9-16	1259-1271	representing	_	_	_	_
9-17	1272-1275	the	abstract[72]	new[72]	_	_
9-18	1276-1282	source	abstract[72]	new[72]	_	_
9-19	1283-1285	of	abstract[72]	new[72]	_	_
9-20	1286-1293	thermal	abstract[72]|abstract[73]	new[72]|new[73]	coref	11-22[88_73]
9-21	1294-1301	changes	abstract[72]|abstract[73]	new[72]|new[73]	_	_
9-22	1302-1303	(	_	_	_	_
9-23	1304-1307	due	_	_	_	_
9-24	1308-1310	to	_	_	_	_
9-25	1311-1322	respiration	abstract	new	_	_
9-26	1323-1324	)	_	_	_	_
9-27	1325-1327	in	_	_	_	_
9-28	1328-1331	the	place[75]	new[75]	_	_
9-29	1332-1336	area	place[75]	new[75]	_	_
9-30	1337-1339	of	place[75]	new[75]	_	_
9-31	1340-1348	nostrils	place[75]|object	new[75]|new	_	_
9-32	1349-1351	or	place[75]	new[75]	_	_
9-33	1352-1353	a	place[75]|object[77]	new[75]|new[77]	_	_
9-34	1354-1359	mouth	place[75]|object[77]	new[75]|new[77]	_	_
9-35	1360-1361	.	_	_	_	_

#Text=The ROI can be specified manually or can be automatically detected ( in a frame or for each frame ) and tracked ( between frames ) .
10-1	1362-1365	The	abstract[78]	giv[78]	coref	12-5[0_78]
10-2	1366-1369	ROI	abstract[78]	giv[78]	_	_
10-3	1370-1373	can	_	_	_	_
10-4	1374-1376	be	_	_	_	_
10-5	1377-1386	specified	_	_	_	_
10-6	1387-1395	manually	_	_	_	_
10-7	1396-1398	or	_	_	_	_
10-8	1399-1402	can	_	_	_	_
10-9	1403-1405	be	_	_	_	_
10-10	1406-1419	automatically	_	_	_	_
10-11	1420-1428	detected	_	_	_	_
10-12	1429-1430	(	_	_	_	_
10-13	1431-1433	in	_	_	_	_
10-14	1434-1435	a	abstract[79]	giv[79]	coref	10-18[80_79]
10-15	1436-1441	frame	abstract[79]	giv[79]	_	_
10-16	1442-1444	or	_	_	_	_
10-17	1445-1448	for	_	_	_	_
10-18	1449-1453	each	abstract[80]	giv[80]	_	_
10-19	1454-1459	frame	abstract[80]	giv[80]	_	_
10-20	1460-1461	)	_	_	_	_
10-21	1462-1465	and	_	_	_	_
10-22	1466-1473	tracked	_	_	_	_
10-23	1474-1475	(	_	_	_	_
10-24	1476-1483	between	_	_	_	_
10-25	1484-1490	frames	abstract	new	_	_
10-26	1491-1492	)	_	_	_	_
10-27	1493-1494	.	_	_	_	_

#Text=In , the authors described a particle filter tracker driven by a probabilistic template function that was capable of adapting to abrupt positional and physiological changes .
11-1	1495-1497	In	_	_	_	_
11-2	1498-1499	,	_	_	_	_
11-3	1500-1503	the	person[82]	new[82]	coref	12-1[89_82]
11-4	1504-1511	authors	person[82]	new[82]	_	_
11-5	1512-1521	described	_	_	_	_
11-6	1522-1523	a	object[85]	new[85]	_	_
11-7	1524-1532	particle	object|object[85]	new|new[85]	_	_
11-8	1533-1539	filter	object|object[85]	new|new[85]	_	_
11-9	1540-1547	tracker	object[85]	new[85]	_	_
11-10	1548-1554	driven	_	_	_	_
11-11	1555-1557	by	_	_	_	_
11-12	1558-1559	a	abstract[87]	new[87]	_	_
11-13	1560-1573	probabilistic	abstract[87]	new[87]	_	_
11-14	1574-1582	template	object|abstract[87]	new|new[87]	_	_
11-15	1583-1591	function	abstract[87]	new[87]	_	_
11-16	1592-1596	that	_	_	_	_
11-17	1597-1600	was	_	_	_	_
11-18	1601-1608	capable	_	_	_	_
11-19	1609-1611	of	_	_	_	_
11-20	1612-1620	adapting	_	_	_	_
11-21	1621-1623	to	_	_	_	_
11-22	1624-1630	abrupt	abstract[88]	giv[88]	coref	14-10[99_88]
11-23	1631-1641	positional	abstract[88]	giv[88]	_	_
11-24	1642-1645	and	abstract[88]	giv[88]	_	_
11-25	1646-1659	physiological	abstract[88]	giv[88]	_	_
11-26	1660-1667	changes	abstract[88]	giv[88]	_	_
11-27	1668-1669	.	_	_	_	_

#Text=Other authors also proposed ROI tracking methods ( e. g. , ) .
12-1	1670-1675	Other	person[89]	giv[89]	_	_
12-2	1676-1683	authors	person[89]	giv[89]	_	_
12-3	1684-1688	also	_	_	_	_
12-4	1689-1697	proposed	_	_	_	_
12-5	1698-1701	ROI	abstract|abstract[91]	giv|giv[91]	coref|coref|coref|coref	13-13[95_0]|22-1[138_91]|13-13[95_0]|22-1[138_91]
12-6	1702-1710	tracking	abstract[91]	giv[91]	_	_
12-7	1711-1718	methods	abstract[91]	giv[91]	_	_
12-8	1719-1720	(	_	_	_	_
12-9	1721-1723	e.	event[92]	new[92]	coref	19-26[124_92]
12-10	1724-1726	g.	event[92]	new[92]	_	_
12-11	1727-1728	,	_	_	_	_
12-12	1729-1730	)	_	_	_	_
12-13	1731-1732	.	_	_	_	_

#Text=In the next step , a single value is calculated to represent each ROI .
13-1	1733-1735	In	_	_	_	_
13-2	1736-1739	the	event[93]	giv[93]	_	_
13-3	1740-1744	next	event[93]	giv[93]	_	_
13-4	1745-1749	step	event[93]	giv[93]	_	_
13-5	1750-1751	,	_	_	_	_
13-6	1752-1753	a	abstract[94]	new[94]	_	_
13-7	1754-1760	single	abstract[94]	new[94]	_	_
13-8	1761-1766	value	abstract[94]	new[94]	_	_
13-9	1767-1769	is	_	_	_	_
13-10	1770-1780	calculated	_	_	_	_
13-11	1781-1783	to	_	_	_	_
13-12	1784-1793	represent	_	_	_	_
13-13	1794-1798	each	abstract[95]	giv[95]	coref	21-17[136_95]
13-14	1799-1802	ROI	abstract[95]	giv[95]	_	_
13-15	1803-1804	.	_	_	_	_

#Text=A collection of such values forms a signal representing local temperature changes in time .
14-1	1805-1806	A	object[96]	new[96]	_	_
14-2	1807-1817	collection	object[96]	new[96]	_	_
14-3	1818-1820	of	object[96]	new[96]	_	_
14-4	1821-1825	such	object[96]|abstract[97]	new[96]|new[97]	_	_
14-5	1826-1832	values	object[96]|abstract[97]	new[96]|new[97]	_	_
14-6	1833-1838	forms	_	_	_	_
14-7	1839-1840	a	abstract[98]	new[98]	coref	15-3[100_98]
14-8	1841-1847	signal	abstract[98]	new[98]	_	_
14-9	1848-1860	representing	_	_	_	_
14-10	1861-1866	local	abstract[99]	giv[99]	coref	15-19[104_99]
14-11	1867-1878	temperature	abstract[99]	giv[99]	_	_
14-12	1879-1886	changes	abstract[99]	giv[99]	_	_
14-13	1887-1889	in	_	_	_	_
14-14	1890-1894	time	_	_	_	_
14-15	1895-1896	.	_	_	_	_

#Text=Finally , a signal is filtered ( e. g. removing high frequency components ) and a frequency for dominated changes is calculated .
15-1	1897-1904	Finally	_	_	_	_
15-2	1905-1906	,	_	_	_	_
15-3	1907-1908	a	abstract[100]	giv[100]	_	_
15-4	1909-1915	signal	abstract[100]	giv[100]	_	_
15-5	1916-1918	is	_	_	_	_
15-6	1919-1927	filtered	_	_	_	_
15-7	1928-1929	(	_	_	_	_
15-8	1930-1932	e.	_	_	_	_
15-9	1933-1935	g.	_	_	_	_
15-10	1936-1944	removing	_	_	_	_
15-11	1945-1949	high	abstract[102]	new[102]	_	_
15-12	1950-1959	frequency	abstract|abstract[102]	new|new[102]	coref	15-16[103_0]
15-13	1960-1970	components	abstract[102]	new[102]	_	_
15-14	1971-1972	)	_	_	_	_
15-15	1973-1976	and	_	_	_	_
15-16	1977-1978	a	abstract[103]	giv[103]	ana	16-1[0_103]
15-17	1979-1988	frequency	abstract[103]	giv[103]	_	_
15-18	1989-1992	for	abstract[103]	giv[103]	_	_
15-19	1993-2002	dominated	abstract[103]|abstract[104]	giv[103]|giv[104]	coref	21-20[137_104]
15-20	2003-2010	changes	abstract[103]|abstract[104]	giv[103]|giv[104]	_	_
15-21	2011-2013	is	_	_	_	_
15-22	2014-2024	calculated	_	_	_	_
15-23	2025-2026	.	_	_	_	_

#Text=It is assumed , that this frequency represents the respiratory rate .
16-1	2027-2029	It	abstract	giv	coref	16-6[106_0]
16-2	2030-2032	is	_	_	_	_
16-3	2033-2040	assumed	_	_	_	_
16-4	2041-2042	,	_	_	_	_
16-5	2043-2047	that	_	_	_	_
16-6	2048-2052	this	abstract[106]	giv[106]	coref	24-9[0_106]
16-7	2053-2062	frequency	abstract[106]	giv[106]	_	_
16-8	2063-2073	represents	_	_	_	_
16-9	2074-2077	the	abstract[107]	new[107]	coref	25-5[165_107]
16-10	2078-2089	respiratory	abstract[107]	new[107]	_	_
16-11	2090-2094	rate	abstract[107]	new[107]	_	_
16-12	2095-2096	.	_	_	_	_

#Text=In recent years , new portable and cost-effective thermal cameras have been available .
17-1	2097-2099	In	_	_	_	_
17-2	2100-2106	recent	time[108]	new[108]	_	_
17-3	2107-2112	years	time[108]	new[108]	_	_
17-4	2113-2114	,	_	_	_	_
17-5	2115-2118	new	object[110]	giv[110]	coref	18-4[113_110]
17-6	2119-2127	portable	object[110]	giv[110]	_	_
17-7	2128-2131	and	object[110]	giv[110]	_	_
17-8	2132-2146	cost-effective	object[110]	giv[110]	_	_
17-9	2147-2154	thermal	animal|object[110]	giv|giv[110]	coref	19-10
17-10	2155-2162	cameras	object[110]	giv[110]	_	_
17-11	2163-2167	have	_	_	_	_
17-12	2168-2172	been	_	_	_	_
17-13	2173-2182	available	_	_	_	_
17-14	2183-2184	.	_	_	_	_

#Text=For example , FLIR® Lepton family cameras are very small ( e. g. , 10.5 × 11.7 × 6.4 mm , with an internal shutter ) and cost less that 200USD .
18-1	2185-2188	For	_	_	_	_
18-2	2189-2196	example	_	_	_	_
18-3	2197-2198	,	_	_	_	_
18-4	2199-2204	FLIR®	abstract|object[113]	new|giv[113]	coref|coref	20-7[130_113]|20-7[130_113]
18-5	2205-2211	Lepton	object[113]	giv[113]	_	_
18-6	2212-2218	family	abstract|object[113]	new|giv[113]	_	_
18-7	2219-2226	cameras	object[113]	giv[113]	_	_
18-8	2227-2230	are	_	_	_	_
18-9	2231-2235	very	_	_	_	_
18-10	2236-2241	small	_	_	_	_
18-11	2242-2243	(	_	_	_	_
18-12	2244-2246	e.	_	_	_	_
18-13	2247-2249	g.	_	_	_	_
18-14	2250-2251	,	_	_	_	_
18-15	2252-2256	10.5	_	_	_	_
18-16	2257-2258	×	_	_	_	_
18-17	2259-2263	11.7	_	_	_	_
18-18	2264-2265	×	_	_	_	_
18-19	2266-2269	6.4	quantity[114]	new[114]	_	_
18-20	2270-2272	mm	quantity[114]	new[114]	_	_
18-21	2273-2274	,	_	_	_	_
18-22	2275-2279	with	_	_	_	_
18-23	2280-2282	an	object[115]	new[115]	_	_
18-24	2283-2291	internal	object[115]	new[115]	_	_
18-25	2292-2299	shutter	object[115]	new[115]	_	_
18-26	2300-2301	)	_	_	_	_
18-27	2302-2305	and	_	_	_	_
18-28	2306-2310	cost	_	_	_	_
18-29	2311-2315	less	_	_	_	_
18-30	2316-2320	that	quantity[116]	new[116]	_	_
18-31	2321-2327	200USD	quantity[116]	new[116]	_	_
18-32	2328-2329	.	_	_	_	_

#Text=These features allow to think about wide application of thermal monitoring , e. g. , to support remote diagnosis of elderly people at home ( e. g. , during a video talk or as a self-diagnostics ) .
19-1	2330-2335	These	abstract[117]	new[117]	coref	21-12[135_117]
19-2	2336-2344	features	abstract[117]	new[117]	_	_
19-3	2345-2350	allow	_	_	_	_
19-4	2351-2353	to	_	_	_	_
19-5	2354-2359	think	_	_	_	_
19-6	2360-2365	about	_	_	_	_
19-7	2366-2370	wide	abstract[118]	new[118]	_	_
19-8	2371-2382	application	abstract[118]	new[118]	_	_
19-9	2383-2385	of	abstract[118]	new[118]	_	_
19-10	2386-2393	thermal	abstract[118]|animal|abstract[120]	new[118]|giv|new[120]	coref|coref	20-9|20-9
19-11	2394-2404	monitoring	abstract[118]|abstract[120]	new[118]|new[120]	_	_
19-12	2405-2406	,	abstract[118]	new[118]	_	_
19-13	2407-2409	e.	abstract[118]	new[118]	_	_
19-14	2410-2412	g.	abstract[118]	new[118]	_	_
19-15	2413-2414	,	_	_	_	_
19-16	2415-2417	to	_	_	_	_
19-17	2418-2425	support	_	_	_	_
19-18	2426-2432	remote	abstract[121]	new[121]	_	_
19-19	2433-2442	diagnosis	abstract[121]	new[121]	_	_
19-20	2443-2445	of	abstract[121]	new[121]	_	_
19-21	2446-2453	elderly	abstract[121]|person[122]	new[121]|new[122]	_	_
19-22	2454-2460	people	abstract[121]|person[122]	new[121]|new[122]	_	_
19-23	2461-2463	at	abstract[121]|person[122]	new[121]|new[122]	_	_
19-24	2464-2468	home	abstract[121]|person[122]|place	new[121]|new[122]|new	_	_
19-25	2469-2470	(	_	_	_	_
19-26	2471-2473	e.	place[124]	giv[124]	_	_
19-27	2474-2476	g.	place[124]	giv[124]	_	_
19-28	2477-2478	,	_	_	_	_
19-29	2479-2485	during	_	_	_	_
19-30	2486-2487	a	event[126]	new[126]	_	_
19-31	2488-2493	video	abstract|event[126]	new|new[126]	coref	27-12[172_0]
19-32	2494-2498	talk	event[126]	new[126]	_	_
19-33	2499-2501	or	_	_	_	_
19-34	2502-2504	as	_	_	_	_
19-35	2505-2506	a	abstract[127]	new[127]	_	_
19-36	2507-2523	self-diagnostics	abstract[127]	new[127]	_	_
19-37	2524-2525	)	_	_	_	_
19-38	2526-2527	.	_	_	_	_

#Text=However , a spatial resolution of these small thermal cameras is as low as 80 × 60 or 160 × 120 .
20-1	2528-2535	However	_	_	_	_
20-2	2536-2537	,	_	_	_	_
20-3	2538-2539	a	abstract[128]	giv[128]	_	_
20-4	2540-2547	spatial	abstract[128]	giv[128]	_	_
20-5	2548-2558	resolution	abstract[128]	giv[128]	_	_
20-6	2559-2561	of	abstract[128]	giv[128]	_	_
20-7	2562-2567	these	abstract[128]|object[130]	giv[128]|giv[130]	_	_
20-8	2568-2573	small	abstract[128]|object[130]	giv[128]|giv[130]	_	_
20-9	2574-2581	thermal	abstract[128]|animal|object[130]	giv[128]|giv|giv[130]	coref	23-6
20-10	2582-2589	cameras	abstract[128]|object[130]	giv[128]|giv[130]	_	_
20-11	2590-2592	is	_	_	_	_
20-12	2593-2595	as	_	_	_	_
20-13	2596-2599	low	_	_	_	_
20-14	2600-2602	as	_	_	_	_
20-15	2603-2605	80	_	_	_	_
20-16	2606-2607	×	_	_	_	_
20-17	2608-2610	60	_	_	_	_
20-18	2611-2613	or	_	_	_	_
20-19	2614-2617	160	_	_	_	_
20-20	2618-2619	×	_	_	_	_
20-21	2620-2623	120	_	_	_	_
20-22	2624-2625	.	_	_	_	_

#Text=Small resolution of images could be a problem for detection of facial features or detection of a ROI representing respiration-related temperature changes .
21-1	2626-2631	Small	abstract[131]	new[131]	coref	21-7[133_131]
21-2	2632-2642	resolution	abstract[131]	new[131]	_	_
21-3	2643-2645	of	abstract[131]	new[131]	_	_
21-4	2646-2652	images	abstract[131]|object	new[131]|giv	coref	22-17[144_0]
21-5	2653-2658	could	_	_	_	_
21-6	2659-2661	be	_	_	_	_
21-7	2662-2663	a	abstract[133]	giv[133]	coref	22-18[0_133]
21-8	2664-2671	problem	abstract[133]	giv[133]	_	_
21-9	2672-2675	for	abstract[133]	giv[133]	_	_
21-10	2676-2685	detection	abstract[133]|abstract[134]	giv[133]|giv[134]	_	_
21-11	2686-2688	of	abstract[133]|abstract[134]	giv[133]|giv[134]	_	_
21-12	2689-2695	facial	abstract[133]|abstract[134]|abstract[135]	giv[133]|giv[134]|giv[135]	_	_
21-13	2696-2704	features	abstract[133]|abstract[134]|abstract[135]	giv[133]|giv[134]|giv[135]	_	_
21-14	2705-2707	or	abstract[133]|abstract[134]|abstract[135]	giv[133]|giv[134]|giv[135]	_	_
21-15	2708-2717	detection	abstract[133]|abstract[134]|abstract[135]	giv[133]|giv[134]|giv[135]	_	_
21-16	2718-2720	of	abstract[133]|abstract[134]|abstract[135]	giv[133]|giv[134]|giv[135]	_	_
21-17	2721-2722	a	abstract[133]|abstract[134]|abstract[135]|abstract[136]	giv[133]|giv[134]|giv[135]|giv[136]	_	_
21-18	2723-2726	ROI	abstract[133]|abstract[134]|abstract[135]|abstract[136]	giv[133]|giv[134]|giv[135]|giv[136]	_	_
21-19	2727-2739	representing	_	_	_	_
21-20	2740-2759	respiration-related	abstract[137]	giv[137]	coref	22-29[145_137]
21-21	2760-2771	temperature	abstract[137]	giv[137]	_	_
21-22	2772-2779	changes	abstract[137]	giv[137]	_	_
21-23	2780-2781	.	_	_	_	_

#Text=Different methods have been proposed in ( a visible light spectrum ) computer vision to improve low resolution images or to detect ( and amplify ) small , local changes in videos .
22-1	2782-2791	Different	abstract[138]	giv[138]	_	_
22-2	2792-2799	methods	abstract[138]	giv[138]	_	_
22-3	2800-2804	have	_	_	_	_
22-4	2805-2809	been	_	_	_	_
22-5	2810-2818	proposed	_	_	_	_
22-6	2819-2821	in	_	_	_	_
22-7	2822-2823	(	abstract[142]	new[142]	_	_
22-8	2824-2825	a	abstract[140]|abstract[142]	new[140]|new[142]	coref	24-7[162_140]
22-9	2826-2833	visible	abstract[140]|abstract[142]	new[140]|new[142]	_	_
22-10	2834-2839	light	abstract|abstract[140]|abstract[142]	new|new[140]|new[142]	coref	30-23
22-11	2840-2848	spectrum	abstract[140]|abstract[142]	new[140]|new[142]	_	_
22-12	2849-2850	)	abstract[142]	new[142]	_	_
22-13	2851-2859	computer	object|abstract[142]	new|new[142]	_	_
22-14	2860-2866	vision	abstract[142]	new[142]	_	_
22-15	2867-2869	to	_	_	_	_
22-16	2870-2877	improve	_	_	_	_
22-17	2878-2881	low	object[144]	giv[144]	coref	30-23[186_144]
22-18	2882-2892	resolution	abstract|object[144]	giv|giv[144]	coref	29-8[178_0]
22-19	2893-2899	images	object[144]	giv[144]	_	_
22-20	2900-2902	or	_	_	_	_
22-21	2903-2905	to	_	_	_	_
22-22	2906-2912	detect	_	_	_	_
22-23	2913-2914	(	_	_	_	_
22-24	2915-2918	and	_	_	_	_
22-25	2919-2926	amplify	_	_	_	_
22-26	2927-2928	)	_	_	_	_
22-27	2929-2934	small	_	_	_	_
22-28	2935-2936	,	_	_	_	_
22-29	2937-2942	local	abstract[145]	giv[145]	_	_
22-30	2943-2950	changes	abstract[145]	giv[145]	_	_
22-31	2951-2953	in	abstract[145]	giv[145]	_	_
22-32	2954-2960	videos	abstract[145]|object	giv[145]|new	coref	23-6[150_0]
22-33	2961-2962	.	_	_	_	_

#Text=Subtle intensity variations introduced in thermal videos of a face due to respiratory activities can be enhanced using Eulerian Video Magnification ( EVM ) or related algorithms .
23-1	2963-2969	Subtle	abstract[148]	new[148]	_	_
23-2	2970-2979	intensity	abstract|abstract[148]	new|new[148]	coref	24-4
23-3	2980-2990	variations	abstract[148]	new[148]	_	_
23-4	2991-3001	introduced	_	_	_	_
23-5	3002-3004	in	_	_	_	_
23-6	3005-3012	thermal	animal|object[150]	giv|giv[150]	_	_
23-7	3013-3019	videos	object[150]	giv[150]	_	_
23-8	3020-3022	of	object[150]	giv[150]	_	_
23-9	3023-3024	a	object[150]|object[151]	giv[150]|giv[151]	_	_
23-10	3025-3029	face	object[150]|object[151]	giv[150]|giv[151]	_	_
23-11	3030-3033	due	_	_	_	_
23-12	3034-3036	to	_	_	_	_
23-13	3037-3048	respiratory	event[152]	new[152]	_	_
23-14	3049-3059	activities	event[152]	new[152]	_	_
23-15	3060-3063	can	_	_	_	_
23-16	3064-3066	be	_	_	_	_
23-17	3067-3075	enhanced	_	_	_	_
23-18	3076-3081	using	_	_	_	_
23-19	3082-3090	Eulerian	person|abstract[155]	new|new[155]	appos|appos	23-23[0_155]|23-23[0_155]
23-20	3091-3096	Video	person|abstract[155]	new|new[155]	_	_
23-21	3097-3110	Magnification	abstract[155]	new[155]	_	_
23-22	3111-3112	(	_	_	_	_
23-23	3113-3116	EVM	abstract	giv	coref	28-2
23-24	3117-3118	)	_	_	_	_
23-25	3119-3121	or	_	_	_	_
23-26	3122-3129	related	abstract[157]	giv[157]	coref	29-3[177_157]
23-27	3130-3140	algorithms	abstract[157]	giv[157]	_	_
23-28	3141-3142	.	_	_	_	_

#Text=This technique amplifies intensity differences within a particular frequency spectrum .
24-1	3143-3147	This	abstract[158]	new[158]	_	_
24-2	3148-3157	technique	abstract[158]	new[158]	_	_
24-3	3158-3167	amplifies	_	_	_	_
24-4	3168-3177	intensity	abstract|abstract[160]	giv|new[160]	_	_
24-5	3178-3189	differences	abstract[160]	new[160]	_	_
24-6	3190-3196	within	abstract[160]	new[160]	_	_
24-7	3197-3198	a	abstract[160]|abstract[162]	new[160]|giv[162]	ana	25-1[0_162]
24-8	3199-3209	particular	abstract[160]|abstract[162]	new[160]|giv[162]	_	_
24-9	3210-3219	frequency	abstract[160]|abstract|abstract[162]	new[160]|giv|giv[162]	_	_
24-10	3220-3228	spectrum	abstract[160]|abstract[162]	new[160]|giv[162]	_	_
24-11	3229-3230	.	_	_	_	_

#Text=This works well if the estimate respiratory rate ( frequency ) is known .
25-1	3231-3235	This	abstract	giv	_	_
25-2	3236-3241	works	_	_	_	_
25-3	3242-3246	well	_	_	_	_
25-4	3247-3249	if	_	_	_	_
25-5	3250-3253	the	abstract[165]	giv[165]	appos	25-10[0_165]
25-6	3254-3262	estimate	abstract|abstract[165]	new|giv[165]	_	_
25-7	3263-3274	respiratory	abstract[165]	giv[165]	_	_
25-8	3275-3279	rate	abstract[165]	giv[165]	_	_
25-9	3280-3281	(	_	_	_	_
25-10	3282-3291	frequency	abstract	giv	_	_
25-11	3292-3293	)	_	_	_	_
25-12	3294-3296	is	_	_	_	_
25-13	3297-3302	known	_	_	_	_
25-14	3303-3304	.	_	_	_	_

#Text=Otherwise , noise and motion artefacts are highly amplified .
26-1	3305-3314	Otherwise	_	_	_	_
26-2	3315-3316	,	_	_	_	_
26-3	3317-3322	noise	abstract	new	_	_
26-4	3323-3326	and	_	_	_	_
26-5	3327-3333	motion	abstract|abstract[169]	new|new[169]	_	_
26-6	3334-3343	artefacts	abstract[169]	new[169]	_	_
26-7	3344-3347	are	_	_	_	_
26-8	3348-3354	highly	_	_	_	_
26-9	3355-3364	amplified	_	_	_	_
26-10	3365-3366	.	_	_	_	_

#Text=Therefore , some researchers propose to magnify only selected segments within a video .
27-1	3367-3376	Therefore	_	_	_	_
27-2	3377-3378	,	_	_	_	_
27-3	3379-3383	some	person[170]	new[170]	_	_
27-4	3384-3395	researchers	person[170]	new[170]	_	_
27-5	3396-3403	propose	_	_	_	_
27-6	3404-3406	to	_	_	_	_
27-7	3407-3414	magnify	_	_	_	_
27-8	3415-3419	only	abstract[171]	new[171]	_	_
27-9	3420-3428	selected	abstract[171]	new[171]	_	_
27-10	3429-3437	segments	abstract[171]	new[171]	_	_
27-11	3438-3444	within	_	_	_	_
27-12	3445-3446	a	abstract[172]	giv[172]	_	_
27-13	3447-3452	video	abstract[172]	giv[172]	_	_
27-14	3453-3454	.	_	_	_	_

#Text=The EVM algorithm has been already successfully used for enhancing vital sign signals .
28-1	3455-3458	The	abstract[174]	new[174]	_	_
28-2	3459-3462	EVM	abstract|abstract[174]	giv|new[174]	_	_
28-3	3463-3472	algorithm	abstract[174]	new[174]	_	_
28-4	3473-3476	has	_	_	_	_
28-5	3477-3481	been	_	_	_	_
28-6	3482-3489	already	_	_	_	_
28-7	3490-3502	successfully	_	_	_	_
28-8	3503-3507	used	_	_	_	_
28-9	3508-3511	for	_	_	_	_
28-10	3512-3521	enhancing	_	_	_	_
28-11	3522-3527	vital	abstract[176]	new[176]	_	_
28-12	3528-3532	sign	abstract|abstract[176]	new|new[176]	_	_
28-13	3533-3540	signals	abstract[176]	new[176]	_	_
28-14	3541-3542	.	_	_	_	_

#Text=Recently , many different deep-learning algorithms for super resolution have been proposed .
29-1	3543-3551	Recently	_	_	_	_
29-2	3552-3553	,	_	_	_	_
29-3	3554-3558	many	abstract[177]	giv[177]	coref	30-6[180_177]
29-4	3559-3568	different	abstract[177]	giv[177]	_	_
29-5	3569-3582	deep-learning	abstract[177]	giv[177]	_	_
29-6	3583-3593	algorithms	abstract[177]	giv[177]	_	_
29-7	3594-3597	for	abstract[177]	giv[177]	_	_
29-8	3598-3603	super	abstract[177]|abstract[178]	giv[177]|giv[178]	ana	30-1[0_178]
29-9	3604-3614	resolution	abstract[177]|abstract[178]	giv[177]|giv[178]	_	_
29-10	3615-3619	have	_	_	_	_
29-11	3620-3624	been	_	_	_	_
29-12	3625-3633	proposed	_	_	_	_
29-13	3634-3635	.	_	_	_	_

#Text=It has been proved that such algorithms can efficiently improve the presentation of details in the processed low-resolution ( LR ) visible light images .
30-1	3636-3638	It	abstract	giv	coref	34-11[214_0]
30-2	3639-3642	has	_	_	_	_
30-3	3643-3647	been	_	_	_	_
30-4	3648-3654	proved	_	_	_	_
30-5	3655-3659	that	_	_	_	_
30-6	3660-3664	such	abstract[180]	giv[180]	coref	36-10[237_180]
30-7	3665-3675	algorithms	abstract[180]	giv[180]	_	_
30-8	3676-3679	can	_	_	_	_
30-9	3680-3691	efficiently	_	_	_	_
30-10	3692-3699	improve	_	_	_	_
30-11	3700-3703	the	abstract[181]	new[181]	_	_
30-12	3704-3716	presentation	abstract[181]	new[181]	_	_
30-13	3717-3719	of	abstract[181]	new[181]	_	_
30-14	3720-3727	details	abstract[181]|abstract[182]	new[181]|new[182]	_	_
30-15	3728-3730	in	abstract[181]|abstract[182]	new[181]|new[182]	_	_
30-16	3731-3734	the	abstract[181]|abstract[182]|abstract[183]	new[181]|new[182]|new[183]	appos	30-20[0_183]
30-17	3735-3744	processed	abstract[181]|abstract[182]|abstract[183]	new[181]|new[182]|new[183]	_	_
30-18	3745-3759	low-resolution	abstract[181]|abstract[182]|abstract[183]	new[181]|new[182]|new[183]	_	_
30-19	3760-3761	(	_	_	_	_
30-20	3762-3764	LR	abstract	giv	coref	34-8
30-21	3765-3766	)	_	_	_	_
30-22	3767-3774	visible	_	_	_	_
30-23	3775-3780	light	abstract|object[186]	giv|giv[186]	_	_
30-24	3781-3787	images	object[186]	giv[186]	_	_
30-25	3788-3789	.	_	_	_	_

#Text=One of the first method in this area was SRCNN , which implemented a single Convolutional Neural Network ( CNN ) achieving the state-of-the-art restoration quality .
31-1	3790-3793	One	abstract[187]	new[187]	coref	31-10[0_187]
31-2	3794-3796	of	abstract[187]	new[187]	_	_
31-3	3797-3800	the	abstract[187]|abstract[188]	new[187]|new[188]	_	_
31-4	3801-3806	first	abstract[187]|abstract[188]	new[187]|new[188]	_	_
31-5	3807-3813	method	abstract[187]|abstract[188]	new[187]|new[188]	_	_
31-6	3814-3816	in	abstract[187]|abstract[188]	new[187]|new[188]	_	_
31-7	3817-3821	this	abstract[187]|abstract[188]|abstract[189]	new[187]|new[188]|new[189]	_	_
31-8	3822-3826	area	abstract[187]|abstract[188]|abstract[189]	new[187]|new[188]|new[189]	_	_
31-9	3827-3830	was	_	_	_	_
31-10	3831-3836	SRCNN	abstract	giv	_	_
31-11	3837-3838	,	_	_	_	_
31-12	3839-3844	which	_	_	_	_
31-13	3845-3856	implemented	_	_	_	_
31-14	3857-3858	a	abstract[192]	new[192]	appos	31-20[0_192]
31-15	3859-3865	single	abstract[192]	new[192]	_	_
31-16	3866-3879	Convolutional	abstract[192]	new[192]	_	_
31-17	3880-3886	Neural	abstract|abstract[192]	new|new[192]	coref	32-5
31-18	3887-3894	Network	abstract[192]	new[192]	_	_
31-19	3895-3896	(	_	_	_	_
31-20	3897-3900	CNN	abstract	giv	coref	33-8[206_0]
31-21	3901-3902	)	_	_	_	_
31-22	3903-3912	achieving	_	_	_	_
31-23	3913-3916	the	abstract[195]	new[195]	coref	32-18[201_195]
31-24	3917-3933	state-of-the-art	abstract[195]	new[195]	_	_
31-25	3934-3945	restoration	abstract|abstract[195]	new|new[195]	coref	32-19
31-26	3946-3953	quality	abstract[195]	new[195]	_	_
31-27	3954-3955	.	_	_	_	_

#Text=Later , different Deep Neural Networks ( DNNs ) based solutions have been introduced to further improve the restoration quality ( or perception ) .
32-1	3956-3961	Later	_	_	_	_
32-2	3962-3963	,	_	_	_	_
32-3	3964-3973	different	place[197]	new[197]	coref	35-27[232_197]
32-4	3974-3978	Deep	place[197]	new[197]	_	_
32-5	3979-3985	Neural	abstract|place[197]	giv|new[197]	_	_
32-6	3986-3994	Networks	place[197]	new[197]	_	_
32-7	3995-3996	(	_	_	_	_
32-8	3997-4001	DNNs	abstract	new	_	_
32-9	4002-4003	)	_	_	_	_
32-10	4004-4009	based	_	_	_	_
32-11	4010-4019	solutions	abstract	new	_	_
32-12	4020-4024	have	_	_	_	_
32-13	4025-4029	been	_	_	_	_
32-14	4030-4040	introduced	_	_	_	_
32-15	4041-4043	to	_	_	_	_
32-16	4044-4051	further	_	_	_	_
32-17	4052-4059	improve	_	_	_	_
32-18	4060-4063	the	abstract[201]	giv[201]	_	_
32-19	4064-4075	restoration	abstract|abstract[201]	giv|giv[201]	_	_
32-20	4076-4083	quality	abstract[201]	giv[201]	_	_
32-21	4084-4085	(	_	_	_	_
32-22	4086-4088	or	_	_	_	_
32-23	4089-4099	perception	abstract	new	_	_
32-24	4100-4101	)	_	_	_	_
32-25	4102-4103	.	_	_	_	_

#Text=In Kim et al. introduced a novel Deeply Recursive Convolutional Network ( DRCN ) model .
33-1	4104-4106	In	_	_	_	_
33-2	4107-4110	Kim	person	new	_	_
33-3	4111-4113	et	_	_	_	_
33-4	4114-4117	al.	_	_	_	_
33-5	4118-4128	introduced	_	_	_	_
33-6	4129-4130	a	_	_	_	_
33-7	4131-4136	novel	_	_	_	_
33-8	4137-4143	Deeply	abstract[206]|abstract[208]	giv[206]|new[208]	appos|ana|appos|ana	33-13[0_206]|34-1[0_208]|33-13[0_206]|34-1[0_208]
33-9	4144-4153	Recursive	substance|abstract[206]|abstract[208]	new|giv[206]|new[208]	coref	35-16
33-10	4154-4167	Convolutional	person|abstract[206]|abstract[208]	new|giv[206]|new[208]	_	_
33-11	4168-4175	Network	abstract[206]|abstract[208]	giv[206]|new[208]	_	_
33-12	4176-4177	(	abstract[208]	new[208]	_	_
33-13	4178-4182	DRCN	abstract|abstract[208]	giv|new[208]	_	_
33-14	4183-4184	)	abstract[208]	new[208]	_	_
33-15	4185-4190	model	abstract[208]	new[208]	_	_
33-16	4191-4192	.	_	_	_	_

#Text=It utilizes a skip connection correlating a LR input with a high resolution ( HR ) reference data and uses recursive supervision to minimize the exploding/vanishing gradients problem .
34-1	4193-4195	It	abstract	giv	_	_
34-2	4196-4204	utilizes	_	_	_	_
34-3	4205-4206	a	abstract[211]	new[211]	_	_
34-4	4207-4211	skip	abstract|abstract[211]	new|new[211]	_	_
34-5	4212-4222	connection	abstract[211]	new[211]	_	_
34-6	4223-4234	correlating	_	_	_	_
34-7	4235-4236	a	abstract[213]	new[213]	_	_
34-8	4237-4239	LR	abstract|abstract[213]	giv|new[213]	_	_
34-9	4240-4245	input	abstract[213]	new[213]	_	_
34-10	4246-4250	with	abstract[213]	new[213]	_	_
34-11	4251-4252	a	abstract[213]|abstract[214]	new[213]|giv[214]	coref	34-25[219_214]
34-12	4253-4257	high	abstract[213]|abstract[214]	new[213]|giv[214]	_	_
34-13	4258-4268	resolution	abstract[213]|abstract[214]	new[213]|giv[214]	_	_
34-14	4269-4270	(	_	_	_	_
34-15	4271-4273	HR	time	new	_	_
34-16	4274-4275	)	_	_	_	_
34-17	4276-4285	reference	abstract[216]	new[216]	_	_
34-18	4286-4290	data	abstract[216]	new[216]	_	_
34-19	4291-4294	and	_	_	_	_
34-20	4295-4299	uses	_	_	_	_
34-21	4300-4309	recursive	abstract[217]	new[217]	_	_
34-22	4310-4321	supervision	abstract[217]	new[217]	_	_
34-23	4322-4324	to	_	_	_	_
34-24	4325-4333	minimize	_	_	_	_
34-25	4334-4337	the	abstract[219]	giv[219]	_	_
34-26	4338-4357	exploding/vanishing	abstract[219]	giv[219]	_	_
34-27	4358-4367	gradients	abstract|abstract[219]	new|giv[219]	_	_
34-28	4368-4375	problem	abstract[219]	giv[219]	_	_
34-29	4376-4377	.	_	_	_	_

#Text=Other improvements to SR include the application of residual mappings and gradient clipping ( Deeply Recursive Residual Network ( DRRN ) ) , the use of attention networks , the application of multi-scale residual hierarchical networks , etc.
35-1	4378-4383	Other	abstract[220]	new[220]	_	_
35-2	4384-4396	improvements	abstract[220]	new[220]	_	_
35-3	4397-4399	to	abstract[220]	new[220]	_	_
35-4	4400-4402	SR	abstract[220]|abstract	new[220]|new	_	_
35-5	4403-4410	include	_	_	_	_
35-6	4411-4414	the	abstract[222]	new[222]	_	_
35-7	4415-4426	application	abstract[222]	new[222]	_	_
35-8	4427-4429	of	abstract[222]	new[222]	_	_
35-9	4430-4438	residual	abstract[222]|abstract[223]	new[222]|new[223]	_	_
35-10	4439-4447	mappings	abstract[222]|abstract[223]	new[222]|new[223]	_	_
35-11	4448-4451	and	abstract[222]	new[222]	_	_
35-12	4452-4460	gradient	abstract[222]|substance|abstract[225]	new[222]|new|new[225]	appos|appos	35-15[228_225]|35-15[228_225]
35-13	4461-4469	clipping	abstract[222]|abstract[225]	new[222]|new[225]	_	_
35-14	4470-4471	(	_	_	_	_
35-15	4472-4478	Deeply	abstract[228]	giv[228]	_	_
35-16	4479-4488	Recursive	substance|abstract[228]	giv|giv[228]	_	_
35-17	4489-4497	Residual	person|abstract[228]	new|giv[228]	_	_
35-18	4498-4505	Network	abstract[228]	giv[228]	_	_
35-19	4506-4507	(	_	_	_	_
35-20	4508-4512	DRRN	object	new	_	_
35-21	4513-4514	)	_	_	_	_
35-22	4515-4516	)	_	_	_	_
35-23	4517-4518	,	_	_	_	_
35-24	4519-4522	the	abstract[230]	new[230]	_	_
35-25	4523-4526	use	abstract[230]	new[230]	_	_
35-26	4527-4529	of	abstract[230]	new[230]	_	_
35-27	4530-4539	attention	abstract[230]|abstract|place[232]	new[230]|new|giv[232]	coref|coref	35-33[234_232]|35-33[234_232]
35-28	4540-4548	networks	abstract[230]|place[232]	new[230]|giv[232]	_	_
35-29	4549-4550	,	_	_	_	_
35-30	4551-4554	the	abstract[233]	new[233]	_	_
35-31	4555-4566	application	abstract[233]	new[233]	_	_
35-32	4567-4569	of	abstract[233]	new[233]	_	_
35-33	4570-4581	multi-scale	abstract[233]|place[234]	new[233]|giv[234]	coref	36-14[238_234]
35-34	4582-4590	residual	abstract[233]|place[234]	new[233]|giv[234]	_	_
35-35	4591-4603	hierarchical	abstract[233]|place[234]	new[233]|giv[234]	_	_
35-36	4604-4612	networks	abstract[233]|place[234]	new[233]|giv[234]	_	_
35-37	4613-4614	,	abstract[233]	new[233]	_	_
35-38	4615-4619	etc.	abstract[233]	new[233]	_	_

#Text=The very good results have also been obtained using SR algorithms based on generative networks .
36-1	4620-4623	The	abstract[235]	new[235]	_	_
36-2	4624-4628	very	abstract[235]	new[235]	_	_
36-3	4629-4633	good	abstract[235]	new[235]	_	_
36-4	4634-4641	results	abstract[235]	new[235]	_	_
36-5	4642-4646	have	_	_	_	_
36-6	4647-4651	also	_	_	_	_
36-7	4652-4656	been	_	_	_	_
36-8	4657-4665	obtained	_	_	_	_
36-9	4666-4671	using	_	_	_	_
36-10	4672-4674	SR	person|abstract[237]	new|giv[237]	_	_
36-11	4675-4685	algorithms	abstract[237]	giv[237]	_	_
36-12	4686-4691	based	_	_	_	_
36-13	4692-4694	on	_	_	_	_
36-14	4695-4705	generative	place[238]	giv[238]	_	_
36-15	4706-4714	networks	place[238]	giv[238]	_	_
36-16	4715-4716	.	_	_	_	_
