<text id="autogum_academic_doc339" title="Uncertainty Assessment in Multitemporal Land Use/Cover Mapping with Classification System Semantic Heterogeneity" shortTile="uncertainty-assessment" author="Xiaokang Zhang, Wenzhong Shi, Zhiyong Lv" type="academic" dateCollected="2019-11-03" sourceURL="https://www.mdpi.com/2072-4292/11/21/2509/htm" speakerList="none" speakerCount="0">
<head> 1. Introduction</head>
<p>
Land use/cover (LUC) information derived from the vast amount of available remote sensing data is widely used when studying changes in atmospheric composition, sustainable urban development, and ecosystem modification. LUC data can provide a thematic representation of a land surface that is spatially continuous and highly consistent across a range of spatial and temporal scales. However, the amount of uncertainty in existing LUC mapping information significantly impairs the reliability of classification products. Researchers developing methods of measuring the uncertainty in LUC data focused on quantifying the uncertainty in remote sensing images, determining the classification uncertainty, and assessing the accuracy of LUC products. For example, Griffith and Chun studied the uncertainty in spatial autocorrelation parameters in a spatial autoregressive model associated with remotely sensed images. Zhang and Zhang proposed a quantitative descriptor that considered the spatial distribution and semantic uncertainty when investigating the inherent uncertainty in remote sensing images caused by object boundaries and high intra-class differences. Comber, Fisher, Brunsdon, and Khmag used a geographically weighted approach to model spatial variations in the classification accuracy of land cover data. Löw, Knöfel, and Conrad investigated the classification uncertainty of remotely sensed data using alpha-quadratic entropy based on per-object class membership estimations obtained via a support vector machine algorithm, whereas the researchers in Reference detailed good practice recommendations for sampling, response, and analysis to facilitate the accurate assessment of land change maps. Shi, Zhang, Hao, Shao, Cai, and Lyu analyzed reliability propagation in the data production process and proposed a validation schema to evaluate the reliability of land cover products based on seven reliability indicators derived from reliability and consistency measurements. </p>

<p>Currently available LUC data are typically provided by national, regional, or global land inventory projects to support the interests of specific communities and different initiatives. However, LUC datasets are often incompatible as they employ different classification schemes in the conversion of satellite images to thematic maps, which is problematic for potential users. </p>

<p>Land inventory projects require an LUC classification system (CS) that defines the standards used for data acquisition, interchange, and sharing along with descriptions of the systematic frameworks, class names, criteria used to discriminate them, and relationships between classes. Some well-known LUC datasets include the global land cover map (GlobCover 2009), the coordination of information on the environment (CORINE) land cover data of the European Union, the International Geosphere Biosphere Program (IGBP) land classification data, the 30-m-resolution global land cover dataset (GlobeLand30), and the national-scale LUC datasets developed by various governmental agencies and institutions, such as the National Land Cover Database (NLCD) in the United States (US) and the National Land Survey (NLS) database in China. However, despite the wide availability of LUC information, both data producers and users continue to be hampered by data interoperability and exchange problems between heterogeneous datasets due to differences in the classification schemas and class definitions, and such incompatibilities limit the scope of available applications that employ LUC data.  </p>

<p>To address these challenges, an international joint initiative was launched in 2006 to work toward the harmonization and validation of existing and future land cover datasets. One potential solution to increase the interoperability of various CSs is to develop methods to translate classes between datasets, and this is an area of increasing international focus for those maintaining and developing existing regional and global CSs.  </p>

<p>Semantic translation methodologies can be divided into two groups: conventional class by class comparison approaches and semantic analysis based on sets of attributes. In terms of global land cover products, the Land Cover Classification System (LCCS) and the IGBP classification schema are commonly used as links in the conversion between other classification systems to facilitate comparative analysis. For example, LCCS-based legend translation protocols were leveraged in an effort to provide a generalized categorization of land cover classes on a global scale in which input classes were harmonized into 13 general classes. In a comparison of land cover maps in northern Eurasia, a generalized legend was developed based on six dominant life form types (LFT) to serve as a common denominator. Information semantics and tools for the integration of heterogeneous ontologies were applied to model the semantic relationship between LUC CSs, and ontology-based semantic similarity measures were used to characterize similarities between different LUC classes.  </p>
</text>
