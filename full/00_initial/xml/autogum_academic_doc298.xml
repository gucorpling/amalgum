<text id="autogum_academic_doc298" title="An Enhanced Feature Pyramid Object Detection Network for Autonomous Driving" shortTile="enhanced-feature" author="Yutian Wu, Shuming Tang, Shuwei Zhang, Harutoshi Ogai" type="academic" dateCollected="2019-11-03" sourceURL="https://www.mdpi.com/2076-3417/9/20/4363/htm" speakerList="none" speakerCount="0">
<head> 2. Proposed Method</head>
<p>
EFPN is our proposed object detection network. Its architecture is shown in <figure>Figure 1</figure>. Firstly, in enhanced feature extraction subnet, we generate pyramid features in the same way as FPN. Features in each pyramid level are weighted by our proposed FWM, and a new enhanced feature pyramid is reconstructed as the input for the following procedure. Secondly, in the proposal extraction subnet, Region Proposal Network (RPN) is used to generate anchors of various shapes on the enhanced pyramidal feature map. Thirdly, in adaptive parallel detection subnet, ACE is applied to extract the feature of ceRoI and RoI for each foreground RoI. Two kinds of RoI features are, respectively, fed into PDB to predict classification and regression as the final detection results. </p>

<head> 2.1. Enhanced Feature Extraction Subnet</head>
<p>
Generally, FPN first builds the bottom-up layers  by the feedforward computation of backbone ConvNet. Then, FPN constructs each top-down feature maps by element-wised adding the top-down feature maps of the last pyramid level with the bottom-up feature maps of the same pyramid level, which is shown in t <figure>Figure 2</figure> (left). The set of pyramidal feature maps built by FPN is . </p>

<p>Despite such a careful design for generating refined merged feature maps for different levels, it is not strong enough for the information of spatial and channel features to different scaled objects. We hypothesize that both spatial-wise and channel-wise recalibrating merged feature maps can encourage current pyramid layer detection. Hence, we propose FWM to enhance the pyramid feature. The structure of FWM is shown in <figure>Figure 2</figure> (right). </p>

<p>FWM starts by modeling the feature dependency of the feature maps in each pyramid level, and further learns the feature importance vector to recalibrate the feature maps to emphasize the useful features. Specially, FWM in each pyramid level is in the same structure but has different learnable weights, which results in different calculated feature weights. Each FWM consists of three sub-modules: Feature Channel Weight Module (FCWM), Feature Spatial Weight Module (FSWM) and Feature Channel Spatial Weight Module (FCSWM). FCWM and FSWM calculate the feature importance vector along channel and spatial location. FCSWM combines the recalibrated weighted feature maps after FCWM and FSWM as the new pyramidal feature maps. The detailed design of the three submodules are described in the following subsections. </p>

<head> 2.1.1. Feature Channel Weight Module (FCWM)</head>
<p>
FCWM focuses on enhancing features along channel of each pyramid level. FCWM first explicitly models the dependency of features along channel and learns a channel specific descriptor through the squeeze-and-excitation method. Then, it emphasizes the useful channels for more efficient global information expression of feature maps in each pyramid level. </p>

<p>Suppose the feature maps in <hi rend="italic">n</hi>th pyramid level is , which is generated by FPN.  and  are the spatial height and width of , respectively. The <hi rend="italic">i</hi>th channel feature is . </p>

<p>At the beginning, we do global average pooling on  to get the global distribution response :

(1)

</p>

<p>We use two fully connected layers to map the non-linear correlation between all global distribution responses  and obtain the feature importance vectors :

(2)

where  is the weight of the first fully connected layer.  is the weight of the second fully connected layer.  represents the ReLU function. </p>

<p>Then, we normalize  to  as a weight vector:

(3)

where  represents Sigmoid function. </p>

<p>Finally, we assign the weight  to the original feature  and get the new pyramid feature  after channel-wised recalibration:

(4)

</p>

<head> 2.1.2. Feature Spatial Weight Module (FSWM)</head>
<p>
Similar to the design of FCWM, FSWM enhances the features along spatial location of each pyramid level, which emphasizes the effective pixels and depresses the ineffective or low-effect pixels. </p>

<p>We define  as the clipping of all channel features at each feature point  of . First, we integrate all the features of each point through a convolution operation to get the spatial importance vector :

(5)

where  is the convolution kernel weight. </p>

<p>Then, we normalize  to  as a weight vector

(6)

where  represents Sigmoid function. </p>

<p>Finally, the normalized weights are spatially weighted to each pixel to get the new feature :

(7)

</p>

<head> 2.1.3. Feature Channel Spatial Weight Module (FCSWM)</head>
<p>
FCSWM combines the channel-wised weighted  obtained by FCWM and the spatially weighted  obtained by FSWM to generate a new recalibrated feature . The combination operation is implemented by addition:

(8)

</p>

<p> encourages original feature maps to be both spatial-wise and channel-wise more informative. In EFPN, we replace the initial feature pyramid features  by the recalibrated enhanced pyramid features  as the input feature of proposal extraction subnet and detection subnet. </p>
</text>
