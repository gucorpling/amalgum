<text id="autogum_academic_doc575" title="Integrated Robotic and Network Simulation Method" shortTile="integrated-robotic" author="Daniel Ramos, Luis Almeida, Ubirajara Moreno" type="academic" dateCollected="2019-11-03" sourceURL="https://www.mdpi.com/1424-8220/19/20/4585/htm" speakerList="none" speakerCount="0">
<head> 3. IRoNS Method</head>
<p>The proposed method uses a workflow structure to guide the study simulation development, dividing the study in three development stages: Problem definition, simulation framework, and experimentation. The last two stages can be further divided following a ‘plan, execute and assess’ methodology, which leads to a final 10-steps procedure that is briefly described below (<figure>Figure 1</figure>).
<list>
<item><b>Problem Formulation (1):</b> The first part of the method is to state and define what kind of problem is going to be the object of study. In general, this initial part derives from an initial study or a demand that urges for a complex simulation for validation.</item>
<item><b>Choosing Solutions (2):</b> After defining the problem, it is necessary to choose the techniques that allow solving the problem, i.e., techniques that will be simulated to emulate and assess the situation referred in the problem study. It is important to note that the IRoNS Method does not depend on any specific robotic or network techniques.</item>
<item><b>System—Specifying (Initial Documentation) (3):</b> Consists in organizing all the information decided so far, describing the concepts behind the chosen techniques and giving a special attention to creating an assumptions document, which should be updated during the entire development cycle.</item>
<item><b>Base Simulation—Planning (4):</b> The next step consists in planning the simulation framework (Base Simulation—BS), which is also referred to as conceptual and communicative modelling. This modelling includes documentation procedures with different objectives: firstly as a visual documentation to guide simulation implementation and secondly as textual documentation for study reproducibility. The idea is to gather all necessary information about the simulation study and framework before starting the implementation, including the system structure, expected interactions, simulator selection, desirable simulation characteristics, initial parameters values, and any other related information. The main documented topics are described in Section 3.1.</item>
<item><b>Base Simulation—Implementing (5):</b> after the documentation, the focus now is implementing the simulation. In this case, we opted to continue extending a network simulator simulation with cooperative robotics features, as shown in. The OMNeT++/INET network simulator was selected for its modularity, graphical interface, community support, and easy code debug. Moreover, we did not observe significant performance differences between network simulators that could justify using another simulator.</item>
<item><b>Base Simulation—Validating (6):</b> The resulting simulation, as referred a priori, is a candidate base simulation until it passes through a validation process, which verifies whether it keeps the main characteristics of a real system or of the original simulation. This part uses Verification, Validation, and Test (VV&amp;T) techniques, integrated with statistical analysis with confidence interval, which is further detailed in Section 3.2.</item>
<item><b>Case-Study—Experimentation Design (Planning) (7):</b> Once the candidate simulation passes the validation process, it becomes a Base Simulation that is ready for experimentation. However, it is necessary to plan case studies to make sure they are aligned with the objectives defined in the first step of the method, thus requiring an experimentation design. A suggestion of experimental design is presented in Section 3.3.</item>
<item><b>Case-Study—Experimenting (8):</b> This step consists in implementing the planned studies, executing simulations and gathering experimental results. The main concern, here, is to enforce experimental rigor to avoid collecting incorrect data or producing incorrect behaviors.</item>
<item><b>Case-Study—Data Analysis (9):</b> Once data is collected, it must be analyzed and converted from raw into useful information, also presenting it in an adequate form. Structuring these results as defined in the experimentation design allows using statistical analysis with confidence intervals to assess their significance. Detailed execution of this item for this type of simulation presented in Section 3.4 is the main contribution of this paper as the use of confidence intervals integrated with experimental design contribute to better results presentation and validation.</item>
<item><b>Conclusion (10):</b> The last step is to check if the obtained results are enough to satisfy the study objectives, answering the problem study. If results are deemed not good enough, the method cycle should be iterated.</item>
</list>
</p>

<p>The main objective of this method is to provide a systematic tool to develop a simulation study in sequential steps, considering the particularities of this type of simulation, i.e., the cross-domain complexity. Our main contribution lies in integrating techniques in four critical points, namely for simulation planning, base simulation validation, case-study experimentation, and result analysis, which we describe in the following subsections. An example use-case is presented in the next section. </p>

<head> 3.1. Base Simulation—Planning</head>
<p>Due to its impact in the entire process, we consider this step a critical point, consisting in preparing information to simplify simulation implementation and improve simulation reproducibility, a step also known as conceptual and communicative modelling. </p>

<p>This type of modelling is usually simple and easy to use, but its complexity may grow quickly in the following three situations: (1) If there are several developers working in the same implementation; (2) when simulation is complex and involves several views; and (3) in the case of poor team knowledge on the simulation topics. For integrated robotics and communication simulations, all three cases may be true, requiring more details and explanations in the conceptual model. In practice, this implies a large and detailed documentation process that, yet, can be too complex to be used as guide in implementation or too simple to help others understand the simulation topics. </p>
</text>
