<text id="autogum_academic_doc599" title="Artificial Intelligence for Automatic Measurement of Sagittal Vertical Axis Using ResUNet Framework" shortTile="artificial-intelligence" author="Chi-Hung Weng, Chih-Li Wang, Yu-Jui Huang, Yu-Cheng Yeh, Chen-Ju Fu, Chao-Yuan Yeh, Tsung-Ting Tsai" type="academic" dateCollected="2019-11-03" sourceURL="https://www.mdpi.com/2077-0383/8/11/1826/htm" speakerList="none" speakerCount="0">
<head> 1. Introduction</head>
<p>
Adult spinal deformity (ASD) is a broad diagnosis referring to stable asymptomatic curves and disabling deformities in the spine that contribute to pain, weakness, and low health-related quality of life (HRQOL). Although ASD is quite common, the variation and unique pattern of each spinal deformity make reproducible measurement difficult. Previous studies investigating the correlation between radiographic appearances and clinical symptoms yielded rather low predictive power due to highly variable health status. Little correlation between radiographic assessment and questionnaire scores was found for adolescent idiopathic scoliosis. However, in 2005, Glassman et al. showed that sagittal plane balance is the most reliable predictor of clinical symptoms in adults with spinal deformity. Even mild positive sagittal balance results in destructive spinal deformity, clinical symptoms of which deteriorate linearly. Therefore, a surgical plan for restoring sagittal balance is crucial in all spinal reconstructive surgeries.  </p>

<p>Parameters to describe the sagittal alignment of the spine include the sagittal vertical axis (SVA), thoracic kyphosis, lumbar lordosis, pelvic incidence, pelvic tilt, and sacral slope. SVA, which is the most commonly used measure of the sagittal plane, is obtained from standing lateral radiographs and is defined as the horizontal distance between two landmarks: the center of C7 vertebral body and the posterior superior aspect of the S1 vertebral body. According to Schwab’s classification based on Jean Dubousset‘s cone of economy, the realignment of the spine should aim to meet the criteria of SVA &lt; 50 mm to alleviate sensations of falling over. Consequently, formulating a patient-specific surgical plan requires SVA measurement both preoperatively and postoperatively, using whole-spine lateral radiographs. However, manual SVA estimation on radiographs is rather inconvenient due to lack of easy-to-use tools. To solve this issue, we propose using deep-learning models for fully automatic estimation of SVA. </p>

<p>A well-known family of deep-learning models is the convolutional neural networks (CNNs). CNNs have drawn considerable attention since 2012, as they were found to outperform traditional image processing algorithms on image classification tasks. Since then, CNNs have been increasingly used for medical image analysis. A CNN is primarily made of stacked convolution layers, which can be regarded as a series of learnable feature extractors designed for acquiring low-to-high-level features of an image. In general, basic image features, such as blob of colors or edges of different orientations, are learnable by the shallow convolution layers. On the other hand, complex image features, such as appearances of objects, are learnable by the deep convolution layers. Therefore, well-trained convolution layers can be used to extract informative features that are useful for landmark localization or other specific tasks. </p>

<p>Automatic SVA estimation can generally be regarded as the task of landmark localization, as SVA was defined as the horizontal difference between two anatomical landmarks. In this study, we investigated the performance of ResUNet for automatic vertebrae localization on radiographs. ResUNet is a variant of CNN. Its UNet-like structure combines the contextual information produced by deep layers and better location information produced by shallow layers, allowing better utilization of low- and high-level features. In addition, the encapsulated residual blocks of ResUNet enable better flow of information and can avoid performance deterioration as the network goes deeper. ResUNet has been used for cell segmentation from biomedical images and road extraction from satellite images. To the best of our knowledge, our study is the first to utilize ResUNet for anatomical landmark localization.  </p>

<p>Some previous works use CNN for vertebrae segmentation or localization. For example, for 3D CT and MR images, Lessmann et al. used a 3D UNet-like model for vertebrae segmentation. In addition, Wimmer et al. used 3D CNN for vertebrae localization. There were also studies on radiographs: for biplanar radiographs, including A-P and lateral view, Gallbusera et al. used a database collected using the EOS™ imaging system and trained CNN models for each of the landmarks. For lateral spine radiographs, Al Arif et al. applied a UNet model for the localization of cervical vertebral centers.  </p>

<p>In this study, we applied ResUNet on plain lateral spine radiographs. Although our algorithm is similar to the one in, there are some major differences. First, we did not split images into patches, as patching leads to extra pre- and post-processing steps, and the correlation between landmarks of different patches will be ignored completely. However, if patching was not performed, the large image size would lead to insufficient amount of RAM on GPU. To alleviate this issue, we used a small batch size (batch size = 2) and replaced the widely used batch normalization with the group normalization in our network. Group normalization is known to perform well even when the batch size is small, as it does not perform normalization along the batch axis. Secondly, we let probability maps of landmarks to be predicted separately. Thus, predictions were not on the same map and further post-processing steps involving separation and identification of the landmarks can be eliminated. </p>
</text>
