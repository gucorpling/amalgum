<?xml version="1.0" ?>
<text author="Hua Wang, Xiaoyu He, Mingge Pan" dateCollected="2019-11-03" id="autogum_academic_doc278" shortTile="interactive-personalized" sourceURL="https://www.mdpi.com/2076-3417/9/20/4426/htm" speakerCount="0" speakerList="none" title="An Interactive and Personalized Erasure Animation System for a Large Group of Participants" type="academic">
<head>
<s>
1
.
</s>
<s>
Introduction
</s>
</head>
<p>
<s>
With
the
rapid
development
of
virtual
reality
technology
,
mixed
reality
technology
,
and
human
–
computer
interaction
technology
,
an
increasing
number
of
businesses
are
working
from
various
angles
to
realize
erasure
animations
in
mixed
reality
so
that
their
users
’
participations
can
be
improved
.
</s>
<s>
Some
examples
are
Fruit
Ninja
and
The
Swords
.
</s>
<s>
In
these
systems
,
limits
exist
in
the
number
of
face-to-face
participants
and
the
unnatural
interactive
devices
.
</s>
<s>
How
to
realize
rich
somatosensory
interactive
erasure
animations
for
a
large
group
of
face-to-face
participants
by
some
popular
interactive
devices
has
great
influence
on
the
participations
.
</s>
</p>
<p>
<s>
The
technologies
of
image
matting
and
interactive
erasing
are
working
to
develop
users
’
participations
in
erasure
animations
.
</s>
<s>
Existing
image
matting
methods
are
mainly
used
for
two-dimensional
(
2D
)
scenes
and
their
mask
images
and
background
images
are
all
2D
data
.
</s>
<s>
They
do
not
support
customizations
of
three-dimensional
(
3D
)
scenes
.
</s>
<s>
Some
3D
simulation
software
systems
,
such
as
Unity3D
and
Unreal
Engine
4
,
use
their
powerful
shader
functions
to
perform
texture
transparency
blending
on
the
image
which
contains
the
information
of
erasure
shapes
and
background
scenes
,
and
thus
reveal
the
scenes
.
</s>
<s>
The
erasure
can
be
performed
in
every
position
.
</s>
<s>
However
,
the
visualization
of
multiple
erasure
actions
simultaneously
requires
to
create
and
load
multiple
shaders
,
which
is
very
time-consuming
.
</s>
<s>
Therefore
,
they
are
not
suitable
for
a
larger
number
of
participants
.
</s>
<s>
In
the
field
of
interactive
erasing
technology
,
some
sensor-based
,
and
vision-based
gesture
recognition
methods
are
used
for
interactions
,
for
example
,
virtual
reality
glasses
,
Kinect
,
cameras
.
</s>
<s>
Some
of
them
are
not
easy
in
implementation
and
some
of
them
suffer
from
serious
occlusion
of
a
larger
number
participants
.
</s>
</p>
<p>
<s>
To
tackle
the
aforementioned
challenges
,
we
design
a
system
to
realize
interactive
and
personalized
erasure
animations
by
using
mobile
terminals
,
a
shared
display
terminal
and
a
database
server
.
</s>
<s>
The
system
is
implemented
by
a
data
preprocessing
module
and
an
interactive
erasure
animation
module
(
</s>
<figure>
<s>
Figure
1
</s>
</figure>
<s>
)
.
</s>
<s>
The
data
preprocessing
module
is
mainly
responsible
for
preprocessing
the
input
erasure
shape
data
,
including
cleaning
the
personalized
shape
data
and
semantic
standardizations
.
</s>
<s>
The
interactive
erasure
animation
module
consists
of
three
parts
:
shaking
mobile
terminals
,
visualization
of
the
erasure
animations
in
the
shared
display
terminal
,
and
dynamic
and
personalized
data
editing
in
the
database
server
.
</s>
<s>
In
our
system
,
users
shake
their
mobile
terminals
continuously
and
simultaneously
with
their
hands
,
and
their
valid
shaking
data
are
captured
and
saved
in
the
database
server
.
</s>
<s>
Then
the
shared
display
terminal
accesses
the
database
server
and
shows
visualizations
of
real-time
erasure
animations
according
to
the
data
.
</s>
<s>
Note
that
the
system
can
only
show
a
continuous
animation
for
many
shakings
:
one
valid
shaking
occurs
when
a
user
shakes
his
mobile
terminal
,
then
the
shared
display
shows
an
erasure
shape
;
another
valid
shaking
occurs
when
another
user
shakes
his
mobile
terminal
,
then
the
shared
display
shows
two
erasure
shapes
;
more
valid
shakings
occur
and
then
the
shared
display
shows
more
erasure
shapes
.
</s>
</p>
<p>
<s>
The
main
contributions
of
our
system
are
as
follows
:
</s>
<list>
<item>
<s>
We
introduce
a
novel
interactive
erasure
animation
system
based
on
a
shared
display
terminal
and
mobile
terminals
(
mobile
phone/tablet
computer
)
,
the
implementation
of
which
is
very
easy
for
a
larger
number
of
participants
.
</s>
</item>
<item>
<s>
In
our
system
,
the
shared
display
terminal
can
respond
to
a
larger
number
of
shaking
actions
from
participants
in
real
time
and
show
an
immersive
and
somatosensory
erasure
animation
,
the
erasure
shapes
which
are
highly
consistent
with
the
participants
’
shaking
actions
(
position
,
travel
distance
,
angle
,
etc.
)
.
</s>
</item>
<item>
<s>
Our
system
supports
real-time
personalized
erasure
animations
.
</s>
<s>
The
erasure
shape
,
mask
data
,
scene
data
,
and
so
on
can
be
customized
on
our
backend
management
platform
.
</s>
<s>
The
scale
,
rotation
,
and
translation
of
each
shape
are
personalized
and
determined
by
the
corresponding
shaking
action
.
</s>
</item>
</list>
</p>
</text>
