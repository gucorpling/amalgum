<?xml version="1.0" ?><text author="Tao Liu, Hao Liu, Yingying Wu, Bo Yin, Zhiqiang Wei" dateCollected="2019-11-03" id="autogum_academic_doc548" shortTile="exposure-bracketing" sourceURL="https://www.mdpi.com/2076-3417/9/21/4529/htm" speakerCount="0" speakerList="none" title="Exposure Bracketing Techniques for Camera Document Image Enhancement" type="academic">
<head>
3
.
HDR
Document
Image
Generation
</head>
<head>
3.1
.
Document
Image
Registration
</head>
<p>
The
image
registration
problem
has
been
intensively
studied
in
remote
sensing
images
,
medical
images
,
and
camera
images
and
very
rarely
,
research
can
be
found
for
document
image
registration
.
The
most
popular
registration
in
the
context
of
exposure
bracketing
is
from
,
where
a
translational
geometric
model
was
employed
to
account
for
the
geometric
disparity
between
two
images
.
However
,
we
found
that
the
translational
model
is
not
suitable
for
general
camera
document
images
.
</p>
<p>
<figure>
Figure
4
</figure>
shows
two
pseudo
color
image
patches
that
are
composed
of
two
LDR
images
that
are
already
illustrated
in
<figure>
Figure
1
</figure>
.
The
green
band
and
blue
band
come
from
the
corresponding
bands
in
the
well-exposed
image
while
the
red
band
is
from
the
corresponding
band
in
the
over-exposed
image
.
If
there
are
no
geometric
disparities
between
these
two
images
,
the
foreground
(
textual
part
)
of
the
image
should
overlap
.
In
<figure>
Figure
4
</figure>
,
we
can
clearly
see
that
geometric
difference
exists
as
the
foreground
texts
do
not
overlap
.
On
top
of
it
,
we
can
clearly
see
that
the
global
translational
model
cannot
account
for
the
geometric
disparity
between
these
two
images
.
For
example
,
<figure>
Figure
4
</figure>
a
is
the
left
central
image
patch
and
we
can
see
that
the
geometric
difference
between
the
well-exposed
image
and
over-exposed
image
in
this
region
is
around
10
pixels
(
half
the
size
of
the
lowercase
letter
“
a
”
)
in
the
vertical
direction
.
However
,
in
<figure>
Figure
4
</figure>
b
,
the
right
central
image
patch
,
we
can
see
that
the
geometric
difference
between
the
well-exposed
image
and
over-exposed
image
in
this
region
is
around
20
pixels
(
the
size
of
the
lowercase
letter
“
a
”
)
in
the
vertical
direction
.
This
is
obvious
evidence
that
the
geometric
disparity
between
LDR
images
cannot
be
translational
and
that
it
must
follow
a
more
complicated
geometric
model
.
</p>
<p>
Among
all
the
geometric
models
,
such
as
the
affine
model
,
translational
model
,
rotation
model
,
and
so
on
,
we
ended
up
selecting
the
planar
homograph
model
to
represent
the
geometric
disparity
between
LDR
images
.
Under
this
model
,
points
in
two
different
images
can
be
mapped
as
:
(
1
)
where
points
are
represented
by
homogeneous
coordinates
and
so
point
(
<hi rend="italic">
x
</hi>
,
<hi rend="italic">
y
</hi>
,
<hi rend="italic">
z
</hi>
)
is
the
same
as
(
<hi rend="italic">
x
</hi>
/
<hi rend="italic">
z
</hi>
,
<hi rend="italic">
y
</hi>
/
<hi rend="italic">
z
</hi>
)
in
the
inhomogeneous
coordinate
.
We
selected
this
model
because
during
the
bracketing
stage
,
hand-shake
is
inevitably
introduced
,
leading
to
different
imaging
angles
for
the
same
document
object
,
and
the
planar
homograph
model
is
suitable
for
the
situation
where
the
imaging
object
is
put
on
a
planar
surface
and
is
captured
from
different
view-angles
.
</p>
<p>
When
the
planar
homograph
model
is
selected
,
we
have
to
estimate
this
model
’s
eight
parameters
.
Basically
,
there
are
two
methods
.
The
first
method
is
called
the
area-based
method
.
Using
this
method
to
estimate
the
planar
homograph
model
involves
two
steps
:
in
the
first
step
,
a
moving
window
is
defined
in
the
reference
image
and
the
image
patch
within
the
window
is
regarded
as
the
template
.
We
used
the
template
to
search
for
a
corresponding
image
patch
in
the
sensed
image
(
an
image
that
was
registered
)
.
The
centers
of
matched
image
templates
are
used
as
control
points
(
CPs
)
.
There
are
many
ways
of
finding
a
matching
template
,
and
one
of
the
most
popular
criteria
is
cross
correlation
.
When
multiple
CPs
are
generated
,
we
then
use
these
CPs
to
estimate
the
planar
homograph
model
.
Area-based
methods
,
however
,
are
not
employed
due
to
two
reasons
:
(
1
)
the
first
reason
is
that
this
method
is
computationally
heavy
as
it
performs
cross
correlation
on
multiple
image
patches
and
(
2
)
the
second
reason
is
that
image
patches
under
different
exposure
levels
may
display
extremely
different
characteristics
,
which
may
fail
cross
the
correlation
method
.
</p>
<p>
The
second
method
to
estimate
the
planar
homograph
transformation
is
called
the
feature-based
method
.
Two
critical
steps
in
feature-based
methods
are
feature
extraction
and
feature
matching
.
We
expect
that
the
extracted
features
will
be
consistent
regardless
of
exposure
levels
and
among
all
the
feature
extraction
methods
,
we
selected
the
Scale-invariant
Feature
Transform
(
SIFT
)
method
because
it
improves
detection
stability
in
situations
of
illumination
changes
.
In
the
meantime
,
it
achieves
almost
real-time
performance
and
the
features
that
are
detected
are
highly
distinctive
.
SIFT
does
not
only
define
the
position
of
detected
points
,
but
also
provides
a
description
of
the
region
around
the
feature
point
by
means
of
a
descriptor
,
which
is
then
used
to
match
SIFT
feature
points
.
Therefore
,
we
have
used
the
SIFT
method
to
find
CP
pairs
.
<figure>
Figure
5
</figure>
shows
the
extracted
matched
SIFT
features
for
two
LDR
images
.
</p>
</text>