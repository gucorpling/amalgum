<?xml version="1.0" ?><text author="Karol Nowakowski, Michal Ptaszynski, Fumito Masui, Yoshio Momouchi" dateCollected="2019-11-03" id="autogum_academic_doc254" shortTile="improving-basic-natural" sourceURL="https://www.mdpi.com/2078-2489/10/11/329/htm" speakerCount="0" speakerList="none" title="Improving Basic Natural Language Processing Tools for the Ainu Language" type="academic">
<head>
<s>
8
.
</s>
<s>
Results
and
Discussion
</s>
</head>
<head>
<s>
8.1
.
</s>
<s>
Transcription
Normalization
</s>
</head>
<p>
<s>
Table
11
shows
the
results
of
transcription
normalization
experiments
.
</s>
<s>
Transcription
normalization
based
on
Kirikae
’s
lexicon
achieved
the
highest
scores
for
the
Y9
–
13
dataset
,
which
is
not
surprising
,
since
the
dictionary
is
based
on
<hi rend="italic">
yukar
</hi>
epics
.
</s>
<s>
In
the
case
of
JK
samples
,
however
,
performance
with
the
combined
dictionary
(
JK+KK
)
was
as
good
as
with
the
JK
dictionary
only
.
</s>
<s>
Furthermore
,
the
combined
dictionary
achieved
the
best
overall
results
.
</s>
<s>
In
all
test
configurations
the
results
for
texts
with
original
word
segmentation
retained
were
slightly
better
.
</s>
<s>
Relatively
low
values
of
recall
for
normalization
in
JK
samples
,
observed
across
all
combinations
of
dictionaries
and
input
text
versions
,
can
be
explained
by
a
high
occurrence
of
forms
transcribed
according
to
non-standard
rules
modified
by
Bugaeva
et
al.
in
the
modernized
version
of
the
dictionary
,
but
not
included
in
the
list
of
universal
transcription
change
rules
applied
in
this
research
,
such
as
‘
ra’→‘r
’
(
e.
g.
,
<hi rend="italic">
arapa
</hi>
→
<hi rend="italic">
arpa
</hi>
)
,
‘
ri’→‘r
’
(
e.
g.
,
<hi rend="italic">
pirika
</hi>
→
<hi rend="italic">
pirka
</hi>
)
,
‘
ru’→‘r
’
(
e.
g.
,
<hi rend="italic">
kuru
</hi>
→
<hi rend="italic">
kur
</hi>
)
,
‘
ro’→‘r
’
(
e.
g.
,
<hi rend="italic">
koro
</hi>
→
<hi rend="italic">
kor
</hi>
)
or
‘
ei’→‘e
’
(
e.
g.
,
<hi rend="italic">
reihei
</hi>
→
<hi rend="italic">
rehe
</hi>
)
.
</s>
<s>
This
is
due
to
the
fact
that
these
rules
are
so
far
only
observed
in
the
dictionary
of
Jinbō
and
Kanazawa
and
more
importantly
,
initial
tests
performed
during
the
development
of
the
algorithm
showed
that
including
them
in
the
algorithm
can
cause
errors
when
processing
yukars
and
other
texts
.
</s>
</p>
<head>
<s>
8.2
.
</s>
<s>
Tokenization
</s>
</head>
<p>
<s>
The
results
of
tokenization
experiments
are
shown
in
Table
12
.
</s>
<s>
Table
13
shows
a
fragment
from
Y9
–
13
(
M-SR
)
before
and
after
segmentation
.
</s>
<s>
Similarly
to
transcription
normalization
,
the
tokenization
algorithm
also
performed
the
best
for
<hi rend="italic">
yukar
</hi>
stories
(
Y9
–
13
)
when
coupled
with
the
<hi rend="italic">
Ainu
shin-yōshū
jiten
</hi>
(
KK
)
.
</s>
<s>
Analogically
,
for
JK
samples
,
the
JK
dictionary
was
the
best
.
</s>
<s>
It
shows
a
weak
point
of
the
presented
segmentation
algorithm
:
while
adding
new
forms
to
the
lexicon
improves
its
versatility
(
ability
to
process
texts
from
different
domains
)
,
it
also
increases
the
number
of
possible
mistakes
the
tokenizer
can
make
with
texts
for
which
the
original
lexicon
had
been
(
nearly
)
optimal
.
</s>
<s>
The
combined
dictionary
performed
better
than
the
other
two
dictionaries
on
test
data
unrelated
to
the
training
data
(
Shib
.
and
Muk
.
)
,
and
also
achieved
the
best
overall
results
(
F-score
)
.
</s>
<s>
On
the
other
hand
,
overall
recall
was
higher
with
the
KK
dictionary
.
</s>
<s>
To
some
extent
this
might
be
explained
by
the
differences
in
word
segmentation
between
the
two
dictionaries
applied
in
this
research
:
many
expressions
(
e.
g.
,
<hi rend="italic">
oro
wa
</hi>
,
’
from
’
or
<hi rend="italic">
pet
turasi
</hi>
,
’
to
go
upstream
’
)
written
as
two
separate
segments
by
Kirikae
(
both
in
the
lexicon
part
of
the
<hi rend="italic">
Ainu
shin-yōshū
jiten
</hi>
,
as
well
as
in
his
modernized
transcriptions
of
the
<hi rend="italic">
yukar
</hi>
stories
,
which
we
use
as
the
gold
standard
data
)
,
are
transcribed
as
a
single
unit
(
<hi rend="italic">
orowa
</hi>
,
<hi rend="italic">
petturasi
</hi>
)
by
Bugaeva
et
al.
Once
these
forms
are
added
to
the
lexicon
,
the
word
segmentation
algorithm
,
which
prefers
long
tokens
over
shorter
ones
,
stops
applying
segmentation
to
the
tokens
<hi rend="italic">
orowa
</hi>
and
<hi rend="italic">
petturasi
</hi>
(
and
that
causes
recall
to
drop
)
.
</s>
<s>
This
phenomenon
occurs
in
the
opposite
direction
as
well
:
</s>
<s>
The
only
two
types
of
tokenization
errors
made
in
the
JK
samples
(
O/M
)
when
the
combined
dictionary
was
used
,
but
not
with
the
JK
dictionary
,
were
both
of
this
type
—
the
expressions
transcribed
by
Bugaeva
et
al.
as
<hi rend="italic">
somo
ki
</hi>
(
’
do
not
’
)
and
<hi rend="italic">
te
ta
</hi>
(
’
here
’
)
are
listed
as
<hi rend="italic">
somoki
</hi>
and
<hi rend="italic">
teta
</hi>
in
the
<hi rend="italic">
Ainu
shin-yōshū
jiten
</hi>
.
</s>
<s>
Scores
achieved
by
the
tokenizer
on
texts
with
original
word
boundaries
retained
(
Y9
–
13
(
O/M
)
and
JK
samples
(
O/M
)
)
were
higher
than
with
spaces
removed
.
</s>
<s>
This
means
that
the
original
word
segmentation
,
even
if
it
causes
some
errors
(
as
with
the
word
<hi rend="italic">
tuyka
</hi>
—
see
Section
6.2
)
,
still
supports
tokenization
rather
than
hindering
it
.
</s>
</p>
</text>