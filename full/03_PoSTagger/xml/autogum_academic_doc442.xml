<?xml version="1.0" ?><text author="Junghee Jo, Kang-Woo Lee" dateCollected="2019-11-03" id="autogum_academic_doc442" shortTile="mapreducebased-delt" sourceURL="https://www.mdpi.com/2220-9964/8/11/475/htm" speakerCount="0" speakerList="none" title="MapReduce-Based D_ELT Framework to Address the Challenges of Geospatial Big Data" type="academic">
<head>
<s>
1
.
</s>
<s>
Introduction
</s>
</head>
<p>
<s>
In
recent
years
,
numerous
types
of
sensors
have
been
connected
to
the
Internet
of
Things
(
IoT
)
and
have
produced
huge
volumes
of
data
with
high
velocity
.
</s>
<s>
A
large
percentage
of
these
sensor
big
data
is
geospatial
data
,
describing
information
about
physical
things
in
relation
to
geographic
space
that
can
be
represented
in
a
coordinate
system
.
</s>
<s>
With
the
advance
of
IoT
technologies
,
more
diverse
data
have
now
become
available
,
thereby
greatly
increasing
the
amount
of
geospatial
big
data
.
</s>
</p>
<p>
<s>
Given
the
general
properties
of
big
data
,
the
unique
characteristics
of
geospatial
data
create
an
innovative
challenge
in
data
preparation
.
</s>
<s>
Geospatial
data
typically
include
position
data
.
</s>
<s>
These
coordinate
data
differ
from
normal
string
or
integer
data
,
requiring
the
data
pre-processing
process
to
include
a
lot
of
floating-point
arithmetic
computations
.
</s>
<s>
Examples
include
transformation
in
geometry
,
converting
coordination
reference
systems
,
and
evaluating
spatial
relationships
.
</s>
<s>
Among
these
,
the
most
well-known
aspect
of
geospatial
data
is
spatial
relationship
,
describing
the
relationship
of
some
objects
in
a
specific
location
to
other
objects
in
neighboring
locations
.
</s>
<s>
The
calculation
of
spatial
relationship
is
mostly
included
in
spatial
analysis
and
has
been
generally
regarded
as
a
sophisticated
problem
.
</s>
<s>
Moreover
,
processing
temporal
elements
also
complicates
the
handling
of
geospatial
data
.
</s>
</p>
<p>
<s>
To
deal
with
the
challenges
in
processing
and
analyzing
geospatial
big
data
,
several
systems
have
emerged
.
</s>
<s>
Systems
designed
for
big
data
have
existed
for
years
(
e.
g.
,
Hadoop
and
Spark
)
;
however
,
they
are
uninformed
about
spatial
properties
.
</s>
<s>
This
has
led
to
a
number
of
geospatial
systems
(
e.
g.
,
SpatialHadoop
and
GeoSpark
)
being
developed
,
mostly
by
injecting
spatial
data
types
or
functions
inside
existing
big
data
systems
.
</s>
<s>
Hadoop
,
especially
,
has
proven
to
be
a
mature
big
data
platform
and
so
several
geospatial
big
data
systems
have
been
constructed
by
inserting
spatial
data
awareness
into
Hadoop
.
</s>
<s>
However
,
it
is
still
not
easy
for
big
data
software
developers
to
create
geospatial
applications
.
</s>
<s>
Typically
,
to
generate
a
MapReduce
job
for
a
required
operation
in
Hadoop
,
developers
need
to
program
a
map
and
reduce
functions
.
</s>
<s>
Spatial
analysis
usually
requires
handling
more
than
one
MapReduce
step
,
where
the
output
of
the
data
from
a
previous
MapReduce
step
becomes
the
input
to
the
next
MapReduce
step
.
</s>
<s>
As
the
complexity
level
of
spatial
analysis
is
increased
,
the
number
of
MapReduce
steps
is
also
increased
,
resulting
in
augmented
difficulties
for
the
developers
to
write
iterative
code
to
define
the
increasingly
more
complicated
MapReduce
steps
.
</s>
</p>
<p>
<s>
To
resolve
this
issue
,
in
our
previous
work
,
we
found
a
way
to
represent
spatial
analysis
as
a
sequence
of
one
or
more
units
of
spatial
or
non-spatial
operators
.
</s>
<s>
This
allows
developers
of
geospatial
big
data
applications
to
create
spatial
applications
by
simply
combining
built-in
spatial
or
non-spatial
operators
,
without
having
any
detailed
knowledge
of
MapReduce
.
</s>
<s>
Once
the
sequence
of
operators
has
been
incorporated
,
it
is
automatically
transformed
to
the
map
and
reduces
jobs
in
our
Hadoop-based
geospatial
big
data
system
.
</s>
<s>
During
this
conversion
process
,
our
system
controls
the
number
of
MapReduce
steps
in
such
a
way
as
to
achieve
better
performance
by
decreasing
the
overhead
of
mapping
and
reducing
.
</s>
<s>
The
challenges
for
geospatial
big
data
,
however
,
lie
in
confronting
not
only
how
to
store
and
analyze
the
data
,
but
also
how
to
transform
the
data
while
achieving
good
performance
.
</s>
</p>
<p>
<s>
Currently
,
a
large
amount
of
geospatial
data
is
continuously
provided
from
many
spatial
sensors
.
</s>
<s>
It
is
important
to
analyze
this
geospatial
big
data
as
soon
as
possible
to
extract
useful
insights
.
</s>
<s>
However
,
the
time
required
to
transform
massive
amounts
of
geospatial
data
into
the
Hadoop
platform
has
gradually
increased
.
</s>
<s>
That
is
,
it
takes
a
lot
of
time
to
prepare
the
data
required
for
geospatial
analysis
,
thereby
delaying
obtaining
the
results
of
spatial
analysis
results
.
</s>
<s>
For
example
,
we
found
that
it
took
about
13
hours
and
30
minutes
to
load
821
GB
of
digital
tachograph
(
DTG
)
data
using
the
traditional
ETL
method
.
</s>
<s>
In
the
ETL
process
,
data
are
extracted
from
data
sources
,
then
transformed
,
involving
normalization
and
cleansing
,
and
loaded
into
the
target
data
base
.
</s>
<s>
The
conventional
ETL
system
is
typically
operated
on
a
single
machine
that
cannot
effectively
handle
huge
volumes
of
big
data
.
</s>
<s>
To
deal
with
the
considerable
quantity
of
big
data
in
the
ETL
process
,
there
have
been
several
attempts
in
recent
years
to
utilize
a
parallelized
data
processing
concept
.
</s>
</p>
</text>